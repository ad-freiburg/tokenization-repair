Nigel (Mann, 1983) is a fourth system that makes use of functional information and is based on systemic grammar (Hudson, 1974). A systemic grammar contains choice points that query the environment to decide between alternatives (the environment may include functional, discourse, semantic, or contextual information). Mann's emphasis, so far, has been on the development of the system, on the development of a large linguistically justified grammar, and on the influence of underlying semantics on choices. The influence of functional information on syntactic hoice as well as the generation of complex propositions are issues he has not yet addressed within the systemic grammar framework.
Correct Incorrect Accuracy
Overall Polysemous
Abstract English
While the length of a phrase is fairly equal between VMand CH, the number of phrases (and, thus, words) persentence is higher for VM. Neither casual nor formal ad-dressing are present in the TABA corpus (talking to amachine) while the VM setting (negotiation of businessappointments) evokes formal speech. The CH dialoguesare mostly between family members and close friends(Linguistic Data Consortium, 1997), and casual address-ings are frequent. Variations in the number of commonwords can be related to the list of common words used,which was based on the VM corpus. The larger num-ber of different words per speaker in the TABA corpusresults from less words per speaker with less chance forrepetition. Average word length and density are similarin all three corpora.
Similarly, the CONTRAST relation that holds between the two spans \[1,2\] and \[3,4\] in text (4) can be explained in terms of a CONTRAST relation that holds between units 1 and 3, the most important units in spans \[1,2\] and \[3,4\], respectively.
In the first, the phrase "in bytes" modifies "specify", and "of the word" modifies "the length". In the second, "on Sunday" modifies "saw" and "with a wooden leg" modifies "a man". Stucky \[1987\] argues that such examples are acceptable and quite frequent.
The other class, which constituted just over half of our sample, forms part of a larger intonational phrase and is either deaccented or uttered with a L* accent. Both classes share the property of appearing in initial intona-tional phrase position.
Switchboard test.
Figure 3 . The boys whd study ge t good grades B. Junc t ion Grammar Representa t ions of the Same Sentences We now d i s c u s s how J u n c t i o n Grammar represents t h e above d i s t i n c t i o n s i n its r e p r e s e n t a t i o n s . If the r e a d e r i s n o t as y e t familiar with Junc t ion Grammar, it might be a d v i s a b l e t o consu l t Apperidix A before roeading this s e c t i o n . A s i n d i c a t e d therein, some recent refinements of Junc t ion Grammar are not y e t available i n published form. W e therefore b r i e f l y discuss two of them here. One i s the specLa l i za t ions of subjunction i n J-trees, and t h e o t h e r i s the e x p l i c i t r e p r e s e n t a t i o n of modal izers .
VALUE IN
An SBA is successful iff a syntactic subtree can be attached to the OSS as described above.
L3: the; DET, -~ , (1" SPEC) = DEF
Anaphora resolution 76% 88% 81%
Figure 4 A schema method overview new schemata are described (4.4) (4.5). F inal ly error- correction is i l lustrated (4.6).
We really have two problems: inferring from early experiences a set of structural primitives at an appro-priate descriptive level and learning the semantics to associate with these structural primitives. In this paper we shall only address the first problem. Even though we will not address the semantics attachment task, we will describe a method that yields the minimal structural units with which we will want to associate semantics. We feel that since the inferred structural primitives will be appropriate for describing a par- titular environment, they will have appropriate seman-tics and that unlike pro-defined primitives, these learned primitives are guaranteed to be at the appro-priate level for a given descriptive task. Identify-ing the structural primitives is the first step (prob-ably a parallel step) in identifylng semantic primi-tives, which are composed of structural units and associated procedures that 81ve the structures meaning.
Stage 3: create a sentence boundary when the combined clause reaches pre-determined thresholds.
The o f f i c i a l language and medium of ins t ruc t ion is Englfsh. However, the medium of da i ly communication ranges from a type of Creole-English t o a modifed var ie ty of Internat ional ly Acceptable English ( I A E ) . The term 'post- creole d ia l ec t continuum" has been used by severa l researchers, notably Le Page (1957), De Camp (1971) and Bickerton (1973) t o r e f e r to apparently analagous s i tua t ions i n Jamaica and Guyana. In addition t o Creole, English and var ian ts of both, a large p a r t of t h e population i s exposed t o a loca l var ie ty of Hindi (Bho jpuri) . Smaller numbers a re exposed t o Lesser Antillean French Creole and fewer s t i l l t o Spanish.
Redmond WA 98052 USA
Se io vedi, saluta Giovanni
This bibl iography was machine processed after all input was subjected to human analys is .
Manua l feedback: an English sentence based on reading 5-10 relevant documents only (by some-one who doesn't know the topic statement).
New York , NY 10012
TEXTRACT is a robust document analysis framework, whose design has been motivated by the requirements of an operational system capable of efficient processing of thousands of documents/gigabytes of data. It has been engineered for flexible configuration in implementing a broad range of document analysis and linguistic proc-essing tasks. The common architecture features it shares with TAF include: ? interchangeable document parsers allow the ?in-gestion? of source documents in more than one format (specifically, XML, HTML, ASCII, as well as a range of proprietary ones); ? a document model provides an abstraction layer between the character-based document stream and annotation-based document components, both structurally derived (such as paragraphs and sections) and linguistically discovered (such as named entities, terms, or phrases); ? linguistic analysis functionalities are provided via tightly coupled individual plugin compo-nents; these share the annotation repository, lexi-cal cache, and vocabulary and communicate with each other by posting results to, and reading prior analyses from, them; ? plugins share a common interface, and are dis-patched by a plugin manager according to de-clared dependencies among plugins; a resource manager controls shared resources such as lexi-cons, glossaries, or gazetteers; and at a higher level of abstraction, an engine maintains the document processing cycle; ? the system and individual plugins are softly con-figurable, completely from the outside; ? the architecture allows for processing of a stream of documents; furthermore, by means of collec-tion-level plugins and applications, cross-document analysis and statistics can be derived for entire document collections.
This work was supported in part by Ministry of Science & Technology of Korean government and Korea Science & Engineering Foundation.
Example 1 Revisited um it'll be there it'll get to Dansville at three a.m.
Serbian, Swedish, Turkish, Tibetan
We discuss an application of this method to a word predictor, that is, the method for transforming task- specific l inguistic constraint defined in a CFG or a DCG into a Prolog program which acts as a lef t - to- right word predictor.
A major edit is made at this point in the system by the linguist, who surveys the sets of proto-projections, and, from his background knowledge decides on the correct reconstruction and adds the vowels.
TD: 255 32.2 225 27.9 358 47.2
We have currently collected ata from three subjects. All the participants had prior experience with spreadsheets, having used them in their own work. Other than witnessing demonstrations, one had used a speech recognition system before. Three input modes were defined: keyboard only, voice with (keyboard) editing, and voice only. In the first condition, users keyed in all information, using the spread-sheet as they might under conventional circumstances. In the voice with editing condition, they spoke the commands and had an opportunity oedit each preparser string before it was acted upon.
1.2. T rans la t ing wi th :Lsomorphle M-grammars The translation relation between two (or more) lan-guages is defined by attuning their grammars as follows: (i) For each basic expression of a grammar there is at least one corresponding basic expression of the other grammar with the same meaning.
The system includes a knowledge ditor, with which a technical author can define the procedures for using common software applications uch as word processors .and diary managers; in this way the author builds the domain model from which atext generator produces instructions, in English and French, that describe thesepr0cedures. The eventual aim of such Systems is to support he technical authors who produce tutorial guides and user manuals for software applications, by automatically generating routine procedural passages in many languages.
More specifically, less than 30% of the English words in the context of LecDOCE examples translate into one of the relevant DTs in the same dictionary.
Whi le developing the automata which include interaction, we took great care not to ask too much of the user. So far we have used less than ten different question patterns and the vocabulary has been restricted to terminology famil iar to potential users. In addition we only ask one question per inter-action.
[10] TEI, \Text Encoding Initiative (TEI),"(http://www.uic.edu:80/orgs/tei/)[11] Watanabe, H., \A Method for Accelerating CFG-Parsing by Using Dependency Information," Proc. of18th COLING, 2000.
VSO-50 223.4 21.8 9.8 3.5 D iscuss ion
Symantec clearly recognizes the importance of translating Q&A into multiple languages.
System Development Corporation
1 Introduction and Background
The improvements obtained using INQUERY are often small, but the overall effectiveness i consis-tently better than other approaches.
Figure 13
Levelt, W. (1989). Speaking. l:rom Intention to
Table shows some examples of LCTs. All these templates can be easily acquired fiom the Chinese treebanks or (.hme:e ~ " s corpus annotated with constituent boundary tags.
Temporary forwarding links are links that are only valid during one unification. The currency of the temporary links is determined by matching the content of the mark field for the links with the global counter and if they match then the content of this field is respected 8. As in \[Pereira, 1985\], we have three types of nodes: 1) :atomic, 2) :bottom 9, and 3) :complex. :atomic type nodes represent a omic symbol values (such as Noun), :bottom type nodes are variables and :complex type nodes are nodes that have arcs coming out of them.
OBJ(head, dependent) Object
I +-domain: Film
A second ditliculty in the exalnple-t)ased att- proach ix the algorithm itself, namely, the be.st- match algorithm, which was used in earlier systems built around a thesaurus that consisted of a hierttr- chy of is-a or synonym relationships between words (word-senses).
? "A Proolem Solver with Formal Descriptive Kuck, D. J , and Krulee, G. K., Inputs". Computers and Information Science. Baltimore: Spartan, 1964, pp. 344-374.
static concepts: above, below, left, right, in, out, on, and off; and their dynamic equivalents: above, be-low, left, right, around, in, on, out of, through, and over .
T h e grammar associates w i t h t h e s t a t e of t h e c o n f i g u r a t i o n a l is t of a rcs w h i c h may be tes ted ( u s i n g t h e a r c t y p e , t h e c o n t e x t free t e s t on t h e a r c , a n d t h e C u r r e n t i n p u t ) t o d e t e r m i n e w h e t h e r a t r a n s i t i o n c a n be made to e x t e n d t h e p a t h . We w i l l c o n s i d e r e a c h t y p e of a rc i n t u r n , s i n c e t h e e f f ec t s of t a k i n g v a r i o u s t y p e s of arca are d i f f e r e n t , a n d e x p l a i n f o r each case w h a t h a p p e n s i f t h e arc is t a k e n . W h e t h e r j u s t o n e t r a n s i t i o n , o r s e v e r a l , o r a l l p o s s i b l e t r a n s i t i o n s a r e made from a n a c t i v e
This is one aspect of the NLTooLSET that makes it highly portable from one domain to another .
4.2 The Number of Comput ing Agents (Objects) As is obvious from the construction of the network, the number of computing agents is exactly the same as that of the nodes of the network. Since the node set of the network has one-to-one correspondence to the set of symbol occur-rences in a given set of grammar rules, the nmnber of com-puting agents can be very large if the grammar iscomplex.
In Korean, the syntactic relation of nominal words toward a verb is mainly determined by case particles. During the extraction of SRPs (Ni, SRj,Vk), we only consider the syntactic relation SRjs determined by 5 types of case particles: nominative (-i/ka/kkeyse), accusative (-ul/lul), and three adverbial (-ey/eynun, se/eyse/eysenun, -to/ulo/ulonun).
Following the same reasoning as above, we will obtain, n(+a + 1) < n(a), and (3) + 1) < (4) A string 'a' is a rigid expression if it satisfies the following conditions, n(+a + 1) << n(a), and (5) n ( -a + 1) << n(a). (6) 3.2 Data preparation Following are the steps for creating n-gram text data according to the fundamental features of Thai text corpora. The results are shown in Ta-ble 1 and Table 2. In each table, "n" is the number of occurrences and "d" is the difference in occur-rence with the next string.
3.1.3 Reverse Order Error. If a in canary is dropped, we get: cnary. The 3win converts cnary to canary with two transformations: 1) reverse order 'na': canry and 2) insert an 'a': canary.
What is the shortest day of the year
Pick up the lemon.
The reason for some models being more relatedto others is generally easy to see. For example, LL-CONFIG and LL-CONGLOM are highly related to LL-PROD, of which they are both components. In bothof these cases, using AL for use by LL-PROD beatsrandom sampling by a large amount.
An important considerat ion here is which of the words i n the descr ip t ion t o use i n the search f o r candidate topics . In an e a r l y vers ion of the system, w e t r i e d using each noun and modifier i n turn. Although this approach w a s suc- ce s s fu l i n many cases, i t of ten r e su l t ed i n an extremely lengthy list of a l t e r - na t ives . We a l s o noted t h a t words a t the highes t dependency l e v e l more o f ten l ed t o i d e n t i f i c a t i o n of the t o p i c node than those words occurr ing a t subordin- ate levels . For t h i s reason, it w a s decided t o c u r t a i l the word search, using 1 I only t h e words i n t he roo t phrase" of t h e descr ip t ion . Fop the non-active descr ip t ion PAPER ON CLUSTERING I N THE SMART SYSTEM, the words PAPSR and CLUS- TERING would be used in the search f o r candidate nodes. A s a user option, the system w i l l expand t h e search t o inc lude the remaining words i n the descr ip t ion .
Step 1: Extracting similar example for queryFor a speech recognition result, the systemextracts the most similar example from theDEDB. The robustness of the similarity cal-culation between the input utterance and theutterance in the DEDB should be consideredagainst the speech recognition error. Therefore,a keyword matching method using the wordclass information is adopted. For a speechrecognition result combined with a morpholog-ical analysis result, independent words and theInput: Etto, spaghetti no omise ni ikitai na.
Interpretation processes have long been studied by logicians. They consist in putting the abstract forms which we hold into correspond-ence with a portion of some universe. Evaluation processes consist in reaching decisions as to the response which is appropriate in a partic-ular case. An important point to keep in mind is that such processes are not limited to speech activity. They are ever present in our con-scious life. We can look upon speech as a particularly effective way of nudging someone's cognitive activity in a certain direction. That this particularly effective tool need not always be successful is apparent in all cases where the hearer fails to understand, misunderstands, etc.
I- INTRODUCTION
Linguistics, 15(2):75-96.
JHU. 2003. Syntax for statistical machinetranslation, Final report, JHU summer workshop.
Figure 2. Initial tree selected in region rl sible for spawning the creation of subregions in which the arguments (and modifiers) are realized.
The following is an example of a fairly specific, but productive, knowledge-rich morphological suffix rule: ((f i s h) (kill 4) (test (plausible-root root)) (cat nmsp (is-root-of-cat root '(adj n)) eval (progu (mark-dict lex (mark-dict (mark-dict (mark-d ict ' -es))) 'false-root root t t) lex 'kindof 'fish t t ) lex 'has-prefix root t t ) l ex 'root 'fish t t) This rule matches a word that ends in fish and removes four letters from the end (the fish part) to produce a root word which it then tests to see if it is a plausible root (e.g., does it at least have a vowel in it?). If it gets this fax, the rule will construct a category nmsp interpretation (a kind of noun), if the condition ( i s - root -o f -cat root ' (adj n)) is true (i.e., if the root is a known adjective or noun).
5.3 Conclusions
3. Disambiguated Subcorpora
In \[Simmons, 1993\], it is shown that if any self- dependent sequence 7~ is active on the labelling of a system of product constraints, then a certain sub-sequence T~' of ~ will be active infinitely many times. Moreover, on the rn-th execution of each re-finement Ri in ~ ' , there is a term 7~n/, where each T/m > T/m-1 > 1, such that OUT(Ri) is multiplied by: (T~) -1, if OUT(e,) is an upper bound sty-, if OUT(R~) is a lower bound It follows that upper bounds are refined so as to become arbitrarily small (asymptotically approach-ing zero), and that lower bounds become arbitrarily large, up to infinity.
However, for the kinds of problems we are concerned with, we can also distinguish subsolutions. Knowing which subsolution has provided the resulting certainty factor is an important part of the answer. Thus, for the goal (WITH (EAT)(FORK)), we want to know, if pos-sible, not only if fork is a credible with complement ofeat, but also what kind of semantic relation is expressed by this complement (in that case, INSTRUMENT). As another example, when checking if a word satisfies a semantic preference, we might be interested in knowing for which sense of the word the preference is best satisfied.
3 Although I will concentrate on dialog, much of what I have to say carries over to other forms of discourse.
A label will consist of a set bf variables. Each variable must be defined with its set of possible values. Thus if one defines the variable "category" the set of "categories" that can be used must be specified. The set is writ ten category = (NOUN, ARTICLE, PRONOUN, ADJECTIVE, VERB, . . . ) (A constraint requires that the name of a variable must not be longer than 7 characters. Thus the preceding var2able could be written, for example, CAT = (NN, ART, Pm, ADJ, VRB, . . . ) ) The definitdon of a particular label consists in an enume-ration of the variables relevant to the label. A se t of labels can be predefined and is collected in a so-called format file.
and Future Prospects
XIIth International Congress of Linguists working groups :
Clearly, for every i = 1 ,2 , . . . ,n F(A;wi) = F(A;wi) whenever A # S and F(S;wi) < F(S; wi). Hence qs = 0, completing the proof of the theorem. \[\] Now let ~, be the system of probabilities produced by the nth iteration of the EM
McFetridge, Paul and Aline Villavicencio.
Figure 2 shows the user testing a regular expressionloaded on to the stack of the xfst. The left win-dow under the Networks tab, shows the networkspushed on to the xfst stack. The bottom right win-dow under Test tab lists a series of input, one ofwhich can be selected as the input string and thenapplied up or down to the topmost network on thestack.4 The result of application appears on thebottom pane on the right. In this case, we see theinput with the brackets inserted around the longestmatching date pattern, Sunday, January 23,2004 in this case.
In the course of transformational p rsing, most of the spurious ur- face structures are rejected very quickly by special blocking rules which employ transformational pattern matching to filter out ill-formed configurations ot detectable by a context-free phrase structure mech-anism. In the experiments we have carried out to date, it has almost uniformly been our experience that precisely one underlying structure is assigned to each sentence xcept in cases where a) there is genuine semantic ambiguity or b) a sentence outside the current coverage of the transformational grammar has been entered into the system. At least some of this initial success in disambiguation is due to a policy of making certain transformations sensitive to semantic as well as syntactic information.
The experience of the ARPA speech project, which resulted in the design of a number of speech recognit ion systems, has demonstrated that the task of control l ing the interactions between the knowledge bases which make up the system is at least as problematic as that of def ining the knowledge bases. Major inadequacies in the systems developed during the ARPA project can be attr ibuted to an early commitment in one or more areas of design which were not apparent until final testing and evaluation of the complete system began. An architecture is required, therefore, which will permit the development in parallel and relat ively independently of component knowledge bases and methods of deploying them computationally. It should also permit the evaluation and testing of solutions with partial ly specif ied or simulated components. This will ensure that the design of one component will not inf luence unduly the design of any other component, possibly to the detr iment of both. In addition, we should have the abi l i ty to determine the consequences of component design decisions by testing their contributions to the overall goals of speech recognition.
7.2 P i tch
4. Identification of IFTs
% UC
ORE_COUNTRY string (IN_AND_OUT)
4. a list of vowels headed by some other vowel than a or u harmonizes with itself.
\[Mann and Thompsm~, 1987\] Willi;tm C. Mam~ and Sandra A. Thompson. IlhetoricM structure the-ory: A theory of text ()rg;tnization. In L.Pohmyi, editor, 7'he Sl*"uctttre of Discmtrse. Ablex, Nor-wood, N.J., 1987. Also as USC/Informatim~ Sci-ences Institute Research Report IIS-87-t90.
3) Synthesize the \[dir-object\] if it has not been synthesized as a reflexive pronoun in Step 1. In Step 3, the form of the conjugated verb provided by Step 2 is used to determine if the \[dir-object\] has to be synthesized as a personal pronoun.
Aano: \[Proper(W) \]
Unsupervised Models for Named Entity Classification
Empirical studies of discourse representations for natural language interfaces
Kansas City, MO, 64110
Thus, the positive and negative examples arecreated for each class (POS tag), and a modelof SVMs is trained for each class using thetraining examples.
Possessed Nominals
A d-tree d is complete if it does not contain any substitution odes, i.e., all the frontier nodes of the description d are labeled by terminals. Given a d-tree d, we say that a pair of nodes, x and y (variables in vars(d)), are related by an i-edge if d ::~ xAy .
SA1.X: Come here , p lease .
H. Hirseh, P. Meyer, and H.W. Ruehl, "Improved Speech Recognition using High-Pass Filtering of Subband Enve- lopes," Eurospeech, Sept. 1991, pp. 413-416.
The negotiation between agents aims to eliminate underlying conflicts and uncertainty among them. The process of multi-agent negotiation is carried out as follows.
Overall Error Rate
T(t . fA) = Aria)
M(n)(S,A)IP(A) = pn,(s) = O.
TA tile number of terms in AGROVOC in which tile relational adjective appears in an epithetic position, i.e. the terms of Noun RAdj structure. Fox" example TA=15 tbr the adjective cellulairc (eellular) because it appears in 15 terms of AGROVOC such as di./~renciation cellulairc (cellular differ'- enciation), division cclIulaire (cellular divi-sion).
[8] Theeramunkong, T., Sornlertlamvanich, V., Tanhermhong,T., Chinnan, W., Character-Cluster Based Thai InformationRetrieval, Proceedings of the Fifth International Workshopon Information Retrieval with Asian Languages, September30 - October 20, 2000, Hong Kong, pp.75-80.
Nounsduluth7 duluth8 0.57 0.11 0.32 0.76umcp duluth9 0.50 0.17 0.33 0.65duluth7 duluthY 0.49 0.21 0.30 0.57umcp duluthY 0.48 0.21 0.31 0.56duluth8 duluthY 0.50 0.21 0.29 0.56umcp duluth8 0.50 0.23 0.27 0.51umcp duluth7 0.50 0.23 0.27 0.51cs224 umcp 0.51 0.24 0.25 0.49duluth9 duluthY 0.44 0.26 0.30 0.47duluth8 duluth9 0.47 0.27 0.27 0.45cs224 duluth9 0.47 0.27 0.26 0.44cs224 jhu 0.55 0.25 0.20 0.43cs224 duluth8 0.51 0.27 0.22 0.42jhu umcp 0.51 0.29 0.21 0.38jhu duluth8 0.53 0.28 0.19 0.37
lSThis comparison could be extended to other corpus frequency based technics (mutual information, etc.).
Can we dispense with the idea of innate ideas? In order to show that we can account for mentalese without requiring innate ideas, I must show (I) that the mechanisms proposed are capable of generating all the primitive concepts of mentalese, and (2) that I have not simply buried innate ideas somewhere in the mechanisms. Let me say in~nediately, relative to point (2) that there are some innate ideas in my account; one set of ideas are related to the values (good/bad, symmetrical/nonsyrmnetrical, etc.) discussed earlier. There must also be ideas relating to generating hypotheses on which the values can operate, and the idea of objectness (if this can be called an idea) must be present. Hypothesis generation might seem a candidate for further search for embedded ideas; however, as I have described it, hypothesis generation is primarily a categorizing operation, where it acts on the "raw material" of perception. On the whole I do not believe that it is difficult to accept the sorts of innate ideas which remain in my account.
Significance = N.S.
15That is: (K,?) is a monoid (i.e., ? : K ? K ? K isassociative) with identity 1. (K,?) is a commutative monoidwith identity 0. ? distributes over ? from both sides, 0 ? k =k? 0 = 0, and k? = 1? k? k? = 1? k?? k. For finite-statecomposition, commutativity of ? is needed as well.
We study Spectral?s performance in comparison with thealgorithms discussed in the previous sections.
Unknown Words
Surf: \[11 \[Pref: IV: \[2i~ \] 1
A new sentence such as She saw the dress with the te lescope can be parsed by combining subtrees from this corpus by means of lel 'tmost-substitution (indicated as ?):
SHORI(processing) WO ...
These te rms are used a lmost interchangeably in our corpus, but they don't fare as well in Roget's because of anthropocentric attachments o concepts uch as fame, duty and legal liability.
Concept to Speech System
DEC 1968
Finally, (6i) demonstrates that reflexive datives can sometimes be formed from intransitive verbs. The semantic restrictions on the source for such constructions are not entirely clear to us, however, all the putative similar examples to the attested (6i) seem innovative and much less conventionalized than the core dative examples. Itwould be straightforward to introduce a lexical rule mapping intransitive verbs to the dative construction. However, the relative productivity of this putative rule should be represented as being much lower than the two rules discussed above. Nothing in the representation we have presented so far equips us to deal with the issue of (semi)productivity which also arises with the two rules introduced earlier; consider the famous example of donate, which does not undergo the dative alternation although it is uncontroversially an oblique transfer verb. In the next section we consider this issue in detail.
By word experts (consider the word expert prototype provided below) we refer to a declarative organiza-tion of linguistic knowledge in terms of a decision net whose root is assigned the name of a lexical class or a specific word, Appropriate occurrences of lexical items in the text prompt the execution of corresponding word experts. Non-terminal nodes of a word expert's decision net are constructed of boolean expressions of query predicates or messages while its terminal nodes are composed of readings. With respect to non-terminal nodes word experts -query the frame knowledge base,e.g, testing for se-mantic relations (e.g. is-a, instance-of) to hold, for the existence and activation weight of concepts in the knowledge base, or for integrity criteria that restrict the assignment of slot entries -investigate the current state of text analysis~ e.g. the types of operations already performed in the knowledge base (activation, slot entry assign-ment, creation of new concepts~ etc.) -consider the immediate textual environment, e.g.
? Reintroducing old goals. As long ~ the current transaction is not closed the system tries to real-ize postponed goals if a dialogue opportunity (e.g.
Common denominators and default unification. Proceedings ofthe First Meeting, Computational Linguistics in the Netherlands (CLIN-91), pages 1-16, Utrecht.
For example, because ?diabetes mellitus? is nested in ?insulin dependent diabetes mellitus? and two terms are all disease names, ?diabetes mellitus? is head term and ?insulin dependent? is modifier. The specificity of Y is measured as equation (9).
1 In t roduct ion
S imple Backward App l i ca t ion (<)"
An Incrementa l Parser - In terpreter
Average 0.1429 0.1837 0.2672 0.2859 %change +28.5 +87.0 +100.0 At 10 docs 0.3000 0.3840 0.5060 0.5200 %change +28.0 +68.6 +73.3 At 30 docs 0.2387 0.2747 0.3887 0.3940 %change +15.0 +62.8 +65.0 At 100 doc 0.1600 0.1736 0.2480 0.2574 %change +8.5 +55.0 +60.8
Restrictive postmodification (RPostm): yes if the definite description ismodified by relative or associative clauses.
Rank Xerox Research Centre
7. Future Work
This measure has proven to be an appropriate anda vast improvement over previous subjective tech-niques. We have also presented the first wide spreadcomparison of different grammatical inference tech-niques. This involved the implementation of the ex-isting Alergia, k-contextual, (k, h)-contextual andsk-strings methods, as well as the creation of newalgorithms. The new methods include the Greedystrategy, the ACO meta-heuristic, Stochastic HillClimbing and our proposed, hybrid sk-ANT heuris-tic. Comprehensive experimental data revealed thatour proposed method was the most effective andmost stable of the methods, followed by the sk-strings heuristic. From this work we may concludethat the problem of structural inference is both im-portant and tractable. For current applications werecommend use of the sk-ANT technique. The useof MML as a quality measure is also recommended,due to its generality and objectivity.
Haas N., Hendrix G.G.: Learning by Being Told: Acquir ing Knowledge for Information Management, in R.S.Michalski et al(eds.), Machine Learning: An Art i f ic ia l \]intelligence Approach, Tioga, Calif.; 1982 Knopik T.: MORPHY - Die morpho\]ogische Komponente zu einem Gener\ ]erungssystem fHr das Deutsche, Dip\]om- arbeit, Inst.f. Informatik, Univ. Stuttgart; \]984.
Scoring Metrics
AN EXPERIMENTAL APPLICATIVE PROGRAMMING LANGUAGE
EL PERRO RIEGA LAS FLORES
Macleod, Catherine, Ralph Grishman,
APPENDIX: SAMPLE SEGMENTATION RULES
In this article we will investigate the effectiveness of CLIR systems based onprobabilistic translation models trained on parallel texts mined from the Web. Glob-ally, our approach to the CLIR problem can be viewed informally as ?cross-lingualsense matching.? Both query and documents are modeled as a distribution over se-mantic concepts, which in reality is approximated by a distribution over words. Thechallenge for CLIR is to measure to what extent these concepts (or word senses) arerelated. From this point of view, our approach is similar in principle to that usinglatent semantic analysis (LSI) (Dumais et al 1997), which also tries to create semanticsimilarity between documents, queries, and terms by transposing them into a newvector space. An alternative way of integrating translation and IR is to create ?struc-tured queries,? in which translations are modeled as synonyms (Pirkola 1998). Sincethis approach is simple and effective, we will use it as one of the reference systems inour experiments.
Arabic IR is enhanced when the roots are used in indexing and searching [3] [4] [5].
1) S --. NP VP <NP feature1 > = <VP feature1 > 2) NP ~ det N <N feature1 > = + <NP> = <N> 3) VP --* V <V feature1 > = - <VP> ~ <V> 5 Conc lus ion I have shown how a terminological language, such as Classic, can be used to manage lexical seman-tics data during analysis with two minor exten-sions. First, a test to identify LEGAL-LINKINGs is necessary since this cannot be directly expressed in the language and second, set membership tests, have-instances-of and have-no-instances-of are necessary since this type of expressiveness is not provided in Classic. While the solution of sev-eral knowledge acquisition issues would result in a friendlier tool for a linguistics researcher, the tool still performs a useful function.
AvgAnalj - The average contr ibut ion of a single word in SWj to SumAnalj.
1986. Attention, intention, and thestructure of discourse. Computational
Px %sub %del %ins %error 60 5.9 2.5 0.4 8.8 60 6.4 2.5 0.3 9.2 1000 I 21.0 5.2 1.5 27.7 10001 23.4 6.1 1.8 31.3 Table 3: DECIPHER'S Performance using DARPA's 1989 Speaker-Independent Test Set works, cross-word boundary contexts were a natural extension to the SRI DECIPHER system.
Michael McCord. 1989. Slot grammar: a system forsimple construction of practical natural languagegrammars. Natural Language and Logic, pages118?145.
In some sense, regions and descriptors cover the focus space in an orthogonal way: while the former cover a connected area on a picture, the latter typically appear there as a set of islands. As opposed to that, a descriptor covers a connected area in the abstract descriptor-referent space, while a region typically appears there as a set of islands. In some occasions, locality descriptors may do a similar job as regions, but this would probably be less effective in many cases, when multiple locality descriptors are required. As a consequence, the selection of an adequate region differs in some crucial sense from the selection of an adequate descriptor: acandidate descriptor is chosen from a set of distinct alternatives, while deter-mining a candidate region is more a matter of accuracy and precision in terms of appropriately fixing the border- lines of the region which lies around the intended referent or some other entity related to it. Altogether, a region typically comprises the equivalent of several descriptors as far as the contribution to the identification task is concerned: either a category of the object enclosed by the region, accompanied by a set of further descriptors, ifnecessary, or a suitable combination of locality descriptors.
University of Waterloo
One of the goals of studies in Distributional Semantics is the establishment of word classes on the basis of the observed behavior of words in written texts. A convenient and significant way of discussing "behavior" of words is in terms of syntactic relationship. At the outset, in fact, it is necessary that we treat a word in terms of its Syntactically Related Words (SRW). In a given text, each word bears a given syntactic relationship to a finite num-ber of other words; e.g., a finite number of words (nouns and pronouns) appear as "subject" for each active verb; another group of nouns and pronouns are used as "direct object" of each transitive verb; other words of the class, "adverb," appear as modifiers of a given verb. In each instance we may speak of the related words as SRW of a given verb, so that in our example three different ~ of SRW emerge; a given SRW is then defined in terms both of word class and specific relationship to the verb. (A given noun may of course belong to two different types of SRW, e.g., as both subject and object of the same verb.) Distributionally, we may compare two verbs in terms of their SRN. The objective of the present study is to test the premise that "similar" words tend to have the same SRW. This premise is tested, not with verbs, as in the l , a rper above example , but w i th nouns . Our procedure i s ( i ) to f ind in a g iven text th ree types of SRW for a smal l g roup o f nouns , (2) to f ind the number o f Sill; T shared by each pa i r of nouns fo rmed f rom the group , and (3) to express the "s imi la r i ty" between ind iv idua l nouns) and groups of nouns , as a funct ion o f the i r shared SRI~. Another example : i t might tu rn out that in a g iven text the nouns "a" and "b" ( "avocado" and "cher ry" ) share such ad jec t ive mod i f ie rs as " r ipe , " whereas nouns "c )' and "d" ( "cha i r " and " fu rn i tu re" ) have in common the ad jec t ive mod i f ie r "modern . " These fac ts would lead us to conc lude that "a" and "b" a re s imi - la r , that "c" and "d" a re s imi la r ) that "a" and "c" a re less s imi la r , e tc .
\[Marr, 1982\] David Marr. Vision. W. H. Freeman, 1982.
Temporal Operators Expressing Anteriorityand Posteriority? (paper presented at theconference The Syntax and Semantics ofTense and Mood Selection, University ofBergamo, Italy, July 1998; to be publishedby Cambridge University Press).
Sylvain DUPUY, Arjan EGGES, Vincent LEGENDRE, and Pierre NUGUES
Remi Zajac, Mark Casper, and Nigel Sharples. 1997. An opendistributed architecture for reuse and integration of hetero-geneous NLP components. In Fifth Conference on Applied
\[2\] Berwick, R. C. and Weinberg, A. (1984) The Grammatical Basis of Linguistic Performance,
Following the constraints of Figure 3, the linearizer will place the occupants of the AGENT and ASPECT cases before the predicate in the output, but will also ensure that the ASPECT follows the AGENT and directly precedes the verb.
alent to tile Xlib package wrilten in C.
There is no doubt that restricting the lexicon to basic morphemes and deriving all complex words as well as all the inflected forms by morphological rules, reduces substantially the size of the lexicon. This was indeed a crucial issue not so long ago, when computer memory was scarce and expensive.
3.2 hfforlnation Mapping for CLIR
Wilks, Y., Huang, X.-M., and Fass, D. (1985).
C++, providing a rapid and easy code-compile-train-test development cycle. In fact, many NLP systems suffer from a lack of software and computer-science engineering effort: running efficiency is key to performing numerous experiments, which, in turn, is key to improving performance. A system may have excellent performance on a given task, but if it takes long to compile and/or run on test data, the rate of improvement of that system will be contrained compared to that which can run very efficiently.
Abst rac t
A restricted environment consists of the nodes one link outside of a TU normally. If corre-sponding nodes are same in two environments, those environments are extended one more link outside. Figure 2 illustrates restricted environ-ments of a TU. We estimate xternal similarity as the best matching of two restricted environ-ments. To find the best matching, we first deter-mine the correspondences between odes in two restricted environments. Some nodes have sev-eral candidates of correspondence. For example, n7 corresponds with rn6 or m7. In this case, we select the most similar node. To do this, we assume that similarity values between odes (words) are defined as numeric values between 0and 1 in a thesaurus. When the best matching is found, we can calculate the matching point between two environments, mpoint(TU, WD).
Mari Ostendorf J. Robin Rohlicek
L. Iordanskaja, R. Kittredge t A. Polgu~re. 1991.
The primary innovation of Bresnan's framework is that it eliminates a large class of transformations in favor of an enriched conception of the lexicon. The grammar that results is one that Bresnan claims is far more realistic from a processing point of view than other versions of transformational grammar. She points out striking similarities between her proposals and recent compt, tational and psycholinguistic work by Kaplan and Wanner, and she argues that Augmented Transition Networks can provide at least a partial answer to the grammatical realization problem within her framework.
Embedding Web-Based Statistical
LabEL?s simple and multiword electronic dictionaries were then applied to the acquisition corpus. These dictionaries contained 171,159 nominal entries, from which 82% were simple words and 18% compounds. From the 22,581 compounds, 61,7% are NA, 33,6% are NDN and the remaining 4,7% belong to other strucutres.
In order to produce the above configuration, the current system implements two user interthces (UIs): the Client UI, which provides peech and text input capabilities to the primary end-users of the system; and the Editor UI, which provides translation edit-ing capabilities to a human translation expert, in the rest of this section, we describe in detail certain unique aspects of each interface.
When different words express the same sense, we say they are g~iQ~ym~USo On the other hand, if you enter the matrix with a word and look down that column, you find all the different senses that that word can express. When one word can express two or more senses, we say that it is ambiguous, or ~ixsemglL~. Thus, the two great complications of lexical knowledge, synonymy and polysemy, are seen as complementary aspects of a single abstract structure=
J1, e
A disadvantage in using MMR-based feature selection is that the computational cost of computing the pairwise information gain (i.e. IGpair) is quadratic time with respect to the number of features. To reduce this compu-tational cost, we can use MMR-based feature selection method on the reduced feature set resulting from IG as our experiments in section 4. Another drawback of our method is the need to tune for ? . It appears that a tun-ing method based on held-out data is needed here
The limited left-context parser can be thought of as at a midway point between the pure bottom- up parser and the left-corner parser, constructing a subset of the phrases found by the bottom-up parser, and a superset of the phrases found by the left-corner parser. Using limited left-context o constrain categories containing syntactic gaps re-duces the number of phrases by more than a fac-tor of 5 and is almost 15 times faster than the pure bottom-up arser. The limited left-context parser builds 81% more edges than the left-corner parser, but many fewer predictions. Somewhat surprisingly, this results in the limited left-context parser being 4 times faster than the left-corner parser. We conjecture that this is due to the fact that context-independent phrases are licensed by a static table that is quicker to check against han dynamic predictions. This results in a lower av-erage time per edge for the limited left-context parser (0.005 seconds) than the left-corner parser (0.036 seconds). Some additional penalty may also have been incurred by not using dotted grammar rules to generate reductions, as in standard left- corner parsing algorithms. 2 There are important differences between the technique for limited prediction in this parser, and other techniques for limited prediction such as Shieber's notion of restriction (Shieber, 1985) (which we also use). In methods uch as Shieber's, predictions are weakened in ways that can re-sult in an overall gain in efficiency, but predic-tions nevertheless must be dynamically generated for every phrase that is built bottom-up. In our log version 3.1.4.
This set was also used on a previous paper (Agirre & artinez, 2000).
Utrecht, The Netherlands. The BYU-HRC is a center which promotes research in the College of Humanities at Brigham Young University (BYU), in particular providing support for research involving language and computers.
Ullman, Jeffrey D. 1982. Principles o/Database
6 Acknowledgments
Calzolari, 1977?)
The first question can be rephrased as "given certain intensional objects in one viewpoint (the system, in this case), what are the corresponding intensional objects in the system's version of another viewpoint (Mary's)?" Extending the normal default rule for belief ascription to cope with intensional object ascription, we would say, naturally enough, that intensional objects in one environment directly correspond to intensional objects in another environment, unless there is counter evi-dence to believing this. This notion of correspondence of intensional objects between environments can be expressed as beliefs, but these beliefs must be of a type different from those we have previously discussed.
Root('S') / \
Omneya A. R izk***
Situation 3. Input beliefs
W/if.decision ,---
Table 1: Switchboard dialogue fragment
4. Slot Overgeneration: Subtracting the TEMPLATE-ID scores from the MATCHED/MISSING over -generation column results in slot overgeneration .
Zhan Weidong, Mr. Li Kangnian and Dr. Chang Baobao. The blithesome collaboration with Dr.
Error type Errors Detections and Diagnoses Corrections
The next two subsections motivate search over the morpheme boundary relations and the c-suffix set inclusion relations respectively.
Secondly, to annotate spoken data is to add linguistic explanations to the plain transcript to represent linguistic structures at selected levels.
Abst rac t
Carberry S., "User Models: the Problem of Disparity," Procredinos of the Xlth International Cortlcr~nce on Computa- t/ona/L/ngu/~ics, pp. 29-34, Bonn (FR Germany), 1986.
The action of a path node is shown in Figure 5. "faihn'e" means there is no PD whose seman-tic structure subsumes the given dag. Thus the entire retrieval process fails.
This has focused increased attention on the importance of obtaining reliable training corpora. Unfortunately, acquiring such data has usually been a labor-intensive and time-consuming exercise.
2.3 Conjunct ion
VERBAL IZED PUNCTUATIONS VS
ing the graph. The paper introduces two
In the cod ing to the le f t of each s t ructure , the f i r s t le t te r represents the grammatical ro le ( sub jec t or ob jec t ) of the NP on which the re la t ive c lause i s formed, wh i le the second le t te r represents the grammatical ro le p layed by the re la t ive pronoun. The th i rd le t te r represents the fact that the re la t ive c lause i s in the ac t ive vo ice .
Once the grammatical framework is defined,we are in position to make use of the informa-tion provided by the SCFG. In order to define thegrammatical features, we first introduce some no-tation.
Extension to PTM
Dictionary definitions of nouns are normally written in such a way that one can identify a "genus term" for the headword (the word being defined) via an IS-A relation. The information following the genus term, the differentia, serves to differentiate he * ~Pnis research was supported by the New Mexico State University Computing Research Laboratory through NSF Grant No. 1RI-8811108 - - Grateful acknowledgement is ac- corded to all the members of file CRL Natural Language Group for their comments and suggestions.
Yarowsky, D. 1994. Decision Lists for Lexical Ambiguity Resolution: Application to Accent Restoration in Spanish and French. Proceedings of the 32nd Annual Meeting of the Association for Computational Linguistics, pp. 88--95.
REFERENCES i.
$ They lined.
E. Agirre and D. Martinez. 2000. Decision Lists and Automatic Word Sense Disambiguation. In Pro-ceedings of the COLING Workshop on Semantic
J oshua Goodman*
Computational Linguistics Volume 27, Number 4 Ge, Niyu, John Hale, and Eugene Charniak.
3.1 Coverage and Complet ion
In the sections that follow, we will describe the BBN BYBLOS system briefly. Then we enumerate several modifications to the BBN BYBLOS system. Following this we will describe four different experiments hat we performed and the results obtained.
Food and
Annual Meeting of the ACL.
Fields in database 133 231 666
N: which hole the bottom one on the side?
Sitcom 97 Series 24 Series-Old 3
M. Kearns and L. G. Valiant. 1989. Crypto- graphic limitations on learning boolean for-mulae and finite automata. In Proceedings of the 21st Annual ACM Symposium on The-ory of Computing, pages 433-444, New York.
(The capitalization of first letters of sentences, proper names, or nouns, is a kind of punctuation,) Identical graphic forms may also be assigned more than one code because they are distinct units in information processing. Thus the letter form "C"' is used in the Russian alphabet to represent the sound /s/, but it is not the same information unit as English "C", so it has a distinct code. So far this seems relatively obvious.
NE Tagging
Accuracy (%)
The result of a sample query "'Clinton" to our search engine is shown starting in Figure 4.
' John-glves-a('cer t aln')-book-to-everybody' The order of Q-NPs in the Spanish sentence has to be awitr~_mmchaw~ SNEG is introduced syncategorematically, lthough it could have been a basic expression as well.
KB Accessor
puter Understanding of Newspaper Storzes New Haven, CT Depaxtment of Computer Science,
The implementation of the left-corner parser based on selective memorization and goal weakening seems to be substantially more efficient han the chart-based imple-mentation of Carroll. The head-corner parser running in left-corner mode is almost as fast as this specialized left-corner parser. This suggests that the use of selective memorization with goal weakening is on the right track.
This siml)liti(:ation (toes not atfe(:t the (:om- pul;~tion of the (tistril)ui;ions we are inl;(;resl;ed in; l;h;fl; is, the marginals of the synset nodes.
R. Bod, 1995. Enriching Linguistics with Statistics: Performance Models of Natural Language, ILLC Dissertation Series 1995-14, University of Amsterdam.
dj ohns @ war son. ibm. com
Translation seems a strenuous test.
Trawick, D.J. 1983 Robust Sentence Analysis and Habitability.
Some of the things restricted by some of the major provisions of the state's Fair Campaign Code which restrict something a r e activities having to do with election campaigning.
with un i f i cat ion-or iented
K. Humphreys, M. Calcagno, and D. Weise. 2001. Reusing aStatistical Language Model for Generation. In Proceedingsof the EWNLG.
C@
Figure 3: Flow of window adjustment
The l i n k in an occurrence r of a construction o f t e N f L f t h e expression f has not occurred in the t e x t berore. r,.
1The effects of polysemy were compounded by not having anyreliable method for determining valence. We consider that sim-ply partitioning VPC items into intransitive and transitive usageswould reduce polysemy significantly.
? The feature Rhetorical relation specifies the names of rhetorical relations that may be signaled by the cue phrase under consideration. Its value is given by the names listed in the instances of the database field Rhetorical relation that were consistent with the discourse usage being considered.
categorised. As (Hansen-Schirra and Neumann,2003) point out, for many research questionsneither type of alignment is sufficient, since themost interesting phenomena can be found on alevel between these two extremes.
Moran, Douglas B. 1988. Quantifier scopingin the SRI core language engine. InProceedings of the 26th Annual Meeting of theAssociation for Computational Linguistics(ACL?88), pages 33?40.
Table 6 shows the percentage ofeach evaluation item. We have 120 open data, not 100, for LASA- 1, because the data is expanded ue to the seman-tic ambiguity. The term "incomplete" in the table denotes the cases where the tree retrieval stopped mid-way because of an "unknown word" in the classification. Such cases, however, could some-times hit the correct translation since the algo-rithm output the most frequent translation under the stopped node as the default answer.
The application of techniques from the domain of Automated Reasoning to the problem of natural language correctness offers solutions to at least some of the deficiencies of tradit ional approaches to computer assisted language learning. By supplying a special ized inference mecha-nism with knowledge about what is correct within fragments of natural language utterances, a flexible training device can be designed. It prompts the student with e .g . randomly generated sentence frames, where slots have to be fil led in.
PHRASAL PARSER
A. Gruenstein. 2002. Conversational interfaces:A domain-independent architecture for task-oriented dialogues. Master?s thesis, Stanford
"Interpretation asabduction." In 26th
The integration of discourse purpose and coherence relations ill one theory of discourse representation would contribute to the solution of these problems. One interesting starting point would be the correlation between classes of coherence relations and different discourse types / purposes. For instance, the difference between semantic and pragmatic relations correlates with expository and argumentative discourse, of which the purposes can be formulated as to inform and to persuade respectively (Brewer, 1980). Van de Vijfeyke (1992) shows that expository discourse is characterized by a relatively high number and a more dominant position of semantic vs. pragmatic relations, whereas pragmatic relations occur more and in more dominant places in advertisements.
To implement his approach we partitioned the set of grammatical categories into context-independent a d context-dependent subsets, with the context-dependent categories being those that implicitly contain gaps.
2. What is MTS?
\[MeKeown 85\] McKeown, K.R. Text Generation: Using Discourse Strategies and Focus Constraints to Generate Natural Language Text. Studies in Natural Language Processing. Cambridge University Press,
2.3 Other Features
Restructuring 52.1 34.7 33.6 15.2+ dictionary disambiguated+ hierarchical lexicon 52.9 33.9 31.8 13.70 Baseline 23.3 53.6 60.4 29.8
All and only the possible morphemes of the language
I 5 Conclusion
Aho, Alfred V. and Jeffrey D. Ullman.
Generat ion
Processes, 6(1):1?28.
MT system)
Approach to 8,yntax. New York: Elsevier, 1969, , HajiSov~ Eva and Bene~ov~
The generation algorithm also requires us to define a similarity metric between POS fea-ture vectors.
Hirosh i Nomiyama
1992. An Evaluation A))stem ./i)r Parsing and
In bracket matching model, these cases can be generalized asa matching restriction region (MRR), which is informally represented as the region <RL, RR> in Figure 3.
PP\[fiir\] NPD V\[danken\] 'thauk NP for' Verb with dative object and PP
4. Memory: what everybody knows ( t h i n k s , believes) ; w h a t Joe Bear knows; what J o e Bear t h i n k s I r v i n g B i ~ d knows; e t c .
Rickel, J., & Johnson, W.L. (1999). Animated Agents for Procedural Training in Virtual Reality: Percep-tion, Cognition, and Motor Control. Applied Artifi-cial Intelligence, 13, 343-382.
ONE 0.944
Therefore head-modifier/argument examples only resolve most of semantic role assignments.
J. Huang, B. Kingsbury, L. Mangu, M. Padmanabhan,G. Saon, and G. Zweig. 2000. Recent improve-ments in speech recognition performance on largevocabulary conversational speech (voicemail andswitchboard). In Sixth International Conference onSpoken Language Processing, Beijing, China.
4 Relation to Previous Work
An Analogical Parser for Restricted Domains
3 TSNI,P Annotat ion Schema
We shall call sequence Xk,t s the sequence of lexical categories of word inflective paradigm of t-type hk. One of lexical categories, usually the first, is named X*t,k and called normalized.
3.3 Comparative experiments and results We compared the ability of each measure to gather class P words. We randomly sorted the 20,000 words mentioned above, and then compared the result with the results of sorting by other measures.
The necessary ordering that'comes with motional references is allowed for by associating temporal elements with the functions.
c. Rerank each candidate compression set using SIG score first and then
FB : this introduces 7 bytes of obscure signification; there is almost always one of these following a null-terminated label.
University Press, Oxford, UK, pages 36-51.
13. Licklider, J.C.R., "A Duplex Theory of Pitch Perception,"
The parallel structure of the MUC competition, with many different systems attempting to extract he same data from the same material, creates an opportunity to achieve even greater performance by combining the results of two or more systems. A combined system could use the outputs of several different systems to produce performance l vels potentially superior to those of any one component alone. BBN has produced an architecture for system output combination.
Machine Learning. 1:81-106.
6 Conclusion
CAT N
? Words carrying the same feature if they aresimilar as strings. Candidates are all kinds ofproper names, as well as distinguishingparts-of-speech.
AN APPROACH TO TRANSLATING
The implications of this for NLP is that any language processing system should be able to work equally well with world-knowledge r presentations that may vary significantly in format, structure, and contents. If lexical items are strictly tied to elements in a particular knowledge base, this is not possible.
One alternative is to show the two trees aboveeach other (as in figure 1). And there aremany ways to visualize the alignment: Eitherby drawing lines between the nodes (as we did),or by color marking the nodes, or by opening an-other window where only chosen parallel nodesare shown. The latter case corresponds to azoom function, but this also entails that the userhas to click on a node to view the alignment.
N))\]> <ETRAD CDLANG="FR-EN"> <TRADN NUM="01">N_deverbatif--> N_deverbatif_lex <TRADN NUM="02">dev-OBJ\[SN\] --> dev-OBJ\[SP\] This format, though a bit complex for an human eye, has the advantage to clearly separate annotations from the original textual data. Moreover, this format allows an easy exploitation of the contained data provided the evaluator uses SGML tools with which selection and extraction of subset of data become really easy (each tagged data is a potential selection criteria).
We directed most of our energies to linguistic development, as shown in Table 2 below ,and except for the discourse component, the linguistic aspects of the task have essentially beencompleted. Because we had less time remaining to devote to engineering issues, much of th einformation that PAKTUS produced has not yet been used in template-filling . In using thelinguistic output to fill templates, we began with the two aspects of the template-filling task w econsidered the most important: identification of relevant incidents (template id) and identificatio nof incident type . Our recall and precision scores for those slots reflect the amount of time we spenton them (see Table 1) . We believe that, given more time to convert linguistic output to templat efills, we will be able to achieve comparable scores for the other slots as well .
He let the letter to everybody read
(~) 1993 Association for Computational Linguistics Computational Linguistics Volume 19, Number 2 the POS tagging phase is automatically parsed and simplified to yield a skeletal syn-tactic representation, which is then corrected by human annotators. After presenting the set of syntactic tags that we use, we illustrate and discuss the bracketing process. In particular, we will outline various factors that affect the speed with which annotators are able to correct bracketed structures, a task that--not surprisingly--is considerably more difficult than correcting POS-tagged text. Finally, Section 5 describes the com-position and size of the current Treebank corpus, briefly reviews some of the research projects that have relied on it to date, and indicates the directions that the project is likely to take in the future.
Because any of the utterances in a segment may contribute information relevant to a complete determi-nation of the DSP, the recognition process is not complete until the end of the segment. However, the OCP must be able to recognize at least a generalization of the DSP so that he can make the proper moves with respect to the attentional structure. That is, some combination of explicit indicators and intentional and propositional content must allow the OCP to ascertain where the DSP will fit in the intentional structure at the beginning of a segment, even if the specific intention that is the DSP cannot be determined until the end of the segment.
Evaluation (LREC2004).
(20) a. Describe the x4.
(4.6d) A wants to inform S that John wants him to leave.
Character type and word length are related to word candidate generation in section 2.2.3.
Re l , t ion Candidate I -_zz \i, -'
To return to the discussion of (r)FLM? and(r)ALM?, an obvious fact about their behavior isthat regressor based systems rFLM? and rALM?,whether V-by-M enabled or not, surpass in per-formance their less sophisticated counterparts (seeTable 8: HF accuracy of MEMTs with perturbed SVregressor in the V-by-M scheme.
Chung Yong Lim. 2001. A machinelearning approach to coreferenceresolution of noun phrases. Computational
In Proceedings of the 4th IEEE InternationalConference on Multimodal Interfaces, pages 93?98, Pittsburgh, PA.
Engelson and Dagan (1996) present a scheme for selecting corpus sentences whose judging is likely to provide useful new information, rather than those that merely repeat old patterns. The TreeBanker offers a related facility whereby judgments on one sentence may be propagated to others having the same sequence of parts of speech. This can be com-bined with the use of representative corpora in the CLE (Rayner, Bouillon and Carter, 1995) to allow only one representative of a particular pattern, out of perhaps dozens in the corpus as a whole, to be in-spected. This already significantly reduces the num-ber of sentences needing to be judged, and hence the time required, and we expect further reductions as Engelson's and Dagan's ideas are applied at a finer level.
HA (Adverb)
ltowever l, he expansion of a recnrsive type itself is a little bit harder. In T'D?, we are using a lazy expan-sion technique whMt only makes those constraints explicit which are really new. To pslt it in anoth-.
1.3. The Computational Lexicon
Prefixes, Suffixes I 0.5
This dictionary gave us the possible lexical tags for each word from the corpus. In no case, was the test used to estimate the lexical probabili-ties.
Ava&lability of suxEaee at.ruct:ura
Most of these parsing strategies presented above are language speci f ic , and I do not see them as a l te r - natives to my pivot parser but as additions to i t .
Noun Prepos i t ion Art ic le
Joe
Let us say that a discourse is headed if each of its segments i headed, and non-headed, otherwise. Our assumption is that a discourse is either headed or non-headed, and not both (e.g. figure 1, figure 2). 5 Formally, this will be expressed through the value for the head attribute.
Terms may consist of either one or more words.
This indicates that the structural features were quiteefficient in performing these tasks. In general wecan say that the use of structural features can im-prove the performance of NLP tasks that require thedetails of the contents to perform the task.
In contrast, a quasi-determinizer produces a device that simulates M in an amount of time independent of the size of M itself.
This says that any instance of a go- can use the subject position to indicate the agent of the go- event. These facts can be inherited in the typical way via the isa hierarchy, so this fact would more generally be expressed as (case ?a.action- subject agent), Using case and the previously introduced - -OR connec-tive, we can express the rule of case relations. Formally, it says that for all syntactic positional relations and all meanings of the head, there must exist a case relation which is the significance of that syntactic position: (syn-pos ?tel ?head ?val) A (inst ?head ?frame) =~ ('--*OR (case ?hea~l ?tel ?slot) (== (?slot ?hesd) ?val)))
PHRAN CPHRasal ANalyzer) is a natural language understanding system based on this view of language use.
Bates E, McNew S, MacWhinney B, Devescovi A,Smith S (1982) Functional constraints onsentence processing: A cross linguistic study,
Our experiments also indicated that relatively l imited domain-speci f ic information (primarily a character izat ion of the structure of information in a domain, rather than specif ic facts about the domain) can be adequate for certain natural language appl icat ions, such as those described. Problems arose more often because the selectional constraints were too "tight" than because constraints deducible from specif ic facts of the domain were not available. As a result, we are now beginning to experiment with the automatic selective relaxation of these restr ict ions in order to improve parsing performance.
Jing, Hongyan and Kathleen R. McKeown.
Eric Brill and Jun Wu. 1998. Classifier Combination forImproved Lexical Disambiguation. In Proceedings of
The results presented in the previous section showthat it is possible to improve over the simple patternmatching algorithm of (Johnson, 2002), using de-pendency rather than phrase structure information,more skeletal patterns, as was suggested by John-son, and a set of features associated with instancesof patterns.
DERIV AFF -> INFL AFF POSSIBLE
School of Computer Science, Language
Schank, R. (1973) . "Identification of GmeptWizatiofls Urderlying Natural Language", in Ckqutesr Wels of 'IIYXEght and Lmguag w e , R. Schiurk anl K. Col- by (eds) , W. H. FYecmm ard Capmy", San Francism, Qlifomia.
The above-presented interpretation process assumesthat all inferred propositions are equally likely to beincluded in a user?s argument. However, this is notnecessarily the case. We posit that a user is morelikely to imply (inside an inferential leap) proposi-tions previously seen by him/her than propositionss/he has never encountered. In this case, the lengthof the part of the message which conveys SysIntshould not only depend on the size of the interpre-tation (in terms of number of nodes and links), butalso on the probability that the user will employ inhis/her argument the nodes in that interpretation.
CN: Glycogen Storage Disease Type I
Two related issues are system stability and obsoles- cence, or forgetting. Stability concerns the ease with which well-established knowledge can be modified. If the behavior of the program is too dynamic, then it might easily get thrown off by one esoteric, or incorrect use of a phrase. It is not desirable that an adult native speaker would get his lexicon ruined by listening to a second language speaker. Forgetting involves inacces- sibility of unused phrases, or getting rid of incorrect hypotheses. Are incorrect hypotheses simply de-stroyed, or is there a more realistic model of obsoles- cence? These two issues involve quantitative reasoning which require implementation of strength of links and activation. These kind of problems demonstrate the limitations of a strictly qualitative approach, such as ours, which rely on manipulation of logical proposi-tions, and it raises the need for quantitative approaches such as connectionism \[Waltz85, McClelland86\], and spreading activation \[Anderson84, Charniak83\].
After merging at step 2, the message list left in an action group either has only one message, or it has more than one message with at least two distinct attributes between them. Instead of generating two separate sentences for (E2 (S1 $2) D1) and (El $3 D2), the system realizes that both the subject and verb are the same, thus it uses deletion on identity to generate "This refinement activated DLC for CSAs 3122 and 3130 in 1994 Q1 and \[this refinement ac-tivated\] ALL-DLC for CSA 3134 in 1994 Q3." For identical attributes across two messages (as shown in the bracketed phrase), a "deletion" feature is in-serted into the semantic FD, so that SURGE will suppress the output.
Boons, J., Gutllet, A. and Lecl~re, Ch. 1976b. La structure des phrases simplea en franFals. Clas~ea de constructions transitives, Rapport de recherches NO 6, Paris: University
"1 am knowing the answer, 2. For verb predications denoting processes, the progressive of the verb form entails the perfect form, i.e., x is V.ing - - x has V-ed.
Segment 5
TI-UC ? TI-FN.
Denise drank the bottle.
Hit T
The concept of markedness originated in phonology and is most systematical ly presented in the work of Trubetzkoy (1939). On this leve l , one can observe a clear and convincing correlat ion between the markedness property and the s tat i s - t ica l facts of language use. The unmarked phonemes, e.g. short vowels, occur with considerably higher frequencies than the marked ones, e.g. long vowels, in a l l languages where this bpposition has been investigated. Greenberg (1966:67-69) gives data from Icelandic, Sanskrit, Czech, Hungarian, Finnish, Karok and Chirichua to demonstrate this point. Similar s ta t i s t i ca l relat ions can be found with refer- ence to other unmarked vs. marked oppositions, such as voiceless vs. voiced ob-struents, non-palatal ized vs. palatal ized consonants, non-nasal vs. nasal vowels, etc. (For some s ta t i s t i ca l data in Czech, German, and Russian, cf. Ku~era and Monroe 1968.) This corre lat ion between structure and language s tat i s t i cs is important since i t supports the basic notion that the markedness re la t ion , in ref lect ing an informational economy in language coding, has the expected s tat i s - t ica l effects.
For example, f r o m the e2presSion we can derive t h a t T is a wtransformatianw and tha t A and @ B W are w s e t s M . From the expression we can derive t h a t 'B' is a "setu and that 'ap is an 'Subset of A'
Global Info1..1
Fulltext0.60.650.70.750.80.850.96 7 8 9 10 11 12 13 14
O?Donnell, and Chris Mellish. 2001. Beyondelaboration: The interaction of relationsand focus in coherent text. In T. Sanders,
Apparently tourism does not occur as a category in the DDC. On a closer inspection it came out that the categories which are most clearly related to tourism are 910.202:World travel guides and 910.4:Accounts of travel.
Knowledge Citation
Toshikazu Fukushima, Yutaka Ohyama nd Hitoshi Miyai
Marcus M. P., Santorini B. and Marcinkiewicz M. A.
Ours 0.8363 0.7673 0.1997
P~idagogischer Verlag Schwann.
ALL 297/750 272/750
The focus in D14 is the seminar of 014-1. The math department chairman is not directly related to the seminar.
DOP4 51% 68% 93.2%
Ph.D. thesis, Universiteit van Amsterdam.
Exact Match 19(70%) 489(75.9%)
utilization and Definition of rules
5. An Abst:ract Mach ine for
SYN: 3
Extensions to the PTQ fragment have had to deal with this issue of tense and how it interacts with the other components of a sentence. We agree with Dowty's basic premise that tense is really a property of the sentence (actually, clause) as a whole. This is particu-larly important when, as in our fragment, there are different kinds of sentences: declarative, wh-questions, yes-no-questions, and when-questions. For under a straightforward extension of the FI'Q treatment he number of rules would proliferate, since separate rules would be needed for each kind and tense of the sentence formed by conjoining a term and a VP. However, under Dowty's treatment, he tense rules applied after $4 in most cases must undo the syntactic work that it has done, viz. the inflection of the verb as third-person singular present ense. (Semantically, the treatment is the same, i.e., the untensed version denotes exactly what the present-tensed version does.) This syntactic undoing is both inelegant and computationally unattrac-tive. For this reason, we have incorporated into QE-III the additional categories of tensed sentences of each variety, and have modified $4 so that it creates an untensed sentence from a term and an IV. The strings of ultimate interest in the fragment, then, are the tensed sentences (categories T-t, T-WHQ, T-YNQ, and WHENQ). The following example from QE-III illus-trates this for a simple declarative sentence.
There is more than one predicate in (lb) and thus the predicates have to be in an ordination relation in order to satisfy the Multipredicate Constraint. This relation cannot be subor-dination, since no subordinating ORS is present; assuming co-ordination to be the only other possibility, and given that there is a coordinating conjunction between the two predicates, we con-clude that the predicates are in fact coordinate. In order to satisfy all of the constraints Attack must herefore r move John and Fred from PCL-L leaving hits as the sole member of that list. It must also remove guys and him from PCL-R leaving attack as the only word in that list. The configuration of these lists thus indicates that the only possible coordinates in (lb) are hits and attack.
R. Krovetz. 1993. Viewing Morphology as an InferenceProcess,. In Proceedings of the Sixteenth Annual In-ternational ACM SIGIR Conference on Research andDevelopment in Information Retrieval, pages 191?203.
old-fashioned housemaid in tile following advice to visitors to grand homes: (13) Quite a few of you have asked about tipping, and these days problems can arise. A nice old- fashioned housemaid, labelled by cap and apron, is easy enough; when you leave you will give her your little present as a thankyou for looking af-ter you. It is the 'lady who obliges' thai can con-found you; on that point, tile simplest way is to quietly consult your hostess.
3) Use syntactic and semantic constraints to eliminate antecedent candidates.
Concept Grammar Rule Deficiency
Suppose that $, O, and V are nontermlna ls which are fur ther expanded by appropr ia te rewri te rules. R ight hand side of such expans ions can also show word order var iat ions as shown in (2.9).
Computational Linguistics Volume 23, Number 2 semr structural floating % Relation 1 marked as structural by the content planner % Stockton scored 45 points name performance \[cat p layer \ ] actor \[1\] name Stockton relation1 surname John perf \[2\] value 45 unit points % Relation 2 marked as floating by the content planner % This performance improves Stockton's maximum relation2 args past_perf \[3\] \[\] % Past performance that the new performance \[2\] improves: % Maximum of the set of all scoring+ performances scored by Stockton cat maximum cat set ref _set generic_elf actor \[1\] cat statistic perf unit points
The real number E is added to the total score whenever aphrase satisfying Body fills any slot, or is used as a conjunct in a coordinate structure, or is taken as a top-level analysis.
When generating a text from a fact base in VINST the text becomes very tedious to read since the text is very redundant and does not feel correct conceptually. To make the text smoother to read a new architecture is suggested where a new aggregation rule from (Dalianis & Hovy 1993) is suggested to be used, namely predicate grouping rule.
University of Western Ontario
The transition is matched to bind variables in the head.
3. Recursively using substitution - - i.e., when Rl and Rz are identical, except that Rl contains a referring expression subRl exactly where Rz contains a referring expression subRz, and 8ubRl and subR2 belong to the same individ- uating set.
The task was to classify a given paraphrase pairinto either left, right, or comparable. Model M ?soutput class for (si; sj) was given by
XSL Transformations (XSLT) 1.0
Two main theorems establish the correctness of derivable items w.r.t, derivable configurations.
MIT Press.
CLAIRE, CLAIRE 80.9
SU sets the reigster of t he - higher level processing
Contextual information and the mapping from WordNet synsets to Cilin sense tags deal with word sense disambiguation. The average performance is 63.36% when small categories are used, and 1, 2 and 3 candidates are proposed for low, middle and high ambiguous words. The performance of tagging unknown words is 34.35%, which is much better than that of baseline mode.
experiments, one of these words is always a verb, since this yields the most important GRs. The other word is the head of the phrase which is annotated with this grammatical relation in the treebank. A preposition is the head of a PP, a noun of an NP and so on. Defining relations to hold between heads means that the algorithm can, for example, find a subject relation between a noun and a verb without necessarily having to make decisions about the precise boundaries of the subject NP.
from the meaning of the component phrases.
Microsoft Corp. classaction lawsuit struggle against SonyIntel Corp. a petition in federal court Apple ComputerComputer an appeal were filed General MotorsPower a motion charging General Electric
Computational Linguistics, 20(2):301?317.
Grandchamp, 1994).
Since only numbers can be represented in a continuous domain, the elements of the domain are defined by giv-ing the endpoints of the domain (or closed interval) and the unit size of representation is used in computing the distance between fillers. When defined in this manner, the same scoring function that was used for an ordered domain with single fillers (namely Equation 1) can be used to compute the penalty for continuous domain sets as well.
Symposium on Biocomputing, 6, 483-96.
Cases, " i ta-morat-ta"
Note that we allow the treatment of clauses with VP coordination (subject ellipsis) as com-plex coordinated clauses as done in Kameyalna (1998), thus handling subject ellipsis as a dis-course pronoun; our algorithm does not; insist on this view however.
set Vi = ~-1 U A.
7. A problem that will not have escaped the reader's attention is that I have discussed parsing purely in terms of finding surface parse-trees (which hapEens to be the task which the UCREL group are engaged on). It is not obvious how to extend the annealing approach so as to yield deep parses. However, there is nothing about simulated annealing that makes it intrinsically inapplicable to the task of deep parsing. What needs to be done is to define a class of logically-possible deep parse-trees and a class of moves between them, and to find an evaluation function which takes any pairing of a deep structure with a surface word-sequence into a likelihood-value. This task is very different in kind from the work currently done by theoretical linguists and AI researchers interested in underlying or logical grammar, who tend to have little time for statistical thinking, but that is not to say that the task is necessarily senseless or impossible. Deep parsing, if possible at all, will presumably need to exploit semantic/"inferencing" consideratJons as well as information about grammar in the narrow sense, but nothing says that these matters might not be built into the evaluation function.
The problem with these heuristics i that when they are formulated loosely, as in the previous paragraph, they appear to conflict. In particular, in (2a), Right Associ-ation seems to call for the parse which makes for Mary a modifier of song.
? Parsing may already take place in concurrency to sentence production. Therefore the speaking time becomes available as computing time.
While the details of the curves vary depending on the particular triggers, this behavior appears to be universal. For triggers that appear too few times in the data for this behavior to exhibit itself, the curves emerge when the counts are pooled with those from a collection of other rare words. An example of this law of large numbers is shown in Figure 4.
In our ext)eriment , he obtained rules were applied to 1.7% of the sentences in a non-training corpus. For this group of sentences, 78.4% of the changes made in tagging results were an improvement. We also saw a 15.5 % improvement in tagging and parsing speed and an 8.0 % increase of parsable sentences.
ORG 79.71 39.89 53.17
Secondary Score 0.399 0.465
Universitgt Stuttgart
Figure 2.
Studies of the planning unit in sentence production \[Ford and Holmes, 1978\] give additional support o the psychological p ausibility of our model. They report hat deep clause instead of surface clause is the unit of sen-tence planning. This is consistent to our model which em-ploys CSCs, which account for deep propositional units and the realization of deep clauses as the basic units of sen-tence planning. They also report hat people are planning the next clause while speaking the current clause. This is exactly what our model is performing, and is consistent with our observations from transcripts of simultaneous interpretation.
7 Acknowledgments
Intelli~enc~e, Washington D.C., I~3o
Our transliteration algorithm maps an English word to its most likely Katakana possibilities.
Ph.D. Dissertation.
Keywords: Deixis, referent identification, NP analysis, parsing 1. In t roduct ion Various aspects of referent identification by hearers have been investigated in the last few years: It has been studied as a pro-cess of noun phrase resolution and attribute comparison (Lip- kis 1982), as a planned action (Cohen 1981, 84), as a pro-cess which depends on focus (Grosz 1981), context (Reichman 1981), the mutual beliefs shared between speaker and hearer (Clark & Marshall 1.981) and the modality of linguistic com-munication (telephone vs. teletype, cf. Cohen 1984), and as a process which is prone to various sorts of conversational failure (Goodman 1985). In all of these studies, natural language is the only conversational medium. For identifying objects un-der discussion, the hearer can therefore only utilize the NL de-scriptions provided by the speaker, and information about the previous dialog and the task domain at hand.
Experiment 1: (Performance on the Wall Street Journal corpus). We used the two sets of data, from the XTAG parses and from the conversion of the Penn Treebank parses to evaluate the performance of the trigram model. Table 5 shows the performance on the two sets of data. The first data set, data collected from the XTAG parses, was split into 8,000 words of training and 3,000 words of test material. The data collected from converting the Penn Treebank was used in two experiments differing in the size of the training corpus--200,000 words 8and 1,000,000 words9--and tested on 47,000 words 1?.
Books, New York, 1987.
371 2.3 Funct ional Content of LF Se-quences Semantics, lexis, and syntax of LF sequences do not provide sufficient criteria for the choice of one sequence over all other comparable ones. These criteria nmst be provided by tile functional con lent we associate with each sequence (or reiteration and collocation relation, respectively). The flmctional content of tile reiteration and collocation relations listed in Table 1 is presented in Table 2. '~ strict repetition issisting~ restatement synonymy clarifying restatement superordination generalizing restatement, clarifying restatement, class-referencing metaphor, illustrative restatement, repetition pictoresque restatement, intensifying restatement negated antonymy contrastiw~ restatement conversion clarifying restatement, constituent enhancement, pespective shirting process-actor iden tiiication, actor-lntroduction cause-process i)rocessu al ellhallCeulellt~ causal enhancement, causer introduction initiMiz~ttion- process processual extension, beginning extension attribution attributive refinenmnt manifestation predicative relinement manifestatlon e halleelnent Table 2: Functional content of some reiteration and collocation relations 3 TOWARDS LEXICALLY B IASED
We extract the syntatic relations and make 5 windows (modifier, target word, modifiee, josa, predicate) as a context. We conduct a comparative experiment using the Uchimoto?s method, 5 windows (two words before/after the target word) and then we show that our method brings to a better result (Table 4).
John R. Gillett, John D. Lafferty, Harry
Autosegmental rules can also be expressed in this framework. Consider again the case of assimilation. The following diagram is the autosegmental rule corresponding to the SPE rule in (21). Here, ~place is a hybrid autosegment (see Section 4.1) ranging over places of articulation.
Peter Ford Dominey
2 System overview
Suppose there are Xdfeg=T;"#%$ such that Xeih . There is a least element, so X and e havemore than one maximal lower bound, jSk&jml andothers. But then +nj k j l 8 is upper-bounded andjSkojplqh , so the algorithm should not have termi-nated. Suppose instead that X!reih . Again, thealgorithm should not have terminated. So T;"#%$with W added is a complete lattice.
Assume that m is the order of the matrices A and B, n is the natural number associated with m as in Definition 3, and ? = n + 1. Let C = A x B and C / = G(Rp).
Verlag, pp.496-510
As is clear from the presentation of the algorithm, this part contains a rather time- consuming sorting procedure plus a floating point multiplication. It is obvious that this is an unacceptable time delay for real-time applications.
>> DECIDE: DOES *IRVINGBIRD* AGREE? *NO
SPECIAL USAGE NOTES: 1. This slot has a 0 or more valence to allow the situation where an unnamed entity participates in an event (or relation) of interest and is perhaps referenced only by a descriptive phrase.
The Relationship Between Tree Adjoining Grammars And Head Grammars, K. ViJay-Shanker, David J. Weir and Aravind
Table 2 :
A: havde alvorlig, ch. . . spmdbcrnsgulsot da han blev fcdt (had serious, uh ... infant icterus when he was born)
Dekker, New York, 1998 (published in
The final model selected can be based on a predefined cutoff value. In the case of measures uch as AIC and BIC, a cutoff on the value of the measure itself can be defined. In the case of statistics uch as G 2, the appropriate cutoff is a predetermined threshold efining statistical significance. Alternatively, all the models generated ur- ing search can be considered, and the one with the highest accuracy on a held-out portion of the training data can be selected as the final model (Kayaalp, Pedersen, and Bruce 1997; Wiebe, Bruce, and Duan 1997). 3The freely available software package CoCo performs forward and backward search using all of the measures described above (Badsberg 1995). 4 Pedersen, Bruce, and Wiebe (1997) present he results of experiments covarying these measures and the direction of search. In addition to these methods, Buntine (1996) describes other search strategies and measures, such as minimum description length, that can be used for model selection.
\[8\] Ackermann, Ammon, Ebert, Krause, Krug, Marschke, Sauerer, Zimmermann (ed.~ , Cobis. ComputergestUtztes BUro-lnformationssystem als Pilotanwendung von CONDOR, BMFT-report (Karlsruhe, 1982).
A practical part-of-speech tagger. In In Proc. of the Third Conference on Applied Natural Language Pro-cessing.
Other Forms of Ellipsis: Other forms of eb lipsis, besides VP-ellipsis can be handled substitu- tionally. For example, NP-ellipsis (e.g. Who slept? John.) is straightforwardly accommodated. PP- ellipsis (e.g. Who left on Tnesdayf And on Wednes-day?) requires ubstitutions for form constructions in QLF (not described here) representing preposi-tional phrases.
G.J Path, A. Resnick, and T. R. Savage. 1961. The formation of abstracts by the selection of sentences.
3 Exper iments and Results
American ESL and Japanese EFL." World
Cognitive Science Society Conference,
NOUN MODIFIERS
RYJIK K. (1980)
Possess(mother)  PER
69118 Heidelberg, Germany
Let us now follow one such recursive call: the one on the sub-FM inside a bold sub-frame in Fig. 6 to the right of the exception column in the third row group. The result of the first four aggregation steps of this recursive call is given in Fig. 7. This time it is the product dimension that has been left-shifted and that provided the basis for row sorting, row grouping and cell merging. Further recursive calls are now triggered. These calls are different from the preceding ones, however, in that at this point all the input constraints provided by the discourse planner have already been satisfied. It is thus now up to the sentence planner to choose along which dimension to perform the next factorization step. In the current implementation, the column with the lowest number of distinct values is always chosen. In our example, this translates as factoring along the time dimension for some row groups and along the space dimension for the others. The result of the recursive aggregation call on the sub-FM inside the bold frame of Fig. 7 is given in Fig. 8. In this case, factoring occurred along the time dimension. The fully aggregated FM resulting from all the recursive calls is given in Fig. 9. Note how the left to right embedding of its cells reflects exactly the left to right embedding of the phrases in the natural language summary of Fig. 4 generated from it.
Finally, we show two graphs which illustrate the convergence of the simulated annealing technique to the minimum energy ? ' (E) level. The second graph is a close-up of the final cycles of the complete process shown in the first graph.
lack of the adequate DW) in the dict ionary because of assuming the human usage of the dictionary.
AN IMPLEMENTATION NOTE
3. Utterances that identify relevant constraints, e.g., (a) We must get the oranges there by 3 PM.
The subj_char is Newt
Proceedings of NAACL?00, pages 63?69.
A.4.2. Hub 2: 5K Baseline. Because run times for full 20K systems were in some cases regarded as prohibitive, asecond baseline Hub test, requiring only a 5K lexicon, was permitted.
Features assigned to each element are e. g. "beginning of sentence" - unconditional sentence boundary assigned to some PES commands, or "capitalized" - this one is assigned to the word starting with exactly one uppercase letter. Among other features we use there are "common word", "uppercase only", "number" and some other classifying PES commands.
Harmon, D. 1999. "A Framework for Evaluation in TIDES." Presentation at TIDES Planning Workshop, with link at http://www.dyncorp- is.com/darpa/meetings/fides99jul/agenda.html, July 28-30, Leesburg, VA.
Russ Greiner, the anonymous reviewers, and especially Diane Horton for helpful comments on earlier drafts of this paper.
Use of this type of test is not limited to the fieldof Computational Linguistics. Wherever textheavy or even picture based topics are taughtuse of this type of test is possible.
\[Fillmore, Kay & O'Conner 84\] Charles Fillmore, Paul Kay & M.C. O'Conner, Regularity and idiomaticity in grammar: the case of let alne, University of California, Coginitive Science Working Paper, 1984.
Th is WqNT i s a p r e d i c t i o n that one reason Mqr may have k i ssecl John i s so t h a t he uou d knob1 she f e l t , a p o s i t i v e m o t i o n Y toward him.
Truth annotation
Dmttonanes How to Tell a Pine Cone from an Ice
Table 3 presents the results (F1-score) we obtained with the different search strategies for the thesaurus-based model: the Viterbi search , the complete one considering the first 100 and first 200 concept classes for each source word, and the subtree search with different values of n), and two different values for p, 5 and 10. The average rank is given next to each F1-score. As one can see, the combination significantly improves the results over the models alone, since the F1-score goes from 62% to 84%, a score that may be good enough to consider manual revisions.
teruko @cs.cmu.edu
Below we link a suffix-tree to more than one suffix- tree. In the notation of a-links we then use a sub-script indicating the suffix tree of the target node, in order to distinguish among different linkings. We now schematically specify the learning algorithm; additional computational details will be provided later in the discussion of the complexity.
I argue that this kind of reasoning underlies the propositional ct account. First, I show that Searle's conditions on referring are a special case of the conditions for requesting referent identification. Then, I show that if one extends the definition of IDENTIFY-REFERENT to cover Searle's more general concept of identificatiou, the IAA is applicable in the same circumstances a~s Searle's analysis. Because the IAA is independently motivated and covers more cases, it should be preferred.
Different feature sets can be evaluated by assessing how they influence the various control parameters of the HLsyn engine and the quality of the synthesised speech.
12. G. Salton and C. Buckley. Term Weighting Approaches in Automatic Text Retrieval. Information Processing 0
BIBLIOGRAPHY[1] Cardie, C. and Lehnert, W . (1991) "A Cognitively Plausible Approach to Understanding Complex Syntax" inProceedings of the Ninth National Conference on Artificial Intelligence . Anaheim, CA . pp. 117-124.[2] Lehnert, W. (1991) "Symbolic/Subsymbolic Sentence Analysis: Exploiting the Best of Two Worlds" i nAdvances in Connectionist and Neural Computation Theory. Vol 1 . (eds: J . Pollack and J . Barnden). pp. 135-164 . Ablex Publishing . Norwood, NJ. pp. 135-164.
University Press.
The remainder of the sentence is straightforward.
Descriptions produced by the algorithm fullfillthe criterion of co-extensivity. According to thisprinciple, a description is semantically correct ifit has the target as its referent (i.e., its extension).
Input Layer 89 units
Figure 1 depicts a comparative (Moore and Paris, 1993; Paris et al, 1991; Hovy, 1988) conceptual view of the system while Fig. 2 shows the system archi-tecture. A prototype has been fully implemented with the exception of the statechart axiomatization module, x 2 A Log ica l Semant ics for
Table 2 shows tim remflt of exl)erimenl,s for find~ ing 1)hrasal correspondences. The row with ALL in I;he l;yt)c cohlmn shows l;he l;ol;al accuracy of phrasal (:ol'r(~sl)ondo, n(:(~s found by the 1)rol)osed 1)rocedure.
2 Morphological Analysis
of COLING'90, pp.449-451 (August 1990).
? A lexicon session, chaired by Ralph Grishman (NYU).
4 Summary and Future Work
J2, STRAND: 113 0.81 0.61
For our second sample, we examined the first 52 instances of now taken from another four randomly chosen sides of tapes. 9 This sample included tokens from fifteen speak-ers, with exactly half produced by the host and half by others. I0 This time, six people (including the authors) determined whether instances were cue or non-cue before we analyzed the intonational features. We next examined phrasing and accent used with these tokens to test the hypotheses derived from our first sample.
Reading, MA.
Steedman introduces information structure asan integral part of the CCG formalism (Steed-man, 2000). He argues that there is a specificset of pitch accents in English that can accom-pany theme, and another set that accompanyrheme, the most common theme pitch accentbeing L+H* and the most common rheme pitchaccent being H*.2 The main pitch accent of theintonational phrase combined with a boundarytone gives us a complete intonational phrase.
At the start of this experiment in November 1994, we had no idea whether it was possible. While researchers were reporting good accuracy (upwards of 95%) for speech systems in simple question-answering tasks, our domain was considerably different with a much more spontaneous form of interaction.
INTRODUCTION lately, a proliferation of computational lexicon environments (CLE) has been noticed, which sign iftcantly influence the work on natural language (mainly, machine translation) (Byrd et al 1987), (Nircnburg and Raskin 1987), (Ritchie et al 1987) etc. With more and more computing power incor-porated, the modern CLEs are capable to process not only individual inflected words or derivatives but also idioms and collocations. Nonetheless, there are many applications in language industry which consider a CLE an unfordable luxury. We believe that such an objection may be refused if the CLE is so designed that it should function in a data-driven manner.
2.2 Building CSP graphs for good readersHaving reconfigured the results of our corpus analy-sis, we searched for the best way to model the choicesthey represent. We tried exploring both discriminantanalysis statistics and machine learning of decision treesin attempts to identify which feature(s) would mostclearly divide the data into groups. For most discourserelations, the positions of discourse cue phrases werethe most discriminating features.
In dealing with linguistic grammars, on the other hand, we clearly wish to exclude any expres-sion from signhood that is neither a phrase nor a word; these choices are meant o be exhaustive ina grammar. The fact that signs can be either words or phrases is explicit; what we need is a way to say that nothing else can be a sign.
A.1 Stopping Conditions of the Iterative Algorithm Let fi be the increase in the similarity value in iteration i: f~(X,y) = simi(X, y ) - simi_l(X, 32) (9) where X, y can be either words or sentences. For each item X, the algorithm stops updating its similarity values to other items (that is, updating its row in the similarity matrix) in the first iteration that satisfies maxyfi(X, 3;) _< ?, where c > 0 is a preset threshold.
By way of illustration, consider the following relational database, consisting of clinical history information about patients at a given hospital and of information about doctors working there: PAT I ENTS (PAT I D, SEX, AGE, D I S EASE, PHYS, D I AMOTHER) DOCTORS (DOC I D. NAME. SEX, SPECIALTY) where "PHYS" is the ID of the t reat ing phys ic ian, and "DIAMOTHER" is a boo lean field ind icat ing whether or not the pat ient ' s mother is d iabet ic . Here are the ru les for the one-p lace pred icate PATIENTS, the one-p lace pred icate SPECIALTIES, and the two- p lace pred icate TREATING-PHYSICIAN: PATIENTS => (PROJECT PATIENTS OVER PATID) SPECIALTIES => (PROJECT DOCTORS OVER SPECIALTY) TREATING-PHYSICIAN => (PROJECT (JOIN PATIENTS
All of the six sub-databases can be linked to the general database through four key fields, namely ENTRY, POS, HOMOMORPHISM and SENSE. As a result, the son knots can inherit all information from their father knots (Figure 1).
Model ?1 ?2 CER CER reduction
2) A f te r an input-KFC is matched, the matched twin-KFC is ac t ivated as "the f i r s t deuter" in a t r iggered deuter se-quence.
We havc therefore addcd a principle which says that constructions that are analysed as collocations (indi cated by tile type COLI.OCATION) are either head-adjunct structure or head-complement structures with specific rcstrietions holding between the head anti the adjunct or aNoticc that hcrc we use a simple VCl'Sion of HPSG based on (Pollard and Sag, 1987) whereas the actual i nplmncntation was based on (Pollard and Sag, to appear).
(Fritz pulls the brake. ) anziehen C0/CI/(C3) Die Fmtter zie/tt dem,
Does Mr. Brown have a book? @*We must stop to complain.
all aspect expressions, including both simple primary aspect forms and complex aspect forms, are systematically organized. We are implementing the system using the KPML multilingual generator (Bateman, 1997), interpreting the intrinsic semantics of each aspect form in terms of existing temporal logic theories. In this paper we focus on the generation of complex aspect.
bolette@cst ku dk
Generalized Quantifiers and Natural Language.
[14] D. Wu. 1997. Statistical inversion transduction grammars anbilingual parsing of parallel corpora. Computational
Copeck, Terry and Stan Szpakowicz. 2003. Pick-ing phrases, picking sentences. In DUC Work-shop at HLT/NAACL-2003 Workshop on
Jan Hajic?, Eva Hajic?ova?, Petr Pajas, Jarmila Panevova?,Petr Sgall, and Barbora Vidova?-Hladka?. 2001a.
Martin Plfitek
Namely, the morpho-phonenfic/graphemic rules can be tbrmalized in a general and very elegant way. It also has computational dvantages, but the lexicons must contain entries with diacritics and other sophistications in order to produce the needed surface Yorms. Non-linguist users need an easy-to- extend dictionary rote which words can be inserted (ahnost) automatically. The lexical basis oF Humor contain surface characters only and no transforma-tions are applied.
Fox Eng 13:13 9:14 194 171 s
Normally, compositionality in such structures simply refers to the application of the functional element, the verb, to its arguments. Yet, such examples indicate that in order to capture the systematicity of such ambiguity, something else is at play, where a richer notion of composition is operative. What then accounts for the polysemy of the verbs in the examples above? The basic idea I will pursue is the following. Rather than treating the expressions that behave as arguments to a function as simple, passive objects, imagine that they are as active in the semantics as the verb itself. The product of function application would be sensitive to both the function and its active argument. Something like this is suggested in Keenan and Faltz (1985), as the Meaning-Form Correlation Principle. I will refer to such behavior as cocompositionality (see below). What I have in mind can best be illustrated by returning to the examples in 28.
presented fo r COLING--86
Q-hypotheses 67 60 16 71 52
2http : / / c r l . ransu, edu/sh i raz 3ht tp : / / c r l . nmsu. edu/exped i t ion we developed a, morphological grammar for Per- siai~ using a unifies.lion-based formalism (Zajac, 1998). A sample rule is showtt in Figure 6 (of.
Paola Merlo Modularity and Information Content Classes
Z;tl Forme et Fonction ,o
Workshop, pp. 187-192.
4. Construct a list, Arg-List, of the phrases which fill the SUBCAT list slots of
Basic 96.6 92.3 94.4 76.3 91.9 83.1
Sentence no./ LINK =IR previous mention K/D the price R 1~apartment the 33-year-old housewife = 1/Y.J. Park the past 15 years K the inequities in the current land-ownership system - - D In case of doubt just leave the line in blank and comment at the back of the page using the key number to identify the DD you are commenting on.
As a result, it was shown that about 70% (952) of all utterances should be improved to use polite expressions. This result shows that a cur-rent translation system is not enough to make a conversation smoothly. Not surprisingly, if all expressions were polite, some Japanese speakers would feel insulted. Therefore, Japanese speak-ers do not have to use polite expression in all utterances.
4Due to the smaller grammar and lexicon of Clark et al, ourparser can only be evaluated on slightly over 94% of the sen-tences in section 23, whereas the figures for Clark et al (2002)are on 97%.
Thesis, The University of Western Ontario.
Adv 88.3% 8.51% 3.19% 100% 382 78 36 496
Figure 4: left, a derived tree, middle, its derivation, right, an elementary tree participating in the derivation.
Linguistic Data Consortium
A. Peters and J, Kock (1997), The digital phone operator, User appreciation and evaluation of the VIOS speech recognition system, Technical Re-port 97-05, Alparon, Delft University of Technol-ogy.
3.7 Presuppositions and Implicatures
Hiroshi Kinukawa
Tree Maximum Rooc
Benjamin Han. 2003. Text temporal analysis. Researchstatus summary. Draft of January 2003.
VSM and come comparably to global
4-3-11 T~keda, Kofu 4(10 ,b~pan
Ingenu ine nodes can be removed from the graph U w i thout a f fec t ing the language accepted by G = <U, S, P>.
