{"total": {"NONE": 94, "TOKENIZATION_ERROR": 16452, "OCR_ERROR": 39, "MIXED": 4357}, "correct": {"google": {"NONE": 91, "TOKENIZATION_ERROR": 569, "OCR_ERROR": 15, "MIXED": 50}, "BS-bid-OCR": {"NONE": 91, "TOKENIZATION_ERROR": 15878, "OCR_ERROR": 0, "MIXED": 29}, "BS-bid-OCR+google": {"NONE": 91, "TOKENIZATION_ERROR": 15856, "OCR_ERROR": 14, "MIXED": 1874}}, "sequences": [{"corrupt": {"tokens": ["Cnsistencyaraongmatrixelementsandmassdifferences"], "labels": ["WRONG"]}, "correct": {"tokens": ["Consistency", "among", "matrix", "elements", "and", "mass", "differences"], "labels": ["MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["Cnsistencyaraongmatrixelementsandmassdifferences"], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["Cnsistency", "araong", "matrix", "elements", "and", "mass", "differences"], "labels": ["WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["Consistency", "among", "matrix", "elements", "and", "mass", "differences"], "labels": ["MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["Heuce,"], "labels": ["WRONG"]}, "correct": {"tokens": ["Hence,"], "labels": ["OCR_ERROR"]}, "predicted": {"google": {"tokens": ["Heuce,"], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["Heuce,"], "labels": ["WRONG"]}, "BS-bid-OCR+google": {"tokens": ["Heuce,"], "labels": ["WRONG"]}}}, {"corrupt": {"tokens": ["wherethescale'ofnon-c0mmutativity\u039bisdefiedas"], "labels": ["WRONG"]}, "correct": {"tokens": ["where", "the", "scale", "of", "non-commutativity", "\u039b", "is", "defined", "as"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["wherethescale'ofnon-c0mmutativity\u039bisdefiedas"], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["where", "the", "scale'", "of", "non-c0mmutativity", "\u039b", "is", "defied", "as"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["where", "the", "scale'", "of", "non-commutativity", "\u039b", "is", "defined", "as"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["Conclusions"], "labels": ["NONE"]}, "correct": {"tokens": ["Conclusions"], "labels": ["NONE"]}, "predicted": {"google": {"tokens": ["Conclusions"], "labels": ["NONE"]}, "BS-bid-OCR": {"tokens": ["Conclusions"], "labels": ["NONE"]}, "BS-bid-OCR+google": {"tokens": ["Conclusions"], "labels": ["NONE"]}}}, {"corrupt": {"tokens": ["and"], "labels": ["NONE"]}, "correct": {"tokens": ["and"], "labels": ["NONE"]}, "predicted": {"google": {"tokens": ["and"], "labels": ["NONE"]}, "BS-bid-OCR": {"tokens": ["and"], "labels": ["NONE"]}, "BS-bid-OCR+google": {"tokens": ["and"], "labels": ["NONE"]}}}, {"corrupt": {"tokens": ["ThispaperisanoverviewofwhatwehaveachievedduringthepasttenyearsinthisnewfieldofBiology:theroleofw~termemoryandele(:tromAagneticwavesinbiologic~lprocesses,in?cludingpathologicalcon(titions.Thereporteddalaisnotonlyofteoreticalinterest,butleadstomanymedicalapplications."], "labels": ["WRONG"]}, "correct": {"tokens": ["This", "paper", "is", "an", "overview", "of", "what", "we", "have", "achieved", "during", "the", "past", "ten", "years", "in", "this", "new", "field", "of", "Biology:", "the", "role", "of", "water", "memory", "and", "electromagnetic", "waves", "in", "biological", "processes,", "including", "pathological", "conditions.", "The", "reported", "data", "is", "not", "only", "of", "theoretical", "interest,", "but", "leads", "to", "many", "medical", "applications."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["ThispaperisanoverviewofwhatwehaveachievedduringthepasttenyearsinthisnewfieldofBiology:theroleofw~termemoryandele(:tromAgnetic", "waves", "biologic~processes,in?cludingpathologicalcon(titions.Thereporteddalaisnotonlyofteoreticalinterest,butleadstomanymedicalapplications."], "labels": ["WRONG", "TOKENIZATION_ERROR", "WRONG"]}, "BS-bid-OCR": {"tokens": ["This", "paper", "is", "an", "overview", "of", "what", "we", "have", "achieved", "during", "the", "past", "ten", "years", "in", "this", "new", "field", "of", "Biology:", "the", "role", "of", "w~ter", "memory", "and", "ele(:tromAagnetic", "waves", "in", "biologic~l", "processes,", "in?cluding", "pathological", "con(titions.", "The", "reported", "dala", "is", "not", "only", "of", "teoretical", "interest,", "but", "leads", "to", "many", "medical", "applications."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["This", "paper", "is", "an", "overview", "of", "what", "we", "have", "achieved", "during", "the", "past", "ten", "years", "in", "this", "new", "field", "of", "Biology:", "the", "role", "of", "w~ter", "memory", "and", "ele(:tromAgnetic", "waves", "in", "biologic~l", "processes,", "including", "pathological", "con(titions.", "The", "reported", "data", "is", "not", "only", "of", "theoretical", "interest,", "but", "leads", "to", "many", "medical", "applications."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["altd"], "labels": ["WRONG"]}, "correct": {"tokens": ["and"], "labels": ["OCR_ERROR"]}, "predicted": {"google": {"tokens": ["altd"], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["altd"], "labels": ["WRONG"]}, "BS-bid-OCR+google": {"tokens": ["altd"], "labels": ["WRONG"]}}}, {"corrupt": {"tokens": ["Logaritbmicearopycorrechologr\\aphicdarkenargywithF(R,T)gravity"], "labels": ["WRONG"]}, "correct": {"tokens": ["Logarithmic", "entropy", "corrected", "holographic", "dark", "energy", "with", "F(R,", "T)", "gravity"], "labels": ["MIXED", "MIXED", "MIXED", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["Logaritbmicearopycorrechologr\\aphicdarkenargywithF(R,T)gravity"], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["Logaritbmic", "earopy", "correc", "hologr\\aphic", "dark", "enargy", "with", "F(R,", "T)", "gravity"], "labels": ["WRONG", "WRONG", "WRONG", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["Logarithmic", "europy", "correct", "hologr\\aphic", "dark", "energy", "with", "F(R,", "T)", "gravity"], "labels": ["MIXED", "WRONG", "WRONG", "WRONG", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["whichimpliesthat"], "labels": ["WRONG"]}, "correct": {"tokens": ["which", "implies", "that"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["which", "implies", "that"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR": {"tokens": ["which", "implies", "that"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["which", "implies", "that"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["beaslnoothfunctiononN\u03a3supportedinN\u03a3\u03bb\u03b4thatequals1onN\u03a3\u03bb\u03b41with0<\u03b41<\u03b4and~\u2264\u03b71\u22641."], "labels": ["WRONG"]}, "correct": {"tokens": ["be", "a", "smooth", "function", "on", "N\u03a3", "supported", "in", "N\u03a3\u03bb\u03b4", "that", "equals", "1", "on", "N\u03a3\u03bb\u03b41", "with", "0", "<", "\u03b41", "<", "\u03b4", "and", "0", "\u2264", "\u03b71", "\u2264", "1."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["beaslnoothfunctiononN\u03a3supportedinN\u03a3\u03bb\u03b4thatequals1onN\u03a3\u03bb\u03b41with0<\u03b41<\u03b4and~\u2264\u03b71\u22641."], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["be", "a", "slnooth", "function", "on", "N\u03a3", "supported", "in", "N\u03a3\u03bb\u03b4", "that", "equals", "1", "on", "N\u03a3\u03bb\u03b41", "with", "0", "<", "\u03b41", "<", "\u03b4", "and", "~", "\u2264", "\u03b71", "\u2264", "1."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["be", "a", "smooth", "function", "on", "N\u03a3", "supported", "in", "\u03a3\u03bb\u03b4", "that", "equals", "1", "on", "N\u03a3\u03bb\u03b41", "with", "0", "<", "\u03b41", "<", "\u03b4", "and", "~", "\u2264", "\u03b71", "\u2264", "1."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["ManipulatingAndrecvandMajaranaBoundStateswithmicrowaves"], "labels": ["WRONG"]}, "correct": {"tokens": ["Manipulating", "Andreev", "and", "Majorana", "Bound", "States", "with", "microwaves"], "labels": ["TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["ManipulatingAndrecvandMajaranaBoundStateswithmicrowaves"], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["Manipulating", "Andrecv", "and", "Majarana", "Bound", "States", "with", "microwaves"], "labels": ["TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["Manipulating", "Andrecv", "and", "Majorana", "Bound", "States", "with", "microwaves"], "labels": ["TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["Theweakeigenstatesarerelatedtothemasseigenstittesasfollows:"], "labels": ["WRONG"]}, "correct": {"tokens": ["The", "weak", "eigenstates", "are", "related", "to", "the", "mass", "eigenstates", "as", "follows:"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["Theweakeigenstatesarerelatedtothemasseigenstittesasfollows:"], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["The", "weak", "eigenstates", "are", "related", "to", "the", "mass", "eigenstittes", "as", "follows:"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["The", "weak", "eigenstates", "are", "related", "to", "the", "mass", "eigenstates", "as", "follows:"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["Thecatalog"], "labels": ["WRONG"]}, "correct": {"tokens": ["The", "catalog"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["Thecatalog"], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["The", "catalog"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["The", "catalog"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["6l.2ObservatlonsVIIIversusthe2/3slopeoftheBlOs-vs.-nHplot"], "labels": ["WRONG"]}, "correct": {"tokens": ["6.2", "Observations", "VIII", "versus", "the", "2/3", "slope", "of", "the", "Blos-vs.-nH", "plot"], "labels": ["MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["6l.2ObservatlonsVIIIversusthe2/3slopeoftheBlOs-vs.-nHplot"], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["6l.2", "Observatlons", "VIII", "versus", "the", "2/3", "slope", "of", "the", "BlOs-vs.-nH", "plot"], "labels": ["WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["6l.2", "Observations", "VIII", "versus", "the", "2/3", "slope", "of", "the", "BlOs-vs.-nH", "plot"], "labels": ["WRONG", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["therebygiving"], "labels": ["WRONG"]}, "correct": {"tokens": ["thereby", "giving"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["thereby", "giving"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR": {"tokens": ["thereby", "giving"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["thereby", "giving"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["Wenextgivealawerbouadonthepowerofnoisyqunntumcircuits:weshowthanoi\"syquantumcir(;uitscansimulategeneralquantumcircuits,withanexponentialcost."], "labels": ["WRONG"]}, "correct": {"tokens": ["We", "next", "give", "a", "lower", "bound", "on", "the", "power", "of", "noisy", "quantum", "circuits:", "We", "show", "that", "noisy", "quantum", "circuits", "can", "simulate", "general", "quantum", "circuits,", "with", "an", "exponential", "cost."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["Wenextgivealawerbouadonthepowerofnoisyqunntumcircuits:weshowthanoi\"squantum", "cir(;uit", "can", "simulate", "general", "quantum", "circuits,with", "an", "exponential", "cost."], "labels": ["WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR": {"tokens": ["We", "next", "give", "a", "lawer", "bouad", "on", "the", "power", "of", "noisy", "qunntum", "circuits:", "we", "show", "tha", "noi\"sy", "quantum", "cir(;uits", "can", "simulate", "general", "quantum", "circuits,", "with", "an", "exponential", "cost."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["We", "next", "give", "a", "lower", "bound", "on", "the", "power", "of", "noisy", "quantum", "circuits:", "we", "show", "tha", "noi\"sy", "quantum", "cir(;uits", "can", "simulate", "general", "quantum", "circuits,", "with", "an", "exponential", "cost."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["Let"], "labels": ["NONE"]}, "correct": {"tokens": ["Let"], "labels": ["NONE"]}, "predicted": {"google": {"tokens": ["Let"], "labels": ["NONE"]}, "BS-bid-OCR": {"tokens": ["Let"], "labels": ["NONE"]}, "BS-bid-OCR+google": {"tokens": ["Let"], "labels": ["NONE"]}}}, {"corrupt": {"tokens": ["First~Ipecifythebasisvector~fortheamb<iguouscirections.Thesevectorsare"], "labels": ["WRONG"]}, "correct": {"tokens": ["First,", "I", "specify", "the", "basis", "vectors", "for", "the", "ambiguous", "directions.", "These", "vectors", "are"], "labels": ["MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["First~Specify", "Basis", "Vector~fortheamb<iguouscirections.Thesevectorsare"], "labels": ["WRONG", "WRONG", "WRONG"]}, "BS-bid-OCR": {"tokens": ["First~", "I", "pecify", "the", "basis", "vector~", "for", "the", "amb<iguous", "cirections.", "These", "vectors", "are"], "labels": ["WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["First~", "I", "specify", "the", "basis", "vector~", "for", "the", "amb<iguous", "directions.", "These", "vectors", "are"], "labels": ["WRONG", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["Heretheextinctioncoefficient\u03c7(z,\u03bb)isthesumoftheabsorptioncoefficient\u03ba(z,\u03bb)andthe8catteringcoefficient\u03c3(z,\u03bb)atheightzandwa.vele~lgth\u03bb.T(?z)isthdteml)eratureatheights."], "labels": ["WRONG"]}, "correct": {"tokens": ["Here", "the", "extinction", "coefficient", "\u03c7(z,", "\u03bb)", "is", "the", "sum", "of", "the", "absorption", "coefficient", "\u03ba(z,", "\u03bb)", "and", "the", "scattering", "coefficient", "\u03c3(z,", "\u03bb)", "at", "height", "z", "and", "wavelength", "\u03bb.", "T(z)", "is", "the", "temperature", "at", "height", "z."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED"]}, "predicted": {"google": {"tokens": ["Heretheextinctioncoefficient\u03c7(z,\u03bb)isthesumoftheabsorptioncoefficient\u03ba(z,\u03bb)andthe8catteringcoefficient\u03c3(z,\u03bb)atheightzandwa.vele~lgth\u03bb.T(?z)ist", "html)eratureatheights."], "labels": ["WRONG", "WRONG"]}, "BS-bid-OCR": {"tokens": ["Here", "the", "extinction", "coefficient", "\u03c7(z,", "\u03bb)", "is", "the", "sum", "of", "the", "absorption", "coefficient", "\u03ba(z,", "\u03bb)", "and", "the", "8cattering", "coefficient", "\u03c3(z,", "\u03bb)", "at", "height", "z", "and", "wa.vele~lgth", "\u03bb.", "T(?z)", "is", "thd", "teml)erature", "at", "heights."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "WRONG"]}, "BS-bid-OCR+google": {"tokens": ["Here", "the", "extinction", "coefficient", "\u03c7(z,", "\u03bb)", "is", "the", "sum", "of", "the", "absorption", "coefficient", "\u03ba(z,", "\u03bb)", "and", "the", "8cattering", "coefficient", "\u03c3(z,", "\u03bb)", "at", "height", "z", "and", "wa.vele~lgth", "\u03bb.", "T(?z)", "is", "the", "temp)erature", "at", "heights."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "MIXED", "WRONG", "TOKENIZATION_ERROR", "WRONG"]}}}, {"corrupt": {"tokens": ["For"], "labels": ["NONE"]}, "correct": {"tokens": ["For"], "labels": ["NONE"]}, "predicted": {"google": {"tokens": ["For"], "labels": ["NONE"]}, "BS-bid-OCR": {"tokens": ["For"], "labels": ["NONE"]}, "BS-bid-OCR+google": {"tokens": ["For"], "labels": ["NONE"]}}}, {"corrupt": {"tokens": ["FigureCap\\tions:"], "labels": ["WRONG"]}, "correct": {"tokens": ["Figure", "Captions:"], "labels": ["TOKENIZATION_ERROR", "MIXED"]}, "predicted": {"google": {"tokens": ["FigureCap\\tions:"], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["Figure", "Cap\\tions:"], "labels": ["TOKENIZATION_ERROR", "WRONG"]}, "BS-bid-OCR+google": {"tokens": ["Figure", "Cap\\tions:"], "labels": ["TOKENIZATION_ERROR", "WRONG"]}}}, {"corrupt": {"tokens": ["ACKNOWLEDGMENT"], "labels": ["NONE"]}, "correct": {"tokens": ["ACKNOWLEDGMENT"], "labels": ["NONE"]}, "predicted": {"google": {"tokens": ["ACKNOWLEDGMENT"], "labels": ["NONE"]}, "BS-bid-OCR": {"tokens": ["ACKNOWLEDGMENT"], "labels": ["NONE"]}, "BS-bid-OCR+google": {"tokens": ["ACKNOWLEDGMENT"], "labels": ["NONE"]}}}, {"corrupt": {"tokens": ["where"], "labels": ["NONE"]}, "correct": {"tokens": ["where"], "labels": ["NONE"]}, "predicted": {"google": {"tokens": ["where"], "labels": ["NONE"]}, "BS-bid-OCR": {"tokens": ["where"], "labels": ["NONE"]}, "BS-bid-OCR+google": {"tokens": ["where"], "labels": ["NONE"]}}}, {"corrupt": {"tokens": ["Asummaryoftheinformsationsonourdatasampleisreportedintab.I."], "labels": ["WRONG"]}, "correct": {"tokens": ["A", "summary", "of", "the", "informations", "on", "our", "data", "sample", "is", "reported", "in", "tab.I", "."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["Asummaryoftheinformsationsonourdatasampleisreportedintab.I."], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["A", "summary", "of", "the", "informsations", "on", "our", "data", "sample", "is", "reported", "in", "tab.", "I."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG"]}, "BS-bid-OCR+google": {"tokens": ["A", "summary", "of", "the", "information", "on", "our", "data", "sample", "is", "reported", "in", "the", "tab.", "I"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "WRONG"]}}}, {"corrupt": {"tokens": ["observethat"], "labels": ["WRONG"]}, "correct": {"tokens": ["Observe", "that"], "labels": ["MIXED", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["observe", "that"], "labels": ["WRONG", "TOKENIZATION_ERROR"]}, "BS-bid-OCR": {"tokens": ["observe", "that"], "labels": ["WRONG", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["observe", "that"], "labels": ["WRONG", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["ThescalarpartoftheEMaction"], "labels": ["WRONG"]}, "correct": {"tokens": ["The", "scalar", "part", "of", "the", "EM", "action"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["ThescalarpartoftheEMaction"], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["The", "scalar", "part", "of", "the", "EM", "action"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["The", "scalar", "part", "of", "the", "EM", "action"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["whiclhhasthesolution"], "labels": ["WRONG"]}, "correct": {"tokens": ["which", "has", "the", "solution"], "labels": ["MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["whiclhhasthesolution"], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["whiclh", "has", "the", "solution"], "labels": ["WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["which", "has", "the", "solution"], "labels": ["MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["Finally,weshouldalsotakeintoaccountthegenerator,whichc?ontributesfirstatthe'PNnonspinlngsector,withthefollowinggeneralform"], "labels": ["WRONG"]}, "correct": {"tokens": ["Finally,", "we", "should", "also", "take", "into", "account", "the", "generator,", "which", "contributes", "first", "at", "the", "2PN", "non", "spinning", "sector,", "with", "the", "following", "general", "form"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["Finally,weshouldalsotakeintoaccountthegenerator,whichc?ontributesfirstatthe'PNnonspinlngsector,withthefollowinggeneralform"], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["Finally,", "we", "should", "also", "take", "into", "account", "the", "generator,", "which", "c?ontributes", "first", "at", "the", "'PN", "nonspinlng", "sector,", "with", "the", "following", "general", "form"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["Finally,", "we", "should", "also", "take", "into", "account", "the", "generator,", "which", "contributes", "first", "at", "the", "'PN", "non", "spin", "lng", "sector,", "with", "the", "following", "general", "form"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["Weproceednowwiththeproofoftheorem1,considcringthecasewheren1doesnotvan1shidentically."], "labels": ["WRONG"]}, "correct": {"tokens": ["We", "proceed", "now", "with", "the", "proof", "of", "theorem", "1,", "considering", "the", "case", "where", "n1", "does", "not", "vanish", "identically."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["Weproceednowwiththeproofoftheorem1,considcringthecasewheren1doesnotvan1shidentically."], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["We", "proceed", "now", "with", "the", "proof", "of", "theorem", "1,", "considcring", "the", "case", "where", "n1", "does", "not", "van1sh", "identically."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["We", "proceed", "now", "with", "the", "proof", "of", "theorem", "1,", "considering", "the", "case", "where", "n1", "does", "not", "van1sh", "identically."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["Thesecondtypeofmassfunctionfittin~appl:oachistofitdire?ctlythemultip\\l1ityfunction"], "labels": ["WRONG"]}, "correct": {"tokens": ["The", "second", "type", "of", "mass", "function", "fitting", "approach", "is", "to", "fit", "directly", "the", "multiplicity", "function"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["Thesecondtypeofmassfunctionfittin~appl:oachistofitdire?ctlythemultip\\l1ityfunction"], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["The", "second", "type", "of", "mass", "function", "fittin~", "appl:oach", "is", "to", "fit", "dire?ctly", "the", "multip\\l1ity", "function"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["The", "second", "type", "of", "mass", "function", "fitting~", "appl:coach", "is", "to", "fit", "directly", "the", "multip\\l1ity", "function"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["Thisisachievedbyputting"], "labels": ["WRONG"]}, "correct": {"tokens": ["This", "is", "achieved", "by", "putting"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["Thisisachievedbyputting"], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["This", "is", "achieved", "by", "putting"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["This", "is", "achieved", "by", "putting"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["Thustherearephysica2problemswithallofthesemodels:theComptonizeudiscannote~plainthenarrowrangei.ninferl\"eds,teperatures,smearedreflectkmcannotproducetilestrogestsoftexcessesseenifthediscisinhydrostaticequilibrium,andsmearedabsorptionmequixesafast?wind/jetwhichisnotreadilyssociatedwiththepropertiesofanyknowncompofnent."], "labels": ["WRONG"]}, "correct": {"tokens": ["Thus", "there", "are", "physical", "problems", "with", "all", "of", "these", "models:", "the", "Comptonized", "disc", "cannot", "explain", "the", "narrow", "range", "in", "inferred", "temperatures,", "smeared", "reflection", "cannot", "produce", "the", "strongest", "soft", "excesses", "seen", "if", "the", "disc", "is", "in", "hydrostatic", "equilibrium,", "and", "smeared", "absorption", "requires", "a", "fast", "wind/jet", "which", "is", "not", "readily", "associated", "with", "the", "properties", "of", "any", "known", "component."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED"]}, "predicted": {"google": {"tokens": ["Thustherearephysica2problemswithallofthesemodels:theComptonizeudiscannote~plainthenarrowrangei.ninferl\"eds,teperatures,smearedreflectkmcannotproducetilestrogestsoftexcessesseenifthediscisinhydrostaticequilibrium,andsmearedabsorptionmequixesafast?wind/jetwhichisnotreadilyssociatedwiththepropertiesofanyknowncompofnent."], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["Thus", "there", "are", "physica2", "problems", "with", "all", "of", "these", "models:", "the", "Comptonizeudis", "cannot", "e~plain", "the", "narrow", "range", "i.n", "inferl\"eds,", "teperatures,", "smeared", "reflectkm", "cannot", "produce", "tile", "strogest", "soft", "excesses", "seen", "if", "the", "disc", "is", "in", "hydrostatic", "equilibrium,", "and", "smeared", "absorption", "mequixes", "a", "fast?", "wind/jet", "which", "is", "not", "readily", "ssociated", "with", "the", "properties", "of", "any", "known", "compofnent."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG"]}, "BS-bid-OCR+google": {"tokens": ["Thus", "there", "are", "physical", "problems", "with", "all", "of", "these", "models:", "the", "Comptonizeudis", "cannot", "e~plain", "the", "narrow", "range", "i.n", "inferno\"eds,", "temperatures,", "smeared", "reflect", "cannot", "produce", "tile", "strongest", "soft", "excesses", "seen", "if", "the", "disc", "is", "in", "hydrostatic", "equilibrium,", "and", "smeared", "absorption", "mequixes", "a", "fast?", "wind/jet", "which", "is", "not", "readily", "associated", "with", "the", "properties", "of", "any", "known", "component."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "MIXED", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED"]}}}, {"corrupt": {"tokens": ["Dep~rtmentofMatematicsCaliforniaInstituteofTechnologyrahulp@cco.caltecb.edu"], "labels": ["WRONG"]}, "correct": {"tokens": ["Department", "of", "Mathematics", "California", "Institute", "of", "Technology", "rahulp@cco.caltech.edu"], "labels": ["MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED"]}, "predicted": {"google": {"tokens": ["Dep~rtmentofMatematicsCaliforniaInstituteofTechnologyrahulp@cco.caltecb.edu"], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["Dep~rtment", "of", "Matematics", "California", "Institute", "of", "Technologyrahulp@cco.caltecb.edu"], "labels": ["WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG"]}, "BS-bid-OCR+google": {"tokens": ["Dep~rtment", "of", "Mathematics", "California", "Institute", "of", "Technologyrahulp@cco.caltecb.edu"], "labels": ["WRONG", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG"]}}}, {"corrupt": {"tokens": ["Obviously,fsorlaetimesthevisconsTingisunconditianallyunstableagainstnon-axisymmetricperturb?a\"tions."], "labels": ["WRONG"]}, "correct": {"tokens": ["Obviously,", "for", "late", "times", "the", "viscous", "ring", "is", "unconditionally", "unstable", "against", "non-axisymmetric", "perturbations."], "labels": ["TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED"]}, "predicted": {"google": {"tokens": ["Obviously,fsorlaetimesthevisconsTingisunconditianallyunstableagainstnon-axisymmetricperturb?a\"tions."], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["Obviously,", "fsor", "lae", "times", "the", "visconsTing", "is", "unconditianally", "unstable", "against", "non-axisymmetric", "perturb?a\"tions."], "labels": ["TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG"]}, "BS-bid-OCR+google": {"tokens": ["Obviously,", "for", "law", "times", "the", "visconsTing", "is", "unconditionally", "unstable", "against", "non-axisymmetric", "perturbation?a\"tions."], "labels": ["TOKENIZATION_ERROR", "MIXED", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG"]}}}, {"corrupt": {"tokens": ["InterpretingKURAMACarandBusSurveyData"], "labels": ["WRONG"]}, "correct": {"tokens": ["Interpreting", "KURAMA", "Car", "and", "Bus", "Survey", "Data"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["InterpretingKURAMACarandBusSurveyData"], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["Interpreting", "KURAMA", "Car", "and", "Bus", "Survey", "Data"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["Interpreting", "KURAMA", "Car", "and", "Bus", "Survey", "Data"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["REFERENCES"], "labels": ["NONE"]}, "correct": {"tokens": ["REFERENCES"], "labels": ["NONE"]}, "predicted": {"google": {"tokens": ["REFERENCES"], "labels": ["NONE"]}, "BS-bid-OCR": {"tokens": ["REFERENCES"], "labels": ["NONE"]}, "BS-bid-OCR+google": {"tokens": ["REFERENCES"], "labels": ["NONE"]}}}, {"corrupt": {"tokens": ["Methodstability"], "labels": ["WRONG"]}, "correct": {"tokens": ["Method", "stability"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["Method", "Stability"], "labels": ["TOKENIZATION_ERROR", "WRONG"]}, "BS-bid-OCR": {"tokens": ["Method", "stability"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["Method", "stability"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["isstructunrallycontrllab.1e,whereB(I)issomediagonalmatrixsatisfying"], "labels": ["WRONG"]}, "correct": {"tokens": ["is", "structurally", "controllable,", "where", "B(I)", "is", "some", "diagonal", "matrix", "satisfying"], "labels": ["TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["isstructunrallycontrllab.1e,whereB(I)is", "some", "diagonal", "matrix", "satisfying"], "labels": ["WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR": {"tokens": ["is", "structunrally", "contrllab.1e,", "where", "B(I)", "is", "some", "diagonal", "matrix", "satisfying"], "labels": ["TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["is", "structurally", "contrllab.1e,", "where", "B(I)", "is", "some", "diagonal", "matrix", "satisfying"], "labels": ["TOKENIZATION_ERROR", "MIXED", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["Osually\u03c01(B1)willbe5freeadiwilbeusefultoreplacethisparticularcrossedmodl~lebyagenealon<~."], "labels": ["WRONG"]}, "correct": {"tokens": ["Usually", "\u03c01(B1)", "will", "be", "free", "and", "it", "will", "be", "useful", "to", "replace", "this", "particular", "crossed", "module", "by", "a", "general", "one."], "labels": ["MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED"]}, "predicted": {"google": {"tokens": ["Osually\u03c01(B1)willbe5freeadiwilbeusefultoreplacethisparticularcrossedmodl~lebyagenealon<~."], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["Osually", "\u03c01(B1)", "will", "be", "5free", "adi", "wil", "be", "useful", "to", "replace", "this", "particular", "crossed", "modl~le", "by", "a", "geneal", "on<~."], "labels": ["WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG"]}, "BS-bid-OCR+google": {"tokens": ["Usually", "\u03c01(B1)", "will", "be", "5free", "adi", "will", "be", "useful", "to", "replace", "this", "particular", "crossed", "modl~le", "by", "a", "general", "on<~."], "labels": ["MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "WRONG"]}}}, {"corrupt": {"tokens": ["Soatransactionis156bytesl220bytesmaximum)l?nginbinaryformatand19Scharacters(275ch?aractersmaximum)longwithabase85readableencoding.OtherrepresentationscanbeuscdinASN1,XML,JSON,butitis1important~okeepthetransaci;tol~formatassimpleandassmallaspossible"], "labels": ["WRONG"]}, "correct": {"tokens": ["So", "a", "transaction", "is", "156", "bytes", "(220", "bytes", "maximum)", "long", "in", "binary", "format", "and", "195", "characters", "(275", "characters", "maximum)", "long", "with", "a", "base85", "readable", "encoding.", "Other", "representations", "can", "be", "used", "in", "ASN1,", "XML,", "JSON,", "but", "it", "is", "important", "to", "keep", "the", "transaction", "format", "as", "simple", "and", "as", "small", "as", "possible."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED"]}, "predicted": {"google": {"tokens": ["Soa", "Transaction", "Is", "156", "Bytes", "L220", "Bytes", "Maximum)l?nginbinaryformatand19S", "characters(275ch?characters", "maximum)longwithabase85readableencoding.OtherrepresentationscanbeuscdinASN1,XML,JSON,but", "it", "is", "important~okeepthetransaci;tol~formatassimpleandassmallaspossible"], "labels": ["WRONG", "WRONG", "WRONG", "TOKENIZATION_ERROR", "WRONG", "WRONG", "WRONG", "WRONG", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG"]}, "BS-bid-OCR": {"tokens": ["So", "a", "transaction", "is", "156", "bytesl", "220", "bytes", "maximum)", "l?ng", "in", "binary", "format", "and", "19S", "characters", "(275", "ch?aracters", "maximum)", "long", "with", "a", "base", "85", "readable", "encoding.", "Other", "representations", "can", "be", "uscd", "in", "ASN1,", "XML,", "JSON,", "but", "it", "is1", "important", "~o", "keep", "the", "transaci;tol~", "format", "as", "simple", "and", "as", "small", "as", "possible"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "MIXED", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG"]}, "BS-bid-OCR+google": {"tokens": ["So", "a", "transaction", "is", "156", "bytesl", "220", "bytes", "maximum)", "l?ng", "in", "binary", "format", "and", "19S", "characters", "(275", "characters", "maximum)", "long", "with", "a", "base", "85", "readable", "encoding.", "Other", "representations", "can", "be", "uscd", "in", "ASN1,", "XML,", "JSON,", "but", "it", "is1", "important", "~to", "keep", "the", "transaksi;tol~", "format", "as", "simple", "and", "as", "small", "as", "possible"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "MIXED", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG"]}}}, {"corrupt": {"tokens": ["and"], "labels": ["NONE"]}, "correct": {"tokens": ["and"], "labels": ["NONE"]}, "predicted": {"google": {"tokens": ["and"], "labels": ["NONE"]}, "BS-bid-OCR": {"tokens": ["and"], "labels": ["NONE"]}, "BS-bid-OCR+google": {"tokens": ["and"], "labels": ["NONE"]}}}, {"corrupt": {"tokens": ["AppendixA"], "labels": ["WRONG"]}, "correct": {"tokens": ["Appendix", "A"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["AppendixA"], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["Appendix", "A"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["Appendix", "A"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["Semantics"], "labels": ["NONE"]}, "correct": {"tokens": ["Semantics"], "labels": ["NONE"]}, "predicted": {"google": {"tokens": ["Semantics"], "labels": ["NONE"]}, "BS-bid-OCR": {"tokens": ["Semantics"], "labels": ["NONE"]}, "BS-bid-OCR+google": {"tokens": ["Semantics"], "labels": ["NONE"]}}}, {"corrupt": {"tokens": ["DOSGRs/AXPsANDRADIOAXPsMAVETHESA?MI~NATURE?"], "labels": ["WRONG"]}, "correct": {"tokens": ["DO", "SGRs/AXPs", "AND", "RADIO", "AXPs", "HAVE", "THE", "SAME", "NATURE?"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["DOSGRs/AXPsANDRADIOAXPsMAVETHESA?MI~NATURE?"], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["DOSGRs/AXPs", "AND", "RADIO", "AXPs", "MAVE", "THE", "SA?MI~NATURE?"], "labels": ["WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG"]}, "BS-bid-OCR+google": {"tokens": ["DOSGRs/AXPs", "AND", "RADIO", "AXPs", "MAVE", "THE", "SA?MI~NATURE?"], "labels": ["WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG"]}}}, {"corrupt": {"tokens": ["Here\u03c8(z)isthelogaritilmtcderivativeofthegammafnnc{ion,\u0393(z).Theeige?functions,E\u03bd,aregivenby"], "labels": ["WRONG"]}, "correct": {"tokens": ["Here", "\u03c8(z)", "is", "the", "logarithmic", "derivative", "of", "the", "gamma", "function,", "\u0393(z).", "The", "eigenfunctions,", "E\u03bd,", "are", "given", "by"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["Here\u03c8(z)is", "the", "logarithm", "il", "mtc", "derivative", "of", "the", "gammafn", "nc{ion,\u0393(z).Theage?functions,E\u03bd,are", "given", "by"], "labels": ["WRONG", "TOKENIZATION_ERROR", "WRONG", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR": {"tokens": ["Here", "\u03c8(z)", "is", "the", "logaritilmtc", "derivative", "of", "the", "gamma", "fnnc{ion,", "\u0393(z).", "The", "eige?functions,", "E\u03bd,", "are", "given", "by"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["Here", "\u03c8(z)", "is", "the", "logarithmic", "derivative", "of", "the", "gamma", "fnnc{ion,", "\u0393(z).", "The", "eigenfunctions,", "E\u03bd,", "are", "given", "by"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["UataRcduction"], "labels": ["WRONG"]}, "correct": {"tokens": ["Data", "Reduction"], "labels": ["MIXED", "MIXED"]}, "predicted": {"google": {"tokens": ["UataRcduction"], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["Uata", "Rcduction"], "labels": ["WRONG", "WRONG"]}, "BS-bid-OCR+google": {"tokens": ["Usta", "Reduction"], "labels": ["WRONG", "MIXED"]}}}, {"corrupt": {"tokens": ["Wetakeasbackgroundmetrictheexpr-ession"], "labels": ["WRONG"]}, "correct": {"tokens": ["We", "take", "as", "background", "metric", "the", "expression"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED"]}, "predicted": {"google": {"tokens": ["Wetakeasbackgroundmetrictheexpr-ession"], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["We", "take", "as", "background", "metric", "the", "expr-ession"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG"]}, "BS-bid-OCR+google": {"tokens": ["We", "take", "as", "background", "metric", "the", "expr-ession"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG"]}}}, {"corrupt": {"tokens": ["Themomentumisgi\\venby"], "labels": ["WRONG"]}, "correct": {"tokens": ["The", "momentum", "is", "given", "by"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["Themomentumisgi\\venby"], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["The", "momentum", "is", "gi\\ven", "by"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["The", "momentum", "is", "gi\\ven", "by"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["asdesired."], "labels": ["WRONG"]}, "correct": {"tokens": ["as", "desired."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["as", "desired."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR": {"tokens": ["as", "desired."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["as", "desired."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["Atm?crowavefrequencieswherecomplexreflectionandtra~nsmissionlneasurements(S-p~trameter)arecommon,itisdifficulttocharacterizebanisotropicmateials.~ThisdifficultystemsfrOmthefactthatthesematerialsorenecessarilydescribedbythemostgencralformoftheconsitutiverelations.Theremaybe36cRomplcxquantitiestodetermine,andthusstnandrdcoMplexreflectionandtransmisSionmeasurcmentsyieldincompleIeEMinformation.AtTHzandhigher\\frequcieswherepascsensitivemeasurementsarenotcommoni\\tiseveumoredifficult,althoughmel,hodssuchasellipsome~ryorTHztimedomainspectroscopymayproveusefSul.Furthersinceamagneticandelecl,ricresoltantresponstentersimilarlyintot\\[leli'rcsllelequations,itisdiffi,culttodeterminetheoriginofTherespcnse.Typicallsy,artificialmagneticmetamaterialsarecontcuctedfromconductingelements,andthusa?fullelectromagneticcharacterizationisanecessityisinccanelectricresponseisunavodble.Analyticatheorieshaveyieldevequtionsablcl;opredi(:?ttheresunantfrequellcy\u03c90andplasnlafrequency\u03c9pofmetamaterials.Howeverthereisalackofsuitabeanalyticalmthodscapa1)leofdeterminingthemanyvaryingandcomplicatedEMproperties.$imulationeiastlllheavilyrelieduponand,asofyet,isstill'unablet?odetcrm?ineanddistinguishingbiailisotropiresponse."], "labels": ["WRONG"]}, "correct": {"tokens": ["At", "microwave", "frequencies", "where", "complex", "reflection", "and", "transmission", "measurements", "(S-parameter)", "are", "common,", "it", "is", "difficult", "to", "characterize", "bianisotropic", "materials.", "This", "difficulty", "stems", "from", "the", "fact", "that", "these", "materials", "are", "necessarily", "described", "by", "the", "most", "general", "form", "of", "the", "constitutive", "relations.", "There", "may", "be", "36", "complex", "quantities", "to", "determine,", "and", "thus", "standard", "complex", "reflection", "and", "transmission", "measurements", "yield", "incomplete", "EM", "information.", "At", "THz", "and", "higher", "frequencies", "where", "phase", "sensitive", "measurements", "are", "not", "common", "it", "is", "even", "more", "difficult,", "although", "methods", "such", "as", "ellipsometry", "or", "THz", "time", "domain", "spectroscopy", "may", "prove", "useful.", "Further", "since", "a", "magnetic", "and", "electric", "resonant", "response", "enter", "similarly", "into", "the", "Fresnel", "equations,", "it", "is", "difficult", "to", "determine", "the", "origin", "of", "the", "response.", "Typically,", "artificial", "magnetic", "metamaterials", "are", "constructed", "from", "conducting", "elements,", "and", "thus", "a", "full", "electromagnetic", "characterization", "is", "a", "necessity,", "since", "an", "electric", "response", "is", "unavoidable.", "Analytical", "theories", "have", "yielded", "equations", "able", "to", "predict", "the", "resonant", "frequency", "\u03c90", "and", "plasma", "frequency", "\u03c9p", "of", "metamaterials.", "However", "there", "is", "a", "lack", "of", "suitable", "analytical", "methods", "capable", "of", "determining", "the", "many", "varying", "and", "complicated", "EM", "properties.", "Simulation", "is", "still", "heavily", "relied", "upon", "and,", "as", "of", "yet,", "is", "still", "unable", "to", "determine", "and", "distinguishing", "bianisotropic", "response."], "labels": ["TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "MIXED", "MIXED", "MIXED", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["Atm?crowavefrequencieswherecomplexreflectionandtra~nsmissionlneasurements(S-p~trameter)arecommon,itisdifficulttocharacterizebanisotropicmateials.~ThisdifficultystemsfrOmthefactthatthesematerialsorenecessarilydescribedbythemostgencralformoftheconsitutiverelations.Theremaybe36cRomplcxquantitiestodetermine,andthusstnandrdcoMplexreflectionandtransmisSionmeasurcmentsyieldincompleIeEMinformation.AtTHzandhigher\\frequcieswherepascsensitivemeasurementsarenotcommoni\\tiseveumoredifficult,althoughmel,hodssuchasellipsome~ryorTHztimedomainspectroscopymayproveusefSul.Furthersinceamagneticandelecl,ricresoltantresponstentersimilarlyintot\\[leli'rcsllelequations,itisdiffi,culttodeterminetheoriginofTherespcnse.Typicallsy,artificialmagneticmetamaterialsarecontcuctedfromconductingelements,andthusa?fullelectromagneticcharacterizationisanecessityisinccanelectricresponseisunavodble.Analyticatheorieshaveyieldevequtionsablcl;opredi(:?ttheresunantfrequellcy\u03c90andplasnlafrequency\u03c9pofmetamaterials.Howeverthereisalackofsuitabeanalyticalmthodscapa1)leofdeterminingthemanyvaryingandcomplicatedEMproperties.$imulationeiastlllheavilyrelieduponand,asofyet,isstill'unablet?odetcrm?ineanddistinguishingbiailisotropiresponse."], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["At", "m?crowave", "frequencies", "where", "complex", "reflection", "and", "tra~nsmission", "lneasurements", "(S-p~trameter)", "are", "common,", "it", "is", "difficult", "to", "characterize", "b", "anisotropic", "mateials.~", "This", "difficulty", "stems", "frOm", "the", "fact", "that", "these", "materials", "ore", "necessarily", "described", "by", "the", "most", "gencral", "form", "of", "the", "consitutive", "relations.", "There", "may", "be", "36", "cRomplcx", "quantities", "to", "determine,", "and", "thus", "stnandrd", "coMplex", "reflection", "and", "transmisSion", "measurcments", "yield", "incompleIe", "EM", "information.", "At", "THz", "and", "higher\\", "frequcies", "where", "pasc", "sensitive", "measurements", "are", "not", "common", "i\\t", "is", "eveu", "more", "difficult,", "although", "mel,hods", "such", "as", "ellipsome~ry", "or", "THz", "time", "domain", "spectroscopy", "may", "prove", "usefSul.", "Further", "since", "a", "magnetic", "and", "elecl,ric", "resoltant", "responst", "enter", "similarly", "into", "t\\[le", "li'rcsllel", "equations,", "it", "is", "diffi,cult", "to", "determine", "the", "origin", "of", "The", "respcnse.", "Typicallsy,", "artificial", "magnetic", "metamaterials", "are", "contcucted", "from", "conducting", "elements,", "and", "thus", "a?", "full", "electromagnetic", "characterization", "is", "a", "necessityi", "sincc", "an", "electric", "response", "is", "unavodble.", "Analytica", "theories", "have", "yield", "evequtions", "ablc", "l;o", "predi(:?t", "the", "resunant", "frequellcy", "\u03c90", "and", "plasnla", "frequency", "\u03c9p", "of", "metamaterials.", "However", "there", "is", "a", "lack", "of", "suitabe", "analytical", "mthods", "capa1)le", "of", "determining", "the", "many", "varying", "and", "complicated", "EM", "properties.", "$imulatione", "ia", "stlll", "heavily", "relied", "upon", "and,", "as", "of", "yet,", "is", "still", "'unable", "t?o", "detcrm?ine", "and", "distinguishing", "biail", "isotropi", "response."], "labels": ["TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "WRONG", "WRONG", "WRONG", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["At", "microwave", "frequencies", "where", "complex", "reflection", "and", "tra~nsmission", "measurements", "(S-p~trameter)", "are", "common,", "it", "is", "difficult", "to", "characterize", "b", "anisotropic", "materials.~", "This", "difficulty", "stems", "frOm", "the", "fact", "that", "these", "materials", "are", "necessarily", "described", "by", "the", "most", "general", "form", "of", "the", "constitutive", "relations.", "There", "may", "be", "36", "complex", "quantities", "to", "determine,", "and", "thus", "standard", "coMplex", "reflection", "and", "transmisSion", "measurements", "yield", "incompleTe", "EM", "information.", "At", "THz", "and", "higher\\", "frequencies", "where", "pasc", "sensitive", "measurements", "are", "not", "common", "i\\t", "is", "even", "more", "difficult,", "although", "mel,gods", "such", "as", "ellipsome~ry", "or", "THz", "time", "domain", "spectroscopy", "may", "prove", "useful.", "Further", "since", "a", "magnetic", "and", "elecl,ric", "resultant", "response", "center", "similarly", "into", "t\\[le", "lyricsll", "equations,", "it", "is", "difficult", "to", "determine", "the", "origin", "of", "The", "response.", "Typically,", "artificial", "magnetic", "metamaterials", "are", "constructed", "from", "conducting", "elements,", "and", "thus", "a?", "Full", "electromagnetic", "characterization", "is", "a", "necessity", "since", "an", "electric", "response", "is", "unavoidable.", "Analytical", "theories", "have", "yield", "equations", "ablc", "l;o", "predi(:?t", "the", "resonant", "frequency", "\u03c90", "and", "plasma", "frequency", "\u03c9p", "of", "metamaterials.", "However", "there", "is", "a", "lack", "of", "suitable", "analytical", "methods", "capa1)le", "of", "determining", "the", "many", "varying", "and", "complicated", "EM", "properties.", "$simulation", "is", "still", "heavily", "relied", "upon", "and,", "as", "of", "yet,", "is", "still", "'unable", "to", "determine", "and", "distinguish", "bilal", "isotropic", "response."], "labels": ["TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "MIXED", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "MIXED", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "MIXED", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "MIXED", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "MIXED", "WRONG", "WRONG", "WRONG", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "MIXED", "MIXED", "TOKENIZATION_ERROR", "WRONG", "WRONG", "WRONG", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["First,wecalcuLatethen-point\\['unctionsofg\u03b6withouttheIRsuppressingoperatol'Rx:"], "labels": ["WRONG"]}, "correct": {"tokens": ["First,", "we", "calculate", "the", "n-point", "functions", "of", "g", "\u03b6", "without", "the", "IR", "suppressing", "operator", "Rx:"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["First,we", "calcuLate", "the-point\\['unctionsofg\u03b6withouttheIRsuppressingoperatol'Rx:"], "labels": ["WRONG", "WRONG", "WRONG"]}, "BS-bid-OCR": {"tokens": ["First,", "we", "calcuLate", "the", "n-point", "\\['unctions", "of", "g\u03b6", "without", "the", "IR", "suppressing", "operatol'", "Rx:"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["First,", "we", "calcuLate", "the", "n-point", "\\['functions", "of", "g\u03b6", "without", "theIR", "suppressing", "operator'", "Rx:"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["andaninteractionpartSint(therest),req\\uiringthatthebackgroundfieldssatisfyth(discretized)equationofmotionofS(0)andtheboundaFyconditions.Hen\\ceqN=q0=0.Withthecontinuumlimtiilmindweparametrize\\theexdiscreteqkusingcontinuummodesofS(0)"], "labels": ["WRONG"]}, "correct": {"tokens": ["and", "an", "interaction", "part", "Sint", "(the", "rest),", "requiring", "that", "the", "background", "fields", "satisfy", "the", "(discretized)", "equation", "of", "motion", "of", "S(0)", "and", "the", "boundary", "conditions.", "Hence", "qN", "=", "q0", "=", "0.", "With", "the", "continuum", "limit", "in", "mind", "we", "parametrize", "the", "discrete", "qk", "using", "continuum", "modes", "of", "S(0)"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["andaninteractionpartSint(therest),req\\uiringthatthebackgroundfieldssatisfyth(discretized)equationofmotionofS(0)and", "boundaRy", "conditions.Hen\\ceqN=q0=0.Withthecontinuumlimtiilmindweparametrize\\theexdiscreteqkusingcontinuummodesofS(0)"], "labels": ["WRONG", "WRONG", "WRONG"]}, "BS-bid-OCR": {"tokens": ["and", "an", "interaction", "part", "Sint", "(the", "rest),", "req\\uiring", "that", "the", "background", "fields", "satisfy", "th", "(discretized)", "equation", "of", "motion", "of", "S(0)", "and", "the", "boundaFy", "conditions.", "Hen\\ce", "qN", "=", "q0", "=", "0.", "With", "the", "continuum", "limt", "iil", "mind", "we", "parametrize", "\\the", "exdiscrete", "qk", "using", "continuum", "modes", "of", "S(0)"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["and", "an", "interaction", "part", "Sint", "(the", "rest),", "req\\uiring", "that", "the", "background", "fields", "satisfy", "the", "(discretized)", "equation", "of", "motion", "of", "S(0)", "and", "the", "boundaRy", "conditions.", "Hen\\ce", "qN", "=", "q0", "=", "0.", "With", "the", "continuum", "limit", "ill", "mind", "we", "parametrize", "\\the", "discrete", "qk", "using", "continuum", "modes", "of", "S(0)"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["whereq\u2208(0,1)isasympI;oticallystablelfandonlyif"], "labels": ["WRONG"]}, "correct": {"tokens": ["where", "q", "\u2208", "(0,", "1)", "is", "asymptotically", "stable", "if", "and", "only", "if"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["whereq\u2208(0,1)isasympI;oticallystablelfandonlyif"], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["where", "q", "\u2208", "(0,", "1)", "is", "asympI;otically", "stable", "lf", "and", "only", "if"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["where", "q", "\u2208", "(0,", "1)", "is", "asympI;optically", "stable", "if", "and", "only", "if"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["with\"\u03c4mbeingreelazaCiontime,diffusionconstant)can\\berewritten.intilesimpleform,"], "labels": ["WRONG"]}, "correct": {"tokens": ["with", "\u03c4", "being", "relaxation", "time,", "diffusion", "constant", "can", "be", "rewritten", "in", "the", "simple", "form,"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["with\"\u03c4mbeingreelazaCiontime,diffusion", "constant)can\\be", "rewritten.intel", "simpleform,"], "labels": ["WRONG", "WRONG", "WRONG", "WRONG"]}, "BS-bid-OCR": {"tokens": ["with", "\"\u03c4m", "being", "reelazaCion", "time,", "diffusion", "constant)", "can", "\\be", "rewritten.", "in", "tile", "simple", "form,"], "labels": ["TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["with", "\"\u03c4m", "being", "realizaCion", "time,", "diffusion", "constant)", "can", "\\be", "rewritten.", "in", "tile", "simple", "form,"], "labels": ["TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["HlghF\\]'equencyGeodesicAcousticModesinElectronTemperatureGradietodeTm'bulence"], "labels": ["WRONG"]}, "correct": {"tokens": ["High", "Frequency", "Geodesic", "Acoustic", "Modes", "in", "Electron", "Temperature", "Gradient", "Mode", "Turbulence"], "labels": ["MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "MIXED"]}, "predicted": {"google": {"tokens": ["HlghF\\]'equencyGeodesicAcousticModesinElectronTemperatureGradietodeTm'bulence"], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["Hlgh", "F\\]'equency", "Geodesic", "Acoustic", "Modes", "in", "Electron", "Temperature", "Gradietode", "Tm'bulence"], "labels": ["WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG"]}, "BS-bid-OCR+google": {"tokens": ["Hlgh", "F\\]'frequency", "Geodesic", "Acoustic", "Modes", "in", "Electron", "Temperature", "Gradient", "Turbulence"], "labels": ["WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED"]}}}, {"corrupt": {"tokens": ["ACknowledgemcnt:Oneofus(S.T.)wouldliketothankF.FerrariandW.LercheforvaluablediscussionssndTelAviUnversityfot-hospitality.S.Y.wouldlil~etothankG.Venezianoforinterestingdiscussiqns.?"], "labels": ["WRONG"]}, "correct": {"tokens": ["Acknowledgement:", "One", "of", "us", "(S.T.)", "would", "like", "to", "thank", "F.", "Ferrari", "and", "W.", "Lerche", "for", "valuable", "discussions", "and", "Tel", "Aviv", "University", "for", "hospitality.", "S.Y.", "would", "like", "to", "thank", "G.", "Veneziano", "for", "interesting", "discussions."], "labels": ["MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED"]}, "predicted": {"google": {"tokens": ["ACknowledgemcnt:Oneofus(S.T.)wouldliketothankF.FerrariandW.LercheforvaluablediscussionssndTelAviUnversityfot-hospitality.S.Y.wouldlil~etothankG.Venezianoforinterestingdiscussiqns.?"], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["ACknowledgemcnt:", "One", "of", "us", "(S.T.)", "would", "like", "to", "thank", "F.", "Ferrari", "and", "W.", "Lerche", "for", "valuable", "discussions", "snd", "Tel", "Avi", "Unversity", "fot-", "hospitality.", "S.Y.", "would", "lil~e", "to", "thank", "G.", "Veneziano", "for", "interesting", "discussiqns.?"], "labels": ["WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG"]}, "BS-bid-OCR+google": {"tokens": ["ACknowledgement:", "One", "of", "us", "(S.T.)", "would", "like", "to", "thank", "F.", "Ferrari", "and", "W.", "Lerche", "for", "valuable", "discussions", "and", "Tel", "Aviv", "University", "for-", "hospitality.", "S.Y.", "would", "lil~e", "to", "thank", "G.", "Veneziano", "for", "interesting", "discussions.?"], "labels": ["WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "MIXED", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG"]}}}, {"corrupt": {"tokens": ["PhysicsDepartment&INFN,UniversityofPerugia,Pel'ugia,Italy"], "labels": ["WRONG"]}, "correct": {"tokens": ["Physics", "Department", "&", "INFN,", "University", "of", "Perugia,", "Perugia,", "Italy"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["PhysicsDepartment&INFN,UniversityofPerugia,Perugia,Italy"], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["Physics", "Department", "&", "INFN,", "University", "of", "Perugia,", "Pel'ugia,", "Italy"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "WRONG", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["Physics", "Department", "&", "INFN,", "University", "of", "Perugia,", "Pel'ugia,", "Italy"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "WRONG", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["toscanthecalcnlationthro--ughallenergyaxis."], "labels": ["WRONG"]}, "correct": {"tokens": ["to", "scan", "the", "calculation", "through", "all", "energy", "axis."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["toscanthecalcnlationthro--ughallenergyaxis."], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["to", "scan", "the", "calcnlation", "thro--ugh", "all", "energy", "axis."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["to", "scan", "the", "calculation", "thro--ugh", "all", "energy", "axes."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG"]}}}, {"corrupt": {"tokens": ["ImproVingEnergyEfficiencyThrughMultimodeTransmissionintheDownlinkMIMOSystems"], "labels": ["WRONG"]}, "correct": {"tokens": ["Improving", "Energy", "Efficiency", "Through", "Multimode", "Transmission", "in", "the", "Downlink", "MIMO", "Systems"], "labels": ["MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["ImproVingEnergyEfficiencyThrughMultimodeTransmissionintheDownlinkMIMOSystems"], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["ImproVing", "Energy", "Efficiency", "Thrugh", "Multimode", "Transmission", "in", "the", "Downlink", "MIMO", "Systems"], "labels": ["WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["ImproVing", "Energy", "Efficiency", "Through", "Multimode", "Transmission", "in", "the", "Downlink", "MIMO", "Systems"], "labels": ["WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["IntegrationbyparI.sgiw:s"], "labels": ["WRONG"]}, "correct": {"tokens": ["Integration", "by", "parts", "gives"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED"]}, "predicted": {"google": {"tokens": ["Integration", "by", "parI.show:s"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG"]}, "BS-bid-OCR": {"tokens": ["Integration", "by", "parI.s", "giw:s"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG"]}, "BS-bid-OCR+google": {"tokens": ["Integration", "by", "parTs", "shows"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG"]}}}, {"corrupt": {"tokens": ["fluidneartheglasgstl'ansition"], "labels": ["WRONG"]}, "correct": {"tokens": ["fluid", "near", "the", "glass", "transition"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED"]}, "predicted": {"google": {"tokens": ["fluidneartheglasgstl'ansition"], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["fluid", "near", "the", "glasgs", "tl'ansition"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG"]}, "BS-bid-OCR+google": {"tokens": ["fluid", "near", "the", "glass", "transition"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED"]}}}, {"corrupt": {"tokens": ["TakngtheexpectationoverYompletestheproof."], "labels": ["WRONG"]}, "correct": {"tokens": ["Taking", "the", "expectation", "over", "Y", "completes", "the", "proof."], "labels": ["MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["Taking", "the", "expectation", "verYompletesthe", "proof."], "labels": ["MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR"]}, "BS-bid-OCR": {"tokens": ["Takng", "the", "expectation", "over", "Y", "ompletes", "the", "proof."], "labels": ["WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["Taking", "the", "expectation", "over", "Y", "completes", "the", "proof."], "labels": ["MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["Thgradialprofileandthefuzzy-S4phys\\icalradlusareagainrelatedby"], "labels": ["WRONG"]}, "correct": {"tokens": ["The", "radial", "profile", "and", "the", "fuzzy-S4", "physical", "radius", "are", "again", "related", "by"], "labels": ["MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["Thgradialprofileandthefuzzy-S4phys\\icalradlusareagainrelatedby"], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["Thg", "radial", "profile", "and", "the", "fuzzy-S4", "phys\\ical", "radlus", "are", "again", "related", "by"], "labels": ["WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["Thg", "radial", "profile", "and", "the", "fuzzy-S4", "phys\\ical", "radius", "are", "again", "related", "by"], "labels": ["WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["Two-StageFormationMo~elandHelicityofGoldNanow,res"], "labels": ["WRONG"]}, "correct": {"tokens": ["Two-Stage", "Formation", "Model", "and", "Helicity", "of", "Gold", "Nanowires"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED"]}, "predicted": {"google": {"tokens": ["Two-StageFormationMo~elandHelicityofGoldNanow,res"], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["Two-Stage", "Formation", "Mo~el", "and", "Helicity", "of", "Gold", "Nanow,res"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG"]}, "BS-bid-OCR+google": {"tokens": ["Two-Stage", "Formation", "Mo~el", "and", "Helicity", "of", "Gold", "Nanowires"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED"]}}}, {"corrupt": {"tokens": ["Letusbegilnbynoticingthat"], "labels": ["WRONG"]}, "correct": {"tokens": ["Let", "us", "begin", "by", "noticing", "that"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["Letusbegilnbynoticingthat"], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["Let", "us", "begiln", "by", "noticing", "that"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["Let", "us", "begin", "by", "noticing", "that"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["Themonochromatic2-armexponent"], "labels": ["WRONG"]}, "correct": {"tokens": ["The", "monochromatic", "2-arm", "exponent"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["Themonochromatic2-arm", "exponent"], "labels": ["WRONG", "TOKENIZATION_ERROR"]}, "BS-bid-OCR": {"tokens": ["The", "monochromatic", "2-arm", "exponent"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["The", "monochromatic", "2-arm", "exponent"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["Notethatherethecla?ssicalrandomvar~able\u03be=\u03be(a,OjA(l),\u03bb)isnotonlyeepasatedinthesenseofBall(i.e.itdependsonlyona)butitisalsolocalinl;he3dimspaces\\inceitdependsonlyontheregi\\onOA(l).Thec\\lassicalrand\\omvariabl(;\u03b7isalsolocalin3dimspacesinceitdependsonlyon2OB.?NotealothatsincethleeigenvaluesoftheprojectorPOar\\e0or1thenoneshouldhave|\u03be(a,OA1|\u22641."], "labels": ["WRONG"]}, "correct": {"tokens": ["Note", "that", "here", "the", "classical", "random", "variable", "\u03be", "=", "\u03be(a,", "OA(l),", "\u03bb)", "is", "not", "only", "separated", "in", "the", "sense", "of", "Bell", "(i.e.", "it", "depends", "only", "on", "a)", "but", "it", "is", "also", "local", "in", "the", "3", "dim", "space", "since", "it", "depends", "only", "on", "the", "region", "OA(l).", "The", "classical", "random", "variable", "\u03b7", "is", "also", "local", "in", "3", "dim", "space", "since", "it", "depends", "only", "on", "OB.", "Note", "also", "that", "since", "the", "eigenvalues", "of", "the", "projector", "PO", "are", "0", "or", "1", "then", "one", "should", "have", "|\u03be(a,", "OA)", "|", "\u22641."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["Notethatherethecla?ssicalrandomvar~able\u03be=\u03be(a,OjA(l),\u03bb)isnotonlyeepasatedinthesenseofBall(i.e.itdependsonlyona)butitisalsolocalinl;he3dimspaces\\inceitdependsonlyontheregi\\onOA(l).Thec\\lassicalrand\\omvariabl(;\u03b7isalsolocalin3dimspacesinceitdependsonlyon2OB.?NotealothatsincethleeigenvaluesoftheprojectorPOar\\e0or1thenoneshouldhave|\u03be(a,OA1|\u22641."], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["Note", "that", "here", "the", "cla?ssical", "random", "var~able", "\u03be", "=", "\u03be(a,", "Oj", "A(l),", "\u03bb)", "is", "not", "only", "eepasated", "in", "the", "sense", "of", "Ball", "(i.e.", "it", "depends", "only", "on", "a)", "but", "it", "is", "also", "local", "in", "l;he", "3dim", "space", "s\\ince", "it", "depends", "only", "on", "the", "regi\\on", "OA(l).", "The", "c\\lassical", "rand\\om", "variabl(;", "\u03b7", "is", "also", "local", "in", "3dim", "space", "since", "it", "depends", "only", "on", "2OB.?", "Note", "alo", "that", "since", "thle", "eigenvalues", "of", "the", "projector", "PO", "ar\\e", "0", "or", "1", "then", "one", "should", "have", "|\u03be(a,", "OA1", "|", "\u22641."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["Note", "that", "here", "the", "classical", "random", "var~able", "\u03be", "=", "\u03be(a,", "Oj", "A(l),", "\u03bb)", "is", "not", "only", "reposted", "in", "the", "sense", "of", "Ball", "(i.e.", "it", "depends", "only", "on", "a)", "but", "it", "is", "also", "local", "in", "l;he", "3dim", "space", "s\\ince", "it", "depends", "only", "on", "the", "regi\\on", "OA(l).", "The", "c\\lassical", "rand\\om", "variable(;", "\u03b7", "is", "also", "local", "in", "3dim", "space", "since", "it", "depends", "only", "on", "2OB.?", "Note", "also", "that", "since", "the", "eigenvalues", "of", "the", "projector", "PO", "ar\\e", "0", "or", "1", "then", "one", "should", "have", "|\u03be(a,", "OA1", "|", "\u22641."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["Thofieldinidethedielectricisagaindivergencefree.Theinducedsurf?acecha:gecanbedeterminedfromthenormalcomponentofhepolrizationasint?hefirstexampleandisfoundtobe"], "labels": ["WRONG"]}, "correct": {"tokens": ["The", "field", "inside", "the", "dielectric", "is", "again", "divergence", "free.", "The", "induced", "surface", "charge", "can", "be", "determined", "from", "the", "normal", "component", "of", "the", "polarization", "as", "in", "the", "first", "example", "and", "is", "found", "to", "be"], "labels": ["MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["Thofieldinidethedielectricisagaindivergencefree.Theinducedsurf?acecha:gecanbedeterminedfromthenormalcomponentofhepolrizationasint?hefirstexampleandisfoundtobe"], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["Tho", "field", "inide", "the", "dielectric", "is", "again", "divergence", "free.", "The", "induced", "surf?ace", "cha:ge", "can", "be", "determined", "from", "the", "normal", "component", "of", "he", "polrization", "as", "in", "t?he", "first", "example", "and", "is", "found", "to", "be"], "labels": ["WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["The", "field", "inside", "the", "dielectric", "is", "again", "divergence", "free.", "The", "induced", "surface", "cha:ge", "can", "be", "determined", "from", "the", "normal", "component", "of", "the", "polarization", "as", "in", "the", "first", "example", "and", "is", "found", "to", "be"], "labels": ["MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["Dynaroicstructulefactorofastrong\\]dcorrelatadFermibup4rfluidwithinadensityfunctionaltheoryapproach"], "labels": ["WRONG"]}, "correct": {"tokens": ["Dynamic", "structure", "factor", "of", "a", "strongly", "correlated", "Fermi", "superfluid", "within", "a", "density", "functional", "theory", "approach"], "labels": ["MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["Dynaroicstructulefactorofastrong\\]dcorrelatadFermibup4rfluidwithinadensityfunctionaltheoryapproach"], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["Dynaroic", "structule", "factor", "of", "a", "strong\\]d", "correlatad", "Fermi", "bup4r", "fluid", "within", "a", "density", "functional", "theory", "approach"], "labels": ["WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["Dynamic", "structure", "factor", "of", "a", "strong\\]d", "correlated", "Fermi", "bup4r", "fluid", "within", "a", "density", "functional", "theory", "approach"], "labels": ["MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "MIXED", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["ands\\o~.Thentheabovestateisg?venby"], "labels": ["WRONG"]}, "correct": {"tokens": ["and", "so", "on.", "Then", "the", "above", "state", "is", "given", "by"], "labels": ["TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["ands\\o~.Thentheabovestateisg?venby"], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["and", "s\\o", "~.", "Then", "the", "above", "state", "is", "g?ven", "by"], "labels": ["TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["and", "s\\o", "~.", "Then", "the", "above", "state", "is", "given", "by"], "labels": ["TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["Foragen6ralcomplexscalarfield\u03a6,wehaw~theconservedenergy-lnomentumtenso?r"], "labels": ["WRONG"]}, "correct": {"tokens": ["For", "a", "general", "complex", "scalar", "field", "\u03a6,", "we", "have", "the", "conserved", "energy-momentum", "tensor"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED"]}, "predicted": {"google": {"tokens": ["Foragen6ralcomplexscalarfield\u03a6,we", "have~the", "conserved", "energy-in", "omentum", "tenzo?r"], "labels": ["WRONG", "WRONG", "TOKENIZATION_ERROR", "WRONG", "WRONG", "WRONG"]}, "BS-bid-OCR": {"tokens": ["For", "a", "gen6ral", "complex", "scalar", "field", "\u03a6,", "we", "haw~", "the", "conserved", "energy-lnomentum", "tenso?r"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG"]}, "BS-bid-OCR+google": {"tokens": ["For", "a", "gen6ral", "complex", "scalar", "field", "\u03a6,", "we", "have~", "the", "conserved", "energy-momentum", "tensor"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED"]}}}, {"corrupt": {"tokens": ["No\\tethatlhecosmologicalconstatisnegative\u039b<0,andtheemperaturebecomespositive.Also\\thisvanish?sifextremeconditionissati,~fied."], "labels": ["WRONG"]}, "correct": {"tokens": ["Note", "that", "the", "cosmological", "constant", "is", "negative", "\u039b", "<", "0,", "and", "the", "temperature", "becomes", "positive.", "Also", "this", "vanishes", "if", "extreme", "condition", "is", "satisfied."], "labels": ["MIXED", "MIXED", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED"]}, "predicted": {"google": {"tokens": ["No\\tethatlhecosmologicalconstatisnegative\u039b<0,and", "emperatur", "becomes", "positive.Also\\this", "vanishes?sifextremeconditionissati,~fied."], "labels": ["WRONG", "WRONG", "TOKENIZATION_ERROR", "WRONG", "WRONG"]}, "BS-bid-OCR": {"tokens": ["No\\te", "that", "lhe", "cosmological", "constat", "is", "negative", "\u039b", "<", "0,", "and", "the", "emperature", "becomes", "positive.", "Also\\", "this", "vanish?s", "if", "extreme", "condition", "is", "sati,~fied."], "labels": ["WRONG", "MIXED", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG"]}, "BS-bid-OCR+google": {"tokens": ["No\\te", "that", "the", "cosmological", "constant", "is", "negative", "\u039b", "<", "0,", "and", "the", "temperature", "becomes", "positive.", "Also\\", "this", "vanishes", "if", "extreme", "conditions", "is", "sati,~fied."], "labels": ["WRONG", "MIXED", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG"]}}}, {"corrupt": {"tokens": ["wimrewehavetakenthsolidangleaverage:"], "labels": ["WRONG"]}, "correct": {"tokens": ["where", "we", "have", "taken", "the", "solid", "angle", "average:"], "labels": ["MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["wimrewehavetakenthsolidangleaverage:"], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["wimre", "we", "have", "taken", "th", "solid", "angle", "average:"], "labels": ["WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["where", "we", "have", "taken", "the", "solid", "angle", "average:"], "labels": ["MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["ofthem\\atter/radiationequality.Thisyieldsthefollowingresl;trictionon?thegravezcitonmasxes:"], "labels": ["WRONG"]}, "correct": {"tokens": ["of", "the", "matter/radiation", "equality.", "This", "yields", "the", "following", "restriction", "on", "the", "gravexciton", "masses:"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED"]}, "predicted": {"google": {"tokens": ["ofthem\\atter/radiationequality.Thisyieldsthefollowingresl;trictionon?thegravezcitonmasxes:"], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["of", "the", "m\\atter/radiation", "equality.", "This", "yields", "the", "following", "resl;triction", "on?", "the", "gravezciton", "masxes:"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "WRONG", "WRONG"]}, "BS-bid-OCR+google": {"tokens": ["of", "the", "m\\atter/radiation", "equality.", "This", "yields", "the", "following", "real;traction", "on?", "the", "grave", "sciton", "maxes:"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "WRONG", "WRONG", "WRONG"]}}}, {"corrupt": {"tokens": ["Hence,theenergyequationforamassiveparticleisgivenby:"], "labels": ["WRONG"]}, "correct": {"tokens": ["Hence,", "the", "energy", "equation", "for", "a", "massive", "particle", "is", "given", "by:"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["Hence,the", "energy", "equation", "foramassiveparticleisgivenby:"], "labels": ["WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG"]}, "BS-bid-OCR": {"tokens": ["Hence,", "the", "energy", "equation", "for", "a", "massive", "particle", "is", "given", "by:"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["Hence,", "the", "energy", "equation", "for", "a", "massive", "particle", "is", "given", "by:"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["ContrastwiLhthestatcRG"], "labels": ["WRONG"]}, "correct": {"tokens": ["Contrast", "with", "the", "static", "RG"], "labels": ["TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["ContrastwiLhthestatcRG"], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["Contrast", "wiLh", "the", "statc", "RG"], "labels": ["TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["Contrast", "wiLh", "the", "static", "RG"], "labels": ["TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["TheMenNovaLifetimeProcedure"], "labels": ["WRONG"]}, "correct": {"tokens": ["The", "Mean", "Nova", "Lifetime", "Procedure"], "labels": ["TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["TheMen", "Nova", "Lifetime", "Procedure"], "labels": ["WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR": {"tokens": ["The", "Men", "Nova", "Lifetime", "Procedure"], "labels": ["TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["The", "Men", "Nova", "Lifetime", "Procedure"], "labels": ["TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["where"], "labels": ["NONE"]}, "correct": {"tokens": ["where"], "labels": ["NONE"]}, "predicted": {"google": {"tokens": ["where"], "labels": ["NONE"]}, "BS-bid-OCR": {"tokens": ["where"], "labels": ["NONE"]}, "BS-bid-OCR+google": {"tokens": ["where"], "labels": ["NONE"]}}}, {"corrupt": {"tokens": ["Westartfromadissipati~edynamicsthaLmicroscoptcallyconservesparticlenumtber,"], "labels": ["WRONG"]}, "correct": {"tokens": ["We", "start", "from", "a", "dissipative", "dynamics", "that", "microscopically", "conserves", "particle", "number,"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED"]}, "predicted": {"google": {"tokens": ["Westartfromadissipati~edynamicsthaLmicroscoptcallyconservesparticlenumtber,"], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["We", "start", "from", "a", "dissipati~e", "dynamics", "thaL", "microscoptcally", "conserves", "particle", "numtber,"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG"]}, "BS-bid-OCR+google": {"tokens": ["We", "start", "from", "a", "dissipati~e", "dynamics", "thaL", "microscopically", "conserves", "particle", "number,"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED"]}}}, {"corrupt": {"tokens": ["Giventhatrate-expectationsidtificationimpliesthat"], "labels": ["WRONG"]}, "correct": {"tokens": ["Given", "that", "rate-expectations", "identification", "implies", "that"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["Giventhatrate-expectationsidtificationimpliesthat"], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["Given", "that", "rate-expectation", "sidtification", "implies", "that"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["Given", "that", "rate-expectation", "identification", "implies", "that"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["satisfies"], "labels": ["NONE"]}, "correct": {"tokens": ["satisfies"], "labels": ["NONE"]}, "predicted": {"google": {"tokens": ["satisfies"], "labels": ["NONE"]}, "BS-bid-OCR": {"tokens": ["satisfies"], "labels": ["NONE"]}, "BS-bid-OCR+google": {"tokens": ["satisfies"], "labels": ["NONE"]}}}, {"corrupt": {"tokens": ["DmainMappingsfromtheCantorTree"], "labels": ["WRONG"]}, "correct": {"tokens": ["Domain", "Mappings", "from", "the", "Cantor", "Tree"], "labels": ["MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["DmainMappingsfromtheCantorTree"], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["Dmain", "Mappings", "from", "the", "Cantor", "Tree"], "labels": ["WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["Domain", "Mappings", "from", "the", "Cantor", "Tree"], "labels": ["MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["Inthispaper,wehaveshown,thatthefir,storderphasetransitionandassociatedcriticalendpointaredrivenbythechiralratherthelldeconfinementtraasition.Theli~esofboththesetranSitioIIssitnearlyatopthecrossoverassociatedwihtheremn;mtsofthefirstorderquakyonicphasetransitionsofthelargeNclimit.Thecriticalendpointitselfmayappe~trwheethecrossoverfromtheauarkyonicandthed.econfinementphasetransitionsmtersect."], "labels": ["WRONG"]}, "correct": {"tokens": ["In", "this", "paper,", "we", "have", "shown,", "that", "the", "first", "order", "phase", "transition", "and", "associated", "critical", "end", "point", "are", "driven", "by", "the", "chiral", "rather", "then", "deconfinement", "transition.", "The", "lines", "of", "both", "these", "transitions", "sit", "nearly", "atop", "the", "cross", "over", "associated", "with", "the", "remnants", "of", "the", "first", "order", "quarkyonic", "phase", "transitions", "of", "the", "large", "Nc", "limit.", "The", "critical", "end", "point", "itself", "may", "appear", "where", "the", "cross", "over", "from", "the", "quarkyonic", "and", "the", "deconfinement", "phase", "transitions", "intersect."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED"]}, "predicted": {"google": {"tokens": ["Inthispaper,wehaveshown,thatthefir,storderphasetransitionandassociatedcriticalendpointaredrivenbythechiralratherthelldeconfinementtraasition.Theli~esofboththesetranSitioIIssitnearlyatopthecrossoverassociatedwihtheremn;mtsofthefirstorderquakyonicphasetransitionsofthelargeNclimit.Thecriticalendpointitselfmayappe~trwheethecrossoverfromtheauarkyonicandthed.econfinementphasetransitionsmtersect."], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["In", "this", "paper,", "we", "have", "shown,", "that", "the", "fir,st", "order", "phase", "transition", "and", "associated", "critical", "endpoint", "are", "driven", "by", "the", "chiral", "rather", "thell", "deconfinement", "traasition.", "The", "li~es", "of", "both", "these", "tranSitioIIs", "sit", "nearly", "atop", "the", "crossover", "associated", "wih", "the", "remn;mts", "of", "the", "first", "order", "quakyonic", "phase", "transitions", "of", "the", "large", "Nc", "limit.", "The", "critical", "endpoint", "itself", "may", "appe~tr", "whee", "the", "crossover", "from", "the", "auarkyonic", "and", "the", "d.econfinement", "phase", "transitions", "mtersect."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG"]}, "BS-bid-OCR+google": {"tokens": ["In", "this", "paper,", "we", "have", "shown,", "that", "the", "first", "order", "phase", "transition", "and", "associated", "critical", "endpoint", "are", "driven", "by", "the", "chiral", "rather", "thell", "deconfinement", "transition.", "The", "li~es", "of", "both", "these", "tranSitioNs", "sit", "nearly", "atop", "the", "crossover", "associated", "with", "the", "remn;mts", "of", "the", "first", "order", "quakyonic", "phase", "transitions", "of", "the", "large", "Nc", "limit.", "The", "critical", "endpoint", "itself", "may", "apple~tr", "where", "the", "crossover", "from", "the", "dark", "sonic", "and", "the", "deconfinement", "phase", "transitions", "intersect."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "MIXED", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED"]}}}, {"corrupt": {"tokens": ["Wetheref\\oreconside?thejointdistribution\u03c0(,\u03b1,\u03b8)=\u03c0(\u03b1)\u03c0(\u03b8|\u03b1)andobtain\u03c0(\u03b1)bymaxlmizingthoentropy"], "labels": ["WRONG"]}, "correct": {"tokens": ["We", "therefore", "consider", "the", "joint", "distribution", "\u03c0(\u03b1,", "\u03b8)", "=", "\u03c0(\u03b1)\u03c0(\u03b8", "|", "\u03b1)", "and", "obtain", "\u03c0(\u03b1)", "by", "maximizing", "the", "entropy"], "labels": ["TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["Wetheref\\oreconside?thejointdistribution\u03c0(,\u03b1,\u03b8)=\u03c0(\u03b1)\u03c0(\u03b8|\u03b1)andobtain\u03c0(\u03b1)bymaxlmizingthoentropy"], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["We", "theref\\ore", "conside?", "the", "joint", "distribution", "\u03c0(,", "\u03b1,", "\u03b8)", "=", "\u03c0(\u03b1)\u03c0(\u03b8", "|", "\u03b1)", "and", "obtain", "\u03c0(\u03b1)", "by", "maxlmizing", "tho", "entropy"], "labels": ["TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["We", "therefore", "consider?", "the", "joint", "distribution", "\u03c0(,", "\u03b1,", "\u03b8)", "=", "\u03c0(\u03b1)\u03c0(\u03b8", "|", "\u03b1)", "and", "obtain", "\u03c0(\u03b1)", "by", "maximizing", "the", "entropy"], "labels": ["TOKENIZATION_ERROR", "MIXED", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["Thus,"], "labels": ["NONE"]}, "correct": {"tokens": ["Thus,"], "labels": ["NONE"]}, "predicted": {"google": {"tokens": ["Thus,"], "labels": ["NONE"]}, "BS-bid-OCR": {"tokens": ["Thus,"], "labels": ["NONE"]}, "BS-bid-OCR+google": {"tokens": ["Thus,"], "labels": ["NONE"]}}}, {"corrupt": {"tokens": ["Underthesehypotheses,"], "labels": ["WRONG"]}, "correct": {"tokens": ["Under", "these", "hypotheses,"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["Under", "These", "Hypotheses,"], "labels": ["TOKENIZATION_ERROR", "WRONG", "WRONG"]}, "BS-bid-OCR": {"tokens": ["Under", "these", "hypotheses,"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["Under", "these", "hypotheses,"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["e-mail\\:mazzei@pd.ascr.ia"], "labels": ["WRONG"]}, "correct": {"tokens": ["e-mail:", "mazzei@pd.astro.it"], "labels": ["MIXED", "MIXED"]}, "predicted": {"google": {"tokens": ["e-mail\\:mazzei@pd.ascr.ia"], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["e-mail\\:", "mazzei@pd.ascr.ia"], "labels": ["WRONG", "WRONG"]}, "BS-bid-OCR+google": {"tokens": ["e-mail\\:", "mazzei@pd.ascr.ia"], "labels": ["WRONG", "WRONG"]}}}, {"corrupt": {"tokens": ["BDBisthesameasLBforrightstochasticmatrices"], "labels": ["WRONG"]}, "correct": {"tokens": ["BDB", "is", "the", "same", "as", "LB", "for", "right", "stochastic", "matrices"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["BDBisthesameasLBforrightstochasticmatrices"], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["BDB", "is", "the", "same", "as", "LB", "for", "right", "stochastic", "matrices"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["BDB", "is", "the", "same", "as", "LB", "for", "right", "stochastic", "matrices"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["Nowecanestimatetheallowedrangeof?.From"], "labels": ["WRONG"]}, "correct": {"tokens": ["Now", "we", "can", "estimate", "the", "allowed", "range", "of", "E.", "From"], "labels": ["MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["No", "Wecan", "Estimate", "The", "Allowed", "Range", "Of?.From"], "labels": ["WRONG", "WRONG", "WRONG", "WRONG", "WRONG", "WRONG", "WRONG"]}, "BS-bid-OCR": {"tokens": ["Now", "e", "can", "estimate", "the", "allowed", "range", "of", "?.", "From"], "labels": ["MIXED", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["Now", "we", "can", "estimate", "the", "allowed", "range", "of", "?.", "From"], "labels": ["MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["i.e.,"], "labels": ["NONE"]}, "correct": {"tokens": ["i.e.,"], "labels": ["NONE"]}, "predicted": {"google": {"tokens": ["i.e.,"], "labels": ["NONE"]}, "BS-bid-OCR": {"tokens": ["i.e.,"], "labels": ["NONE"]}, "BS-bid-OCR+google": {"tokens": ["i.e.,"], "labels": ["NONE"]}}}, {"corrupt": {"tokens": ["ThisanelysisleadstoasimplexplanationforwhyaGHZstateannotbewenvertedtoaW-state.Itisnotpossibletotransformthree-bodycorreletionsintopurelytwo-bodycorrelationsb.ylecaloperationsandclassicalcommuhication."], "labels": ["WRONG"]}, "correct": {"tokens": ["This", "analysis", "leads", "to", "a", "simple", "explanation", "for", "why", "a", "GHZ", "state", "can", "not", "be", "converted", "to", "a", "W-state.", "It", "is", "not", "possible", "to", "transform", "three-body", "correlations", "into", "purely", "two-body", "correlations", "by", "local", "operations", "and", "classical", "communication."], "labels": ["TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED"]}, "predicted": {"google": {"tokens": ["ThisanelysisleadstoasimplexplanationforwhyaGHZstateannotbewenvertedtoaW-state.Itisnotpossibletotransformthree-bodycorreletionsintopurelytwo-bodycorrelationsb.ylecaloperationsandclassicalcommuhication."], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["This", "anelysis", "leads", "to", "a", "simpl", "explanation", "for", "why", "a", "GHZ", "state", "annot", "be", "wenverted", "to", "a", "W-state.", "It", "is", "not", "possible", "to", "transform", "three-body", "correletions", "into", "purely", "two-body", "correlations", "b.y", "lecal", "operations", "and", "classical", "commuhication."], "labels": ["TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG"]}, "BS-bid-OCR+google": {"tokens": ["This", "analysis", "leads", "to", "a", "simple", "explanation", "for", "why", "a", "GHZ", "state", "cannot", "be", "converted", "to", "a", "W-state.", "It", "is", "not", "possible", "to", "transform", "three-body", "correlations", "into", "purely", "two-body", "correlations", "b.y", "local", "operations", "and", "classical", "communication."], "labels": ["TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED"]}}}, {"corrupt": {"tokens": ["Asillusl:ratedbyFig.a,ourmodelssatisfactorilyaccountfartheincreaingsprea?dofK-bandmagnitudesofradiogalaxxesatz\u22651intermsofthecombiPrnedeffenctofevol.utionofstellarpopulationsandofdustex~incti?on."], "labels": ["WRONG"]}, "correct": {"tokens": ["As", "illustrated", "by", "Fig.", "3,", "our", "models", "satisfactorily", "account", "for", "the", "increasing", "spread", "of", "K-band", "magnitudes", "of", "radiogalaxies", "at", "z", "\u2265", "1", "in", "terms", "of", "the", "combined", "effect", "of", "evolution", "of", "stellar", "populations", "and", "of", "dust", "extinction."], "labels": ["TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED"]}, "predicted": {"google": {"tokens": ["Asillusl:ratedbyFig.a,ourmodelssatisfactorilyaccountfartheincreaingsprea?dofK-bandmagnitudesofradiogalaxxesatz\u22651intermsofthecombiPrnedeffenctofevol.utionofstellarpopulationsandofdustex~incti?on."], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["As", "illusl:rated", "by", "Fig.", "a,", "our", "models", "satisfactorily", "account", "far", "the", "increaing", "sprea?d", "of", "K-band", "magnitudes", "of", "radio", "galaxxes", "at", "z", "\u2265", "1", "in", "terms", "of", "the", "combiPrned", "effenct", "of", "evol.ution", "of", "stellar", "populations", "and", "of", "dust", "ex~incti?on."], "labels": ["TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG"]}, "BS-bid-OCR+google": {"tokens": ["As", "illus:rated", "by", "Fig.", "a,", "our", "models", "satisfactorily", "account", "for", "the", "increasing", "spread", "of", "K-band", "magnitudes", "of", "radio", "galaxies", "at", "z", "\u2265", "1", "in", "terms", "of", "the", "combined", "effect", "of", "evolution", "of", "stellar", "populations", "and", "of", "dust", "ex~infection."], "labels": ["TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG"]}}}, {"corrupt": {"tokens": ["Fortelastinequalityweusedthefollowiglemma"], "labels": ["WRONG"]}, "correct": {"tokens": ["For", "the", "last", "inequality", "we", "used", "the", "following", "lemma"], "labels": ["TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["Forte", "Last", "Inequality", "We", "Used", "The", "Following", "Lemma"], "labels": ["WRONG", "WRONG", "WRONG", "WRONG", "WRONG", "WRONG", "WRONG", "WRONG"]}, "BS-bid-OCR": {"tokens": ["For", "te", "last", "inequality", "we", "used", "the", "followig", "lemma"], "labels": ["TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["For", "the", "last", "inequality", "we", "used", "the", "following", "lemma"], "labels": ["TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["Apartial\\conversetothetheoremisgivenbythefollowingl~roposition."], "labels": ["WRONG"]}, "correct": {"tokens": ["A", "partial", "converse", "to", "the", "theorem", "is", "given", "by", "the", "following", "proposition."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED"]}, "predicted": {"google": {"tokens": ["Apartial\\conversetothetheoremisgivenby", "the", "following", "proposition."], "labels": ["WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED"]}, "BS-bid-OCR": {"tokens": ["A", "partial\\", "converse", "to", "the", "theorem", "is", "given", "by", "the", "following", "l~roposition."], "labels": ["TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG"]}, "BS-bid-OCR+google": {"tokens": ["A", "partial\\", "converse", "to", "the", "theorem", "is", "given", "by", "the", "following", "l~roposition."], "labels": ["TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG"]}}}, {"corrupt": {"tokens": ["Thisappendixcontninstheproofsforsomemittedproofs."], "labels": ["WRONG"]}, "correct": {"tokens": ["This", "appendix", "contains", "the", "proofs", "for", "some", "omitted", "proofs."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["Thisappendixcontninstheproofsforsomemittedproofs."], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["This", "appendix", "contnins", "the", "proofs", "for", "some", "mitted", "proofs."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["This", "appendix", "contains", "the", "proofs", "for", "some", "mitted", "proofs."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["Asaconsequcnce:"], "labels": ["WRONG"]}, "correct": {"tokens": ["As", "a", "consequence:"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED"]}, "predicted": {"google": {"tokens": ["Consequence:"], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["As", "a", "consequcnce:"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG"]}, "BS-bid-OCR+google": {"tokens": ["As", "a", "consequence:"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED"]}}}, {"corrupt": {"tokens": ["AbasicideainthepaI)ersquotgdaboveistoconsiderthcspaces"], "labels": ["WRONG"]}, "correct": {"tokens": ["A", "basic", "idea", "in", "the", "papers", "quoted", "above", "is", "to", "consider", "the", "spaces"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["AbasicideainthepaI)ersquotgdaboveistoconsiderthcspaces"], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["A", "basic", "idea", "in", "the", "paI)ers", "quotgd", "above", "is", "to", "consider", "thc", "spaces"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["A", "basic", "idea", "in", "the", "paI)ers", "quotgd", "above", "is", "to", "consider", "thc", "spaces"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["Two-point?functon"], "labels": ["WRONG"]}, "correct": {"tokens": ["Two-point", "function"], "labels": ["TOKENIZATION_ERROR", "MIXED"]}, "predicted": {"google": {"tokens": ["Two-point?function"], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["Two-point", "?functon"], "labels": ["TOKENIZATION_ERROR", "WRONG"]}, "BS-bid-OCR+google": {"tokens": ["Two-point", "?function"], "labels": ["TOKENIZATION_ERROR", "WRONG"]}}}, {"corrupt": {"tokens": ["Abstract"], "labels": ["NONE"]}, "correct": {"tokens": ["Abstract"], "labels": ["NONE"]}, "predicted": {"google": {"tokens": ["Abstract"], "labels": ["NONE"]}, "BS-bid-OCR": {"tokens": ["Abstract"], "labels": ["NONE"]}, "BS-bid-OCR+google": {"tokens": ["Abstract"], "labels": ["NONE"]}}}, {"corrupt": {"tokens": ["Toseehowthesaxionisstabilized2letusfirstfocusonthecaseofA=E:0forsimplicity.Thesaxionisthoils{,abilizedviatheequation"], "labels": ["WRONG"]}, "correct": {"tokens": ["To", "see", "how", "the", "saxion", "is", "stabilized,", "let", "us", "first", "focus", "on", "the", "case", "of", "A", "=", "B", "=", "0", "for", "simplicity.", "The", "saxion", "is", "then", "stabilized", "via", "the", "equation"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["Toseehowthesaxionisstabilized2letusfirstfocusonthecaseofA=E:0forsimplicity.Thesaxionisthoils{,abilizedviathe", "equation"], "labels": ["WRONG", "TOKENIZATION_ERROR"]}, "BS-bid-OCR": {"tokens": ["To", "see", "how", "the", "saxion", "is", "stabilized2", "let", "us", "first", "focus", "on", "the", "case", "of", "A", "=", "E", ":", "0", "for", "simplicity.", "The", "saxion", "is", "thoil", "s{,abilized", "via", "the", "equation"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["To", "see", "how", "the", "saxion", "is", "stabilized2", "let", "us", "first", "focus", "on", "the", "case", "of", "A", "=", "E", ":", "0", "for", "simplicity.", "The", "saxion", "is", "thoil", "s{,abilized", "via", "the", "equation"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["underB1-Baonly:"], "labels": ["WRONG"]}, "correct": {"tokens": ["under", "B1-B3", "only:"], "labels": ["TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["underB1-Baonly:"], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["under", "B1", "-", "Ba", "only:"], "labels": ["TOKENIZATION_ERROR", "WRONG", "WRONG", "WRONG", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["under", "B1", "-", "Ba", "only:"], "labels": ["TOKENIZATION_ERROR", "WRONG", "WRONG", "WRONG", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["IfthenoiseisGaussianandthesignalispresent,thenthesignal-to-noiseratiolsgivenas"], "labels": ["WRONG"]}, "correct": {"tokens": ["If", "the", "noise", "is", "Gaussian", "and", "the", "signal", "is", "present,", "then", "the", "signal-to-noise", "ratio", "is", "given", "as"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["IfthenoiseisGaussianandthesignalispresent,thenthesignal-to-noiseratiolsgivenas"], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["If", "the", "noise", "is", "Gaussian", "and", "the", "signal", "is", "present,", "then", "the", "signal-to-noise", "ratio", "ls", "given", "as"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["If", "the", "noise", "is", "Gaussian", "and", "the", "signal", "is", "present,", "then", "the", "signal-to-noise", "ratio", "is", "given", "as"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["In~;hispa.perweashowourpreliminarycalcul3tio?softheradioactivesecondaryratios26AlI27Al,3\\6Cl/Cl:54Mn/MnusingtheLosAlamDscompilationofexperimentalcrosss\\ectinstogetherwithcalculations6ythecedeCEM2k(recognizedbythenuclearphysicscommunityas?amon6thebestinprcdictivepowerascomparedwithothersimilaravailablechede)."], "labels": ["WRONG"]}, "correct": {"tokens": ["In", "this", "paper", "we", "show", "our", "preliminary", "calculations", "of", "the", "radioactive", "secondary", "ratios", "26Al/27Al,", "36Cl/Cl,", "54Mn/Mn", "using", "the", "Los", "Alamos", "compilation", "of", "experimental", "cross", "sections", "together", "with", "calculations", "by", "the", "code", "CEM2k", "(recognized", "by", "the", "nuclear", "physics", "community", "as", "among", "the", "best", "in", "predictive", "power", "as", "compared", "with", "other", "similar", "available", "codes)."], "labels": ["TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED"]}, "predicted": {"google": {"tokens": ["In~;hispa.perweashowourpreliminarycalcul3tio?softheradioactivesecondaryratios26AlI27Al,3\\6Cl/Cl:54Mn/MnusingtheLosAlamDscompilationofexperimentalcrosss\\ectinstogetherwithcalculations6ythecedeCEM2k(recognizedbythenuclearphysicscommunityas?amon6thebestinprcdictivepowerascomparedwithothersimilaravailablechede)."], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["In", "~;his", "pa.per", "we", "ashow", "our", "preliminary", "calcul3tio?s", "of", "the", "radioactive", "secondary", "ratios", "26AlI27Al,", "3\\6Cl/Cl:54Mn/Mn", "using", "the", "Los", "AlamDs", "compilation", "of", "experimental", "cross", "s\\ectins", "together", "with", "calculations", "6y", "the", "cede", "CEM2k", "(recognized", "by", "the", "nuclear", "physics", "community", "as", "?amon6", "the", "best", "in", "prcdictive", "power", "as", "compared", "with", "other", "similar", "available", "chede)."], "labels": ["TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG"]}, "BS-bid-OCR+google": {"tokens": ["In", "~;his", "paper", "we", "show", "our", "preliminary", "calculations", "of", "the", "radioactive", "secondary", "ratios", "26AlI27Al,", "3\\6Cl/Cl:54Mn/Mn", "using", "the", "Los", "AlamOs", "compilation", "of", "experimental", "cross", "s\\ectins", "together", "with", "calculations", "6y", "the", "cede", "CEM2k", "(recognized", "by", "the", "nuclear", "physics", "community", "as", "?among", "the", "best", "in", "predictive", "power", "as", "compared", "with", "other", "similar", "available", "chede)."], "labels": ["TOKENIZATION_ERROR", "WRONG", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG"]}}}, {"corrupt": {"tokens": ["Furthermore,"], "labels": ["NONE"]}, "correct": {"tokens": ["Furthermore,"], "labels": ["NONE"]}, "predicted": {"google": {"tokens": ["Furthermore,"], "labels": ["NONE"]}, "BS-bid-OCR": {"tokens": ["Furthermore,"], "labels": ["NONE"]}, "BS-bid-OCR+google": {"tokens": ["Furthermore,"], "labels": ["NONE"]}}}, {"corrupt": {"tokens": ["1.6.Proofofthetherem1.4.5."], "labels": ["WRONG"]}, "correct": {"tokens": ["1.6.", "Proof", "of", "the", "theorem", "1.4.5."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["1.6.Proofofthetherem1.4.5."], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["1.6.", "Proof", "of", "the", "therem", "1.4.5."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["1.6.", "Proof", "of", "the", "theorem", "1.4.5."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["whenreT,pandVarethetemperature,pressureandvolumeoftheCFTrespectively.Ifweifintroducethefollowtngdensiies,"], "labels": ["WRONG"]}, "correct": {"tokens": ["where", "T,", "p", "and", "V", "are", "the", "temperature,", "pressure", "and", "volume", "of", "the", "CFT", "respectively.", "If", "we", "introduce", "the", "following", "densities,"], "labels": ["MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED"]}, "predicted": {"google": {"tokens": ["whenreT,pandVarethetemperature,pressureandvolumeoftheCFTrespectively.Ifweifintroducethefollowtngdensiies,"], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["whenre", "T,", "p", "and", "V", "are", "the", "temperature,", "pressure", "and", "volume", "of", "the", "CFT", "respectively.", "If", "we", "ifintroduce", "the", "followtng", "densiies,"], "labels": ["WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "WRONG"]}, "BS-bid-OCR+google": {"tokens": ["where", "T,", "p", "and", "V", "are", "the", "temperature,", "pressure", "and", "volume", "of", "the", "CFT", "respectively.", "If", "we", "introduce", "the", "following", "densities,"], "labels": ["MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED"]}}}, {"corrupt": {"tokens": ["Mostothestatisticallysteadyrunspzoduceasingle,reltivelylargecycloneinasimllarway.Itsaveragesizeincreasesasbmax,andhencequasifriction,arereduce(l.RunsDII2-1654andDI-12-E16-\u221e,withbmax=1/64and0,wereterinatedatt=125yrbecausebythentheyh~ddevelopedsineglecyc\\]oueslarqeenoughtoproduct:anunrealistic0,grosslynonzonal,footprint-dominated\u03b6structure."], "labels": ["WRONG"]}, "correct": {"tokens": ["Most", "of", "the", "statistically", "steady", "runs", "produce", "a", "single,", "relatively", "large", "cyclone", "in", "a", "similar", "way.", "Its", "average", "size", "increases", "as", "bmax,", "and", "hence", "quasifriction,", "are", "reduced.", "Runs", "DI-12-16-64", "and", "DI-12-16-\u221e,", "with", "bmax", "=", "1/64", "and", "0,", "were", "terminated", "at", "t", "=", "125", "yr", "because", "by", "then", "they", "had", "developed", "single", "cyclones", "large", "enough", "to", "produce", "an", "unrealistic,", "grossly", "nonzonal,", "footprint-dominated", "\u03b6", "structure."], "labels": ["TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["Mostothestatisticallysteadyrunspzoduceasingle,reltivelylargecycloneinasimllarway.Itsaveragesizeincreasesasbmax,andhencequasifriction,arereduce(l.RunsDII2-1654andDI-12-E16-\u221e,with", "max=1/64and0,wereterinatedatt=125yrbecausebythentheyh~ddevelopedsineglecyc\\]oueslarqeenoughtoproduct:anunrealistic0,grosslynonzonal,footprint-dominated\u03b6structure."], "labels": ["WRONG", "WRONG"]}, "BS-bid-OCR": {"tokens": ["Most", "o", "the", "statistically", "steady", "runs", "pzoduce", "a", "single,", "reltively", "large", "cyclone", "in", "a", "simllar", "way.", "Its", "average", "size", "increases", "as", "bmax,", "and", "hence", "quasifriction,", "are", "reduce(l.", "Runs", "DII2-1654", "and", "DI-12-E16-\u221e,", "with", "bmax", "=", "1/64", "and", "0,", "were", "terinated", "at", "t", "=", "125", "yr", "because", "by", "then", "they", "h~d", "developed", "sinegle", "cyc\\]oues", "larqe", "enough", "to", "product:", "an", "unrealistic", "0,", "grossly", "nonzonal,", "footprint-dominated", "\u03b6", "structure."], "labels": ["TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["Most", "of", "the", "statistically", "steady", "runs", "produce", "a", "single,", "relatively", "large", "cyclone", "in", "a", "similar", "way.", "Its", "average", "size", "increases", "as", "bmax,", "and", "hence", "quasi", "friction,", "is", "reduced(l.", "Runs", "DII2-1654", "and", "DI-12-E16-\u221e,", "with", "bmax", "=", "1/64", "and", "0,", "were", "terminated", "at", "t", "=", "125", "yr", "because", "by", "then", "they", "h~d", "developed", "single", "cyc\\]oues", "large", "enough", "to", "product:", "an", "unrealistic", "0,", "grossly", "non", "zonal,", "footprint-dominated", "\u03b6", "structure."], "labels": ["TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "WRONG", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "MIXED", "WRONG", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["Rferences"], "labels": ["WRONG"]}, "correct": {"tokens": ["References"], "labels": ["OCR_ERROR"]}, "predicted": {"google": {"tokens": ["References"], "labels": ["OCR_ERROR"]}, "BS-bid-OCR": {"tokens": ["Rferences"], "labels": ["WRONG"]}, "BS-bid-OCR+google": {"tokens": ["References"], "labels": ["OCR_ERROR"]}}}, {"corrupt": {"tokens": ["'Pher-reggeoncontributiontotilepartial-w?veofthescatteringamplitudcisobtainedfromther-rcggeonGreenfuuctionbnconvolutlon~ithimpactfactors\u03a6,dependingonthescatteringparticles.Theangularmomentumjisre;latedto\u03c9be"], "labels": ["WRONG"]}, "correct": {"tokens": ["The", "r-reggeon", "contribution", "to", "the", "partial-wave", "of", "the", "scattering", "amplitude", "is", "obtained", "from", "the", "r-reggeon", "Green", "function", "by", "convolution", "with", "impact", "factors", "\u03a6,", "depending", "on", "the", "scattering", "particles.", "The", "angular", "momentum", "j", "is", "related", "to", "\u03c9", "by"], "labels": ["MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "MIXED", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED"]}, "predicted": {"google": {"tokens": ["'Pher-reggeoncontributiontotilepartial-w?veofthescatteringamplitudcisobtainedfromther-rcggeonGreenfuuctionbnconvolutlon~ithimpactfactors\u03a6,depending", "on", "the", "scattering", "particles.The", "Angular", "Momentum", "J", "Isre;latedto\u03c9be"], "labels": ["WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "WRONG", "WRONG", "WRONG"]}, "BS-bid-OCR": {"tokens": ["'Phe", "r-reggeon", "contribution", "to", "tile", "partial-w?ve", "of", "the", "scattering", "amplitudc", "is", "obtained", "from", "the", "r-rcggeon", "Green", "fuuction", "bn", "convolutlon", "~ith", "impact", "factors", "\u03a6,", "depending", "on", "the", "scattering", "particles.", "The", "angular", "momentum", "j", "is", "re;lated", "to", "\u03c9", "be"], "labels": ["WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "WRONG", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG"]}, "BS-bid-OCR+google": {"tokens": ["'Phe", "r-reggeon", "contribution", "to", "tile", "partial-wave", "of", "the", "scattering", "amplitude", "is", "obtained", "from", "the", "r-region", "Green", "function", "in", "convolution", "~with", "impact", "factors", "\u03a6,", "depending", "on", "the", "scattering", "particles.", "The", "angular", "momentum", "j", "is", "re;lated", "to", "\u03c9", "be"], "labels": ["WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "MIXED", "WRONG", "MIXED", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG"]}}}, {"corrupt": {"tokens": ["Frequencyandtemperaturedependences"], "labels": ["WRONG"]}, "correct": {"tokens": ["Frequency", "and", "temperature", "dependences"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["Frequency", "And", "Temperature", "Dependences"], "labels": ["TOKENIZATION_ERROR", "WRONG", "WRONG", "WRONG"]}, "BS-bid-OCR": {"tokens": ["Frequency", "and", "temperature", "dependences"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["Frequency", "and", "temperature", "dependences"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["Toanalyzeourangle-integratedcresssections,wemakeafurthersimplIficationwhichispossiblebecau~etheS11(1535)resonanceisdominantnearthreshold.Therefore,wei~norethenonresonaltamplitude.Ifonecanisoatethecontrib?utitinofasingleS11resonancetotileE0+multipole,thecrosssectiontakesasimpleform,"], "labels": ["WRONG"]}, "correct": {"tokens": ["To", "analyze", "our", "angle-integrated", "cross", "sections,", "we", "make", "a", "further", "simplification", "which", "is", "possible", "because", "the", "S11(1535)", "resonance", "is", "dominant", "near", "threshold.", "Therefore,", "we", "ignore", "the", "nonresonant", "amplitude.", "If", "one", "can", "isolate", "the", "contribution", "of", "a", "single", "S11", "resonance", "to", "the", "E0", "+", "multipole,", "the", "cross", "section", "takes", "a", "simple", "form,"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["Toanalyzeourangle-integratedcresssections,wemakeafurthersimplIficationwhichispossiblebecau~etheS11(1535)resonance", "isdominantnear", "threshold.Therefore,wei~norethenonresonaltamplitude.Ifonecanisoatethecontrib?utitinofasingleS11resonancetotileE0+multipole,thecrosssectiontakesasimpleform,"], "labels": ["WRONG", "WRONG", "WRONG"]}, "BS-bid-OCR": {"tokens": ["To", "analyze", "our", "angle-integrated", "cress", "sections,", "we", "make", "a", "further", "simplIfication", "which", "is", "possible", "becau~e", "the", "S11(1535)", "resonance", "is", "dominant", "near", "threshold.", "Therefore,", "we", "i~nore", "the", "nonresonalt", "amplitude.", "If", "one", "can", "isoate", "the", "contrib?utitin", "of", "a", "single", "S11", "resonance", "to", "tile", "E0", "+", "multipole,", "the", "cross", "section", "takes", "a", "simple", "form,"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["To", "analyze", "our", "angle-integrated", "cress", "sections,", "we", "make", "a", "further", "simplIfication", "which", "is", "possible", "becau~e", "the", "S11(1535)", "resonance", "is", "dominant", "near", "the", "threshold.", "Therefore,", "we", "i~nore", "the", "non", "resonant", "amplitude.", "If", "one", "can", "isolate", "the", "contribution", "of", "a", "single", "S11", "resonance", "to", "tile", "E0", "+", "multipole,", "the", "cross", "section", "takes", "a", "simple", "form,"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["Nowweneedalinearalgebralemma:"], "labels": ["WRONG"]}, "correct": {"tokens": ["Now", "we", "need", "a", "linear", "algebra", "lemma:"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["Nowweneedalinearalgebralemma:"], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["Now", "we", "need", "a", "linear", "algebra", "lemma:"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["Now", "we", "need", "a", "linear", "algebra", "lemma:"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["wherex12isreal,~m~xI3andx23areimaginary,implyingacontribut\\ontotheCPviolation.Weseethatthesolutionwilhtheoff-diagonalelementexiStsandatleastapartofCP?violationmaycomefromthephaseoftheBCS-NJLorderparameter."], "labels": ["WRONG"]}, "correct": {"tokens": ["where", "x12", "is", "real,", "and", "x13", "and", "x23", "are", "imaginary,", "implying", "a", "contribution", "to", "the", "CP", "violation.", "We", "see", "that", "the", "solution", "with", "the", "off-diagonal", "element", "exists", "and", "at", "least", "a", "part", "of", "CP", "violation", "may", "come", "from", "the", "phase", "of", "the", "BCS-NJL", "order", "parameter."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["wherex12isreal,~m~xI3andx23areimaginary,implyingacontribut\\ontotheCPviolation.Weseethatthesolutionwilhtheoff-diagonalelementexiStsandatleastapartofCP?violationmaycomefromthephaseoftheBCS-NJ", "order", "parameter."], "labels": ["WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR": {"tokens": ["where", "x12", "is", "real,", "~m~", "xI3", "and", "x23", "are", "imaginary,", "implying", "a", "contribut\\on", "to", "the", "CP", "violation.", "We", "see", "that", "the", "solution", "wilh", "the", "off-diagonal", "element", "exiSts", "and", "at", "least", "a", "part", "of", "CP?", "violation", "may", "come", "from", "the", "phase", "of", "the", "BCS-NJL", "order", "parameter."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["where", "x12", "is", "real,", "~m~", "xI3", "and", "x23", "are", "imaginary,", "implying", "a", "contribut\\on", "to", "the", "CP", "violation.", "We", "see", "that", "the", "solution", "wilh", "the", "off-diagonal", "element", "exiSts", "and", "at", "least", "a", "part", "of", "CP?", "violation", "may", "come", "from", "the", "phase", "of", "the", "BCS-NJL", "order", "parameter."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["Ifwewishtogencralisefurth,weneedtodeveloptheanaloguesoftheuniquenessofthedordanal~ebra.Theproofwehadintheseparablecaserestedupontheuniquenessofth(;Cantoralgebra.Inthehigher-dimensalcaewecannothopefo,rthat,butperhapswecanobtainuniquenessrestrinctedto~lgebrathathavethesamcd(,nsese?t.Thisresearchbringsusoutofthescopeofthepresentazticleandweplanitforthefuturework."], "labels": ["WRONG"]}, "correct": {"tokens": ["If", "we", "wish", "to", "generalise", "further,", "we", "need", "to", "develop", "the", "analogues", "of", "the", "uniqueness", "of", "the", "Jordan", "algebra.", "The", "proof", "we", "had", "in", "the", "separable", "case", "rested", "upon", "the", "uniqueness", "of", "the", "Cantor", "algebra.", "In", "the", "higher-dimensional", "case", "we", "cannot", "hope", "for", "that,", "but", "perhaps", "we", "can", "obtain", "uniqueness", "restricted", "to", "algebras", "that", "have", "the", "same", "dense", "set.", "This", "research", "brings", "us", "out", "of", "the", "scope", "of", "the", "present", "article", "and", "we", "plan", "it", "for", "the", "future", "work."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["Ifwewishtogencralisefurth,weneedtodeveloptheanaloguesoftheuniquenessofthedordanal~ebra.Theproofwehadintheseparablecaserestedupontheuniquenessofth(;Cantoralgebra.Inthehigher-dimensalcaewecannothopefo,rthat,butperhapswecanobtainuniquenessrestrinctedto~lgebrathathavethesamcd(,nsese?t.Thisresearchbringsusoutofthescopeofthepresentazticleandweplanitforthefuturework."], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["If", "we", "wish", "to", "gencralise", "furth,", "we", "need", "to", "develop", "the", "analogues", "of", "the", "uniqueness", "of", "the", "dordan", "al~ebra.", "The", "proof", "we", "had", "in", "the", "separable", "case", "rested", "upon", "the", "uniqueness", "of", "th(;", "Cantor", "algebra.", "In", "the", "higher-dimensal", "cae", "we", "cannot", "hope", "fo,r", "that,", "but", "perhaps", "we", "can", "obtain", "uniqueness", "restrincted", "to", "~lgebra", "that", "have", "the", "samc", "d(,nse", "se?t.", "This", "research", "brings", "us", "out", "of", "the", "scope", "of", "the", "present", "azticle", "and", "we", "plan", "it", "for", "the", "future", "work."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["If", "we", "wish", "to", "generalise", "furth,", "we", "need", "to", "develop", "the", "analogues", "of", "the", "uniqueness", "of", "the", "Jordan", "al~ebra.", "The", "proof", "we", "had", "in", "the", "separable", "case", "rested", "upon", "the", "uniqueness", "of", "th(;", "Cantor", "algebra.", "In", "the", "higher-dimensional", "case", "we", "cannot", "hope", "for", "that,", "but", "perhaps", "we", "can", "obtain", "uniqueness", "restricted", "to", "~algebra", "that", "have", "the", "same", "d(,nse", "se?t.", "This", "research", "brings", "us", "out", "of", "the", "scope", "of", "the", "present", "article", "and", "we", "plan", "it", "for", "future", "work."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["ACompactMicrochip-BasedAtmicClockBasedonUltracoldTrappedRbAtoms"], "labels": ["WRONG"]}, "correct": {"tokens": ["A", "Compact", "Microchip-Based", "Atomic", "Clock", "Based", "on", "Ultracold", "Trapped", "Rb", "Atoms"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["ACompactMicrochip-BasedAtmicClockBasedonUltracoldTrappedRbAtoms"], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["A", "Compact", "Microchip-Based", "Atmic", "Clock", "Based", "on", "Ultracold", "Trapped", "Rb", "Atoms"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["A", "Compact", "Microchip-Based", "Atomic", "Clock", "Based", "on", "Ultracold", "Trapped", "Rb", "Atoms"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["|E|\u22652k+2,"], "labels": ["WRONG"]}, "correct": {"tokens": ["|E", "|", "\u22652k", "+", "2,"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["|E|\u22652k+2,"], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["|E", "|", "\u22652k", "+", "2,"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["|E", "|", "\u22652k", "+", "2,"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["Conclusins"], "labels": ["WRONG"]}, "correct": {"tokens": ["Conclusions"], "labels": ["OCR_ERROR"]}, "predicted": {"google": {"tokens": ["Conclusions"], "labels": ["OCR_ERROR"]}, "BS-bid-OCR": {"tokens": ["Conclusins"], "labels": ["WRONG"]}, "BS-bid-OCR+google": {"tokens": ["Conclusions"], "labels": ["OCR_ERROR"]}}}, {"corrupt": {"tokens": ["where"], "labels": ["NONE"]}, "correct": {"tokens": ["where"], "labels": ["NONE"]}, "predicted": {"google": {"tokens": ["where"], "labels": ["NONE"]}, "BS-bid-OCR": {"tokens": ["where"], "labels": ["NONE"]}, "BS-bid-OCR+google": {"tokens": ["where"], "labels": ["NONE"]}}}, {"corrupt": {"tokens": ["ToprovethedifferentiabilLty,wewillusetheimpliitfunctiontieoremiiEanachspaces.Tothisaim,mwedefinetheope?ator"], "labels": ["WRONG"]}, "correct": {"tokens": ["To", "prove", "the", "differentiability,", "we", "will", "use", "the", "implicit", "function", "theorem", "in", "Banach", "spaces.", "To", "this", "aim,", "we", "define", "the", "operator"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED"]}, "predicted": {"google": {"tokens": ["ToprovethedifferentiabilLty,wewillusetheimpliitfunctiontieoremiiEanachspaces.Tothisaim,mwedefinetheope?ator"], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["To", "prove", "the", "differentiabilLty,", "we", "will", "use", "the", "impliit", "function", "tieorem", "ii", "Eanach", "spaces.", "To", "this", "aim,m", "we", "define", "the", "ope?ator"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG"]}, "BS-bid-OCR+google": {"tokens": ["To", "prove", "the", "differentiabilIty,", "we", "will", "use", "the", "implicit", "function", "theorem", "in", "Banach", "spaces.", "To", "this", "aim,m", "we", "define", "the", "ope?ator"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG"]}}}, {"corrupt": {"tokens": ["Therel\\icsofthefirstordercosmicphaetransitionfromquarksto?hadrunscanhusleadtostabletrangequarknuggets,candidatesforcolddarkmatter,appearingintheformnfMACHOsalreadyexperimentatlyobserved."], "labels": ["WRONG"]}, "correct": {"tokens": ["The", "relics", "of", "the", "first", "order", "cosmic", "phase", "transition", "from", "quarks", "to", "hadrons", "can", "thus", "lead", "to", "stable", "strange", "quark", "nuggets,", "candidates", "for", "cold", "dark", "matter,", "appearing", "in", "the", "form", "of", "MACHOs", "already", "experimentally", "observed."], "labels": ["TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["Therel\\icsofthefirstordercosmicphaetransitionfromquarksto?hadrunscanhusleadtostabletrangequarknuggets,candidatesforcolddarkmatter,appearingintheformnfMACHOsalreadyexperimentatlyobserved."], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["The", "rel\\ics", "of", "the", "first", "order", "cosmic", "phae", "transition", "from", "quarks", "to", "?hadruns", "can", "hus", "lead", "to", "stable", "trange", "quark", "nuggets,", "candidates", "for", "cold", "dark", "matter,", "appearing", "in", "the", "form", "nf", "MACHOs", "already", "experimentatly", "observed."], "labels": ["TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["The", "rel\\ics", "of", "the", "first", "order", "cosmic", "phase", "transition", "from", "quarks", "to", "?Hadrons", "can", "bus", "lead", "to", "stable", "strange", "quark", "nuggets,", "candidates", "for", "cold", "dark", "matter,", "appearing", "in", "the", "form", "of", "MACHOs", "already", "experimentally", "observed."], "labels": ["TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["wherefkisgivenby"], "labels": ["WRONG"]}, "correct": {"tokens": ["where", "fk", "is", "given", "by"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["where", "fx", "is", "given", "by"], "labels": ["TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR": {"tokens": ["where", "fk", "is", "given", "by"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["where", "fk", "is", "given", "by"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["~tzerol;hodor,thez-and\u03c4-coMponsntsoftheMaxwellequationboth\\lcadtothesa\\meequation,"], "labels": ["WRONG"]}, "correct": {"tokens": ["At", "zeroth", "order,", "the", "z-", "and", "\u03c4-components", "of", "the", "Maxwell", "equation", "both", "lead", "to", "the", "same", "equation,"], "labels": ["MIXED", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["~tzerol;hodor,the-and\u03c4-coMponent", "softheMaxwellequationboth\\lcadtothesa\\meequation,"], "labels": ["WRONG", "WRONG"]}, "BS-bid-OCR": {"tokens": ["~t", "zerol;hodor,", "the", "z-", "and", "\u03c4-coMponsnts", "of", "the", "Maxwell", "equation", "both\\", "lcad", "to", "the", "sa\\me", "equation,"], "labels": ["WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["~t", "zerol;hodor,", "the", "z-", "and", "\u03c4-coMponents", "of", "the", "Maxwell", "equation", "both\\", "lcad", "to", "the", "sa\\me", "equation,"], "labels": ["WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["wherewehnvadefined"], "labels": ["WRONG"]}, "correct": {"tokens": ["where", "we", "have", "defined"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["wherewehnvadefined"], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["where", "we", "hnva", "defined"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["where", "we", "hnva", "defined"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["In;heprevioussectionwehaveseenthatthelongrangeblock-blockinteractionssreinduced\\intheeffectiveactionf.ortheslowluvabryingfielasofnoncomn~ut?ativescalarth(;oriesafterintegratingoutthe\"off?diagonalcomponents.Theycorl~espondtononpl\\anardiagramswhichcarrynontrivialphasefactors."], "labels": ["WRONG"]}, "correct": {"tokens": ["In", "the", "previous", "section", "we", "have", "seen", "that", "the", "long", "range", "block-block", "interactions", "are", "induced", "in", "the", "effective", "action", "for", "the", "slowly", "varying", "fields", "of", "noncommutative", "scalar", "theories", "after", "integrating", "out", "the", "off-diagonal", "components.", "They", "correspond", "to", "nonplanar", "diagrams", "which", "carry", "nontrivial", "phase", "factors."], "labels": ["TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "MIXED", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["In;heprevioussectionwehaveseenthatthelongrangeblock-blockinteractionssreinduced\\intheeffectiveactionf.ortheslowluvabryingfielasofnoncomn~ut?ativescalarth(;oriesafterintegratingoutthe\"off?diagonal", "components.They", "Corl~espondtononpl\\anardiagramswhichcarrynontrivialphasefactors."], "labels": ["WRONG", "WRONG", "WRONG"]}, "BS-bid-OCR": {"tokens": ["In", ";he", "previous", "section", "we", "have", "seen", "that", "the", "long", "range", "block-block", "interactions", "sre", "induced", "\\in", "the", "effective", "action", "f.or", "the", "slowlu", "vabrying", "fielas", "of", "noncomn~ut?ative", "scalar", "th(;ories", "after", "integrating", "out", "the", "\"off?diagonal", "components.", "They", "corl~espond", "to", "nonpl\\anar", "diagrams", "which", "carry", "nontrivial", "phase", "factors."], "labels": ["TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "WRONG", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["In", ";he", "previous", "section", "we", "have", "seen", "that", "the", "long", "range", "block-block", "interactions", "are", "induced", "\\in", "the", "effective", "action", "for", "the", "slowly", "varying", "fields", "of", "non", "comm~ut?ative", "scalar", "th(;ories", "after", "integrating", "out", "the", "\"off?diagonal", "components.", "They", "call~respond", "to", "nonpl\\anar", "diagrams", "which", "carry", "non", "trivial", "phase", "factors."], "labels": ["TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "MIXED", "MIXED", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["Ifwestudythestructure\u0003oflocalandglobalminimawil,hgreatcare,wediscoverthatfrustrationimpliesthepresenceofdelectswhichcanbeputinmanywaysonthelattice.Thegroundstai;ei\\sdegenerate.Thenumberoflocalandnotglobalrninimaisalsolarge."], "labels": ["WRONG"]}, "correct": {"tokens": ["If", "we", "study", "the", "structure", "of", "local", "and", "global", "minima", "with", "great", "care,", "we", "discover", "that", "frustration", "implies", "the", "presence", "of", "defects", "which", "can", "be", "put", "in", "many", "ways", "on", "the", "lattice.", "The", "ground", "state", "is", "degenerate.", "The", "number", "of", "local", "and", "not", "global", "minima", "is", "also", "large."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["Ifwestudythestructureoflocalandglobalminimawil,hgreatcare,wediscoverthatfrustrationimpliesthepresenceofdelectswhichcanbeputinmanywaysonthelattice.Thegroundstai;ei\\sdegenerate.Thenumberoflocalandnotglobalrninimaisalsolarge."], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["If", "we", "study", "the", "structure\u0003", "of", "local", "and", "global", "minima", "wil,h", "great", "care,", "we", "discover", "that", "frustration", "implies", "the", "presence", "of", "delects", "which", "can", "be", "put", "in", "many", "ways", "on", "the", "lattice.", "The", "ground", "stai;e", "i\\s", "degenerate.", "The", "number", "of", "local", "and", "not", "global", "rninima", "is", "also", "large."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["If", "we", "study", "the", "structure", "of", "local", "and", "global", "minima", "with", "great", "care,", "we", "discover", "that", "frustration", "implies", "the", "presence", "of", "defects", "which", "can", "be", "put", "in", "many", "ways", "on", "the", "lattice.", "The", "ground", "stai;e", "i\\s", "degenerate.", "The", "number", "of", "local", "and", "not", "global", "minima", "is", "also", "large."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["willbesaIxltoaccomPanytheproces1.Theyw\\[ouldbeinvariantundertimeevolutionifthetransitionrateswilerefixedatthesubse\\quenttlrncstotheirtimes-tvc~lues."], "labels": ["WRONG"]}, "correct": {"tokens": ["will", "be", "said", "to", "accompany", "the", "process.", "They", "would", "be", "invariant", "under", "time", "evolution", "if", "the", "transition", "rates", "where", "fixed", "at", "the", "subsequent", "times", "to", "their", "times-t", "values."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED"]}, "predicted": {"google": {"tokens": ["willbesaIxltoaccomPanytheproces1.Theyw\\[ouldbeinvariantundertimeevolutionifthetransitionrateswilerefixedatthesubse\\quenttlrncstotheirtimes-tvc~lues."], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["will", "be", "saIxl", "to", "accomPany", "the", "proces", "1.", "They", "w\\[ould", "be", "invariant", "under", "time", "evolution", "if", "the", "transition", "rates", "wilere", "fixed", "at", "the", "subse\\quent", "tlrncs", "to", "their", "times-t", "vc~lues."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG"]}, "BS-bid-OCR+google": {"tokens": ["will", "be", "saIl", "to", "accomPany", "the", "proces", "1.", "They", "w\\[ould", "be", "invariant", "under", "time", "evolution", "if", "the", "transition", "rates", "were", "fixed", "at", "the", "subse\\quent", "turns", "to", "their", "times-t", "vc~lues."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG"]}}}, {"corrupt": {"tokens": ["Convectivebackwarming"], "labels": ["WRONG"]}, "correct": {"tokens": ["Convective", "backwarming"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["Convectivebackwarming"], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["Convective", "backwarming"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["Convective", "backwarming"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["Faulke\\sIelescopeNorth"], "labels": ["WRONG"]}, "correct": {"tokens": ["Faulkes", "Telescope", "North"], "labels": ["MIXED", "MIXED", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["Faulke\\sIelescopeNorth"], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["Faulke\\s", "Ielescope", "North"], "labels": ["WRONG", "WRONG", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["Faulkes", "Telescope", "North"], "labels": ["MIXED", "MIXED", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["\u03ba\u22480.50."], "labels": ["WRONG"]}, "correct": {"tokens": ["\u03ba", "\u2248", "0.50."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["\u03ba\u22480.50."], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["\u03ba", "\u2248", "0.50."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["\u03ba", "\u2248", "0.50."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["SpecifLcally,"], "labels": ["WRONG"]}, "correct": {"tokens": ["Specifically,"], "labels": ["OCR_ERROR"]}, "predicted": {"google": {"tokens": ["SpecifIcally,"], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["SpecifLcally,"], "labels": ["WRONG"]}, "BS-bid-OCR+google": {"tokens": ["SpecifIcally,"], "labels": ["WRONG"]}}}, {"corrupt": {"tokens": ["F(\u03bba,\u03bbb,\u03bbc}=F(a,b,c)=Fa/c,b/c,1)\u03bb>0."], "labels": ["WRONG"]}, "correct": {"tokens": ["F(\u03bba,", "\u03bbb,", "\u03bbc)", "=", "F(a,", "b,", "c)", "=", "F(a/c,", "b/c,", "1)", "\u03bb", ">", "0."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["F(\u03bba,\u03bbb,\u03bbc}=F(a,b,c)=Fa/c,b/c,1)\u03bb>0."], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["F(\u03bba,", "\u03bbb,", "\u03bbc}", "=", "F(a,", "b,", "c)", "=", "Fa/c,", "b/c,", "1)\u03bb", ">", "0."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["F(\u03bba,", "\u03bbb,", "\u03bbc}", "=", "F(a,", "b,", "c)", "=", "Fa/c,", "b/c,", "1)\u03bb", ">", "0."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["TheHigherrRankRigidityTh('oremforManifoldsWithNoFocalPoints"], "labels": ["WRONG"]}, "correct": {"tokens": ["The", "Higher", "Rank", "Rigidity", "Theorem", "for", "Manifolds", "With", "No", "Focal", "Points"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["The", "Higher", "Rank", "Rigidity('oremforManifoldsWithNoFocalPoints"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG"]}, "BS-bid-OCR": {"tokens": ["The", "Higherr", "Rank", "Rigidity", "Th('orem", "for", "Manifolds", "With", "No", "Focal", "Points"], "labels": ["TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["The", "Higher", "Rank", "Rigidity", "Th('orem", "for", "Manifolds", "With", "No", "Focal", "Points"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["Afterthetipwasmounted,thel'esonancefullwidtilathalfmaximumwasabout5Hzinair(1Hzinvaouum).ItscorrespondingQ-valuewasibout104\\inair(3\u00d7104invacuum).TheseQ-valueswerealmostthesameasthosebefere\\thetipwasmounted.WeattributetheremarkablysmallchangeintheQ-valuestuothew~rysmalla(mountofglueused.BecausetheQ-valuewasroughly100timeslaryerthanthato\\fcantilever,itcompensatedforthcilighstiffnessofth~tuningfork?intetmsofthesensitivity."], "labels": ["WRONG"]}, "correct": {"tokens": ["After", "the", "tip", "was", "mounted,", "the", "resonance", "full", "width", "at", "half", "maximum", "was", "about", "5", "Hz", "in", "air", "(1", "Hz", "in", "vacuum).", "Its", "corresponding", "Q-value", "was", "about", "104", "in", "air", "(3", "\u00d7", "104", "in", "vacuum).", "These", "Q-values", "were", "almost", "the", "same", "as", "those", "before", "the", "tip", "was", "mounted.", "We", "attribute", "the", "remarkably", "small", "change", "in", "the", "Q-values", "to", "the", "very", "small", "amount", "of", "glue", "used.", "Because", "the", "Q-value", "was", "roughly", "100", "times", "larger", "than", "that", "of", "a", "cantilever,", "it", "compensated", "for", "the", "high", "stiffness", "of", "the", "tuning", "fork", "in", "terms", "of", "the", "sensitivity."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["Afterthetipwasmounted,thel'esonancefullwidtilathalfmaximumwasabout5Hzinair(1Hzinvaouum).Its", "corresponding-value", "was", "about", "104\\inair(3\u00d7104invacuum).TheseQ-valueswerealmostthesameasthosebefere\\thetipwasmounted.WeattributetheremarkablysmallchangeintheQ-valuestuothew~rysmalla(mountofglueused.BecausetheQ-valuewasroughly100timeslaryerthanthato\\fcantilever,itcompensatedforthcilighstiffnessofth~tuningfork?intetmsofthesensitivity."], "labels": ["WRONG", "WRONG", "TOKENIZATION_ERROR", "MIXED", "WRONG"]}, "BS-bid-OCR": {"tokens": ["After", "the", "tip", "was", "mounted,", "the", "l'esonance", "full", "widtil", "at", "half", "maximum", "was", "about", "5", "Hz", "in", "air", "(1", "Hz", "in", "vaouum).", "Its", "corresponding", "Q-value", "was", "ibout", "104", "\\in", "air", "(3", "\u00d7", "104", "in", "vacuum).", "These", "Q-values", "were", "almost", "the", "same", "as", "those", "befere", "\\the", "tip", "was", "mounted.", "We", "attribute", "the", "remarkably", "small", "change", "in", "the", "Q-values", "tuo", "the", "w~ry", "small", "a(mount", "of", "glue", "used.", "Because", "the", "Q-value", "was", "roughly", "100", "times", "laryer", "than", "that", "o\\f", "cantilever,", "it", "compensated", "for", "thc", "iligh", "stiffness", "of", "th~", "tuning", "for", "k?", "in", "tetms", "of", "the", "sensitivity."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "MIXED", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["After", "the", "tip", "was", "mounted,", "the", "l'esonance", "full", "width", "at", "half", "maximum", "was", "about", "5", "Hz", "in", "air", "(1", "Hz", "in", "vacuum).", "Its", "corresponding", "Q-value", "was", "about", "104", "\\in", "air", "(3", "\u00d7", "104", "in", "vacuum).", "These", "Q-values", "were", "almost", "the", "same", "as", "those", "before", "\\the", "tip", "was", "mounted.", "We", "attribute", "the", "remarkably", "small", "change", "in", "the", "Q-values", "to", "the", "w~ry", "small", "a(mount", "of", "glue", "used.", "Because", "the", "Q-value", "was", "roughly", "100", "times", "larger", "than", "that", "o\\f", "cantilever,", "it", "compensated", "for", "the", "high", "stiffness", "of", "the~", "tuning", "fork", "in", "terms", "of", "the", "sensitivity."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["Introduction"], "labels": ["NONE"]}, "correct": {"tokens": ["Introduction"], "labels": ["NONE"]}, "predicted": {"google": {"tokens": ["Introduction"], "labels": ["NONE"]}, "BS-bid-OCR": {"tokens": ["Introduction"], "labels": ["NONE"]}, "BS-bid-OCR+google": {"tokens": ["Introduction"], "labels": ["NONE"]}}}, {"corrupt": {"tokens": ["\u03c00reeonstru?ctionefficiency"], "labels": ["WRONG"]}, "correct": {"tokens": ["\u03c00", "reconstruction", "efficiency"], "labels": ["TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["\u03c00reeonstru?ct", "efficiency"], "labels": ["WRONG", "TOKENIZATION_ERROR"]}, "BS-bid-OCR": {"tokens": ["\u03c00", "reeonstru?ction", "efficiency"], "labels": ["TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["\u03c00", "reconstruction", "efficiency"], "labels": ["TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["Thel)osteriorprobabilitydistributionsforindivi_dusalphysicalparmeterscanbeobtainedbymarginalizingPtoo\\verrema.iningparameters,forexample,theposteriOrprobabilitydistributionofthesourcesizeis"], "labels": ["WRONG"]}, "correct": {"tokens": ["The", "posterior", "probability", "distributions", "for", "individual", "physical", "parameters", "can", "be", "obtained", "by", "marginalizing", "Ptot", "over", "remaining", "parameters,", "for", "example,", "the", "posterior", "probability", "distribution", "of", "the", "source", "size", "is"], "labels": ["TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["Thel)osteriorprobabilitydistributionsforindivi_dusalphysicalparmeterscanbeobtainedbymarginalizingPtoo\\verrema.iningparameters,forexample,theposteriOrprobabilitydistributionofthesourcesizeis"], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["The", "l)osterior", "probability", "distributions", "for", "indivi_dusal", "physical", "parmeters", "can", "be", "obtained", "by", "marginalizing", "P", "to", "o\\ver", "rema.ining", "parameters,", "for", "example,", "the", "posteriOr", "probability", "distribution", "of", "the", "source", "size", "is"], "labels": ["TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["The", "l)posterior", "probability", "distributions", "for", "indivi_dusal", "physical", "parameters", "can", "be", "obtained", "by", "marginalizing", "P", "to", "o\\ver", "remaining", "parameters,", "for", "example,", "the", "posteriOr", "probability", "distribution", "of", "the", "source", "size", "is"], "labels": ["TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "WRONG", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["LetuconsideraunitceiIofttlewiremeshwiththreeintersectingonnectedwire.Thetotalchargeqaccumulatedonthesethreewiresperunitcellcanbefounda"], "labels": ["WRONG"]}, "correct": {"tokens": ["Let", "us", "consider", "a", "unit", "cell", "of", "the", "wire", "mesh", "with", "three", "intersecting", "connected", "wires.", "The", "total", "charge", "q", "accumulated", "on", "these", "three", "wires", "per", "unit", "cell", "can", "be", "found", "as"], "labels": ["TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED"]}, "predicted": {"google": {"tokens": ["LetuconsideraunitceiIofttlewiremeshwiththreeintersectingonnectedwire.Thetotalchargeqaccumulatedonthesethreewiresperunitcellcanbefounda"], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["Let", "u", "consider", "a", "unit", "ceiI", "of", "ttle", "wire", "mesh", "with", "three", "intersecting", "onnected", "wire.", "The", "total", "charge", "q", "accumulated", "on", "these", "three", "wires", "per", "unit", "cell", "can", "be", "found", "a"], "labels": ["TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG"]}, "BS-bid-OCR+google": {"tokens": ["Let", "us", "consider", "a", "unit", "cell", "of", "ttle", "wire", "mesh", "with", "three", "intersecting", "connected", "wires.", "The", "total", "charge", "q", "accumulated", "on", "these", "three", "wires", "per", "unit", "cell", "can", "be", "found", "a"], "labels": ["TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG"]}}}, {"corrupt": {"tokens": ["InthissectionwewanttoprovideasimPloestimationofthestatticalfluctua(;ions3itheeffectivetotalleptonnumbcr.ThesearisesimplyI)ecauseoftilefluctuationsinthenumberofparticleswithinthreqion,aroundeitchoscillatingneuttinowawepacket,thatdeterminesthepropertiesofthemediumlhroughthecffectivepotential."], "labels": ["WRONG"]}, "correct": {"tokens": ["In", "this", "section", "we", "want", "to", "provide", "a", "simple", "estimation", "of", "the", "statistical", "fluctuations", "in", "the", "effective", "total", "lepton", "number.", "These", "arise", "simply", "because", "of", "the", "fluctuations", "in", "the", "number", "of", "particles", "within", "the", "region,", "around", "each", "oscillating", "neutrino", "wavepacket,", "that", "determines", "the", "properties", "of", "the", "medium", "through", "the", "effective", "potential."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "MIXED", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["InthissectionwewanttoprovideasimPloestimationofthestatticalfluctua(;ions3itheeffectivetotalleptonnumbcr.ThesearisesimplyI)ecauseoftilefluctuationsinthenumberofparticleswithinthreqion,aroundeitchoscillatingneuttinowawepacket,thatdeterminesthepropertiesofthemediumlhroughthecffectivepotential."], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["In", "this", "section", "we", "want", "to", "provide", "a", "simPlo", "estimation", "of", "the", "stattical", "fluctua(;ions", "3i", "the", "effective", "total", "lepton", "numbcr.", "These", "arise", "simply", "I)ecause", "of", "tile", "fluctuations", "in", "the", "number", "of", "particles", "within", "th", "reqion,", "around", "eitch", "oscillating", "neuttino", "wawe", "packet,", "that", "determines", "the", "properties", "of", "the", "medium", "lhrough", "the", "cffective", "potential."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "MIXED", "WRONG", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["In", "this", "section", "we", "want", "to", "provide", "a", "simPlo", "estimation", "of", "the", "statistical", "fluctua(;ions", "3i", "the", "effective", "total", "lepton", "number.", "These", "arise", "simply", "I)because", "of", "tile", "fluctuations", "in", "the", "number", "of", "particles", "within", "the", "region,", "around", "which", "an", "oscillating", "neutrino", "wave", "packet", "determines", "the", "properties", "of", "the", "medium", "through", "the", "effective", "potential."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "MIXED", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "MIXED", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["A1)owerLhisdeposlt?edin.theplasmaasheatingandescapesthesystemasthreedifferentkindsofradiation:"], "labels": ["WRONG"]}, "correct": {"tokens": ["A", "power", "Lh", "is", "deposited", "in", "the", "plasma", "as", "heating", "and", "escapes", "the", "system", "as", "three", "different", "kinds", "of", "radiation:"], "labels": ["TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["A1)owerLhisdeposlt?edin.theplasmaasheatingandescapesthesystemasthreedifferentkindsofradiation:"], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["A", "1)ower", "Lh", "is", "deposlt?ed", "in.", "the", "plasma", "as", "heating", "and", "escapes", "the", "system", "as", "three", "different", "kinds", "of", "radiation:"], "labels": ["TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["A", "1)lower", "Lh", "is", "deposited", "in.", "the", "plasma", "as", "heating", "and", "escapes", "the", "system", "as", "three", "different", "kinds", "of", "radiation:"], "labels": ["TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["Thesolutionsoftheformallimit"], "labels": ["WRONG"]}, "correct": {"tokens": ["The", "solutions", "of", "the", "formal", "limit"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["Thesolutionsoftheformallimit"], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["The", "solutions", "of", "the", "formal", "limit"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["The", "solutions", "of", "the", "formal", "limit"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["Hence,weobtain"], "labels": ["WRONG"]}, "correct": {"tokens": ["Hence,", "we", "obtain"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["Hence,we", "obtain"], "labels": ["WRONG", "TOKENIZATION_ERROR"]}, "BS-bid-OCR": {"tokens": ["Hence,", "we", "obtain"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["Hence,", "we", "obtain"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["Finally,byTheonrem12,wehave"], "labels": ["WRONG"]}, "correct": {"tokens": ["Finally,", "by", "Theorem", "1.2,", "we", "have"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["Finally,byTheonrem12,wehave"], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["Finally,", "by", "Theonrem", "12,", "we", "have"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["Finally,", "by", "Theorem", "12,", "we", "have"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["\\with"], "labels": ["WRONG"]}, "correct": {"tokens": ["with"], "labels": ["NONE"]}, "predicted": {"google": {"tokens": ["\\with"], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["\\with"], "labels": ["WRONG"]}, "BS-bid-OCR+google": {"tokens": ["\\with"], "labels": ["WRONG"]}}}, {"corrupt": {"tokens": ["TheModel"], "labels": ["WRONG"]}, "correct": {"tokens": ["The", "Model"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["TheModel"], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["The", "Model"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["The", "Model"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["andthevortxenergy"], "labels": ["WRONG"]}, "correct": {"tokens": ["and", "the", "vortex", "energy"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["and", "vortex", "energy"], "labels": ["TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR"]}, "BS-bid-OCR": {"tokens": ["and", "the", "vortx", "energy"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["and", "the", "vortex", "energy"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["Now,"], "labels": ["NONE"]}, "correct": {"tokens": ["Now,"], "labels": ["NONE"]}, "predicted": {"google": {"tokens": ["Now,"], "labels": ["NONE"]}, "BS-bid-OCR": {"tokens": ["Now,"], "labels": ["NONE"]}, "BS-bid-OCR+google": {"tokens": ["Now,"], "labels": ["NONE"]}}}, {"corrupt": {"tokens": ["Inkummary,anultralowlttemperatur0aointcontactsetupusingnanopositionerswasusedtomoneasuredifferenalialresstanceofW/S\\ROpointcontactjullctions.We~ind:1)0~sperconductinggaparouud0.2mVandadonelike~hapeofconductanceenhancement,consistmenlwithchiralp-wavesymmeiry;2SC-likefeaturespersisligupto6.2K,muchhigherthanthebulkTcofSROri,presu?meblyduetothepressureexertedbytheWtipandamechanismsimilartothatofthe3K-phase;s)abroadreCsistancehumpcoexistingwithsuperconductivil;y,whichiascribedtodensi.l,yofstatesefectdueto2Delectron-elecl;roninteracl,Jon,cons\\]stentwiththehighlyani8otropicelectronicsystemofcSRO.WebelievePCSmaycrov??(leusefuli?nformationbyondtheasrfaceprablemforSRO."], "labels": ["WRONG"]}, "correct": {"tokens": ["In", "summary,", "an", "ultralow", "temperature", "point", "contact", "setup", "using", "nanopositioners", "was", "used", "to", "measure", "differential", "resistance", "of", "W/SRO", "point", "contact", "junctions.", "We", "find:", "1)", "a", "superconducting", "gap", "around", "0.2", "mV", "and", "a", "dome", "like", "shape", "of", "conductance", "enhancement,", "consistent", "with", "chiral", "p-wave", "symmetry;", "2)", "SC-like", "features", "persisting", "up", "to", "6.2", "K,", "much", "higher", "than", "the", "bulk", "Tc", "of", "SRO,", "presumably", "due", "to", "the", "pressure", "exerted", "by", "the", "W", "tip", "and", "a", "mechanism", "similar", "to", "that", "of", "the", "3K-phase;", "3)", "a", "broad", "resistance", "hump", "coexisting", "with", "superconductivity,", "which", "is", "ascribed", "to", "density", "of", "states", "effect", "due", "to", "2D", "electron-electron", "interaction,", "consistent", "with", "the", "highly", "anisotropic", "electronic", "system", "of", "SRO.", "We", "believe", "PCS", "may", "provide", "useful", "information", "beyond", "the", "surface", "problem", "for", "SRO."], "labels": ["TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["Inkummary,anultralowlttemperatur0aointcontactsetupusingnanopositionerswasusedtomoneasuredifferenalialresstanceofW/S\\ROpointcontactjullctions.We~ind:1)0~sperconductinggaparouud0.2mVandadonelike~hape", "conductance", "enhancement,consistmenlwithchiralp-wavesymmeiry;2SC-likefeaturespersisligupto6.2K,muchhigherthanthebulkTcofSROri,presu?meblyduetothepressureexertedbytheWtipandamechanismsimilartothatofthe3K-phase;s)abroadreCsistancehumpcoexistingwithsuperconductivil;y,whichiascribedtodensi.l,yofstatesefectdueto2Delectron-elecl;roninteracl,Jon,cons\\]stentwiththehighlyani8otropicelectronicsystemofcSRO.WebelievePCSmaycrov??(leusefuli?nformationbyondtheasrfaceprablemforSRO."], "labels": ["WRONG", "TOKENIZATION_ERROR", "WRONG"]}, "BS-bid-OCR": {"tokens": ["In", "kummary,", "an", "ultralowlt", "temperatur0", "aoint", "contact", "setup", "using", "nanopositioners", "was", "used", "to", "moneasure", "differenalial", "resstance", "of", "W/S\\RO", "point", "contact", "jullctions.", "We", "~ind:", "1)0~", "sperconducting", "gap", "arouud", "0.2", "mV", "and", "a", "done", "like", "~hape", "of", "conductance", "enhancement,", "consistmenl", "with", "chiral", "p-wave", "symmeiry;", "2SC-like", "features", "persislig", "up", "to", "6.2", "K,", "much", "higher", "than", "the", "bulk", "Tc", "of", "SR", "Ori,", "presu?mebly", "due", "to", "the", "pressure", "exerted", "by", "the", "W", "tip", "and", "a", "mechanism", "similar", "to", "that", "of", "the", "3K-phase;", "s)", "a", "broad", "reCsistance", "hump", "coexisting", "with", "superconductivil;y,", "which", "i", "ascribed", "to", "densi.l,y", "of", "states", "efect", "due", "to", "2D", "electron-elecl;ron", "interacl,Jon,", "cons\\]stent", "with", "the", "highly", "ani8otropic", "electronic", "system", "of", "cSRO.", "We", "believe", "PCS", "may", "crov??(le", "useful", "i?nformation", "byond", "the", "asrface", "prablem", "for", "SRO."], "labels": ["TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "WRONG", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["In", "summary,", "an", "ultralow", "lt", "temperatur0", "point", "contact", "setup", "using", "nanopositioners", "was", "used", "to", "measure", "differential", "resistance", "of", "W/S\\RO", "point", "contact", "junctions.", "We", "~ind:", "1)0~", "superconducting", "gap", "around", "0.2", "mV", "and", "a", "dome", "like", "~shape", "of", "conductance", "enhancement,", "consistent", "with", "chiral", "p-wave", "symmetry;", "2SC-like", "features", "personlig", "up", "to", "6.2", "K,", "much", "higher", "than", "the", "bulk", "Tc", "of", "SR", "Ori,", "presumably", "due", "to", "the", "pressure", "exerted", "by", "the", "W", "tip", "and", "a", "mechanism", "similar", "to", "that", "of", "the", "3K-phase;", "s)", "a", "broad", "resistance", "hump", "coexisting", "with", "superconductivil;y,", "which", "i", "ascribed", "to", "densi.l,y", "of", "states", "effect", "due", "to", "2D", "electron-elecl;ron", "interacl,Jon,", "cons\\]stent", "with", "the", "highly", "anisotropic", "electronic", "system", "of", "cSRO.", "We", "believe", "PCS", "may", "crov??(le", "useful", "information", "beyond", "the", "surface", "problem", "for", "SRO."], "labels": ["TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "MIXED", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "WRONG", "WRONG", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["Inconc|usion,wehaveshownlhatheZFCstal;nisstableagainstcurrentcyclingincontrasttotileFCstatewhich,isfoundtobemetastable.Thisbehavi?orisoppositetothethermalcyclingwheretheFCstateisstable.Wealofindthatthedefectdensit~ndferany\\initialstateconvergestothesam(:wdueo!Ic."], "labels": ["WRONG"]}, "correct": {"tokens": ["In", "conclusion,", "we", "have", "shown", "that", "the", "ZFC", "state", "is", "stable", "against", "current", "cycling", "in", "contrast", "to", "the", "FC", "state", "which", "is", "found", "to", "be", "metastable.", "This", "behavior", "is", "opposite", "to", "the", "thermal", "cycling", "where", "the", "FC", "state", "is", "stable.", "We", "also", "find", "that", "the", "defect", "density", "nd", "for", "any", "initial", "state", "converges", "to", "the", "same", "value", "at", "Ic."], "labels": ["TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "MIXED", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["Inconc|usion,wehaveshownlhatheZFCstal;nisstableagainstcurrentcyclingincontrasttotileFCstatewhich,isfoundtobemetastable.Thisbehavi?orisoppositetothethermalcyclingwheretheFCstateisstable.Wealofindthatthedefectdensit~ndferany\\initialstateconvergestothesam(:video!Ic."], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["In", "conc|usion,", "we", "have", "shown", "lha", "the", "ZFC", "stal;n", "is", "stable", "against", "current", "cycling", "in", "contrast", "to", "tile", "FC", "state", "which", ",is", "found", "to", "be", "metastable.", "This", "behavi?or", "is", "opposite", "to", "the", "thermal", "cycling", "where", "the", "FC", "state", "is", "stable.", "We", "alo", "find", "that", "the", "defect", "densit~", "nd", "fer", "any", "\\initial", "state", "converges", "to", "the", "sam(:", "wdue", "o!", "Ic."], "labels": ["TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "WRONG", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["In", "conc|usion,", "we", "have", "shown", "lha", "the", "ZFC", "stal;n", "is", "stable", "against", "current", "cycling", "in", "contrast", "to", "tile", "FC", "state", "which", "is", "found", "to", "be", "metastable.", "This", "behavior", "is", "opposite", "to", "thermal", "cycling", "where", "the", "FC", "state", "is", "stable.", "We", "also", "find", "that", "the", "defect", "density~", "end", "for", "any", "\\initial", "state", "converges", "to", "the", "same(:", "wdio!", "Ic."], "labels": ["TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "MIXED", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["Effectsofcolorsuperconductivltyonthenuleationofquarkmatterintnnelltronstars"], "labels": ["WRONG"]}, "correct": {"tokens": ["Effects", "of", "color", "superconductivity", "on", "the", "nucleation", "of", "quark", "matter", "in", "neutron", "stars"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["Effectsofcolorsuperconductivltyonthenuleationofquarkmatterintnnelltronstars"], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["Effects", "of", "color", "superconductivlty", "on", "the", "nuleation", "of", "quark", "matter", "intn", "nelltron", "stars"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["Effects", "of", "color", "superconductivity", "on", "the", "nucleation", "of", "quark", "matter", "in", "neutron", "stars"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["One-loopself-encrgycalcultion"], "labels": ["WRONG"]}, "correct": {"tokens": ["One-loop", "self-energy", "calculation"], "labels": ["TOKENIZATION_ERROR", "MIXED", "MIXED"]}, "predicted": {"google": {"tokens": ["One-loop", "self-encrgycalcultion"], "labels": ["TOKENIZATION_ERROR", "WRONG"]}, "BS-bid-OCR": {"tokens": ["One-loop", "self-encrgy", "calcultion"], "labels": ["TOKENIZATION_ERROR", "WRONG", "WRONG"]}, "BS-bid-OCR+google": {"tokens": ["One-loop", "self-energy", "calculation"], "labels": ["TOKENIZATION_ERROR", "MIXED", "MIXED"]}}}, {"corrupt": {"tokens": ["Step2:Dividetheprofileseri~_esintonon-overlappingsegmentswithequalle'n\\gthandfittigcachsegmentw-ithasecondorderpolynomialfunction.Regardthefittiugresultsasthetrends,astationaryseriescanbeobtainedbyeliminatingthetrendsfromtheprofileseries."], "labels": ["WRONG"]}, "correct": {"tokens": ["Step", "2:", "Divide", "the", "profile", "series", "into", "non-overlapping", "segments", "with", "equal", "length", "and", "fitting", "each", "segment", "with", "a", "second", "order", "polynomial", "function.", "Regard", "the", "fitting", "results", "as", "the", "trends,", "a", "stationary", "series", "can", "be", "obtained", "by", "eliminating", "the", "trends", "from", "the", "profile", "series."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["Step2:Dividetheprofileseri~_esintonon-overlappingsegmentswithequalle'n\\gthandfittigcachsegmentw-ithasecondorderpolynomialfunction.Regardthefittiugresultsasthetrends,astationaryseriescanbeobtainedbyeliminatingthetrendsfromtheprofileseries."], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["Step", "2:", "Divide", "the", "profile", "seri~_es", "into", "non-overlapping", "segments", "with", "equal", "le'n\\gth", "and", "fittig", "cach", "segment", "w-ith", "a", "second", "order", "polynomial", "function.", "Regard", "the", "fittiug", "results", "as", "the", "trends,", "a", "stationary", "series", "can", "be", "obtained", "by", "eliminating", "the", "trends", "from", "the", "profile", "series."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["Step", "2:", "Divide", "the", "profile", "seri~_es", "into", "non-overlapping", "segments", "with", "equal", "le'n\\gth", "and", "fitting", "cach", "segment", "w-ith", "a", "second", "order", "polynomial", "function.", "Regarding", "the", "fitting", "results", "as", "the", "trends,", "a", "stationary", "series", "can", "be", "obtained", "by", "eliminating", "the", "trends", "from", "the", "profile", "series."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "MIXED", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["WethankD.Greif,A.Rapp,D,Rost,andU.Schneiderforvaluablediscossions.\\SupportbntheDFGwithinSFB/TRR49isgrateful1yacknowled~ed."], "labels": ["WRONG"]}, "correct": {"tokens": ["We", "thank", "D.", "Greif,", "A.", "Rapp,", "D.", "Rost,", "and", "U.", "Schneider", "for", "valuable", "discussions.", "Support", "by", "the", "DFG", "within", "SFB/TRR", "49", "is", "gratefully", "acknowledged."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED"]}, "predicted": {"google": {"tokens": ["WethankD.Greif,A.Rapp,D,Rost,andU.Schneiderforvaluablediscossions.\\SupportbntheDFGwithinSFB/TRR49isgrateful1yacknowled~ed."], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["We", "thank", "D.", "Greif,", "A.", "Rapp,", "D,", "Rost,", "and", "U.", "Schneider", "for", "valuable", "discossions.\\", "Support", "bn", "the", "DFG", "within", "SFB/TRR49", "is", "grateful1y", "acknowled~ed."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "WRONG"]}, "BS-bid-OCR+google": {"tokens": ["We", "thank", "D.", "Greif,", "A.", "Rapp,", "D,", "Rost,", "and", "U.", "Schneider", "for", "valuable", "discussions.\\", "Support", "bn", "the", "DFG", "within", "SFB/TRR49", "is", "grateful", "1y", "acknowledged."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "WRONG", "MIXED"]}}}, {"corrupt": {"tokens": ["Experiment:M.P.M.D.,G.D.,G.G.,R.S.S.,T.S.,F.Y.-H.,K.K.,N.B.B.andL.B.I)ataanalysisandinterprctation:?M.P,M.D.,J.P.H.andX.L.SamI)legrowthI.B.Samplec\\haracteriza~ion:I.B.,Y.-.S.,'mdJ.S.Projectplanning:M.P.M.D.,J.P.H.andI.B.Paperwritillg.M.P.M.D.,J.P.I.andI.B."], "labels": ["WRONG"]}, "correct": {"tokens": ["Experiment:", "M.P.M.D.,", "G.D.,", "G.G.,", "R.S.S.,", "T.S.,", "F.Y.-H.,", "K.K.,", "N.B.B.", "and", "L.B.", "Data", "analysis", "and", "interpretation:", "M.P.M.D.,", "J.P.H.", "and", "X.L.", "Sample", "growth", "I.B.", "Sample", "characterization:", "I.B.,", "Y.-J.S.", "and", "J.S.", "Project", "planning:", "M.P.M.D.,", "J.P.H.", "and", "I.B.", "Paper", "writing.", "M.P.M.D.,", "J.P.H.", "and", "I.B."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["Experiment:M.P.M.D.,G.D.,G.G.,R.S.S.,T.S.,F.Y.-H.,K.K.,N.B.B.andL.B.I)ataanalysisandinterprctation:?M.P,M.D.,J.P.H.andX.L.SamI)legrowthI.B.Samplec\\haracteriza~ion:I.B.,Y.-.S.,'mdJ.S.Projectplanning:M.P.M.D.,J.P.H.andI.B.Paperwritillg.M.P.M.D.,J.P.I.andI.B."], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["Experiment:", "M.P.M.D.,", "G.D.,", "G.G.,", "R.S.S.,", "T.S.,", "F.Y.-H.,", "K.K.,", "N.", "B.", "B.", "and", "L.", "B.", "I)ata", "analysis", "and", "interprctation:", "?M.P,", "M.D.,", "J.P.H.", "and", "X.L.", "SamI)legrowth", "I.", "B.", "Sample", "c\\haracteriza~ion:", "I.B.,", "Y.-.S.,", "'md", "J.", "S.", "Project", "planning:", "M.P.M.D.,", "J.P.H.", "and", "I.B.", "Paperwritillg.", "M.P.M.D.,", "J.P.I.", "and", "I.B."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "WRONG", "TOKENIZATION_ERROR", "WRONG", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "WRONG", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["Experiment:", "M.P.M.D.,", "G.D.,", "G.G.,", "R.S.S.,", "T.S.,", "F.Y.-H.,", "K.K.,", "N.", "B.", "B.", "and", "L.", "B.", "I)data", "analysis", "and", "interpretation:", "?M.P,", "M.D.,", "J.P.H.", "and", "X.L.", "SamI)legrowth", "I.", "B.", "Sample", "c\\haracteriza~ion:", "I.B.,", "Y.-.S.,", "'md", "J.", "S.", "Project", "planning:", "M.P.M.D.,", "J.P.H.", "and", "I.B.", "Paperwritillg.", "M.P.M.D.,", "J.P.I.", "and", "I.B."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "WRONG", "TOKENIZATION_ERROR", "WRONG", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "WRONG", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["forapositiveconstantC(k)explicitlygivenby"], "labels": ["WRONG"]}, "correct": {"tokens": ["for", "a", "positive", "constant", "C(k)", "explicitly", "given", "by"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["for", "positive", "constant", "C(k)explicitly", "given", "by"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR": {"tokens": ["for", "a", "positive", "constant", "C(k)", "explicitly", "given", "by"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["for", "a", "positive", "constant", "C(k)", "explicitly", "given", "by"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["Praof:Let\u03c0betheprojectionB2n+2(C)\u2192B2(C)whichisinducebyprojectiono~~tatheasttwocoordinates.ThisrepresentsB2n+2(C)asak,loffibrationoverthedisc,ithfiberswhicare\\[concentricballsofdifferentcapacities.Notethattheset"], "labels": ["WRONG"]}, "correct": {"tokens": ["Proof:", "Let", "\u03c0", "be", "the", "projection", "B2n", "+", "2(C)", "\u2192", "B2(C)", "which", "is", "induced", "by", "projection", "onto", "the", "last", "two", "coordinates.", "This", "represents", "B2n", "+", "2(C)", "as", "a", "kind", "of", "fibration", "over", "the", "disc,", "with", "fibers", "which", "are", "concentric", "balls", "of", "different", "capacities.", "Note", "that", "the", "set"], "labels": ["MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["Proof:Let\u03c0betheprojectionB2n+2(C)\u2192B2(C)whichisinduce", "byprojectiono~~tatheasttwocoordinates.ThisrepresentsB2n+2(C)asak,loffibrationoverthedisc,ithfiberswhicare\\[concentric", "balls", "of", "different", "capacities.Note", "That", "The", "Set"], "labels": ["WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "WRONG", "WRONG"]}, "BS-bid-OCR": {"tokens": ["Praof:", "Let", "\u03c0", "be", "the", "projection", "B2n", "+", "2(C)", "\u2192", "B2(C)", "which", "is", "induce", "by", "projection", "o~~ta", "the", "ast", "two", "coordinates.", "This", "represents", "B2n", "+", "2(C)", "as", "a", "k,lof", "fibration", "over", "the", "disc,", "ith", "fibers", "whic", "are", "\\[concentric", "balls", "of", "different", "capacities.", "Note", "that", "the", "set"], "labels": ["WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["Proof:", "Let", "\u03c0", "be", "the", "projection", "B2n", "+", "2(C)", "\u2192", "B2(C)", "which", "is", "induced", "by", "projection", "o~~ta", "the", "last", "two", "coordinates.", "This", "represents", "B2n", "+", "2(C)", "as", "a", "k,of", "fibration", "over", "the", "disc,", "with", "fibers", "which", "are", "\\[concentric", "balls", "of", "different", "capacities.", "Note", "that", "the", "set"], "labels": ["MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["suchl;hatthefollowingtheecondltionsholdforx,y\u2208Aandm\u2208M:\u03b1A(x)(ym)=(xy)(\u03b1M(nlul)),(m?)(\u03b1A(y))=(\u03b1M(m))(xy),and\u03b1A(x)(my)=(xm)(\u03b1A(y)).Amorphismf:M\u2192NcfHom-A-bimodulesisamorphismf:(M,\u03b1M)\u2192(~,\u03b1N)ofHom-modulessuchthatf(am)=af(m)andf(ma)=f(maJora\u2208Aandm\u2208M."], "labels": ["WRONG"]}, "correct": {"tokens": ["such", "that", "the", "following", "three", "conditions", "hold", "for", "x,", "y", "\u2208", "A", "and", "m", "\u2208", "M:", "\u03b1A(x)(ym)", "=", "(xy)(\u03b1M(m)),", "(mx)(\u03b1A(y))", "=", "(\u03b1M(m))(xy),", "and", "\u03b1A(x)(my)", "=", "(xm)(\u03b1A(y)).", "A", "morphism", "f:", "M", "\u2192", "N", "of", "Hom-A-bimodules", "is", "a", "morphism", "f:(M,", "\u03b1M)", "\u2192", "(N,", "\u03b1N)", "of", "Hom-modules", "such", "that", "f(am)", "=", "af(m)", "and", "f(ma)", "=", "f(m)a", "for", "a", "\u2208", "A", "and", "m", "\u2208", "M."], "labels": ["TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["suchl;hatthefollowingtheecondltionsholdforx,y\u2208Aandm\u2208M:\u03b1A(x)(ym)=(xy)(\u03b1M(nlul)),(m?)(\u03b1A(y))=(\u03b1M(m))(xy),and\u03b1A(x)(my)=(xm)(\u03b1A(y)).Amorphismf:M\u2192Ncfom-A-bimodule", "isomorphism:(M,\u03b1M)\u2192(~,\u03b1N)ofCom-modulessuchthatf(am)=af(m)and(ma)=f(maJora\u2208Aandm\u2208M."], "labels": ["WRONG", "WRONG"]}, "BS-bid-OCR": {"tokens": ["such", "l;hat", "the", "following", "thee", "condltions", "hold", "for", "x,", "y", "\u2208", "A", "and", "m", "\u2208", "M:", "\u03b1A(x)(ym)", "=", "(xy)(\u03b1M(nlul)),", "(m?)(\u03b1A(y))", "=", "(\u03b1M(m))(xy),", "and", "\u03b1A(x)(my)", "=", "(xm)(\u03b1A(y)).", "A", "morphism", "f:", "M", "\u2192", "N", "cf", "Hom-A-bimodules", "is", "a", "morphism", "f:(M,", "\u03b1M)", "\u2192", "(~,", "\u03b1N)", "of", "Hom-modules", "such", "that", "f(am)", "=", "af(m)", "and", "f(ma)", "=", "f(maJ", "or", "a", "\u2208", "A", "and", "m", "\u2208", "M."], "labels": ["TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["such", "l;hat", "the", "following", "three", "conditions", "hold", "for", "x,", "y", "\u2208", "A", "and", "m", "\u2208", "M:", "\u03b1A(x)(ym)", "=", "(xy)(\u03b1M(nlul)),", "(m?)(\u03b1A(y))", "=", "(\u03b1M(m))(xy),", "and", "\u03b1A(x)(my)", "=", "(xm)(\u03b1A(y)).", "A", "morphism", "f:", "M", "\u2192", "N", "cf", "Hom-A-bimodules", "is", "a", "morphism", "f:(M,", "\u03b1M)", "\u2192", "(~,", "\u03b1N)", "of", "Hom-modules", "such", "that", "f(am)", "=", "af(m)", "and", "f(ma)", "=", "f(maJ", "or", "a", "\u2208", "A", "and", "m", "\u2208", "M."], "labels": ["TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["whchiscorrect.torO(q2).Parformisngthe\u03bbintegratonwefind"], "labels": ["WRONG"]}, "correct": {"tokens": ["which", "is", "correct", "to", "O(q2)", ".", "Performing", "the", "\u03bb", "integration", "we", "find"], "labels": ["MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["whchiscorrect.torO(q2).Parformisngthe\u03bbintegratonwefind"], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["whch", "is", "correct.", "tor", "O(q2).", "Parformisng", "the", "\u03bb", "integraton", "we", "find"], "labels": ["WRONG", "TOKENIZATION_ERROR", "WRONG", "WRONG", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["which", "is", "correct.", "tor", "O(q2).", "Performing", "the", "\u03bb", "integration", "we", "find"], "labels": ["MIXED", "TOKENIZATION_ERROR", "WRONG", "WRONG", "WRONG", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["a?et"], "labels": ["WRONG"]}, "correct": {"tokens": ["Let"], "labels": ["OCR_ERROR"]}, "predicted": {"google": {"tokens": ["a?et"], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["a?et"], "labels": ["WRONG"]}, "BS-bid-OCR+google": {"tokens": ["a?et"], "labels": ["WRONG"]}}}, {"corrupt": {"tokens": ["Itfollowsthat"], "labels": ["WRONG"]}, "correct": {"tokens": ["It", "follows", "that"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["It", "Follows", "That"], "labels": ["TOKENIZATION_ERROR", "WRONG", "WRONG"]}, "BS-bid-OCR": {"tokens": ["It", "follows", "that"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["It", "follows", "that"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["SupplementaryMaterial"], "labels": ["WRONG"]}, "correct": {"tokens": ["Supplementary", "Material"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["SupplementaryMaterial"], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["Supplementary", "Material"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["Supplementary", "Material"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["AoteonDSR"], "labels": ["WRONG"]}, "correct": {"tokens": ["A", "note", "on", "DSR"], "labels": ["TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["Aotea", "DSR"], "labels": ["WRONG", "TOKENIZATION_ERROR"]}, "BS-bid-OCR": {"tokens": ["Aote", "on", "DSR"], "labels": ["WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["Aote", "on", "DSR"], "labels": ["WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["Becauseoftheselimitaticnsofaurcalibration,itisenvisionedthatthecalibrationresultscanbefurtherrefinedinfuture~tudies,althoughweexpectthamainimprovementtobeal)etl;ercons,trainidcolortermfortheUband.Wenotethat.wehaveaireadyTranderivedtighl;c?onstraintsontilepho.tometriczeropoinTs(\u03c3\u2248001mag)andm\u221e(\u03c3\u22480.02mag)~thesaurationmagnitudeusedintheC-losscorrection."], "labels": ["WRONG"]}, "correct": {"tokens": ["Because", "of", "these", "limitations", "of", "our", "calibration,", "it", "is", "envisioned", "that", "the", "calibration", "results", "can", "be", "further", "refined", "in", "future", "studies,", "although", "we", "expect", "the", "main", "improvement", "to", "be", "a", "better", "constrained", "color", "term", "for", "the", "U", "band.", "We", "note", "that", "we", "have", "already", "derived", "tight", "constraints", "on", "the", "photometric", "zero", "points", "(\u03c3", "\u2248", "0.01", "mag)", "and", "m\u221e", "(\u03c3", "\u2248", "0.02", "mag),", "the", "saturation", "magnitude", "used", "in", "the", "C-loss", "correction."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["Becauseoftheselimitaticnsofaurcalibration,itisenvisionedthatthecalibrationresultscanbefurtherrefinedinfuture~tudies,althoughweexpectthamainimprovementtobeal)etl;ercons,trainidcolortermfortheUband.Wenotethat.wehaveaireadyTranderivedtighl;c?onstraintsontilepho.tometriczeropoinTs(\u03c3\u2248001mag)andm\u221e(\u03c3\u22480.02mag)~thesauration", "magnitude", "used", "in", "C-loss", "correction."], "labels": ["WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR": {"tokens": ["Because", "of", "these", "limitaticns", "of", "aur", "calibration,", "it", "is", "envisioned", "that", "the", "calibration", "results", "can", "be", "further", "refined", "in", "future", "~tudies,", "although", "we", "expect", "tha", "main", "improvement", "to", "be", "a", "l)etl;er", "cons,trainid", "color", "term", "for", "the", "U", "band.", "We", "note", "that.", "we", "have", "aiready", "Tran", "derived", "tighl;", "c?onstraints", "on", "tile", "pho.tometric", "zero", "poinTs", "(\u03c3", "\u2248", "001", "mag)", "and", "m\u221e", "(\u03c3", "\u2248", "0.02", "mag)~", "the", "sauration", "magnitude", "used", "in", "the", "C-loss", "correction."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["Because", "of", "these", "limitations", "of", "aur", "calibration,", "it", "is", "envisioned", "that", "the", "calibration", "results", "can", "be", "further", "refined", "in", "future", "~studies,", "although", "we", "expect", "tha", "main", "improvement", "to", "be", "a", "l)etl;er", "cons,trainid", "color", "term", "for", "the", "U", "band.", "We", "note", "that.", "Tran", "derived", "tight;", "constraints", "on", "tile", "photometric", "zero", "poinTs", "(\u03c3", "\u2248", "001", "mag)", "and", "m\u221e", "(\u03c3", "\u2248", "0.02", "mag)~", "the", "sauration", "magnitude", "used", "in", "the", "C-loss", "correction."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "WRONG", "MIXED", "TOKENIZATION_ERROR", "WRONG", "MIXED", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["Insun~mary,we?defimehe,KPilierarchyb~"], "labels": ["WRONG"]}, "correct": {"tokens": ["In", "summary,", "we", "define", "the", "dKP", "hierarchy", "by"], "labels": ["TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "MIXED", "MIXED", "MIXED", "MIXED"]}, "predicted": {"google": {"tokens": ["Insun~mary,we?define,hierarchy~"], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["In", "sun~mary,", "we?", "defime", "he", ",KP", "ilierarchy", "b~"], "labels": ["TOKENIZATION_ERROR", "WRONG", "WRONG", "WRONG", "WRONG", "WRONG", "WRONG", "WRONG"]}, "BS-bid-OCR+google": {"tokens": ["In", "sun~mary,", "we?", "define", "he", ",KP", "hierarchy", "b~"], "labels": ["TOKENIZATION_ERROR", "WRONG", "WRONG", "MIXED", "WRONG", "WRONG", "MIXED", "WRONG"]}}}, {"corrupt": {"tokens": ["Weconsidcrthezero-pointquantumfluctnuationofarealmasslesscala'fjeld\u03c6(x)inthe\\spati\\allytlatFRWsaceti~ne.Themodeexpansionofthefieldis"], "labels": ["WRONG"]}, "correct": {"tokens": ["We", "consider", "the", "zero-point", "quantum", "fluctuation", "of", "a", "real", "massless", "scalar", "field", "\u03c6(x)", "in", "the", "spatially", "flat", "FRW", "spacetime.", "The", "mode", "expansion", "of", "the", "field", "is"], "labels": ["TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["Weconsidcrthezero-pointquantumfluctnuationofarealmasslesscala'fjeld\u03c6(x)inthe\\spati\\allytlatFRWsaceti~ne.Themodeexpansionofthefieldis"], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["We", "considcr", "the", "zero-point", "quantum", "fluctnuation", "of", "a", "real", "massles", "scala'", "fjeld", "\u03c6(x)", "in", "the\\", "spati\\ally", "tlat", "FRW", "saceti~ne.", "The", "mode", "expansion", "of", "the", "field", "is"], "labels": ["TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["We", "consider", "the", "zero-point", "quantum", "fluctuation", "of", "a", "real", "massless", "scalar", "field", "\u03c6(x)", "in", "the\\", "spati\\ally", "FRW", "spacetime~ne.", "The", "mode", "expansion", "of", "the", "field", "is"], "labels": ["TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["Consistencyconit$onsintheclosedstring(2,2)Bmodel"], "labels": ["WRONG"]}, "correct": {"tokens": ["Consistency", "conditions", "in", "the", "closed", "string", "(2,", "2)", "B", "model"], "labels": ["TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["Consistency", "Conit$absinthe", "closed", "string(2,2)Bmodel"], "labels": ["TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG"]}, "BS-bid-OCR": {"tokens": ["Consistency", "conit$ons", "in", "the", "closed", "string", "(2,2)B", "model"], "labels": ["TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["Consistency", "conit$ons", "in", "the", "closed", "string", "(2,2)B", "model"], "labels": ["TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["imitsoftheHcurnistjcsforExactNMF"], "labels": ["WRONG"]}, "correct": {"tokens": ["Limits", "of", "the", "Heuristics", "for", "Exact", "NMF"], "labels": ["MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["imitsoftheHcurnistjcsforExactNMF"], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["imits", "of", "the", "Hcurnistjcs", "for", "Exact", "NMF"], "labels": ["WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["limits", "of", "the", "Hcurnistjcs", "for", "Exact", "NMF"], "labels": ["WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["withasimilar(:xpressionforthetermswiththePauli-Villasregularizationparameter.Animport~ntfeatureof%hisformulaisl;heproductof?thetwointegrals"], "labels": ["WRONG"]}, "correct": {"tokens": ["with", "a", "similar", "expression", "for", "the", "terms", "with", "the", "Pauli-Villars", "regularization", "parameter.", "An", "important", "feature", "of", "this", "formula", "is", "the", "product", "of", "the", "two", "integrals"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["with", "similar(:xpressionforthetermswiththePauli-Villasregularizationparameter.Animport~ntfeatureof%hisformulaisl;he", "product", "of?the", "two", "integrals"], "labels": ["TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR": {"tokens": ["with", "a", "similar", "(:xpression", "for", "the", "terms", "with", "the", "Pauli-Villas", "regularization", "parameter.", "An", "import~nt", "feature", "of", "%his", "formula", "is", "l;he", "product", "of?", "the", "two", "integrals"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["with", "a", "similar", "(:expression", "for", "the", "terms", "with", "the", "Pauli-Villars", "regularization", "parameter.", "An", "import~nt", "feature", "of", "%his", "formula", "is", "l;he", "product", "of?", "the", "two", "integrals"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["Acknowledgmen\\ts"], "labels": ["WRONG"]}, "correct": {"tokens": ["Acknowledgments"], "labels": ["OCR_ERROR"]}, "predicted": {"google": {"tokens": ["Acknowledgmen\\ts"], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["Acknowledgmen\\ts"], "labels": ["WRONG"]}, "BS-bid-OCR+google": {"tokens": ["Acknowledgmen\\ts"], "labels": ["WRONG"]}}}, {"corrupt": {"tokens": ["Wecla.imthaforn\u22650,"], "labels": ["WRONG"]}, "correct": {"tokens": ["We", "claim", "that", "for", "n", "\u2265", "0,"], "labels": ["TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["Wecla.imthaforn\u22650,"], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["We", "cla.im", "tha", "for", "n", "\u2265", "0,"], "labels": ["TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["We", "cla.im", "that", "for", "n", "\u2265", "0,"], "labels": ["TOKENIZATION_ERROR", "WRONG", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["whereXidenoresthelbcatiortoftheithimpuity."], "labels": ["WRONG"]}, "correct": {"tokens": ["where", "xi", "denotes", "the", "location", "of", "the", "ith", "impurity."], "labels": ["TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED"]}, "predicted": {"google": {"tokens": ["whereXidenoresthelbcatiortoftheithimpuity."], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["where", "Xi", "denores", "the", "lbcatiort", "of", "the", "ith", "impuity."], "labels": ["TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG"]}, "BS-bid-OCR+google": {"tokens": ["where", "Xi", "denotes", "the", "lbcatiort", "of", "the", "ith", "impunity."], "labels": ["TOKENIZATION_ERROR", "WRONG", "MIXED", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG"]}}}, {"corrupt": {"tokens": ["Startingfrorethisobservation,weprovethefollowing:"], "labels": ["WRONG"]}, "correct": {"tokens": ["Starting", "from", "this", "observation,", "we", "prove", "the", "following:"], "labels": ["TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["Starting", "For", "This", "Observation,we", "prove", "the", "following:"], "labels": ["TOKENIZATION_ERROR", "WRONG", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR": {"tokens": ["Starting", "frore", "this", "observation,", "we", "prove", "the", "following:"], "labels": ["TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["Starting", "frore", "this", "observation,", "we", "prove", "the", "following:"], "labels": ["TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["whichcanbeanalyzedasdeuscribedabove.."], "labels": ["WRONG"]}, "correct": {"tokens": ["which", "can", "be", "analyzed", "as", "described", "above."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED"]}, "predicted": {"google": {"tokens": ["whichcanbeanalyzedasdeuscribedabove.."], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["which", "can", "be", "analyzed", "as", "deuscribed", "above.."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG"]}, "BS-bid-OCR+google": {"tokens": ["which", "can", "be", "analyzed", "as", "described", "above.."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "WRONG"]}}}, {"corrupt": {"tokens": ["Keywors:overp~l'tition,Ramanujan-tjpecongru('.nce,2-adeicexpansion~dissectionformula"], "labels": ["WRONG"]}, "correct": {"tokens": ["Keywords:", "overpartition,", "Ramanujan-type", "congruence,", "2-adic", "expansion,", "dissection", "formula"], "labels": ["MIXED", "MIXED", "MIXED", "MIXED", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["Keywords:overp~l'tition,Ramanujan-type", "congru('.nce,2-adic", "expansion~dissection", "formula"], "labels": ["WRONG", "WRONG", "WRONG", "TOKENIZATION_ERROR"]}, "BS-bid-OCR": {"tokens": ["Keywors:", "overp~l'tition,", "Ramanujan-tjpe", "congru('.nce,", "2-adeic", "expansion~", "dissection", "formula"], "labels": ["WRONG", "WRONG", "WRONG", "WRONG", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["Keywords:", "overp~l'tition,", "Ramanujan-tjpe", "congru('.nce,", "2-adic", "expansion~", "dissection", "formula"], "labels": ["MIXED", "WRONG", "WRONG", "WRONG", "MIXED", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["The\u03ba-sym\\metry?transformationrulesare"], "labels": ["WRONG"]}, "correct": {"tokens": ["The", "\u03ba-symmetry", "transformation", "rules", "are"], "labels": ["TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["The\u03ba-sym\\metry?transformation", "rules", "are"], "labels": ["WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR": {"tokens": ["The", "\u03ba-sym\\metry?", "transformation", "rules", "are"], "labels": ["TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["The", "\u03ba-sym\\metry?", "transformation", "rules", "are"], "labels": ["TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["ProofsofthemIxingtimelowerbound~nthesubcriticolehas\\e"], "labels": ["WRONG"]}, "correct": {"tokens": ["Proofs", "of", "the", "mixing", "time", "lower", "bound", "in", "the", "subcritical", "case"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "MIXED"]}, "predicted": {"google": {"tokens": ["ProofsofthemIxingtimelowerbound~nthesubcriticolehas\\e"], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["Proofs", "of", "the", "mIxing", "time", "lower", "bound", "~n", "the", "subcriticol", "ehas\\e"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "WRONG"]}, "BS-bid-OCR+google": {"tokens": ["Proofs", "of", "the", "mIxing", "time", "lower", "bound", "~n", "the", "subcritical", "ehsas\\e"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "MIXED", "WRONG"]}}}, {"corrupt": {"tokens": ["(ii)\u21d2(iiiIt?fillowsfromTheorem7.3."], "labels": ["WRONG"]}, "correct": {"tokens": ["(ii)", "\u21d2", "(iii)", "It", "follows", "from", "Theorem", "7.3."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["(ii)\u21d2(iiiIt?fillowsfromTheorem7.3."], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["(ii)", "\u21d2", "(iii", "It?", "fillows", "from", "Theorem", "7.3."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["(ii)", "\u21d2", "(iii", "It?", "follows", "from", "Theorem", "7.3."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["Iutroduction"], "labels": ["WRONG"]}, "correct": {"tokens": ["Introduction"], "labels": ["OCR_ERROR"]}, "predicted": {"google": {"tokens": ["Introduction"], "labels": ["OCR_ERROR"]}, "BS-bid-OCR": {"tokens": ["Iutroduction"], "labels": ["WRONG"]}, "BS-bid-OCR+google": {"tokens": ["Introduction"], "labels": ["OCR_ERROR"]}}}, {"corrupt": {"tokens": ["ADSmodules"], "labels": ["WRONG"]}, "correct": {"tokens": ["ADS", "modules"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["ADD", "Modules"], "labels": ["WRONG", "WRONG"]}, "BS-bid-OCR": {"tokens": ["ADS", "modules"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["ADS", "modules"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["Takingtheinfinitesimalvariation"], "labels": ["WRONG"]}, "correct": {"tokens": ["Taking", "the", "infinitesimal", "variation"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["Taking", "The", "Infinitesimal", "Variation"], "labels": ["TOKENIZATION_ERROR", "WRONG", "WRONG", "WRONG"]}, "BS-bid-OCR": {"tokens": ["Taking", "the", "infinitesimal", "variation"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["Taking", "the", "infinitesimal", "variation"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["Tothisend,wefixanarbitraryH\u2208Hxandfirstshowthat"], "labels": ["WRONG"]}, "correct": {"tokens": ["To", "this", "end,", "we", "fix", "an", "arbitrary", "H", "\u2208", "Hx", "and", "first", "show", "that"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["To", "This", "End,wefixanarbitraryH\u2208Hxandfirstshowthat"], "labels": ["TOKENIZATION_ERROR", "WRONG", "WRONG"]}, "BS-bid-OCR": {"tokens": ["To", "this", "end,", "we", "fix", "an", "arbitrary", "H", "\u2208", "Hx", "and", "first", "show", "that"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["To", "this", "end,", "we", "fix", "an", "arbitrary", "H", "\u2208", "Hx", "and", "first", "show", "that"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["AfteridentifyintheplausiblealignmentstoV-andJ-genes,weturnotheprobleopmofidentifyinD-genemat(:hes.Thisisamorcdi\\[ficultproblembecausetheD-genesaeshoi't,andde\\]etions(occurringonbothends)often.leayeresidulsequenoeswhicharehardtidentifyas~D-genefra~ment.mWethereforeputveryloo~econstraLntontheD-genealignm3nts,relyingont\\]leprol)abilisticrefineme.nttonarrowthem\\dawn.Specificallyc,weconVsiderthereaseqUencesegmentlyingbetweentheendofthehighcst-scoringV-geneandtheendofthehigil(;st-scoringJ-gene,andinclude10nucleotidesofflanhingsequenceonei~,herside,toallowforambignouso~iginofthesebases.Weiden~it'yasapossbr@Dgenematahevexymaximalnon-overlappihgaignmenttothis?segmentofthcthreeD-genealleles.TheseD-genematchesecrescredbytheirlengthan(lthetop200arese\\[ectedaspossibleD-genealidgnmcttts."], "labels": ["WRONG"]}, "correct": {"tokens": ["After", "identifying", "the", "plausible", "alignments", "to", "V-", "and", "J-", "genes,", "we", "turn", "to", "the", "problem", "of", "identifying", "D-gene", "matches.", "This", "is", "a", "more", "difficult", "problem", "because", "the", "D-genes", "are", "short,", "and", "deletions", "(occurring", "on", "both", "ends)", "often", "leave", "residual", "sequences", "which", "are", "hard", "to", "identify", "as", "a", "D-gene", "fragment.", "We", "therefore", "put", "very", "loose", "constraints", "on", "the", "D-gene", "alignments,", "relying", "on", "the", "probabilistic", "refinement", "to", "narrow", "them", "down.", "Specifically,", "we", "consider", "the", "read", "sequence", "segment", "lying", "between", "the", "end", "of", "the", "highest-scoring", "V-gene", "and", "the", "end", "of", "the", "highest-scoring", "J-gene,", "and", "include", "10", "nucleotides", "of", "flanking", "sequence", "on", "either", "side,", "to", "allow", "for", "ambiguous", "origin", "of", "these", "bases.", "We", "identify", "as", "a", "possible", "D-gene", "match", "every", "maximal", "non-overlapping", "alignment", "to", "this", "segment", "of", "the", "three", "D-gene", "alleles.", "These", "D-gene", "matches", "are", "scored", "by", "their", "length", "and", "the", "top", "200", "are", "selected", "as", "possible", "D-gene", "alignments."], "labels": ["TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "MIXED", "MIXED", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED"]}, "predicted": {"google": {"tokens": ["AfteridentifyintheplausiblealignmentstoV-andJ-genes,weturnotheprobleopmofidentifyinD-genemat(:hes.Thisisamorcdi\\[ficultproblembecausetheD-genesaeshoi't,andde\\]etions(occurringonbothends)often.leayeresidulsequenoeswhicharehardtidentifyas~D-genefra~ment.mWethereforeputveryloo~econstraLntontheD-genealignm3nts,relyingont\\]leprol)abilisticrefineme.nttonarrowthem\\dawn.Specificallyc,weconVsiderthereaseqUencesegmentlyingbetweentheendofthehighcst-scoringV-geneandtheendofthehigil(;st-scoringJ-gene,andinclude10nucleotidesofflanhingsequenceonei~,herside,toallowforambignouso~iginofthesebases.Weiden~it'yasapossbr@Dgenematahevexymaximalnon-overlappihgaignmenttothis?segmentofthcthreeD-genealleles.TheseD-genematchesecrescredbytheirlengthan(lthetop200arese\\[ectedaspossibleD-genealidgnmcttts."], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["After", "identifyin", "the", "plausible", "alignments", "to", "V-", "and", "J-genes,", "we", "turn", "o", "the", "probleopm", "of", "identifyin", "D-gene", "mat(:hes.", "This", "is", "a", "morc", "di\\[ficult", "problem", "because", "the", "D-genes", "ae", "shoi't,", "and", "de\\]etions", "(occurring", "on", "both", "ends)", "often", ".leaye", "residul", "sequenoes", "which", "are", "hard", "t", "identify", "as", "~D-gene", "fra~ment.m", "We", "therefore", "put", "very", "loo~e", "constraLnt", "on", "the", "D-gene", "alignm3nts,", "relying", "on", "t\\]le", "prol)abilistic", "refineme.nt", "to", "narrow", "them", "\\dawn.", "Specificallyc,", "we", "conVsider", "the", "rea", "seqUence", "segment", "lying", "between", "the", "end", "of", "the", "highcst-scoring", "V-gene", "and", "the", "end", "of", "the", "higil(;st-scoring", "J-gene,", "and", "include", "10", "nucleotides", "of", "flanhing", "sequence", "on", "ei~,her", "side,", "to", "allow", "for", "ambignous", "o~igin", "of", "these", "bases.", "We", "iden~it'y", "as", "a", "possbr@D", "genemata", "hevexy", "maximal", "non-overlappihg", "aignment", "to", "this?", "segment", "of", "thc", "three", "D-gene", "alleles.", "These", "D-gene", "matches", "ecrescred", "by", "their", "length", "an(l", "the", "top", "200", "are", "se\\[ected", "as", "possible", "D-genealidgnmcttts."], "labels": ["TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "WRONG", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG"]}, "BS-bid-OCR+google": {"tokens": ["After", "identifying", "the", "possible", "alignments", "to", "V-", "and", "J-genes,", "we", "turn", "to", "the", "problem", "of", "identifying", "D-gene", "mat(:hes.", "This", "is", "a", "morc", "di\\[ficult", "problem", "because", "the", "D-genes", "are", "shot,", "and", "de\\]etions", "(occurring", "on", "both", "ends)", "often", ".leave", "residue", "sequences", "which", "are", "hard", "to", "identify", "as", "~D-gene", "fra~ment.m", "We", "therefore", "put", "very", "loo~e", "constraInt", "on", "the", "D-gene", "alignments,", "relying", "on", "t\\]le", "prol)abilistic", "refinement", "to", "narrow", "them", "\\down.", "Specifically,", "we", "consider", "the", "rna", "seqUence", "segment", "lying", "between", "the", "end", "of", "the", "highest-scoring", "V-gene", "and", "the", "end", "of", "the", "higil(;st-scoring", "J-gene,", "and", "include", "10", "nucleotides", "of", "flanking", "sequence", "on", "ei~,her", "side,", "to", "allow", "for", "ambiguous", "o~igin", "of", "these", "bases.", "We", "iden~it'y", "as", "a", "possbr@D", "genemata", "hevexy", "maximal", "non-overlapping", "alignment", "to", "this?", "segment", "of", "thc", "three", "D-gene", "alleles.", "These", "D-gene", "matches", "ecrescred", "by", "their", "length", "an(l", "the", "top", "200", "are", "se\\[ected", "as", "possible", "D-genealogists."], "labels": ["TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "WRONG", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG"]}}}, {"corrupt": {"tokens": ["wheres0isthesaturationparametergivenb"], "labels": ["WRONG"]}, "correct": {"tokens": ["where", "s0", "is", "the", "saturation", "parameter", "given", "by"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED"]}, "predicted": {"google": {"tokens": ["where", "s0", "is", "the", "saturation", "parameter", "given", "b"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG"]}, "BS-bid-OCR": {"tokens": ["where", "s0", "is", "the", "saturation", "parameter", "given", "b"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG"]}, "BS-bid-OCR+google": {"tokens": ["where", "s0", "is", "the", "saturation", "parameter", "given", "b"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG"]}}}, {"corrupt": {"tokens": ["Mathema~icsSubjectClSssifications(200O).82B05,82B20(primary);60K\\]5,05C05(secon.ay).Keywords:Configuration,latticemodel,contour,Gibbsmeasure."], "labels": ["WRONG"]}, "correct": {"tokens": ["Mathematics", "Subject", "Classifications", "(2000).", "82B05,", "82B20", "(primary);", "60K35,", "05C05", "(secondary).", "Keywords:", "Configuration,", "lattice", "model,", "contour,", "Gibbs", "measure."], "labels": ["MIXED", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["Mathema~ics", "Subject", "ClAssifications(200O).82B05,82B20(primary);60K\\]5,05C05(second.day).Keywords:Configuration,lattice", "model,contour,Gibbs", "Measure."], "labels": ["WRONG", "TOKENIZATION_ERROR", "WRONG", "WRONG", "WRONG"]}, "BS-bid-OCR": {"tokens": ["Mathema~ics", "Subject", "ClSssifications", "(200O).", "82B05,", "82B20", "(primary);", "60K\\]5,", "05C05", "(secon.ay).", "Keywords:", "Configuration,", "lattice", "model,", "contour,", "Gibbs", "measure."], "labels": ["WRONG", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["Mathema~ics", "Subject", "ClAssifications", "(200O).", "82B05,", "82B20", "(primary);", "60K\\]5,", "05C05", "(second.day).", "Keywords:", "Configuration,", "lattice", "model,", "contour,", "Gibbs", "measure."], "labels": ["WRONG", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["Then"], "labels": ["NONE"]}, "correct": {"tokens": ["Then"], "labels": ["NONE"]}, "predicted": {"google": {"tokens": ["Then"], "labels": ["NONE"]}, "BS-bid-OCR": {"tokens": ["Then"], "labels": ["NONE"]}, "BS-bid-OCR+google": {"tokens": ["Then"], "labels": ["NONE"]}}}, {"corrupt": {"tokens": ["Twotypicalseqnencescanbeidentifiedinthe+tbundancesOfthevfriousclusters:d,t,h,\u03b1,atlowbaryonicdensitya11dd,t\u0006\u03b1,hal;thehighertotalbryonicdensi1;yatwhlchclu?sotersarestillPresent.Deviationsfromthisbehaviorarefoundforlowertelperature(T=3.5MeV)orhigherprotonfraction(Ypg=0.5).Ingeneral.,thedominanteontributioncomesfromthedeutercns.Atveryh)wdens??ty,thesequencereflectstheorderinginize:thesmallerclustersaremoreabundant.Thedifferehcebetw'~eentandh,andlllorepreciseythefinding?thattritonsaremoreabundantthanhelions,isductotwoeffects:gl?oballytherearemorencuLronsavqilable\\and,mor(,overthetritonisnfore:bound.ThislastpointxplainswhywefindadifferenceamongthemalsoatYpg=0.5."], "labels": ["WRONG"]}, "correct": {"tokens": ["Two", "typical", "sequences", "can", "be", "identified", "in", "the", "abundances", "of", "the", "various", "clusters:", "d,", "t,", "h,", "\u03b1", "at", "low", "baryonic", "density", "and", "d,", "t,", "\u03b1,", "h", "at", "the", "higher", "total", "baryonic", "density", "at", "which", "clusters", "are", "still", "present.", "Deviations", "from", "this", "behavior", "are", "found", "for", "lower", "temperature", "(T", "=", "3.5", "MeV)", "or", "higher", "proton", "fraction", "(Ypg", "=", "0.5).", "In", "general,", "the", "dominant", "contribution", "comes", "from", "the", "deuterons.", "At", "very", "low", "density,", "the", "sequence", "reflects", "the", "ordering", "in", "size:", "the", "smaller", "clusters", "are", "more", "abundant.", "The", "difference", "between", "t", "and", "h,", "and", "more", "precisely", "the", "finding", "that", "tritons", "are", "more", "abundant", "than", "helions,", "is", "due", "to", "two", "effects:", "globally", "there", "are", "more", "neutrons", "available", "and,", "moreover,", "the", "triton", "is", "more", "bound.", "This", "last", "point", "explains", "why", "we", "find", "a", "difference", "among", "them", "also", "at", "Ypg", "=", "0.5."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["Twotypicalseqnencescanbeidentifiedinthe+tbundancesOfthevfriousclusters:d,t,h,\u03b1,atlow", "baryonic", "density", "a", "11dd,t\u03b1,hal;thehighertotalbryonicdensi1;yat", "which", "clu?sotersarestillPresent.Deviationsfromthisbehaviorarefoundforlowertelperature(T=3.5MeV)or", "higher", "proton", "fraction(Ypg=0.5).In", "General.,thedominanteontributioncomesfromthedeutercns.Atveryh)wdens??ty,thesequencereflectstheorderinginize:thesmallerclustersaremoreabundant.Thedifferehcebetw'~eentandh,andlllorepreciseythefinding?thattritonsaremoreabundantthanhelions,isductotwoeffects:gl?oballytherearemorencuLronsavqilable\\and,mor(,overthetritonisnfore:bound.ThislastpointxplainswhywefindadifferenceamongthemalsoatYpg=0.5."], "labels": ["WRONG", "MIXED", "MIXED", "WRONG", "WRONG", "MIXED", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG"]}, "BS-bid-OCR": {"tokens": ["Two", "typical", "seqnences", "can", "be", "identified", "in", "the", "+tbundances", "Of", "the", "vfrious", "clusters:", "d,", "t,", "h,", "\u03b1,", "at", "low", "baryonic", "density", "a11d", "d,t\u0006\u03b1,", "hal;", "the", "higher", "total", "bryonic", "densi1;y", "at", "whlch", "clu?soters", "are", "still", "Present.", "Deviations", "from", "this", "behavior", "are", "found", "for", "lower", "telperature", "(T", "=", "3.5", "MeV)", "or", "higher", "proton", "fraction", "(Ypg", "=", "0.5).", "In", "general.,", "the", "dominant", "eontribution", "comes", "from", "the", "deutercns.", "At", "very", "h)w", "dens??ty,", "the", "sequence", "reflects", "the", "ordering", "in", "ize:", "the", "smaller", "clusters", "are", "more", "abundant.", "The", "differehce", "betw'~een", "t", "and", "h,", "and", "lllore", "precisey", "the", "finding?", "that", "tritons", "are", "more", "abundant", "than", "helions,", "is", "duc", "to", "two", "effects:", "gl?obally", "there", "are", "more", "ncuLrons", "avqilable\\", "and,", "mor(,over", "the", "triton", "is", "nfore:", "bound.", "This", "last", "point", "xplains", "why", "we", "find", "a", "difference", "among", "them", "also", "at", "Ypg", "=", "0.5."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["Two", "typical", "sequences", "can", "be", "identified", "in", "the", "+abundances", "Of", "the", "various", "clusters:", "d,", "t,", "h,", "\u03b1,", "at", "low", "baryonic", "density", "a11d", "d,t\u03b1,", "hal;", "the", "higher", "total", "byronic", "densi1;y", "at", "which", "clusters", "are", "still", "Present.", "Deviations", "from", "this", "behavior", "are", "found", "for", "lower", "temperature", "(T", "=", "3.5", "MeV)", "or", "higher", "proton", "fraction", "(Ypg", "=", "0.5).", "In", "generalThe", "dominant", "contribution", "comes", "from", "the", "deuterons.", "At", "very", "h)w", "density,", "the", "sequence", "reflects", "the", "ordering", "in", "ize:", "the", "smaller", "clusters", "are", "more", "abundant.", "The", "difference", "betw'~een", "t", "and", "h,", "and", "more", "precisely", "the", "finding?", "that", "tritons", "are", "more", "abundant", "than", "helions,", "is", "duc", "to", "two", "effects:", "globally", "there", "are", "more", "cauLdrons", "available\\", "and,", "more(,over", "the", "triton", "is", "nfore:", "bound.", "This", "last", "point", "explains", "why", "we", "find", "a", "difference", "among", "them", "also", "at", "Ypg", "=", "0.5."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["Photoexcitationsareilltroducedbymodifymingth,etransferintegralinthekineticartoftheelectrnioHamiltonian,"], "labels": ["WRONG"]}, "correct": {"tokens": ["Photoexcitations", "are", "introduced", "by", "modifying", "the", "transfer", "integral", "in", "the", "kinetic", "part", "of", "the", "electronic", "Hamiltonian,"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["Photoexcitationsareilltroducedbymodifymingth,etransferintegralinthekineticartoftheelectrnioHamiltonian,"], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["Photo", "excitations", "are", "illtroduced", "by", "modifyming", "th,e", "transfer", "integral", "in", "the", "kinetic", "art", "of", "the", "electrnio", "Hamiltonian,"], "labels": ["WRONG", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["Photo", "excitations", "are", "introduced", "by", "modifying", "the", "transfer", "integral", "in", "the", "kinetic", "art", "of", "the", "electron", "Hamiltonian,"], "labels": ["WRONG", "WRONG", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["FoclargeN,RisRDif,analonlyif"], "labels": ["WRONG"]}, "correct": {"tokens": ["For", "large", "N,", "A", "is", "RD", "if,", "and", "only", "if"], "labels": ["MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["FoclargeN,RisRDif,analonlyif"], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["Foc", "large", "N,", "R", "is", "RD", "if,", "anal", "only", "if"], "labels": ["WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["Foc", "large", "N,", "R", "is", "RD", "if,", "anal", "only", "if"], "labels": ["WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["Hereweintroducedthetotrialdephasingrate"], "labels": ["WRONG"]}, "correct": {"tokens": ["Here", "we", "introduced", "the", "total", "dephasing", "rate"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["Here", "We", "Introduced", "The", "Trial", "Dephasing", "Rate"], "labels": ["TOKENIZATION_ERROR", "WRONG", "WRONG", "WRONG", "WRONG", "WRONG", "WRONG"]}, "BS-bid-OCR": {"tokens": ["Here", "we", "introduced", "the", "totrial", "dephasing", "rate"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["Here", "we", "introduced", "the", "tutorial", "dephasing", "rate"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["ThentheMAgaugewasimposedasagaugefixingconditintion.Finally,alltheoff-disgonnlnieldstakingvaluesintheI,iealgebr;~oftheeosetG/Hwe,'eintegratedout.inlhe\\[unctionalinl;egral,"], "labels": ["WRONG"]}, "correct": {"tokens": ["Then", "the", "MA", "gauge", "was", "imposed", "as", "a", "gauge", "fixing", "condition.", "Finally,", "all", "the", "off-diagonal", "fields", "taking", "values", "in", "the", "Lie", "algebra", "of", "the", "coset", "G/H", "were", "integrated", "out", "in", "the", "functional", "integral,"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "MIXED"]}, "predicted": {"google": {"tokens": ["ThentheMAgaugewasimposedasagaugefixingconditintion.Finally,alltheoff-disgonnlnieldstakingvaluesintheI,iealgebr;~offthepost/We,'e", "integrated", "out.in", "the\\[unctionalinl;egral,"], "labels": ["WRONG", "TOKENIZATION_ERROR", "WRONG", "WRONG"]}, "BS-bid-OCR": {"tokens": ["Then", "the", "MA", "gauge", "was", "imposed", "as", "a", "gauge", "fixing", "conditintion.", "Finally,", "all", "the", "off-disgonnl", "nields", "taking", "values", "in", "the", "I,ie", "algebr;~", "of", "the", "eoset", "G/H", "we,'e", "integrated", "out.", "in", "lhe", "\\[unctional", "inl;egral,"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "WRONG", "WRONG"]}, "BS-bid-OCR+google": {"tokens": ["Then", "the", "MA", "gauge", "was", "imposed", "as", "a", "gauge", "fixing", "condition.", "Finally,", "all", "the", "off-diagonal", "nields", "taking", "values", "in", "the", "Ilie", "algebra;~", "of", "the", "east", "G/H", "we", "are", "integrated", "out.", "in", "lhe", "\\[functional", "inl;egral,"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "WRONG", "WRONG"]}}}, {"corrupt": {"tokens": ["WethankCri\\stianMichelettifOrfruitfuliscu\\ssionsandSteveWhiteforacritiIcalreadingofthemanuserLptan?d/ormayenlighteningsuggestions.ThisworkwassupportedbyINFM(PAISprojct),MURST-COFIN99,oNASAandtheDonorsofThePet?roleumResearchFundadministeredbTheAmericanPhusicalSociety."], "labels": ["WRONG"]}, "correct": {"tokens": ["We", "thank", "Cristian", "Micheletti", "for", "fruitful", "discussions", "and", "Steve", "White", "for", "a", "critical", "reading", "of", "the", "manuscript", "and", "for", "many", "enlightening", "suggestions.", "This", "work", "was", "supported", "by", "INFM", "(PAIS", "project),", "MURST-COFIN99,", "NASA", "and", "the", "Donors", "of", "The", "Petroleum", "Research", "Fund", "administered", "by", "The", "American", "Physical", "Society."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["WethankCri\\stianMichelettifOrfruitfuliscu\\ssionsandSteveWhiteforacritiIcalreadingofthemanuserLptan?d/ormayenlighteningsuggestions.ThisworkwassupportedbyINFM(PAIS", "project),HURST-COFFIN", "99,oNASAandtheDonorsofThePet?roleumResearchFundadministeredbTheAmericanPhusicalSociety."], "labels": ["WRONG", "WRONG", "WRONG"]}, "BS-bid-OCR": {"tokens": ["We", "thank", "Cri\\stian", "Micheletti", "fOr", "fruitful", "iscu\\ssions", "and", "Steve", "White", "for", "a", "critiIcal", "reading", "of", "the", "manuserLpt", "an?d/or", "may", "enlightening", "suggestions.", "This", "work", "was", "supported", "by", "INFM", "(PAIS", "projct),", "MURST-COFIN99,", "o", "NASA", "and", "the", "Donors", "of", "The", "Pet?roleum", "Research", "Fund", "administered", "b", "The", "American", "Phusical", "Society."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["We", "thank", "Cri\\stian", "Micheletti", "fOr", "fruitful", "iscu\\sessions", "and", "Steve", "White", "for", "a", "critical", "reading", "of", "the", "manuscrIpt", "and/or", "may", "enlightening", "suggestions.", "This", "work", "was", "supported", "by", "INFM", "(PAIS", "project),", "HURST-COFFIN", "99,", "o", "NASA", "and", "the", "Donors", "of", "The", "Petroleum", "Research", "Fund", "administered", "by", "The", "American", "Physical", "Society."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "WRONG", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["TheSalemcase"], "labels": ["WRONG"]}, "correct": {"tokens": ["The", "Salem", "case"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["TheSalemcase"], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["The", "Salem", "case"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["The", "Salem", "case"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["Havingdefinedthelco-un\\it,theco-product,andtheantipo@eforthel/?asiselements~\u2208G,thecorrespolldingdef?nitionsforarbitraryvectorsinKGareobtainedbylinearcxtension.KGisaco-commutativeHopfalgebra,whichmeansthatKGiscommutativeifGiscommutative."], "labels": ["WRONG"]}, "correct": {"tokens": ["Having", "defined", "the", "co-unit,", "the", "co-product,", "and", "the", "antipode", "for", "the", "basis", "elements", "g", "\u2208", "G,", "the", "corresponding", "definitions", "for", "arbitrary", "vectors", "in", "KG", "are", "obtained", "by", "linear", "extension.", "KG", "is", "a", "co-commutative", "Hopf", "algebra,", "which", "means", "that", "KG", "is", "commutative", "if", "G", "is", "commutative."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["Havingdefinedthelco-un\\it,theco-product,andtheantipo@eforthel/?asiselements~\u2208G,thecorrespolldingdef?nitionsforarbitraryvectorsinKGareobtainedbylinearcxtension.KGisaco-commutativeHopfalgebra,whichmeansthatKGiscommutativeifGiscommutative."], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["Having", "defined", "the", "lco-un\\it,", "the", "co-product,", "and", "the", "antipo@e", "for", "the", "l/?asis", "elements", "~", "\u2208", "G,", "the", "correspollding", "def?nitions", "for", "arbitrary", "vectors", "in", "KG", "are", "obtained", "by", "linear", "cxtension.", "KG", "is", "a", "co-commutative", "Hopf", "algebra,", "which", "means", "that", "KG", "is", "commutative", "if", "G", "is", "commutative."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["Having", "defined", "the", "lco-un\\it,", "the", "co-product,", "and", "the", "antipo@e", "for", "the", "l/?asis", "elements", "~", "\u2208", "G,", "the", "corresponding", "definitions", "for", "arbitrary", "vectors", "in", "KG", "are", "obtained", "by", "linear", "extension.", "KG", "is", "a", "co-commutative", "Hopf", "algebra,", "which", "means", "that", "KG", "is", "commutative", "if", "G", "is", "commutative."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["tFirst,theexclu?sionregionofWDsis,"], "labels": ["WRONG"]}, "correct": {"tokens": ["First,", "the", "exclusion", "region", "of", "WDs", "is,"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["tFirst,theexclu?sionregionofWDsis,"], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["tFirst,", "the", "exclu?sion", "region", "of", "WDs", "is,"], "labels": ["WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["tFirst,", "the", "exclusion", "region", "of", "WDs", "is,"], "labels": ["WRONG", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["where"], "labels": ["NONE"]}, "correct": {"tokens": ["where"], "labels": ["NONE"]}, "predicted": {"google": {"tokens": ["where"], "labels": ["NONE"]}, "BS-bid-OCR": {"tokens": ["where"], "labels": ["NONE"]}, "BS-bid-OCR+google": {"tokens": ["where"], "labels": ["NONE"]}}}, {"corrupt": {"tokens": ["and"], "labels": ["NONE"]}, "correct": {"tokens": ["and"], "labels": ["NONE"]}, "predicted": {"google": {"tokens": ["and"], "labels": ["NONE"]}, "BS-bid-OCR": {"tokens": ["and"], "labels": ["NONE"]}, "BS-bid-OCR+google": {"tokens": ["and"], "labels": ["NONE"]}}}, {"corrupt": {"tokens": ["ascanbeeasiLyeenbyusing(4.18)."], "labels": ["WRONG"]}, "correct": {"tokens": ["as", "can", "be", "easily", "seen", "by", "using", "(4.18)."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["ascanbeeasiLyeenbyusing(4.18)."], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["as", "can", "be", "easiLy", "een", "by", "using", "(4.18)."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["as", "can", "be", "easiLy", "seen", "by", "using", "(4.18)."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["Our_proof.~lnon-containmentrelyonanontriuialPBWgradingofAn."], "labels": ["WRONG"]}, "correct": {"tokens": ["Our", "proofs", "of", "non-containment", "rely", "on", "a", "nontrivial", "PBW", "grading", "of", "An."], "labels": ["TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["Our_proof.~lnon-containmentrelyonanontriuialPBWgradingofAn."], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["Our", "_proof.~l", "non-containment", "rely", "on", "a", "nontriuial", "PBW", "grading", "of", "An."], "labels": ["TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["Our", "_proof.~l", "non-containment", "relies", "on", "a", "nontrivial", "PBW", "grading", "of", "An."], "labels": ["TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["uhere"], "labels": ["WRONG"]}, "correct": {"tokens": ["where"], "labels": ["OCR_ERROR"]}, "predicted": {"google": {"tokens": ["uhere"], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["uhere"], "labels": ["WRONG"]}, "BS-bid-OCR+google": {"tokens": ["uhere"], "labels": ["WRONG"]}}}, {"corrupt": {"tokens": ["BooleansumoftwoproJectionopelatorsisaalsoaprojectionoperatoranitisdetinedasfcllows"], "labels": ["WRONG"]}, "correct": {"tokens": ["Boolean", "sum", "of", "two", "projection", "operators", "is", "a", "also", "a", "projection", "operator", "and", "it", "is", "defined", "as", "follows"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED"]}, "predicted": {"google": {"tokens": ["BooleansumoftwoproJectionopelatorsisaalsoaprojectionoperatoranitisdetinedasfcllows"], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["Boolean", "sum", "of", "two", "proJection", "opelators", "is", "aalso", "a", "projection", "operator", "an", "it", "is", "detined", "as", "fcllows"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG"]}, "BS-bid-OCR+google": {"tokens": ["Boolean", "sum", "of", "two", "proJection", "operators", "is", "also", "a", "projection", "operator", "an", "it", "is", "defined", "as", "follows"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED"]}}}, {"corrupt": {"tokens": ["Weshow?thattheseconditionscanbeguaranteedprovidedthemodelisihtheKSregime.Tod?os,theproceduremetauresthebiastermsB(y1)andB(y2)usingmethodssimilarodistanceestimatin.Rytestingth~biasand,ifnecessary,compensatingfotanyprevlouslyintroducederror,wecanadap.tiyelychosecoefficients\u03c91,\u03c92sothatSxsaisfiestheetwoconditions,"], "labels": ["WRONG"]}, "correct": {"tokens": ["We", "show", "that", "these", "conditions", "can", "be", "guaranteed", "provided", "the", "model", "is", "in", "the", "KS", "regime.", "To", "do", "so,", "the", "procedure", "measures", "the", "bias", "terms", "B(y1)", "and", "B(y2)", "using", "methods", "similar", "to", "distance", "estimation.", "By", "testing", "the", "bias", "and,", "if", "necessary,", "compensating", "for", "any", "previously", "introduced", "error,", "we", "can", "adaptively", "choose", "coefficients", "\u03c91,", "\u03c92", "so", "that", "Sx", "satisfies", "these", "two", "conditions."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "MIXED"]}, "predicted": {"google": {"tokens": ["Weshow?thattheseconditionscanbeguaranteedprovidedthemodelisihtheKSregime.Tod?os,theproceduremetauresthebiastermsB(y1)andB(y2)usingmethodssimilarodistanceestimatin.Rytestingth~biasand,if", "necessary,compensating", "fotanyprevlouslyintroducederror,wecanadap.tiyelychosecoefficients\u03c91,\u03c92sothatSxsaisfiestheetwoconditions,"], "labels": ["WRONG", "WRONG", "WRONG"]}, "BS-bid-OCR": {"tokens": ["We", "show?", "that", "these", "conditions", "can", "be", "guaranteed", "provided", "the", "model", "is", "ih", "the", "KS", "regime.", "To", "d?os,", "the", "procedure", "metaures", "the", "bias", "terms", "B(y1)", "and", "B(y2)", "using", "methods", "similar", "o", "distance", "estimatin.", "Ry", "testing", "th~", "bias", "and,", "if", "necessary,", "compensating", "fot", "any", "prevlously", "introduced", "error,", "we", "can", "adap.tiyely", "chose", "coefficients", "\u03c91,", "\u03c92", "so", "that", "Sx", "saisfies", "thee", "two", "conditions,"], "labels": ["TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "WRONG"]}, "BS-bid-OCR+google": {"tokens": ["We", "show", "that", "these", "conditions", "can", "be", "guaranteed", "provided", "the", "model", "is", "in", "the", "KS", "regime.", "To", "d?os,", "the", "procedure", "measures", "the", "bias", "terms", "B(y1)", "and", "B(y2)", "using", "methods", "similar", "to", "distance", "estimation.", "Ry", "testing", "th~", "bias", "and,", "if", "necessary,", "compensating", "for", "any", "previously", "introduced", "error,", "we", "can", "adapt.timely", "chose", "coefficients", "\u03c91,", "\u03c92", "so", "that", "X", "satisfies", "the", "two", "conditions,"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "MIXED", "WRONG", "TOKENIZATION_ERROR", "WRONG"]}}}, {"corrupt": {"tokens": ["If\\weevaluatethetimederivativeoftheQfunction"], "labels": ["WRONG"]}, "correct": {"tokens": ["If", "we", "evaluate", "the", "time", "derivative", "of", "the", "Q", "function"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["If\\weevaluatethetimederivativeoftheQfunction"], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["If", "\\we", "evaluate", "the", "time", "derivative", "of", "the", "Q", "function"], "labels": ["TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["If", "\\we", "evaluate", "the", "time", "derivative", "of", "the", "Q", "function"], "labels": ["TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["TilefactthatthefluctuationoperatorscommutefOllowsfromourhypotiresisthntthevariablesatdifferentpointsonthegridareconstructedfrombilinearsofindet)endentfermionicvariables."], "labels": ["WRONG"]}, "correct": {"tokens": ["The", "fact", "that", "the", "fluctuation", "operators", "commute", "follows", "from", "our", "hypothesis", "that", "the", "variables", "at", "different", "points", "on", "the", "grid", "are", "constructed", "from", "bilinears", "of", "independent", "fermionic", "variables."], "labels": ["MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["TilefactthatthefluctuationoperatorscommutefOllowsfromourhypotiresisthntthevariablesatdifferentpointsonthegridareconstructedfrombilinearsofindet)endentfermionicvariables."], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["Tile", "fact", "that", "the", "fluctuation", "operators", "commute", "fOllows", "from", "our", "hypotiresis", "thnt", "the", "variables", "at", "different", "points", "on", "the", "grid", "are", "constructed", "from", "bilinears", "of", "indet)endent", "fermionic", "variables."], "labels": ["WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["The", "fact", "that", "the", "fluctuation", "operators", "commute", "fOllows", "from", "our", "hypothesis", "that", "the", "variables", "at", "different", "points", "on", "the", "grid", "are", "constructed", "from", "bilinears", "of", "indet)endent", "fermionic", "variables."], "labels": ["MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["Tomakethesethillgsclearwewillintrodacesomenotation."], "labels": ["WRONG"]}, "correct": {"tokens": ["To", "make", "these", "things", "clear", "we", "will", "introduce", "some", "notation."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["Tomakethesethillgsclearwewillintrodacesomenotation."], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["To", "make", "these", "thillgs", "clear", "we", "will", "introdace", "some", "notation."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["To", "make", "these", "things", "clear", "we", "will", "introduce", "some", "notation."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["We~lsoneedthedefinitionoftheIowerlink."], "labels": ["WRONG"]}, "correct": {"tokens": ["We", "also", "need", "the", "definition", "of", "the", "lower", "link."], "labels": ["TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["We~also", "need", "the", "definition", "of", "the", "Powerlink."], "labels": ["WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG"]}, "BS-bid-OCR": {"tokens": ["We", "~lso", "need", "the", "definition", "of", "the", "Iower", "link."], "labels": ["TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["We", "~also", "need", "the", "definition", "of", "the", "Lower", "link."], "labels": ["TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["and"], "labels": ["NONE"]}, "correct": {"tokens": ["and"], "labels": ["NONE"]}, "predicted": {"google": {"tokens": ["and"], "labels": ["NONE"]}, "BS-bid-OCR": {"tokens": ["and"], "labels": ["NONE"]}, "BS-bid-OCR+google": {"tokens": ["and"], "labels": ["NONE"]}}}, {"corrupt": {"tokens": ["."], "labels": ["NONE"]}, "correct": {"tokens": ["."], "labels": ["NONE"]}, "predicted": {"google": {"tokens": ["."], "labels": ["NONE"]}, "BS-bid-OCR": {"tokens": ["."], "labels": ["NONE"]}, "BS-bid-OCR+google": {"tokens": ["."], "labels": ["NONE"]}}}, {"corrupt": {"tokens": ["Themassivetr?ianglcintegral"], "labels": ["WRONG"]}, "correct": {"tokens": ["The", "massive", "triangle", "integral"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["The", "Massive", "Triangle", "Integral"], "labels": ["TOKENIZATION_ERROR", "WRONG", "WRONG", "WRONG"]}, "BS-bid-OCR": {"tokens": ["The", "massive", "tr?ianglc", "integral"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["The", "massive", "triangle", "integral"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["Whosecharacteisticpolynomia~sare"], "labels": ["WRONG"]}, "correct": {"tokens": ["Whose", "characteristic", "polynomials", "are"], "labels": ["TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["Whosecharacteisticpolynomia~sare"], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["Whose", "characteistic", "polynomia~s", "are"], "labels": ["TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["Whose", "characteristic", "polynomia~s", "are"], "labels": ["TOKENIZATION_ERROR", "MIXED", "WRONG", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["GrcedyAlgorithm"], "labels": ["WRONG"]}, "correct": {"tokens": ["Greedy", "Algorithm"], "labels": ["MIXED", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["Greedy", "Algorithm"], "labels": ["MIXED", "TOKENIZATION_ERROR"]}, "BS-bid-OCR": {"tokens": ["Grcedy", "Algorithm"], "labels": ["WRONG", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["Greedy", "Algorithm"], "labels": ["MIXED", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["Twochargem<)nplaneinamaqneticfield:II.Movingne.utralquantulasystemaorossamag\\neticfield"], "labels": ["WRONG"]}, "correct": {"tokens": ["Two", "charges", "on", "plane", "in", "a", "magnetic", "field:", "II.", "Moving", "neutral", "quantum", "system", "across", "a", "magnetic", "field"], "labels": ["TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["Twochargem<)nplaneinamaqneticfield:II.Movingne.utralquantulasystemaorossamag\\neticfield"], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["Two", "chargem<)n", "plane", "in", "a", "maqnetic", "field:", "II.", "Moving", "ne.utral", "quantula", "system", "aoross", "a", "mag\\netic", "field"], "labels": ["TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["Two", "chargem<)n", "plane", "in", "a", "magnetic", "field:", "II.", "Moving", "neutral", "quantula", "system", "across", "a", "mag\\netic", "field"], "labels": ["TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "WRONG", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["WeappliedBgoliubovtransfol'mationtothequantizationofgravit??tionalfieldinthenei~hbourhoodofnostrivialclassicalcomprlent,thatpermittedustoavoidzero-modcprbleim."], "labels": ["WRONG"]}, "correct": {"tokens": ["We", "applied", "Bogoliubov", "transformation", "to", "the", "quantization", "of", "gravitational", "field", "in", "the", "neighbourhood", "of", "nontrivial", "classical", "component,", "that", "permitted", "us", "to", "avoid", "zero-mode", "problem."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED"]}, "predicted": {"google": {"tokens": ["WeappliedBgoliubovtransfol'mationtothequantizationofgravit??tionalfieldinthenei~hbourhoodofnostrivialclassicalcomprlent,thatpermittedustoavoidzero-modcprbleim."], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["We", "applied", "Bgoliubov", "transfol'mation", "to", "the", "quantization", "of", "gravit??tional", "field", "in", "the", "nei~hbourhood", "of", "nostrivial", "classical", "comprlent,", "that", "permitted", "us", "to", "avoid", "zero-modc", "prbleim."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG"]}, "BS-bid-OCR+google": {"tokens": ["We", "applied", "the", "Bogoliubov", "transformation", "to", "the", "quantization", "of", "gravity??tional", "field", "in", "the", "nei~hbourhood", "of", "nontrivial", "classical", "complement,", "that", "permitted", "us", "to", "avoid", "zero-mode", "problem."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED"]}}}, {"corrupt": {"tokens": ["WhenalargeopticallythickI>lockisnarrowcompal'edtothestarradius,itdoesnotevercompletelycoverthestar.Themaximum?lopeinthelightcurveduetotheblockatcorotationis"], "labels": ["WRONG"]}, "correct": {"tokens": ["When", "a", "large", "optically", "thick", "block", "is", "narrow", "compared", "to", "the", "star", "radius,", "it", "does", "not", "ever", "completely", "cover", "the", "star.", "The", "maximum", "slope", "in", "the", "light", "curve", "due", "to", "the", "block", "at", "corotation", "is"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["WhenalargeopticallythickI>lockisnarrowcompal'edtothestarradius,itdoesnotevercompletelycoverthestar.Themaximum?lopeinthelightcurveduetotheblockatcorotationis"], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["When", "a", "large", "optically", "thick", "I>lock", "is", "narrow", "compal'ed", "to", "the", "star", "radius,", "it", "does", "not", "ever", "completely", "cover", "the", "star.", "The", "maximum", "?lope", "in", "the", "light", "curve", "due", "to", "the", "block", "at", "corotation", "is"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["When", "a", "large", "optically", "thick", "I>lock", "is", "narrow", "compared", "to", "the", "star", "radius,", "it", "does", "not", "ever", "completely", "cover", "the", "star.", "The", "maximum", "?lope", "in", "the", "light", "curve", "due", "to", "the", "block", "at", "corotation", "is"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["andthesttisticalf\\]uctuationinl;hismiz(!dstateistndependentfromthequantumf\\luctuationarfsingfromthequantumsuperpositioninpurestates."], "labels": ["WRONG"]}, "correct": {"tokens": ["and", "the", "statistical", "fluctuation", "in", "this", "mixed", "state", "is", "independent", "from", "the", "quantum", "fluctuation", "arising", "from", "the", "quantum", "superposition", "in", "pure", "states."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["andthesttisticalf\\]uctuations;hirmiz(!dstateistndependentfromthequantumf\\luctuationarfsingfromthequantumsuperpositioninpurestates."], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["and", "the", "sttistical", "f\\]uctuation", "in", "l;his", "miz(!d", "state", "is", "tndependent", "from", "the", "quantum", "f\\luctuation", "arfsing", "from", "the", "quantum", "superposition", "in", "pure", "states."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["and", "the", "statistical", "f\\]uctuation", "in", "l;his", "miz(!d", "state", "is", "independent", "from", "the", "quantum", "f\\luctuation", "arising", "from", "the", "quantum", "superposition", "in", "pure", "states."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "WRONG", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["Binney,J.,&Tremaine,S.1987,GalacticDynamics(Princeton:Univ.Press}"], "labels": ["WRONG"]}, "correct": {"tokens": ["Binney,", "J.,", "&", "Tremaine,", "S.", "1987,", "Galactic", "Dynamics", "(Princeton:", "Univ.", "Press)"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED"]}, "predicted": {"google": {"tokens": ["Binney,J.,Tremaine,S.1987,GalacticDynamics(Princeton:Univ.Press}"], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["Binney,", "J.,", "&", "Tremaine,", "S.", "1987,", "Galactic", "Dynamics", "(Princeton:", "Univ.", "Press}"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG"]}, "BS-bid-OCR+google": {"tokens": ["Binney,", "J.,", "&", "Tremaine,", "S.", "1987,", "Galactic", "Dynamics", "(Princeton:", "Univ.", "Press}"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG"]}}}, {"corrupt": {"tokens": ["Thisfactstronglly\\supportsthecorectnessftheoff-equihibriumapproachforthecomputationoftheq=0componentofthepropagator(includingtheeffectivenessoftheextrapolatfonprocedure)andconfirmsthatitispossibletocomrpute(;quilibriumexpectationvaluesinoff-equilibriumsimulations.Moreoverthedoublepeakstructureofthecorrelationfunctionprobabilitydistribut~ionsurvivesinUleinfinitevolu~nelimitsincetiredynamicalexpectationvaueshave?beencothputedonaverylarg\\elattice[infinitetoall?practicaleffects).ItisremarkablethatthedistributionprobabilityofC(x)becomeswiderwithincreaingx."], "labels": ["WRONG"]}, "correct": {"tokens": ["This", "fact", "strongly", "supports", "the", "correctness", "of", "the", "off-equilibrium", "approach", "for", "the", "computation", "of", "the", "q", "=", "0", "component", "of", "the", "propagator", "(including", "the", "effectiveness", "of", "the", "extrapolation", "procedure)", "and", "confirms", "that", "it", "is", "possible", "to", "compute", "equilibrium", "expectation", "values", "in", "off-equilibrium", "simulations.", "Moreover", "the", "double", "peak", "structure", "of", "the", "correlation", "function", "probability", "distribution", "survives", "in", "the", "infinite", "volume", "limit", "since", "the", "dynamical", "expectation", "values", "have", "been", "computed", "on", "a", "very", "large", "lattice", "(infinite", "to", "all", "practical", "effects).", "It", "is", "remarkable", "that", "the", "distribution", "probability", "of", "C(x)", "becomes", "wider", "with", "increasing", "x."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["Thisfactstronglly\\supportsthecorectnessftheoff-equihibriumapproachforthecomputationoftheq=0componentofthepropagator(includingtheeffectivenessoftheextrapolatfonprocedure)andconfirmsthatitispossibletocomrpute(;quilibriumexpectationvaluesinoff-equilibriumsimulations.Moreoverthedoublepeakstructureofthecorrelationfunctionprobabilitydistribut~ionsurvivesinUleinfinitevolu~nelimitsincetiredynamicalexpectationvaueshave?beencothputedonaverylarg\\elattice[infinitetoall?practicaleffects).ItisremarkablethatthedistributionprobabilityofC(x)becomeswiderwithincreaingx."], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["This", "fact", "stronglly", "\\supports", "the", "corectness", "f", "the", "off-equihibrium", "approach", "for", "the", "computation", "of", "the", "q", "=", "0", "component", "of", "the", "propagator", "(including", "the", "effectiveness", "of", "the", "extrapolatfon", "procedure)", "and", "confirms", "that", "it", "is", "possible", "to", "comrpute", "(;quilibrium", "expectation", "values", "in", "off-equilibrium", "simulations.", "Moreover", "the", "double", "peak", "structure", "of", "the", "correlation", "function", "probability", "distribut~ion", "survives", "in", "Ule", "infinite", "volu~ne", "limit", "since", "tire", "dynamical", "expectation", "vaues", "have", "?been", "cothputed", "on", "a", "very", "larg\\e", "lattice", "[infinite", "to", "all", "?practical", "effects).", "It", "is", "remarkable", "that", "the", "distribution", "probability", "of", "C(x)", "becomes", "wider", "with", "increaing", "x."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["This", "fact", "strongly", "\\supports", "the", "correctness", "of", "the", "off-equilibrium", "approach", "for", "the", "computation", "of", "the", "q", "=", "0", "component", "of", "the", "propagator", "(including", "the", "effectiveness", "of", "the", "extrapolation", "procedure)", "and", "confirms", "that", "it", "is", "possible", "to", "compute", "(;equilibrium", "expectation", "values", "in", "off-equilibrium", "simulations.", "Moreover", "the", "double", "peak", "structure", "of", "the", "correlation", "function", "probability", "distribut~ion", "survives", "in", "Ule", "infinite", "volu~ne", "limit", "since", "tire", "dynamical", "expectation", "values", "have", "been", "computed", "on", "a", "very", "larg\\e", "lattice", "[infinite", "to", "all", "?practical", "effects).", "It", "is", "remarkable", "that", "the", "distribution", "probability", "of", "C(x)", "becomes", "wider", "with", "increasing", "x."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "WRONG", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["Appendix1"], "labels": ["WRONG"]}, "correct": {"tokens": ["Appendix", "1"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["Appendix1"], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["Appendix", "1"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["Appendix", "1"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["SolutionoftheminussignLiouville-Bratu-Qelfandequat?ioninaunitarysefment"], "labels": ["WRONG"]}, "correct": {"tokens": ["Solution", "of", "the", "minus", "sign", "Liouville-Bratu-Gelfand", "equation", "in", "a", "unitary", "segment"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED"]}, "predicted": {"google": {"tokens": ["SolutionoftheminussignLiouville-Bratu-Qelfandequat?ioninaunitarysefment"], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["Solution", "of", "the", "minus", "sign", "Liouville-Bratu-Qelfand", "equat?ion", "in", "a", "unitary", "sefment"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG"]}, "BS-bid-OCR+google": {"tokens": ["Solution", "of", "the", "minus", "sign", "Liouville-Bratu-Gelfand", "equation", "in", "a", "unitary", "segment"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED"]}}}, {"corrupt": {"tokens": ["(adotdenotesderivativewithres\\pectfo\u03c4)."], "labels": ["WRONG"]}, "correct": {"tokens": ["(a", "dot", "denotes", "derivative", "with", "respect", "to", "\u03c4)."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["(adotdenotesderivativewithres\\pectfo\u03c4)."], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["(a", "dot", "denotes", "derivative", "with", "res\\pect", "fo", "\u03c4)."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["(a", "dot", "denotes", "derivative", "with", "res\\pect", "to", "\u03c4)."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "MIXED", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["forauniversalconstantK"], "labels": ["WRONG"]}, "correct": {"tokens": ["for", "a", "universal", "constant", "K."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED"]}, "predicted": {"google": {"tokens": ["for", "universal", "constant", "K"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG"]}, "BS-bid-OCR": {"tokens": ["for", "a", "universal", "constant", "K"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG"]}, "BS-bid-OCR+google": {"tokens": ["for", "a", "universal", "constant", "K"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG"]}}}, {"corrupt": {"tokens": ["Wenowestimatethe?probabilltytobaveanoff-nucleal'sourcegivenahostgalaxywithaparticularstellarmassandtSFR.WewiltconsiderbothLMXBsandHMXBs."], "labels": ["WRONG"]}, "correct": {"tokens": ["We", "now", "estimate", "the", "probability", "to", "have", "an", "off-nuclear", "source", "given", "a", "host", "galaxy", "with", "a", "particular", "stellar", "mass", "and", "SFR.", "We", "will", "consider", "both", "LMXBs", "and", "HMXBs."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["Wenowestimatethe?probabilltytobaveanoff-nucleal'sourcegivenahostgalaxywithaparticularstellarmassandtSFR.WewiltconsiderbothLMXBsandHMXBs."], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["We", "now", "estimate", "the?", "probabillty", "to", "bave", "an", "off-nucleal'", "source", "given", "a", "host", "galaxy", "with", "a", "particular", "stellar", "mass", "and", "t", "SFR.", "We", "wilt", "consider", "both", "LMXBs", "and", "HMXBs."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["We", "now", "estimate", "the?", "probability", "to", "have", "an", "off-nuclear", "source", "given", "a", "host", "galaxy", "with", "a", "particular", "stellar", "mass", "and", "t", "SFR.", "We", "wilt", "consider", "both", "LMXBs", "and", "HMXBs."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["withbcloseto?2,sllghtlydependingon\u03b1,forsomeA>0."], "labels": ["WRONG"]}, "correct": {"tokens": ["with", "b", "close", "to", "2,", "slightly", "depending", "on", "\u03b1,", "for", "some", "A", ">", "0."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["with", "close", "to?2,sllghtlydependingon\u03b1,foursome>0."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG"]}, "BS-bid-OCR": {"tokens": ["with", "b", "close", "to", "?2,", "sllghtly", "depending", "on", "\u03b1,", "for", "some", "A", ">", "0."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["with", "b", "close", "to", "?2,", "slightly", "depending", "on", "\u03b1,", "for", "some", "A", ">", "0."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["Lasingproceses"], "labels": ["WRONG"]}, "correct": {"tokens": ["Lasing", "processes"], "labels": ["TOKENIZATION_ERROR", "MIXED"]}, "predicted": {"google": {"tokens": ["Lasing", "Process"], "labels": ["TOKENIZATION_ERROR", "WRONG"]}, "BS-bid-OCR": {"tokens": ["Lasing", "proceses"], "labels": ["TOKENIZATION_ERROR", "WRONG"]}, "BS-bid-OCR+google": {"tokens": ["Lasing", "process"], "labels": ["TOKENIZATION_ERROR", "WRONG"]}}}, {"corrupt": {"tokens": ["whereEandJaretileintegralconstantso\\['motion.Introducinganewquantity"], "labels": ["WRONG"]}, "correct": {"tokens": ["where", "E", "and", "J", "are", "the", "integral", "constants", "of", "motion.", "Introducing", "a", "new", "quantity"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["where", "andJaretile", "integral", "constants\\['motion.Introducing", "New", "Quantity"], "labels": ["TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "WRONG", "WRONG"]}, "BS-bid-OCR": {"tokens": ["where", "E", "and", "J", "are", "tile", "integral", "constants", "o\\['", "motion.", "Introducing", "a", "new", "quantity"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["where", "E", "and", "J", "are", "tile", "integral", "constants", "of\\['", "motion.", "Introducing", "a", "new", "quantity"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["Theirln?easurementsyieldthetwoseq.encesofdatasets:"], "labels": ["WRONG"]}, "correct": {"tokens": ["Their", "measurements", "yield", "the", "two", "sequences", "of", "data", "sets:"], "labels": ["TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["Their", "Ln?measurements", "yield", "the", "two", "sequences", "of", "datasets:"], "labels": ["TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "WRONG"]}, "BS-bid-OCR": {"tokens": ["Their", "ln?easurements", "yield", "the", "two", "seq.ences", "of", "data", "sets:"], "labels": ["TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["Their", "ln?measurements", "yield", "the", "two", "sequences", "of", "data", "sets:"], "labels": ["TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["Theeeexpressjosaresufficienttocomputethecmulativebiasforweaklensing?to~ographicslicesan\\dy-maps;thesebiasfunctionsareenoug11to?cnstructtheentirefamilyoftwl)-p;ointcum?ulantcorrelatorsinvolvingweaklensingandtSZmmapseveninthepreenceofno:ise."], "labels": ["WRONG"]}, "correct": {"tokens": ["These", "expressions", "are", "sufficient", "to", "compute", "the", "cumulative", "bias", "for", "weak", "lensing", "tomographic", "slices", "and", "y-maps;", "these", "bias", "functions", "are", "enough", "to", "construct", "the", "entire", "family", "of", "two-point", "cumulant", "correlators", "involving", "weak", "lensing", "and", "tSZ", "maps", "even", "in", "the", "presence", "of", "noise."], "labels": ["MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED"]}, "predicted": {"google": {"tokens": ["Theeeexpressjosaresufficienttocomputethecmulativebiasforweaklensing?to~ographicslicesan\\dy-maps;thesebiasfunctionsareenoug11to?cnstructtheentirefamilyoftwl)-p;ointcum?ulantcorrelatorsinvolvingweaklensingandtSZmmapseveninthepreenceofno:ise."], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["Theee", "expressjos", "are", "sufficient", "to", "compute", "the", "cmulative", "bias", "for", "weak", "lensing", "?to~ographic", "slices", "an\\d", "y-maps;", "these", "bias", "functions", "are", "enoug11", "to", "?cnstruct", "the", "entire", "family", "of", "twl)-p;oint", "cum?ulant", "correlators", "involving", "weak", "lensing", "and", "tSZm", "maps", "even", "in", "the", "preence", "of", "no:ise."], "labels": ["WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG"]}, "BS-bid-OCR+google": {"tokens": ["Three", "expressions", "are", "sufficient", "to", "compute", "the", "cumulative", "bias", "for", "weak", "lensing", "?to~ographic", "slices", "an\\d", "y-maps;", "these", "bias", "functions", "are", "enough", "11", "to", "?construct", "the", "entire", "family", "of", "twl)-p;joint", "cumulant", "correlators", "involving", "weak", "lensing", "and", "tZm", "maps", "even", "in", "the", "presence", "of", "no:ise."], "labels": ["WRONG", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "WRONG"]}}}, {"corrupt": {"tokens": ["..,V.Sukhorukov,A.N.Jardan,S.Gustavson,R.eturcq,T.Ihn&K.Ensslin"], "labels": ["WRONG"]}, "correct": {"tokens": ["E.", "V.", "Sukhorukov,", "A.", "N.", "Jordan,", "S.", "Gustavsson,", "R.", "Leturcq,", "T.", "Ihn", "&", "K.", "Ensslin"], "labels": ["MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["..,V.Sukhorukov,A.N.Jardan,S.Gustavson,R.eturcq,T.Ihn", "K.Ensslin"], "labels": ["WRONG", "WRONG"]}, "BS-bid-OCR": {"tokens": ["..,", "V.", "Sukhorukov,", "A.", "N.", "Jardan,", "S.", "Gustavson,", "R.", "eturcq,", "T.", "Ihn", "&", "K.", "Ensslin"], "labels": ["WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["..,", "V.", "Sukhorukov,", "A.", "N.", "Jardan,", "S.", "Gustavson,", "R.", "eturcq,", "T.", "Ihn", "&", "K.", "Ensslin"], "labels": ["WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["Thelastparticleyettobediscoveredinthestandardntodel(SM)ofs~rongandelect~ounweak(EW)interactIonsistheEnglert-Brout-Higgs(EBH?boson.?PossiblesinalsfortheEBHbosonattheLHCexperinientshavebeenreported,but?morcdataarenecessaryfortheconfirmation."], "labels": ["WRONG"]}, "correct": {"tokens": ["The", "last", "particle", "yet", "to", "be", "discovered", "in", "the", "standard", "model", "(SM)", "of", "strong", "and", "electroweak", "(EW)", "interactions", "is", "the", "Englert-Brout-Higgs", "(EBH)", "boson.", "Possible", "signals", "for", "the", "EBH", "boson", "at", "the", "LHC", "experiments", "have", "been", "reported,", "but", "more", "data", "are", "necessary", "for", "the", "confirmation."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["Thelastparticleyettobediscoveredinthestandardntodel(SM)ofs~rongandelect~ounweak(EW)interactIonsistheEnglert-Brout-Higgs(EBH?boson.?PossiblesinalsfortheEBHbosonattheLHCexperinientshavebeenreported,but?morcdataarenecessaryfortheconfirmation."], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["The", "last", "particle", "yet", "to", "be", "discovered", "in", "the", "standard", "ntodel", "(SM)", "of", "s~rong", "and", "elect~ounweak", "(EW)", "interactIons", "is", "the", "Englert-Brout-Higgs", "(EBH?", "boson.?", "Possible", "sinals", "for", "the", "EBH", "boson", "at", "the", "LHC", "experinients", "have", "been", "reported,", "but?", "morc", "data", "are", "necessary", "for", "the", "confirmation."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["The", "last", "particle", "yet", "to", "be", "discovered", "in", "the", "standard", "model", "(SM)", "of", "s~rong", "and", "elect~out", "weak", "(EW)", "interactIons", "is", "the", "Englert-Brout-Higgs", "(EBH?", "boson.?", "Possible", "signals", "for", "the", "EBH", "boson", "at", "the", "LHC", "experiments", "have", "been", "reported,", "but?", "morc", "data", "is", "necessary", "for", "the", "confirmation."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["But(11)implies(4)aneitfollowsthatb?k+1)Ais\u03ba-jetample.Thiscompletesthel)roofofth\\etlaeorem."], "labels": ["WRONG"]}, "correct": {"tokens": ["But", "(11)", "implies", "(4)", "and", "it", "follows", "that", "(k", "+", "1)A", "is", "\u03ba-jet", "ample.", "This", "completes", "the", "proof", "of", "the", "theorem."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "MIXED"]}, "predicted": {"google": {"tokens": ["But(11)implies(4)aneitfollowsthatb?k+1)Ais\u03ba-jetample.Thiscompletesthel)roofofth\\etlaeorem."], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["But", "(11)", "implies", "(4)", "ane", "it", "follows", "that", "b?k", "+", "1)A", "is", "\u03ba-jet", "ample.", "This", "completes", "the", "l)roof", "of", "th\\e", "tlaeorem."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "WRONG"]}, "BS-bid-OCR+google": {"tokens": ["But", "(11)", "implies", "(4)", "ane", "it", "follows", "that", "b?k", "+", "1)A", "is", "\u03ba-jet", "ample.", "This", "completes", "the", "l)roof", "of", "th\\e", "theorem."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "MIXED"]}}}, {"corrupt": {"tokens": ["Because\u03b6jisharmonic,thefield\u03a6.jD5cori'espondstoaD6-branedeformationthatpreserw'.sthewotldvolumesupersymmetrycolfditions"], "labels": ["WRONG"]}, "correct": {"tokens": ["Because", "\u03b6j", "is", "harmonic,", "the", "field", "\u03a6jD6", "corresponds", "to", "a", "D6-brane", "deformation", "that", "preserves", "the", "worldvolume", "supersymmetry", "conditions"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED"]}, "predicted": {"google": {"tokens": ["Because\u03b6jisharmonic,thefield\u03a6.jD5cori'espondstoaD6-branedeformationthatpreserw'.sthewotldvolumesupersymmetrycolfditions"], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["Because", "\u03b6j", "is", "harmonic,", "the", "field", "\u03a6.jD5", "cori'esponds", "to", "a", "D6-brane", "deformation", "that", "preserw'.s", "the", "wotldvolume", "supersymmetry", "colfditions"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG"]}, "BS-bid-OCR+google": {"tokens": ["Because", "\u03b6j", "is", "harmonic,", "the", "field", "\u03a6.jD5", "corresponds", "to", "a", "D6-brane", "deformation", "that", "preserw'.s", "the", "world", "volume", "supersymmetry", "conditions"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "MIXED"]}}}, {"corrupt": {"tokens": ["Iftheinciden?tlightbeamiswellcollimated,A(kx)isasharplydistributedGaussianfuuctionaroundkx0.Inthiscase,thetrasmissioncoefficientTcanbeapproxmated,bywritingitjnanexponentiaalibrm,ext)andingtheexponentinnTaylorseriesatkx0icatandretainingtiiefirsttwoterms,tobe"], "labels": ["WRONG"]}, "correct": {"tokens": ["If", "the", "incident", "light", "beam", "is", "well", "collimated,", "A(kx)", "is", "a", "sharply", "distributed", "Gaussian", "function", "around", "kx0.", "In", "this", "case,", "the", "transmission", "coefficient", "T", "can", "be", "approximated,", "by", "writing", "it", "in", "an", "exponential", "form,", "expanding", "the", "exponent", "in", "Taylor", "series", "at", "kx0", "and", "retaining", "the", "first", "two", "terms,", "to", "be"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["Iftheinciden?tlightbeamiswellcollimated,A(kx)isasharplydistributedGaussianfuuctionaroundkx0.Inthiscase,thetrasmissioncoefficientTcanbeapproxmated,bywritingitjnanexponentiaalibrm,ext)andingtheexponentinnTaylorseriesatkx0icatandretainingtiiefirsttwoterms,tobe"], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["If", "the", "inciden?t", "light", "beam", "is", "well", "collimated,", "A(kx)", "is", "a", "sharply", "distributed", "Gaussian", "fuuction", "around", "kx0.", "In", "this", "case,", "the", "trasmission", "coefficient", "T", "can", "be", "approxmated,", "by", "writing", "it", "jn", "an", "exponentiaal", "ibrm,", "ext)anding", "the", "exponent", "in", "n", "Taylor", "series", "at", "kx0icat", "and", "retaining", "tiie", "first", "two", "terms,", "to", "be"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["If", "the", "incident", "light", "beam", "is", "well", "collimated,", "A(kx)", "is", "a", "sharply", "distributed", "Gaussian", "function", "around", "kx0.", "In", "this", "case,", "the", "transmission", "coefficient", "T", "can", "be", "approximated,", "by", "writing", "it", "in", "an", "exponential", "ibm,", "ext)anding", "the", "exponent", "in", "n", "Taylor", "series", "at", "kx0icat", "and", "retaining", "tiie", "first", "two", "terms,", "to", "be"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["(i)S(\u03a3,G)can.bee;mbeddedintoMG\u03a3asanopend(~nsesubset."], "labels": ["WRONG"]}, "correct": {"tokens": ["(i)", "S(\u03a3,", "G)", "can", "be", "embedded", "into", "MG\u03a3", "as", "an", "open", "dense", "subset."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["(i)S(\u03a3,G)can.bee;mbeddedintoMG\u03a3asanopend(~nse", "subset."], "labels": ["WRONG", "TOKENIZATION_ERROR"]}, "BS-bid-OCR": {"tokens": ["(i)", "S(\u03a3,", "G)", "can.", "be", "e;mbedded", "into", "MG\u03a3", "as", "an", "open", "d(~nse", "subset."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["(i)", "S(\u03a3,", "G)", "can.", "be", "e;mbedded", "into", "MG\u03a3", "as", "an", "open", "d(~nse", "subset."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["forn\u22651."], "labels": ["WRONG"]}, "correct": {"tokens": ["for", "n", "\u2265", "1."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["form\u22651."], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["for", "n", "\u2265", "1."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["for", "n", "\u2265", "1."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["11?dime?nsionalgammamatrices"], "labels": ["WRONG"]}, "correct": {"tokens": ["11-dimensional", "gamma", "matrices"], "labels": ["MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["11?dimensional", "gamma", "matrices"], "labels": ["WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR": {"tokens": ["11?dime?nsional", "gamma", "matrices"], "labels": ["WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["11?dimensional", "gamma", "matrices"], "labels": ["WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["Ifforsomelinearfunctiononad-polytepewlthd+3vetticesthereisamonotonepaththroughMubt(d,d+3)vertices,?thenthepolytopeissimpleanddual-to-neighborly,and?thelinearfunctioninucesaHamiltonHKAOF.SoforurproblemwehavetoenumerateHam\\iltonHKAOFsonthegraphsfdual-to-neighborlyd-polytopeswithd+3facets,whicha?reinfactdual?to-cyclicinthcaseofeyendimhension."], "labels": ["WRONG"]}, "correct": {"tokens": ["If", "for", "some", "linear", "function", "on", "a", "d-polytope", "with", "d", "+", "3", "vertices", "there", "is", "a", "monotone", "path", "through", "Mubt(d,", "d", "+", "3)", "vertices,", "then", "the", "polytope", "is", "simple", "and", "dual-to-neighborly,", "and", "the", "linear", "function", "induces", "a", "Hamilton", "HK", "AOF.", "So", "for", "our", "problem", "we", "have", "to", "enumerate", "Hamilton", "HK", "AOFs", "on", "the", "graphs", "of", "dual-to-neighborly", "d-polytopes", "with", "d", "+", "3", "facets,", "which", "are", "in", "fact", "dual-to-cyclic", "in", "the", "case", "of", "even", "dimension."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED"]}, "predicted": {"google": {"tokens": ["Ifforsomelinearfunctiononad-polytepewlthd+3vetticesthereisamonotonepaththroughMubt(d,d+3)vertices,?thenthepolytopeissimpleanddual-to-neighborly,and?thelinearfunctioninucesaHamiltonHKAOF.SoforurproblemwehavetoenumerateHam\\iltonHKAOFsonthegraphsfdual-to-neighborly-polytopes", "withd+3facets,which?reinfactdual?to-cyclicinthcaseofeyendimhension."], "labels": ["WRONG", "WRONG"]}, "BS-bid-OCR": {"tokens": ["If", "for", "some", "linear", "function", "on", "a", "d-polytepe", "wlth", "d", "+", "3", "vettices", "there", "is", "a", "monotone", "path", "through", "Mubt", "(d,", "d", "+", "3)", "vertices,?", "then", "the", "polytope", "is", "simple", "and", "dual-to-neighborly,", "and?", "the", "linear", "function", "inuces", "a", "Hamilton", "HKAOF.", "So", "for", "ur", "problem", "we", "have", "to", "enumerate", "Ham\\ilton", "HKAOFs", "on", "the", "graphs", "f", "dual-to-neighborly", "d-polytopes", "with", "d", "+", "3", "facets,", "which", "a?re", "in", "fact", "dual?", "to-cyclic", "in", "th", "case", "of", "eyen", "dimhension."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG"]}, "BS-bid-OCR+google": {"tokens": ["If", "for", "some", "linear", "function", "on", "a", "d-polytope", "with", "d", "+", "3", "vertices", "there", "is", "a", "monotone", "path", "through", "Mubt", "(d,", "d", "+", "3)", "vertices,then", "the", "polytope", "is", "simple", "and", "dual-to-neighborly,", "and?", "The", "linear", "function", "induces", "a", "Hamilton", "HOF.", "So", "for", "our", "problem", "we", "have", "to", "enumerate", "Ham\\ilton", "HKAOFs", "on", "the", "graphs", "of", "dual-to-neighborly", "d-polytopes", "with", "d", "+", "3", "facets,", "which", "are", "in", "fact", "dual-", "to-cyclic", "in", "the", "case", "of", "even", "dimension."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED"]}}}, {"corrupt": {"tokens": ["The:imoflhispaperistodrawattentiontothepossibilityofresolvingseveralproblemsofdynmotheoryforsolaractivitybycombining\\diamagneZicturbulent~pumpingandanonLocal\u03b1-effeetiuasolardynamomodel."], "labels": ["WRONG"]}, "correct": {"tokens": ["The", "aim", "of", "this", "paper", "is", "to", "draw", "attention", "to", "the", "possibility", "of", "resolving", "several", "problems", "of", "dynamo", "theory", "for", "solar", "activity", "by", "combining", "diamagnetic", "turbulent", "pumping", "and", "a", "nonlocal", "\u03b1-effect", "in", "a", "solar", "dynamo", "model."], "labels": ["TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["The:imoflhispaperistodrawattentiontothepossibilityofresolvingseveralproblemsofdynmotheoryforsolaractivitybycombining\\diamagneZicturbulent~pumpingandanonLocal\u03b1-effeetiuasolardynamomodel."], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["The", ":im", "of", "lhis", "paper", "is", "to", "draw", "attention", "to", "the", "possibility", "of", "resolving", "several", "problems", "of", "dynmo", "theory", "for", "solar", "activity", "by", "combining", "\\diamagneZic", "turbulent", "~pumping", "and", "a", "nonLocal", "\u03b1-effeet", "iu", "a", "solar", "dynamo", "model."], "labels": ["TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["The", ":im", "of", "this", "paper", "is", "to", "draw", "attention", "to", "the", "possibility", "of", "resolving", "several", "problems", "of", "dynamo", "theory", "for", "solar", "activity", "by", "combining", "\\diamagneTic", "turbulent", "~pumping", "and", "a", "nonLocal", "\u03b1-effect", "is", "a", "solar", "dynamo", "model."], "labels": ["TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "MIXED", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["Ontheexisteneeofperio;di.cmgncticgeodesics"], "labels": ["WRONG"]}, "correct": {"tokens": ["On", "the", "existence", "of", "periodic", "magnetic", "geodesics"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["Ontheexisteneeofperio;di.cmgncticgeodesics"], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["On", "the", "existenee", "of", "perio;di.c", "mgnctic", "geodesics"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["On", "the", "existence", "of", "perio;di.c", "magnetic", "geodesics"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "WRONG", "MIXED", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["Erratumtothepublishedversin."], "labels": ["WRONG"]}, "correct": {"tokens": ["Erratum", "to", "the", "published", "version."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED"]}, "predicted": {"google": {"tokens": ["Erratumtothepublishedversin."], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["Erratum", "to", "the", "published", "versin."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG"]}, "BS-bid-OCR+google": {"tokens": ["Erratum", "to", "the", "published", "version."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED"]}}}, {"corrupt": {"tokens": ["and"], "labels": ["NONE"]}, "correct": {"tokens": ["and"], "labels": ["NONE"]}, "predicted": {"google": {"tokens": ["and"], "labels": ["NONE"]}, "BS-bid-OCR": {"tokens": ["and"], "labels": ["NONE"]}, "BS-bid-OCR+google": {"tokens": ["and"], "labels": ["NONE"]}}}, {"corrupt": {"tokens": ["Gathei'ingallpreviousresults,weilave"], "labels": ["WRONG"]}, "correct": {"tokens": ["Gathering", "all", "previous", "results,", "we", "have"], "labels": ["MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED"]}, "predicted": {"google": {"tokens": ["Gathering", "Previous", "Results,weil", "ave"], "labels": ["MIXED", "WRONG", "WRONG", "WRONG"]}, "BS-bid-OCR": {"tokens": ["Gathei'ing", "all", "previous", "results,", "we", "ilave"], "labels": ["WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG"]}, "BS-bid-OCR+google": {"tokens": ["Gathering", "all", "previous", "results,", "we", "ilave"], "labels": ["MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG"]}}}, {"corrupt": {"tokens": ["sothat"], "labels": ["WRONG"]}, "correct": {"tokens": ["so", "that"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["so", "that"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR": {"tokens": ["so", "that"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["so", "that"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["Althoughequat\\]on(9)isexact,itsalgeboicreprese~tatioisratherinconvenient?bothanalyticallyandnum\\erically.Equation(10)issignificantlymoretractablethan?9),yetitsinfiniteformeventuallyraisesConvergcnceandtruncationi?ssues."], "labels": ["WRONG"]}, "correct": {"tokens": ["Although", "equation", "(9)", "is", "exact,", "its", "algebraic", "representation", "is", "rather", "inconvenient", "both", "analytically", "and", "numerically.", "Equation", "(10)", "is", "significantly", "more", "tractable", "than", "(9),", "yet", "its", "infinite", "form", "eventually", "raises", "convergence", "and", "truncation", "issues."], "labels": ["TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED"]}, "predicted": {"google": {"tokens": ["Although", "Squat\\]on(9)isexact,itsalgeboicreprese~tatioisratherinconvenient?bothanalyticallyandnum\\erically.Equation(10)is", "significantly", "more", "tractable", "than?9),yetitsinfiniteformeventuallyraisesConvergcnceandtruncationi?ssues."], "labels": ["TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG"]}, "BS-bid-OCR": {"tokens": ["Although", "equat\\]on", "(9)", "is", "exact,", "its", "algeboic", "represe~tatio", "is", "rather", "inconvenient", "?both", "analytically", "and", "num\\erically.", "Equation", "(10)", "is", "significantly", "more", "tractable", "than", "?9),", "yet", "its", "infinite", "form", "eventually", "raises", "Convergcnce", "and", "truncation", "i?ssues."], "labels": ["TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG"]}, "BS-bid-OCR+google": {"tokens": ["Although", "equat\\]on", "(9)", "is", "exact,", "its", "algebraic", "representation~tattoo", "is", "rather", "inconvenient", "?both", "analytically", "and", "num\\erically.", "Equation", "(10)", "is", "significantly", "more", "tractable", "than", "?9),", "yet", "its", "infinitive", "form", "eventually", "raises", "Convergence", "and", "truncation", "issues."], "labels": ["TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED"]}}}, {"corrupt": {"tokens": ["Shor(;-TimeEnhancedDecayofCoherentExcitationsinBose-cinsteinCondensates"], "labels": ["WRONG"]}, "correct": {"tokens": ["Short-Time", "Enhanced", "Decay", "of", "Coherent", "Excitations", "in", "Bose-Einstein", "Condensates"], "labels": ["MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["Shor(;-TimeEnhancedDecayofCoherentExcitationsinBose-cinsteinCondensates"], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["Shor(;-Time", "Enhanced", "Decay", "of", "Coherent", "Excitations", "in", "Bose-cinstein", "Condensates"], "labels": ["WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["Shor(;-Time", "Enhanced", "Decay", "of", "Coherent", "Excitations", "in", "Bose-einstein", "Condensates"], "labels": ["WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["Where,asforreversibleciscuits,we?saythatanoisyquantumc~rcuitisworthlessifonevefyfixed-input,itdfirstoutputbitakesbothvalues(0and1)tiwmithprobabilityofatl,east49/100each."], "labels": ["WRONG"]}, "correct": {"tokens": ["Where,", "as", "for", "reversible", "circuits,", "we", "say", "that", "a", "noisy", "quantum", "circuit", "is", "worthless", "if", "on", "every", "fixed", "input,", "its", "first", "output", "bit", "takes", "both", "values", "(0", "and", "1)", "with", "probability", "of", "at", "least", "49/100", "each."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["Where,asforreversibleciscuits,we?saythatanoisyquantumc~rcuitisworthlessifonevefyfixed-input,itdfirstoutputbitakesbothvalues(0and1)tiw", "with", "probability", "of", "at", "least", "49/100each."], "labels": ["WRONG", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "WRONG"]}, "BS-bid-OCR": {"tokens": ["Where,", "as", "for", "reversible", "ciscuits,", "we", "?say", "that", "a", "noisy", "quantum", "c~rcuit", "is", "worthless", "if", "one", "vefy", "fixed-input,", "itd", "first", "output", "bitakes", "both", "values", "(0", "and", "1)", "ti", "wmith", "probability", "of", "at", "l,east", "49/100", "each."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["Where,", "as", "for", "reversible", "circuits,", "do", "we", "say", "that", "a", "noisy", "quantum", "c~rcuit", "is", "worthless", "if", "one", "very", "fixed-input,", "itd", "first", "output", "bitakes", "both", "values", "(0", "and", "1)", "ti", "with", "probability", "of", "at", "least", "49/100", "each."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["Introd\\uction"], "labels": ["WRONG"]}, "correct": {"tokens": ["Introduction"], "labels": ["OCR_ERROR"]}, "predicted": {"google": {"tokens": ["Introd\\uction"], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["Introd\\uction"], "labels": ["WRONG"]}, "BS-bid-OCR+google": {"tokens": ["Introd\\uction"], "labels": ["WRONG"]}}}, {"corrupt": {"tokens": ["Wearenowinvolvedillplanningalaxgercompetition,togetherwitilA,ValenciaandC.Blaschke(CNB-Ma(lrld),un?dertheumbrellaoftheISCBB?ioLINKSpecialInterestQrsisoupforTextDataMining(seehl;tp://www.pdg.cnb.uam.es/BioLINK/).Wearplannrn~twotasks:thefirstistheexlractionofge,~eorproteinnamesfromtext,sothatw?ecanevalual.ethecurFentstateofth\\eartinbimlogicalentityextractionacrosssystemsthathavebeenreporte?dinthelit,eratureoverthepastfewyears.ThesecondtaskwillrequiresystemstoassociateGeneOntology(GO)terms?withrnentionsofproteinsin.rticlesuratedintheSWIS$-PRGTdatabase.OurexperienceinorganizingtheKDDc{}mp\\etitionleadsustobelcoevethatbyusin\\gdatafromcuratedd?atabasesnndfocusingontasksofimmediateutilitybothtodaabasacurati)rsandtoreseapeher,wecandefineagot)dchallengeevalnationfortextdatamiuingsystems."], "labels": ["WRONG"]}, "correct": {"tokens": ["We", "are", "now", "involved", "in", "planning", "a", "larger", "competition,", "together", "with", "A.", "Valencia", "and", "C.", "Blaschke", "(CNB-Madrid),", "under", "the", "umbrella", "of", "the", "ISCB", "BioLINK", "Special", "Interest", "Group", "for", "Text", "Data", "Mining", "(see", "http://www.pdg.cnb.uam.es/BioLINK/).", "We", "are", "planning", "two", "tasks;", "the", "first", "is", "the", "extraction", "of", "gene", "or", "protein", "names", "from", "text,", "so", "that", "we", "can", "evaluate", "the", "current", "state", "of", "the", "art", "in", "biological", "entity", "extraction", "across", "systems", "that", "have", "been", "reported", "in", "the", "literature", "over", "the", "past", "few", "years.", "The", "second", "task", "will", "require", "systems", "to", "associate", "Gene", "Ontology", "(GO)", "terms", "with", "mentions", "of", "proteins", "in", "articles", "curated", "in", "the", "SWISS-PROT", "database.", "Our", "experience", "in", "organizing", "the", "KDD", "competition", "leads", "us", "to", "believe", "that", "by", "using", "data", "from", "curated", "databases", "and", "focusing", "on", "tasks", "of", "immediate", "utility", "both", "to", "database", "curators", "and", "to", "researchers,", "we", "can", "define", "a", "good", "challenge", "evaluation", "for", "text", "data", "mining", "systems."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["Wearenowinvolvedillplanningalaxgercompetition,togetherwitilA,ValenciaandC.Blaschke(CNB-Ma(lrld),un?dertheumbrellaoftheISCBB?ioLINKSpecialInterestQrsisoupforTextDataMining(seehl;tp://www.pdg.cnb.uam.es/BioLINK/).Wearplannrn~twotasks:thefirstistheexlractionofge,~eorproteinnamesfromtext,sothatw?ecanevalual.ethecurFentstateofth\\eartinbimlogicalentityextractionacrosssystemsthathavebeenreporte?dinthelit,eratureoverthepastfewyears.ThesecondtaskwillrequiresystemstoassociateGeneOntology(GO)terms?withrnentionsofproteinsin.rticlesuratedintheSWIS$-PRGTdatabase.OurexperienceinorganizingtheKDDc{}mp\\etitionleadsustobelcoevethatbyusin\\gdatafromcuratedd?atabasesnndfocusingontasksofimmediateutilitybothtodaabasacurati)rsandtoreseapeher,wecandefineagot)dchallengeevalnationfortextdatamiuingsystems."], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["We", "are", "now", "involved", "ill", "planning", "a", "laxger", "competition,", "together", "witil", "A,", "Valencia", "and", "C.", "Blaschke", "(CNB-Ma(lrld),", "un?der", "the", "umbrella", "of", "the", "ISCB", "B?io", "LINK", "Special", "Interest", "Qrsisoup", "for", "Text", "Data", "Mining", "(see", "hl;tp://www.pdg.cnb.uam.es/BioLINK/).", "We", "ar", "plannrn~", "two", "tasks:", "the", "first", "is", "the", "exlraction", "of", "ge,~eor", "protein", "names", "from", "text,", "so", "that", "w?e", "can", "evalual.e", "the", "curFent", "state", "of", "th\\e", "art", "in", "bimlogical", "entity", "extraction", "across", "systems", "that", "have", "been", "reporte?d", "in", "the", "lit,erature", "over", "the", "past", "few", "years.", "The", "second", "task", "will", "require", "systems", "to", "associate", "Gene", "Ontology", "(GO)", "terms?", "with", "rnentions", "of", "proteins", "in", ".rticles", "urated", "in", "the", "SWIS$-PRGT", "database.", "Our", "experience", "in", "organizing", "the", "KDD", "c{}mp\\etition", "leads", "us", "to", "belcoeve", "that", "by", "usin\\g", "data", "from", "curated", "d?atabases", "nnd", "focusing", "on", "tasks", "of", "immediate", "utility", "both", "to", "daabasa", "curati)rs", "and", "to", "reseapeher,", "we", "can", "define", "a", "got)d", "challenge", "evalnation", "for", "text", "data", "miuing", "systems."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["We", "are", "now", "involved", "in", "planning", "a", "lager", "competition,", "together", "with", "A,", "Valencia", "and", "C.", "Blaschke", "(CNB-Ma(lrld),", "under", "the", "umbrella", "of", "the", "ISCB", "B?io", "LINK", "Special", "Interest", "Group", "for", "Text", "Data", "Mining", "(see", "hl;tp://www.pdg.cnb.uam.es/BioLINK/).", "We", "are", "planning~", "two", "tasks:", "the", "first", "is", "the", "extraction", "of", "ge,~eor", "protein", "names", "from", "text,", "so", "that", "we", "can", "evaluate.e", "the", "curRent", "state", "of", "th\\e", "art", "in", "biological", "entity", "extraction", "across", "systems", "that", "have", "been", "reported", "in", "the", "literature", "over", "the", "past", "few", "years.", "The", "second", "task", "will", "require", "systems", "to", "associate", "Gene", "Ontology", "(GO)", "terms?", "with", "mentions", "of", "proteins", "in", "articles", "curated", "in", "the", "SWIS$-PROT", "database.", "Our", "experience", "in", "organizing", "the", "KDD", "c{}mp\\petition", "leads", "us", "to", "believe", "that", "by", "usin\\g", "data", "from", "curated", "databases", "and", "focusing", "on", "tasks", "of", "immediate", "utility", "both", "to", "database", "curati)rs", "and", "to", "receiver,", "we", "can", "define", "a", "got)d", "challenge", "evaluation", "for", "text", "data", "mining", "systems."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "MIXED", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["and"], "labels": ["NONE"]}, "correct": {"tokens": ["and"], "labels": ["NONE"]}, "predicted": {"google": {"tokens": ["and"], "labels": ["NONE"]}, "BS-bid-OCR": {"tokens": ["and"], "labels": ["NONE"]}, "BS-bid-OCR+google": {"tokens": ["and"], "labels": ["NONE"]}}}, {"corrupt": {"tokens": ["Observethatthdet)encnceontheinitialstateonlyappearsthroifilthetransitiondensty.Severalexam\\pleoofapdlicationofthisformulaaregiven,invol.vingBrownianmotionandBesselprocesseswithlinear,square?drootandsquareboundariex."], "labels": ["WRONG"]}, "correct": {"tokens": ["Observe", "that", "the", "dependence", "on", "the", "initial", "state", "only", "appears", "through", "the", "transition", "density.", "Several", "examples", "of", "application", "of", "this", "formula", "are", "given,", "involving", "Brownian", "motion", "and", "Bessel", "processes", "with", "linear,", "squared", "root", "and", "square", "boundaries."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED"]}, "predicted": {"google": {"tokens": ["Observethatthdet)encnceontheinitialstateonlyappearsthroifilthetransitiondensty.Severalexam\\pleoofapdlicationofthisformulaaregiven,invol.vingBrownianmotionandBesselprocesseswithlinear,square?drootandsquareboundariex."], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["Observe", "that", "th", "det)encnce", "on", "the", "initial", "state", "only", "appears", "throifil", "the", "transition", "densty.", "Several", "exam\\pleo", "of", "apdlication", "of", "this", "formula", "are", "given,", "invol.ving", "Brownian", "motion", "and", "Bessel", "processes", "with", "linear,", "square?d", "root", "and", "square", "boundariex."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG"]}, "BS-bid-OCR+google": {"tokens": ["Observe", "that", "the", "det)encnce", "on", "the", "initial", "state", "only", "appears", "throifil", "the", "transition", "densty.", "Several", "exam\\pleo", "of", "application", "of", "this", "formula", "are", "given,", "involving", "Brownian", "motion", "and", "Bessel", "processes", "with", "linear,", "square", "root", "and", "square", "boundaries."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED"]}}}, {"corrupt": {"tokens": ["withtheeigenenergies"], "labels": ["WRONG"]}, "correct": {"tokens": ["with", "the", "eigenenergies"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["with", "the", "eigenenergies"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR": {"tokens": ["with", "the", "eigenenergies"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["with", "the", "eigenenergies"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["Wesketchthisw(:llknowproofasweneedthe?detailsinlatearguments."], "labels": ["WRONG"]}, "correct": {"tokens": ["We", "sketch", "this", "well", "know", "proof", "as", "we", "need", "the", "details", "in", "later", "arguments."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["Wesketchthisw(:llknowproofasweneed", "the?details", "late", "arguments."], "labels": ["WRONG", "WRONG", "WRONG", "TOKENIZATION_ERROR"]}, "BS-bid-OCR": {"tokens": ["We", "sketch", "this", "w(:ll", "know", "proof", "as", "we", "need", "the?", "details", "in", "late", "arguments."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["We", "sketch", "this", "w(:ll", "know", "proof", "as", "we", "need", "the?", "details", "in", "late", "arguments."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["LightPxofile"], "labels": ["WRONG"]}, "correct": {"tokens": ["Light", "Profile"], "labels": ["TOKENIZATION_ERROR", "MIXED"]}, "predicted": {"google": {"tokens": ["LightPxofile"], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["Light", "Pxofile"], "labels": ["TOKENIZATION_ERROR", "WRONG"]}, "BS-bid-OCR+google": {"tokens": ["Light", "Profile"], "labels": ["TOKENIZATION_ERROR", "MIXED"]}}}, {"corrupt": {"tokens": ["Sin(:etheFPPpacketforwardingmode?ltriestosendcopiesofthepacketdownalldirectedpatilsinthenetwork,pa\u2192bistheprebabi?litythatadlressectedpathofsucc'essfullinksex-istsinGbetweenthesourceaandthesinkb.Thileadstoastraightforwardfo~mulatoacalculatetheFPPmet1ic."], "labels": ["WRONG"]}, "correct": {"tokens": ["Since", "the", "FPP", "packet", "forwarding", "model", "tries", "to", "send", "copies", "of", "the", "packet", "down", "all", "directed", "paths", "in", "the", "network,", "pa", "\u2192", "b", "is", "the", "probability", "that", "a", "directed", "path", "of", "successful", "links", "exists", "in", "G", "between", "the", "source", "a", "and", "the", "sink", "b.", "This", "leads", "to", "a", "straightforward", "formula", "to", "calculate", "the", "FPP", "metric."], "labels": ["MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED"]}, "predicted": {"google": {"tokens": ["Sin(:etheFPPpacketforwardingmode?ltriestosendcopiesofthepacketdownalldirectedpatilsinthenetwork,pa\u2192bistheprebabi?litythatadlressectedpathofsucc'essfullinksex-istsinGbetweenthesourceaandthesinkb.Thileadstoastraightforwardfo~mulatoacalculatetheFPPmet1ic."], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["Sin(:e", "the", "FPP", "packet", "forwarding", "mode?l", "tries", "to", "send", "copies", "of", "the", "packet", "down", "all", "directed", "patils", "in", "the", "network,", "pa", "\u2192", "b", "is", "the", "prebabi?lity", "that", "a", "dlressected", "path", "of", "succ'essful", "links", "ex-ists", "in", "G", "between", "the", "sourcea", "and", "the", "sink", "b.", "Thi", "leads", "to", "a", "straightforward", "fo~mula", "to", "acalculate", "the", "FPP", "met1ic."], "labels": ["WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG"]}, "BS-bid-OCR+google": {"tokens": ["Sin(:e", "the", "FPP", "packet", "forwarding", "model", "tries", "to", "send", "copies", "of", "the", "packet", "down", "all", "directed", "patils", "in", "the", "network,", "pa", "\u2192", "b", "is", "the", "probability", "that", "a", "dissected", "path", "of", "successful", "links", "exists", "in", "G", "between", "the", "sources", "and", "the", "sink", "b.", "Thi", "leads", "to", "a", "straightforward", "fo~mula", "to", "calculate", "the", "FPP", "met1ic."], "labels": ["WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG"]}}}, {"corrupt": {"tokens": ["ThescstronglyYukawacou1)lingconstantstendI;oanunitarycoatantassimilartothecase\\inthesolublemodelbutithsmallervalue.Duelothenumericalaccuracy,the\\resultsrepresentedabovearenotthefinalvaluesofYukawacouplingconstantforleptonandquark,however,th.estrong~yYukawacouplingconstantsdonotdependqualltativelyonthenumericalaccuracy"], "labels": ["WRONG"]}, "correct": {"tokens": ["These", "strongly", "Yukawa", "coupling", "constants", "tend", "to", "an", "unitary", "constant", "as", "similar", "to", "the", "case", "in", "the", "soluble", "model", "but", "with", "smaller", "value.", "Due", "to", "the", "numerical", "accuracy,", "the", "results", "represented", "above", "are", "not", "the", "final", "values", "of", "Yukawa", "coupling", "constant", "for", "lepton", "and", "quark,", "however,", "the", "strongly", "Yukawa", "coupling", "constants", "do", "not", "depend", "qualitatively", "on", "the", "numerical", "accuracy."], "labels": ["MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED"]}, "predicted": {"google": {"tokens": ["These", "strongly", "Yukawa", "cou1)lingconstantstendI;oanunitarycoatantassimilartothecase\\inthesolublemodelbutithsmallervalue.Duelothenumericalaccuracy,the\\resultsrepresentedabovearenotthefinalvaluesofYukawacouplingconstantforleptonandquark,however,th.estrong~yYukawacouplingconstantsdonotdependqualltativelyonthenumericalaccuracy"], "labels": ["MIXED", "MIXED", "TOKENIZATION_ERROR", "WRONG"]}, "BS-bid-OCR": {"tokens": ["Thesc", "strongly", "Yukawa", "cou1)ling", "constants", "tend", "I;o", "an", "unitary", "coatant", "as", "similar", "to", "the", "case", "\\in", "the", "soluble", "model", "but", "ith", "smaller", "value.", "Due", "lo", "the", "numerical", "accuracy,", "the", "\\results", "represented", "above", "are", "not", "the", "final", "values", "of", "Yukawa", "coupling", "constant", "for", "lepton", "and", "quark,", "however,", "th.e", "strong~y", "Yukawa", "coupling", "constants", "do", "not", "depend", "qualltatively", "on", "the", "numerical", "accuracy"], "labels": ["WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG"]}, "BS-bid-OCR+google": {"tokens": ["Thesc", "strongly", "Yukawa", "cou1)ling", "constants", "tend", "I;o", "an", "unitary", "coatant", "as", "similar", "to", "the", "case", "\\in", "the", "soluble", "model", "but", "with", "smaller", "value.", "Due", "lo", "the", "numerical", "accuracy,", "the", "\\results", "represented", "above", "are", "not", "the", "final", "values", "of", "Yukawa", "coupling", "constant", "for", "lepton", "and", "quark,", "however,", "the", "strong~y", "Yukawa", "coupling", "constants", "do", "not", "depend", "qualitatively", "on", "the", "numerical", "accuracy"], "labels": ["WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG"]}}}, {"corrupt": {"tokens": ["MinimallycoupledGalileanfield"], "labels": ["WRONG"]}, "correct": {"tokens": ["Minimally", "coupled", "Galilean", "field"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["MinimallycoupledGalileanfield"], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["Minimally", "coupled", "Galilean", "field"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["Minimally", "coupled", "Galilean", "field"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["Numerifcalconfirmateon"], "labels": ["WRONG"]}, "correct": {"tokens": ["Numerical", "confirmation"], "labels": ["MIXED", "MIXED"]}, "predicted": {"google": {"tokens": ["Numerical", "Confirmation"], "labels": ["MIXED", "WRONG"]}, "BS-bid-OCR": {"tokens": ["Numerifcal", "confirmateon"], "labels": ["WRONG", "WRONG"]}, "BS-bid-OCR+google": {"tokens": ["Numerical", "confirmation"], "labels": ["MIXED", "MIXED"]}}}, {"corrupt": {"tokens": ["aYukawaInstituteforTheoreticalPhysics,2KyotoUni?versity,Xyoto606-8502,Jal)an"], "labels": ["WRONG"]}, "correct": {"tokens": ["aYukawa", "Institute", "for", "Theoretical", "Physics,", "Kyoto", "University,", "Kyoto", "606-8502,", "Japan"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "MIXED"]}, "predicted": {"google": {"tokens": ["aYukawaInstituteforTheoreticalPhysics,2KyotoUni?versity,Xyo", "606-8502,Jal)an"], "labels": ["WRONG", "WRONG"]}, "BS-bid-OCR": {"tokens": ["aYukawa", "Institute", "for", "Theoretical", "Physics,", "2", "Kyoto", "Uni?versity,", "Xyoto", "606-8502,", "Jal)an"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "MIXED", "WRONG", "WRONG", "TOKENIZATION_ERROR", "WRONG"]}, "BS-bid-OCR+google": {"tokens": ["aYukawa", "Institute", "for", "Theoretical", "Physics,", "2", "Kyoto", "University,", "Kyoto", "606-8502,", "Jal)an"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "WRONG"]}}}, {"corrupt": {"tokens": ["Kinematicsurfaceswithnon-zeroconstantso/alarcurvature"], "labels": ["WRONG"]}, "correct": {"tokens": ["Kinematic", "surfaces", "with", "non-zero", "constant", "scalar", "curvature"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["Kinematic", "Surfaces", "With", "Non-zero", "constant", "so/alar", "curvature"], "labels": ["TOKENIZATION_ERROR", "WRONG", "WRONG", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR"]}, "BS-bid-OCR": {"tokens": ["Kinematic", "surfaces", "with", "non-zero", "constant", "so/alar", "curvature"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["Kinematic", "surfaces", "with", "non-zero", "constant", "so/alar", "curvature"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["Wewillbebackinsection5belowtothestudyofconcret?eexamples.Nowletusdiscusssomegeneralduelityisse.Wehav\\ehere:"], "labels": ["WRONG"]}, "correct": {"tokens": ["We", "will", "be", "back", "in", "section", "5", "below", "to", "the", "study", "of", "concrete", "examples.", "Now", "let", "us", "discuss", "some", "general", "duality", "issues.", "We", "have", "here:"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["Wewil", "Bebackinsection5belowtothestudyofconcret?examples.Nowletusdiscusssomegeneralduelityisse.Wehav\\where:"], "labels": ["WRONG", "WRONG"]}, "BS-bid-OCR": {"tokens": ["We", "will", "be", "back", "in", "section", "5", "below", "to", "the", "study", "of", "concret?e", "examples.", "Now", "let", "us", "discuss", "some", "general", "duelity", "isse.", "We", "hav\\e", "here:"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["We", "will", "be", "back", "in", "section", "5", "below", "to", "the", "study", "of", "concrete", "examples.", "Now", "let", "us", "discuss", "some", "general", "duelity", "isse.", "We", "hav\\e", "here:"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["andalndoanelc'mentc\u2208C,contributingtothelabelonthetopedge,Theproblemistirustodecid?what1)inifthecontrib?tionofcisconcenttatedintheoplefttriangl.eorlnthebottomright.Likewisewecouldtriangulatediffere7~tly"], "labels": ["WRONG"]}, "correct": {"tokens": ["and", "also", "an", "element", "c", "\u2208", "C,", "contributing", "to", "the", "label", "on", "the", "top", "edge.", "The", "problem", "is", "thus", "to", "decide", "what", "b", "is", "if", "the", "contribution", "of", "c", "is", "concentrated", "in", "the", "top", "left", "triangle", "or", "in", "the", "bottom", "right.", "Likewise", "we", "could", "triangulate", "differently"], "labels": ["TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED"]}, "predicted": {"google": {"tokens": ["andalndoanelc'mentc\u2208C,contributingtothelabelonthetopedge,Theproblemistirustodecid?what1)inifthecontrib?tion", "cisconcenttatedintheopleft", "triangle", "on", "bottomright.Likewise", "Wecouldtriangulatediffere7~tly"], "labels": ["WRONG", "WRONG", "MIXED", "WRONG", "WRONG", "WRONG"]}, "BS-bid-OCR": {"tokens": ["and", "alndo", "an", "elc'ment", "c", "\u2208", "C,", "contributing", "to", "the", "label", "on", "the", "top", "edge,", "The", "problem", "is", "tirus", "to", "decid?", "what", "1)in", "if", "the", "contrib?tion", "of", "c", "is", "concenttated", "in", "the", "op", "left", "triangl.e", "or", "ln", "the", "bottom", "right.", "Likewise", "we", "could", "triangulate", "differe7~tly"], "labels": ["TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG"]}, "BS-bid-OCR+google": {"tokens": ["and", "alndo", "an", "element", "c", "\u2208", "C,", "contributing", "to", "the", "label", "on", "the", "top", "edge,", "The", "problem", "is", "tirus", "to", "decide?", "what", "1)if", "the", "contribution", "of", "c", "is", "concentrated", "in", "the", "top", "left", "triangle", "or", "on", "the", "bottom", "right.", "Likewise", "we", "could", "triangulate", "differe7~tly"], "labels": ["TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG"]}}}, {"corrupt": {"tokens": ["Inthisap\\pendixweprovidethedetailedequationsofmotioninthehelicalArisatz.Theactionis"], "labels": ["WRONG"]}, "correct": {"tokens": ["In", "this", "appendix", "we", "provide", "the", "detailed", "equations", "of", "motion", "in", "the", "helical", "Ansatz.", "The", "action", "is"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["Inthisap\\pendixweprovidethedetailedequationsofmotioninthehelicalArisatz.Theactionis"], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["In", "this", "ap\\pendix", "we", "provide", "the", "detailed", "equations", "of", "motion", "in", "the", "helical", "Arisatz.", "The", "action", "is"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["In", "this", "ap\\pendix", "we", "provide", "the", "detailed", "equations", "of", "motion", "in", "the", "helical", "Arisatz.", "The", "action", "is"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["nTheassumptionseemsobesupportedhy"], "labels": ["WRONG"]}, "correct": {"tokens": ["The", "assumption", "seems", "to", "be", "supported", "by"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED"]}, "predicted": {"google": {"tokens": ["nTheassumptionseemsobesupportedhy"], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["nThe", "assumption", "seems", "o", "be", "supported", "hy"], "labels": ["WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG"]}, "BS-bid-OCR+google": {"tokens": ["nThe", "assumption", "seems", "to", "be", "supported", "by"], "labels": ["WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED"]}}}, {"corrupt": {"tokens": ["Thispaperisaversionofthepaperacceptedto5thInternadonalYoun\\gScientistsConferenceinHPCandSiinulation."], "labels": ["WRONG"]}, "correct": {"tokens": ["This", "paper", "is", "a", "version", "of", "the", "paper", "accepted", "to", "5th", "International", "Young", "Scientists", "Conference", "in", "HPC", "and", "Simulation."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED"]}, "predicted": {"google": {"tokens": ["Thispaperisaversionofthepaperacceptedto5thInternadonalYoun\\gScientistsConferenceinHPCandSiinulation."], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["This", "paper", "is", "a", "version", "of", "the", "paper", "accepted", "to", "5th", "Internadonal", "Youn\\g", "Scientists", "Conference", "in", "HPC", "and", "Siinulation."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG"]}, "BS-bid-OCR+google": {"tokens": ["This", "paper", "is", "a", "version", "of", "the", "paper", "accepted", "to", "5th", "International", "Youn\\g", "Scientists", "Conference", "in", "HPC", "and", "Simulation."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED"]}}}, {"corrupt": {"tokens": ["EquationsnofTRotion"], "labels": ["WRONG"]}, "correct": {"tokens": ["Equations", "of", "Motion"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED"]}, "predicted": {"google": {"tokens": ["Equations", "of", "Motion"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED"]}, "BS-bid-OCR": {"tokens": ["Equations", "nof", "TRotion"], "labels": ["TOKENIZATION_ERROR", "WRONG", "WRONG"]}, "BS-bid-OCR+google": {"tokens": ["Equations", "of", "Motion"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED"]}}}, {"corrupt": {"tokens": ["Thepaperisorganiz\\e(lasfollowsInSec.\\II,w<;ri~flydescribetheNJLmodelandthcchoiceofparameters.InSec.III,wediscussthecalculatlonsandsomeofitstechnicalaspects.TfiSee.IV,wepresentonwres?ults,andinSec.Vweconclude."], "labels": ["WRONG"]}, "correct": {"tokens": ["The", "paper", "is", "organized", "as", "follows.", "In", "Sec.", "II,", "we", "briefly", "describe", "the", "NJL", "model", "and", "the", "choice", "of", "parameters.", "In", "Sec.", "III,", "we", "discuss", "the", "calculations", "and", "some", "of", "its", "technical", "aspects.", "In", "Sec.", "IV,", "we", "present", "our", "results,", "and", "in", "Sec.", "V", "we", "conclude."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["Thepaperisorganiz\\e(as", "follows", "Sec.\\II,w<;ri~flydescribetheNJLmodelandthcchoiceofparameters.InSec.III,wediscussthecalculatlonsandsomeofitstechnicalaspects.TfiSee.IV,wepresentonwres?ults,andinSec.Vweconclude."], "labels": ["WRONG", "WRONG", "WRONG"]}, "BS-bid-OCR": {"tokens": ["The", "paper", "is", "organiz\\e(l", "as", "follows", "In", "Sec.", "\\II,", "w<;", "ri~fly", "describe", "the", "NJL", "model", "and", "thc", "choice", "of", "parameters.", "In", "Sec.", "III,", "we", "discuss", "the", "calculatlons", "and", "some", "of", "its", "technical", "aspects.", "Tfi", "See.", "IV,", "we", "present", "onw", "res?ults,", "and", "in", "Sec.", "V", "we", "conclude."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["The", "paper", "is", "organiz\\e(l", "as", "follows", "In", "Sec.", "\\II,", "w<;", "ri~fly", "describe", "the", "NJL", "model", "and", "thc", "choice", "of", "parameters.", "In", "Sec.", "III,", "we", "discuss", "the", "calculations", "and", "some", "of", "its", "technical", "aspects.", "Tfi", "See.", "IV,", "we", "present", "one", "result,", "and", "in", "Sec.", "V", "we", "conclude."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["Wehavefoundthezero=temueraturephasediagramofaphysicalsystemwhoserelevantdynamicsiscapturSedbyanonlinarsigmamodelwithaDzyaloshinskii-Moriya'termandaZeemancouplin~toanexternalmagneticfieldThisdynamicscorrespondsothecontlnuauslimitofanchiralferromagnetonasquarelattice."], "labels": ["WRONG"]}, "correct": {"tokens": ["We", "have", "found", "the", "zero-temperature", "phase", "diagram", "of", "a", "physical", "system", "whose", "relevant", "dynamics", "is", "captured", "by", "a", "nonlinear", "sigma", "model", "with", "a", "Dzyaloshinskii-Moriya", "term", "and", "a", "Zeeman", "coupling", "to", "an", "external", "magnetic", "field.", "This", "dynamics", "corresponds", "to", "the", "continuous", "limit", "of", "an", "chiral", "ferromagnet", "on", "a", "square", "lattice."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["Wehavefoundthezero=temueraturephasediagramofaphysicalsystemwhoserelevantdynamicsiscapturSedbyanonlinarsigmamodelwithaDzyaloshinskii-Moriya'termandaZeemancouplin~toanexternalmagneticfieldThisdynamicscorrespondsothecontlnuauslimitofanchiralferromagnetonasquarelattice."], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["We", "have", "found", "the", "zero=temuerature", "phase", "diagram", "of", "a", "physical", "system", "whose", "relevant", "dynamics", "is", "capturSed", "by", "a", "nonlinar", "sigma", "model", "with", "a", "Dzyaloshinskii-Moriya", "'term", "and", "a", "Zeeman", "couplin~", "to", "an", "external", "magnetic", "field", "This", "dynamics", "corresponds", "o", "the", "contlnuaus", "limit", "of", "an", "chiral", "ferromagnet", "on", "a", "square", "lattice."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["We", "have", "found", "the", "zero=temperature", "phase", "diagram", "of", "a", "physical", "system", "whose", "relevant", "dynamics", "is", "captured", "by", "a", "nonlinear", "sigma", "model", "with", "a", "Dzyaloshinskii-Moriya", "'term", "and", "a", "Zeeman", "coupling~", "to", "an", "external", "magnetic", "field", "This", "dynamics", "corresponds", "to", "the", "continuous", "limit", "of", "an", "chiral", "ferromagnet", "on", "a", "square", "lattice."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["Althonghouranalysesyieldirectlyanon-vanishingm(\u03a6\u03b2,k),webelievethatJtwillalsocontributetomphy(\u03a6\u03b2Iintheanevalyticallyc\\ontin\"uedl'eal-timepropa6atoraswell.Noticeth~ttincomputingmphy,thescalekwillbeabsorbedviaasetofself-consistentequations."], "labels": ["WRONG"]}, "correct": {"tokens": ["Although", "our", "analyses", "yield", "directly", "a", "non-vanishing", "m(\u03a6\u03b2,", "k),", "we", "believe", "that", "it", "will", "also", "contribute", "to", "mphy(\u03a6\u03b2)", "in", "the", "analytically", "continued", "real-time", "propagator", "as", "well.", "Notice", "that", "in", "computing", "mphy,", "the", "scale", "k", "will", "be", "absorbed", "via", "a", "set", "of", "self-consistent", "equations."], "labels": ["MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["Althonghouranalysesyieldirectlyanon-vanishing(\u03a6\u03b2,k),we", "believe", "that", "It", "will", "also", "contribute", "to", "m", "phy(\u03a6\u03b2Iintheanevalyticallyc\\ontin\"uedl'eal-timepropa6atoraswell.Noticeth~ttincomputingmphy,thescalekwillbeabsorbedviaaset", "of", "self-consistent", "equations."], "labels": ["WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR": {"tokens": ["Althongh", "our", "analyses", "yiel", "directly", "a", "non-vanishing", "m(\u03a6\u03b2,", "k),", "we", "believe", "that", "Jt", "will", "also", "contribute", "to", "mphy(\u03a6\u03b2I", "in", "the", "anevalytically", "c\\ontin\"ued", "l'eal-time", "propa6ator", "as", "well.", "Notice", "th~tt", "in", "computing", "mphy,", "the", "scale", "k", "will", "be", "absorbed", "via", "a", "set", "of", "self-consistent", "equations."], "labels": ["WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["Although", "our", "analyses", "yield", "directly", "a", "non-vanishing", "m(\u03a6\u03b2,", "k),", "we", "believe", "that", "It", "will", "also", "contribute", "to", "mph(\u03a6\u03b2I", "in", "the", "analytically", "c\\ontin\"used", "l'eau-time", "propagator", "as", "well.", "Notice", "the~tt", "in", "computing", "mphy,", "the", "scale", "k", "will", "be", "absorbed", "via", "a", "set", "of", "self-consistent", "equations."], "labels": ["MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "WRONG", "WRONG", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["ReductionofConttontenso"], "labels": ["WRONG"]}, "correct": {"tokens": ["Reduction", "of", "Cotton", "tensor"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED"]}, "predicted": {"google": {"tokens": ["Reduction", "of", "Cotton", "tenso"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "WRONG"]}, "BS-bid-OCR": {"tokens": ["Reduction", "of", "Contton", "tenso"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG"]}, "BS-bid-OCR+google": {"tokens": ["Reduction", "of", "Cotton", "tenso"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "WRONG"]}}}, {"corrupt": {"tokens": ["Thejetpectru\\mparametrizationfromthisstudyiscombinedwitafragment\\ationfuncionparamctriza'tiontopredicttheminimum-biasjetcotributiontohadronspcctra(spectrumhardcom1)onent).Quantitativecorrespondeucewithdatalendssupporttohejetproductionparametrizaion.Thesuccessoftilejet-productionmodelforp-pcollisionenergieslfelow1TeVandsystematicdevlationsfromthemo(lelathighsrbeamenergiessugestt\\hattheeikonalmodelasabasisforjetproduc|;ionMonteCalosisquestio,~ableatlowerenergiesbutmaybeapplicableforhigherjetandcollisionenergies."], "labels": ["WRONG"]}, "correct": {"tokens": ["The", "jet", "spectrum", "parametrization", "from", "this", "study", "is", "combined", "with", "a", "fragmentation", "function", "parametrization", "to", "predict", "the", "minimum-bias", "jet", "contribution", "to", "hadron", "spectra", "(spectrum", "hard", "component).", "Quantitative", "correspondence", "with", "data", "lends", "support", "to", "the", "jet", "production", "parametrization.", "The", "success", "of", "the", "jet-production", "model", "for", "p-p", "collision", "energies", "below", "1", "TeV", "and", "systematic", "deviations", "from", "the", "model", "at", "higher", "beam", "energies", "suggest", "that", "the", "eikonal", "model", "as", "a", "basis", "for", "jet", "production", "Monte", "Carlos", "is", "questionable", "at", "lower", "energies", "but", "may", "be", "applicable", "for", "higher", "jet", "and", "collision", "energies."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["Thejetpectru\\mparametrizationfromthisstudyiscombinedwitafragment\\ationfuncionparamctriza'tiontopredicttheminimum-biasjetcotributiontohadronspcctra(spectrumhardcom1)onent).Quantitativecorrespondeucewithdatalendssupporttohejetproductionparametrizaion.Thesuccessoftilejet-productionmodelforp-pcollisionenergieslfelow1TeVandsystematicdevlationsfromthemo(lelathighsrbeamenergiessugestt\\hattheeikonalmodelasabasisforjetproduc|;ionMonteCalosisquestio,~ableatlowerenergiesbutmaybeapplicableforhigherjetandcollisionenergies."], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["The", "jet", "pectru\\m", "parametrization", "from", "this", "study", "is", "combined", "wit", "a", "fragment\\ation", "funcion", "paramctriza'tion", "to", "predict", "the", "minimum-bias", "jet", "cotribution", "to", "hadron", "spcctra", "(spectrum", "hard", "com1)onent).", "Quantitative", "correspondeuce", "with", "data", "lends", "support", "to", "he", "jet", "production", "parametrizaion.", "The", "success", "of", "tile", "jet-production", "model", "for", "p-p", "collision", "energies", "lfelow", "1", "TeV", "and", "systematic", "devlations", "from", "the", "mo(lel", "at", "highsr", "beam", "energies", "sugest", "t\\hat", "the", "eikonal", "model", "as", "a", "basis", "for", "jet", "produc|;ion", "Monte", "Calos", "is", "questio,~able", "at", "lower", "energies", "but", "may", "be", "applicable", "for", "higher", "jet", "and", "collision", "energies."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["The", "jet", "pectru\\m", "parametrization", "from", "this", "study", "is", "combined", "with", "a", "fragment\\ation", "function", "parameterization", "to", "predict", "the", "minimum-bias", "jet", "contribution", "to", "hadron", "spectra", "(spectrum", "hard", "com1)onent).", "Quantitative", "correspondence", "with", "data", "lends", "support", "to", "the", "jet", "production", "parametrization.", "The", "success", "of", "tile", "jet-production", "model", "for", "p-p", "collision", "energies", "fellow", "1", "TeV", "and", "systematic", "deviations", "from", "the", "mo(lel", "at", "higher", "beam", "energies", "suggest", "t\\hat", "the", "eikonal", "model", "as", "a", "basis", "for", "jet", "product|;ion", "Monte", "Calos", "is", "questionable,~able", "at", "lower", "energies", "but", "may", "be", "applicable", "for", "higher", "jet", "and", "collision", "energies."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "WRONG", "MIXED", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["Gluon-Gluondoublescattel'ring"], "labels": ["WRONG"]}, "correct": {"tokens": ["Gluon-Gluon", "double", "scattering"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED"]}, "predicted": {"google": {"tokens": ["Gluon-Gluondoublescattel'ring"], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["Gluon-Gluon", "double", "scattel'ring"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG"]}, "BS-bid-OCR+google": {"tokens": ["Gluon-Gluon", "double", "scattering"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED"]}}}, {"corrupt": {"tokens": ["0<D<1,"], "labels": ["WRONG"]}, "correct": {"tokens": ["0", "<", "D", "<", "1,"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["0<D<1,"], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["0", "<", "D", "<", "1,"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["0", "<", "D", "<", "1,"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["Asabasiilsforamethodofparsingtranshormativela?n--goages,LR(1)parsingwouldmeemtobeideal:LR(1)languages?parsefromlefttoright,a.sisrequredfortransformativelanguages;LR(1)i>arsingrequiresnobacktracking;andLR(1)requiressingle-eharactePlookahead."], "labels": ["WRONG"]}, "correct": {"tokens": ["As", "a", "basis", "for", "a", "method", "of", "parsing", "transformative", "languages,", "LR(1)", "parsing", "would", "seem", "to", "be", "ideal:", "LR(1)", "languages", "parse", "from", "left", "to", "right,", "as", "is", "required", "for", "transformative", "languages;", "LR(1)", "parsing", "requires", "no", "backtracking;", "and", "LR(1)", "requires", "single-character", "lookahead."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["Asabasiilsforamethodofparsingtranshormativela?n--goages,LR(1)parsingwouldmeemtobeideal:LR(1)languages?parsefromlefttoright,a.sisrequredfortransformativelanguages;LR(1)i>arsing", "requires", "no", "backtracking;andLR(1)requires", "single-characteR", "lookahead."], "labels": ["WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR"]}, "BS-bid-OCR": {"tokens": ["As", "a", "basiils", "for", "a", "method", "of", "parsing", "transhormative", "la?n--goages,", "LR(1)", "parsing", "would", "meem", "to", "be", "ideal:", "LR(1)", "language", "s?parse", "from", "left", "to", "right,", "a.s", "is", "requred", "for", "transformative", "languages;", "LR(1)", "i>arsing", "requires", "no", "backtracking;", "and", "LR(1)", "requires", "single-eharacteP", "lookahead."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["As", "a", "basis", "for", "a", "method", "of", "parsing", "transformative", "la?n--goages,", "LR(1)", "parsing", "would", "seem", "to", "be", "ideal:", "LR(1)", "language", "s?parse", "from", "left", "to", "right,", "a.s", "is", "required", "for", "transformative", "languages;", "LR(1)", "i>arsing", "requires", "no", "backtracking;", "and", "LR(1)", "requires", "single-characteR", "lookahead."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["fromwhichtileformofW0cmtimmediatelybereadoff"], "labels": ["WRONG"]}, "correct": {"tokens": ["from", "which", "the", "form", "of", "W0", "can", "immediately", "be", "read", "off"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["fromwhichtileformofW0cmtimmediatelybereadoff"], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["from", "which", "tile", "form", "of", "W0", "cmt", "immediately", "be", "read", "off"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["from", "which", "tile", "form", "of", "W0", "cmt", "immediately", "be", "read", "off"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["Itissee;nfromFig.3thatoul:expectations,obtainedfromthevisualanalysisofSEMimages,arebasicallycorrect:ssam1)leS,5whichweresintcreddaringanidtermiatetime,containnarr?ow?gapstio,whichdonotdisppearcompletelyduringthefabricationpvocess.Tbesega\\psbecommoreandmorenarrowwhenmovisg~wayfromthefilmsurfacetowardsi,tsinteriorregions.Spacingsbetweengrainsinfilms,whichwereheat-treatedferalongtime,tendtodisappearandthe~shrink~ntogroovesonthefilmsurface,seeFig.4(b),wilichshowsuchagrooveseparatintworcgionsofthegrainwithdiffer\\entgrow|,ilorientations."], "labels": ["WRONG"]}, "correct": {"tokens": ["It", "is", "seen", "from", "Fig.", "3", "that", "our", "expectations,", "obtained", "from", "the", "visual", "analysis", "of", "SEM", "images,", "are", "basically", "correct:", "samples,", "which", "were", "sintered", "during", "an", "intermediate", "time,", "contain", "narrow", "gaps,", "which", "do", "not", "disappear", "completely", "during", "the", "fabrication", "process.", "These", "gaps", "become", "more", "and", "more", "narrow", "when", "moving", "away", "from", "the", "film", "surface", "towards", "its", "interior", "regions.", "Spacings", "between", "grains", "in", "films,", "which", "were", "heat-treated", "for", "a", "long", "time,", "tend", "to", "disappear", "and", "they", "shrink", "into", "grooves", "on", "the", "film", "surface,", "see", "Fig.", "4(b),", "which", "shows", "such", "a", "groove", "separating", "two", "regions", "of", "the", "grain", "with", "different", "growth", "orientations."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["Itissee;nfromFig.3thatoul:expectations,obtained", "from", "visualanalysisofSEMimages,arebasicallycorrect:ssam1)leS,5whichweresintcreddaringanidtermiatetime,containnarr?ow?gapstio,whichdonotdisppearcompletelyduringthefabricationpvocess.Tbesega\\psbecommoreandmorenarrowwhenmovisg~wayfromthefilmsurfacetowardsi,tsinteriorregions.Spacingsbetweengrainsinfilms,whichwereheat-treatedferalongtime,tendtodisappearandthe~shrink~ntogroovesonthefilmsurface,seeFig.4(b),wilichshowsuchagrooveseparatintworcgionsofthegrainwithdiffer\\entgrow|,ilorientations."], "labels": ["WRONG", "TOKENIZATION_ERROR", "WRONG"]}, "BS-bid-OCR": {"tokens": ["It", "is", "see;n", "from", "Fig.", "3", "that", "oul:", "expectations,", "obtained", "from", "the", "visual", "analysis", "of", "SEM", "images,", "are", "basically", "correct:s", "sam1)leS,5", "which", "were", "sintcred", "daring", "an", "idtermiate", "time,", "contain", "narr?ow", "?gapstio,", "which", "do", "not", "disppear", "completely", "during", "the", "fabrication", "pvocess.", "Tbese", "ga\\ps", "becom", "more", "and", "more", "narrow", "when", "movisg", "~way", "from", "the", "film", "surface", "towards", "i,ts", "interior", "regions.", "Spacings", "between", "grains", "in", "films,", "which", "were", "heat-treated", "fer", "a", "long", "time,", "tend", "to", "disappear", "and", "the~", "shrink", "~nto", "grooves", "on", "the", "film", "surface,", "see", "Fig.", "4(b),", "wilich", "show", "such", "a", "groove", "separatin", "two", "rcgions", "of", "the", "grain", "with", "differ\\ent", "grow|,il", "orientations."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["It", "is", "see;n", "from", "Fig.", "3", "that", "oil:", "expectations,", "obtained", "from", "the", "visual", "analysis", "of", "SEM", "images,", "are", "basically", "correct:s", "sam1)leS,5", "which", "were", "sintered", "dating", "an", "intermediate", "time,", "contain", "narrow", "?gaps", "tio,", "which", "do", "not", "disappear", "completely", "during", "the", "fabrication", "process.", "These", "ga\\ps", "become", "more", "and", "more", "narrow", "when", "moving", "~away", "from", "the", "film", "surface", "towards", "its", "interior", "regions.", "Spacings", "between", "grains", "in", "films,", "which", "were", "heat-treated", "fer", "a", "long", "time,", "tend", "to", "disappear", "and", "the~", "shrink", "~into", "grooves", "on", "the", "film", "surface,", "see", "Fig.", "4(b),", "wilich", "show", "such", "a", "groove", "separating", "two", "regions", "of", "the", "grain", "with", "differ\\ent", "grow|,il", "orientations."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "WRONG", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "WRONG", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["Acknowledgements"], "labels": ["NONE"]}, "correct": {"tokens": ["Acknowledgements"], "labels": ["NONE"]}, "predicted": {"google": {"tokens": ["Acknowledgements"], "labels": ["NONE"]}, "BS-bid-OCR": {"tokens": ["Acknowledgements"], "labels": ["NONE"]}, "BS-bid-OCR+google": {"tokens": ["Acknowledgements"], "labels": ["NONE"]}}}, {"corrupt": {"tokens": ["Axisymlnetricansatz"], "labels": ["WRONG"]}, "correct": {"tokens": ["Axisymmetric", "ansatz"], "labels": ["MIXED", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["Axisymlnetricansatz"], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["Axisymlnetric", "ansatz"], "labels": ["WRONG", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["Axisymmetric", "ansatz"], "labels": ["MIXED", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["Octoberp000"], "labels": ["WRONG"]}, "correct": {"tokens": ["October", "2000"], "labels": ["TOKENIZATION_ERROR", "MIXED"]}, "predicted": {"google": {"tokens": ["Octoberp000"], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["October", "p000"], "labels": ["TOKENIZATION_ERROR", "WRONG"]}, "BS-bid-OCR+google": {"tokens": ["October", "p000"], "labels": ["TOKENIZATION_ERROR", "WRONG"]}}}, {"corrupt": {"tokens": ["Notatio"], "labels": ["WRONG"]}, "correct": {"tokens": ["Notation"], "labels": ["OCR_ERROR"]}, "predicted": {"google": {"tokens": ["Notatio"], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["Notatio"], "labels": ["WRONG"]}, "BS-bid-OCR+google": {"tokens": ["Notatio"], "labels": ["WRONG"]}}}, {"corrupt": {"tokens": ["Inthacase:"], "labels": ["WRONG"]}, "correct": {"tokens": ["In", "that", "case:"], "labels": ["TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["Inthacase:"], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["In", "tha", "case:"], "labels": ["TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["In", "the", "case:"], "labels": ["TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["Neconsiderthe?functionalin?tegralapproachtothe?ang-Millsgaugefieldtheorywiththeaction"], "labels": ["WRONG"]}, "correct": {"tokens": ["We", "consider", "the", "functional", "integral", "approach", "to", "the", "Yang-Mills", "gauge", "field", "theory", "with", "the", "action"], "labels": ["MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["Consider", "The", "Functional", "integral", "approach", "the?ang-Millsgaugefieldtheorywiththeaction"], "labels": ["WRONG", "WRONG", "WRONG", "MIXED", "TOKENIZATION_ERROR", "WRONG"]}, "BS-bid-OCR": {"tokens": ["Ne", "consider", "the?", "functional", "in?tegral", "approach", "to", "the", "?ang-Mills", "gauge", "field", "theory", "with", "the", "action"], "labels": ["WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["Ne", "consider", "the?", "functional", "integral", "approach", "to", "the", "?yang-Mills", "gauge", "field", "theory", "with", "the", "action"], "labels": ["WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["NowweconsiderthebasicgraphstructureoftheLoopvertexexpausion,whichwecallthedirectgraphsortheLVEintilealirectrepresentation."], "labels": ["WRONG"]}, "correct": {"tokens": ["Now", "we", "consider", "the", "basic", "graph", "structure", "of", "the", "Loop", "vertex", "expansion,", "which", "we", "call", "the", "direct", "graphs", "or", "the", "LVE", "in", "the", "direct", "representation."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["NowweconsiderthebasicgraphstructureoftheLoopvertexexpausion,whichwecallthedirectgraphsortheLVEintilealirectrepresentation."], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["Now", "we", "consider", "the", "basic", "graph", "structure", "of", "the", "Loop", "vertex", "expausion,", "which", "we", "call", "the", "direct", "graphs", "or", "the", "LVE", "in", "tile", "alirect", "representation."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["Now", "we", "consider", "the", "basic", "graph", "structure", "of", "the", "Loop", "vertex", "expansion,", "which", "we", "call", "the", "direct", "graphs", "or", "the", "LOVE", "in", "tile", "direct", "representation."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "MIXED", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["(i)Mostclustersreachmasssegregal;iononlltimescalesof10Myr(10ocrossingtimes),andmaintaitilelevelofmasssegregationforthcdurationofcthcimulation."], "labels": ["WRONG"]}, "correct": {"tokens": ["(i)", "Most", "clusters", "reach", "mass", "segregation", "on", "timescales", "of", "10", "Myr", "(100", "crossing", "times),", "and", "maintain", "the", "level", "of", "mass", "segregation", "for", "the", "duration", "of", "the", "simulation."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED"]}, "predicted": {"google": {"tokens": ["(i)Mostclustersreachmasssegregal;iononlltimescalesof10Myr(10ocrossingtimes),andmaintaitilelevelofmasssegregationforthcdurationofcthcimulation."], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["(i)", "Most", "clusters", "reach", "mass", "segregal;ion", "on", "ll", "timescales", "of", "10", "Myr", "(10o", "crossing", "times),", "and", "maintai", "tile", "level", "of", "mass", "segregation", "for", "thc", "duration", "ofc", "thc", "imulation."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "WRONG", "WRONG"]}, "BS-bid-OCR+google": {"tokens": ["(i)", "Most", "clusters", "reach", "mass", "segregal;ion", "on", "all", "timescales", "of", "10", "Myr", "(10o", "crossing", "times),", "and", "maintain", "tile", "level", "of", "mass", "segregation", "for", "the", "duration", "of", "thc", "simulation."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "MIXED"]}}}, {"corrupt": {"tokens": ["Low-encrgyfixedpointsofrnteandomHeisenbergmodels"], "labels": ["WRONG"]}, "correct": {"tokens": ["Low-energy", "fixed", "points", "of", "random", "Heisenberg", "models"], "labels": ["MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["Low-encrgyfixedpointsofrnteandomHeisenbergmodels"], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["Low-encrgy", "fixed", "points", "of", "rnteandom", "Heisenberg", "models"], "labels": ["WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["Low-energy", "fixed", "points", "of", "random", "Heisenberg", "models"], "labels": ["MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["\u03c8(t)=\u03bd\u00b7Mgas(t),"], "labels": ["WRONG"]}, "correct": {"tokens": ["\u03c8(t)", "=", "\u03bd", "\u00b7", "Mgas(t)", ","], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["\u03c8(t)=\u03bd\u00b7Mgas(t),"], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["\u03c8(t)", "=", "\u03bd", "\u00b7", "Mgas(t),"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG"]}, "BS-bid-OCR+google": {"tokens": ["\u03c8(t)", "=", "\u03bd", "\u00b7", "Mgas(t),"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG"]}}}, {"corrupt": {"tokens": ["whLereour\\concentionsfor\\the\u0393-lmatricesare"], "labels": ["WRONG"]}, "correct": {"tokens": ["where", "our", "conventions", "for", "the", "\u0393-matrices", "are"], "labels": ["MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["where", "our\\concentionsfor\\the\u0393-lmatricesare"], "labels": ["MIXED", "WRONG"]}, "BS-bid-OCR": {"tokens": ["whLere", "our", "\\concentions", "for\\", "the", "\u0393-lmatrices", "are"], "labels": ["WRONG", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["where", "our", "\\conventions", "for\\", "the", "\u0393-matrices", "are"], "labels": ["MIXED", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["Thus,iftheevent-generatormoclelcanbc'usedtocalculatethepro(luctionrateofloosely-boundhadronicmoleCule,?il,shouldbeapplicabletotheX(3872)."], "labels": ["WRONG"]}, "correct": {"tokens": ["Thus,", "if", "the", "event-generator", "model", "can", "be", "used", "to", "calculate", "the", "production", "rate", "of", "loosely-bound", "hadronic", "molecules,", "it", "should", "be", "applicable", "to", "the", "X(3872)."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["Thus,iftheevent-generatormoclelcanbc'usedtocalculatethepro(luction", "rate", "of", "loosely-boundhadronicmoleCule,?i,shouldbeapplicabletotheX(3872)."], "labels": ["WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG"]}, "BS-bid-OCR": {"tokens": ["Thus,", "if", "the", "event-generator", "moclel", "can", "bc'", "used", "to", "calculate", "the", "pro(luction", "rate", "of", "loosely-bound", "hadronic", "moleCule,", "?il,", "should", "be", "applicable", "to", "the", "X(3872)."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["Thus,", "if", "the", "event-generator", "model", "can", "be", "used", "to", "calculate", "the", "pro(luction", "rate", "of", "loosely-bound", "hadronic", "molecules,", "?il,", "should", "be", "applicable", "to", "the", "X(3872)."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["isaprettyexample."], "labels": ["WRONG"]}, "correct": {"tokens": ["is", "a", "pretty", "example."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["is", "a", "pretty", "example."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR": {"tokens": ["is", "a", "pretty", "example."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["is", "a", "pretty", "example."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["Acknowledgments"], "labels": ["NONE"]}, "correct": {"tokens": ["Acknowledgments"], "labels": ["NONE"]}, "predicted": {"google": {"tokens": ["Acknowledgments"], "labels": ["NONE"]}, "BS-bid-OCR": {"tokens": ["Acknowledgments"], "labels": ["NONE"]}, "BS-bid-OCR+google": {"tokens": ["Acknowledgments"], "labels": ["NONE"]}}}, {"corrupt": {"tokens": ["Introduction"], "labels": ["NONE"]}, "correct": {"tokens": ["Introduction"], "labels": ["NONE"]}, "predicted": {"google": {"tokens": ["Introduction"], "labels": ["NONE"]}, "BS-bid-OCR": {"tokens": ["Introduction"], "labels": ["NONE"]}, "BS-bid-OCR+google": {"tokens": ["Introduction"], "labels": ["NONE"]}}}, {"corrupt": {"tokens": ["DeltaandSigmaBasis"], "labels": ["WRONG"]}, "correct": {"tokens": ["Delta", "and", "Sigma", "Basis"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["DeltaandSigmaBasis"], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["Delta", "and", "Sigma", "Basis"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["Delta", "and", "Sigma", "Basis"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["TosolveEq.(4),aneffectivewavefunctionisintr()oducedforthestrlngbysummingoverthepaths,whichleadtohesamepoint:"], "labels": ["WRONG"]}, "correct": {"tokens": ["To", "solve", "Eq.", "(4),", "an", "effective", "wave", "function", "is", "introduced", "for", "the", "string", "by", "summing", "over", "the", "paths,", "which", "lead", "to", "the", "same", "point:"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["TosolveEq.(4),aneffectivewavefunctionisintr()oducedforthestrlngbysummingoverthepaths,whichleadtohesamepoint:"], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["To", "solve", "Eq.", "(4),", "an", "effective", "wave", "function", "is", "intr()oduced", "for", "the", "strlng", "by", "summing", "over", "the", "paths,", "which", "lead", "to", "he", "same", "point:"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["To", "solve", "Eq.", "(4),", "an", "effective", "wave", "function", "is", "intr()oduced", "for", "the", "string", "by", "summing", "over", "the", "paths,", "which", "lead", "to", "the", "same", "point:"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["wherethesumisovertheoscillatoFfrequencies"], "labels": ["WRONG"]}, "correct": {"tokens": ["where", "the", "sum", "is", "over", "the", "oscillator", "frequencies"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["wherethesumisovertheoscillatoFfrequencies"], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["where", "the", "sum", "is", "over", "the", "oscillatoF", "frequencies"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["where", "the", "sum", "is", "over", "the", "oscillatoR", "frequencies"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["and"], "labels": ["NONE"]}, "correct": {"tokens": ["and"], "labels": ["NONE"]}, "predicted": {"google": {"tokens": ["and"], "labels": ["NONE"]}, "BS-bid-OCR": {"tokens": ["and"], "labels": ["NONE"]}, "BS-bid-OCR+google": {"tokens": ["and"], "labels": ["NONE"]}}}, {"corrupt": {"tokens": ["ModelingPro(:edurc"], "labels": ["WRONG"]}, "correct": {"tokens": ["Modeling", "Procedure"], "labels": ["TOKENIZATION_ERROR", "MIXED"]}, "predicted": {"google": {"tokens": ["ModelingPro(:edurc"], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["Modeling", "Pro(:edurc"], "labels": ["TOKENIZATION_ERROR", "WRONG"]}, "BS-bid-OCR+google": {"tokens": ["Modeling", "Pro(:edurc"], "labels": ["TOKENIZATION_ERROR", "WRONG"]}}}, {"corrupt": {"tokens": ["WeneedalsothecoherentprojectorsusedbyRawnsley?"], "labels": ["WRONG"]}, "correct": {"tokens": ["We", "need", "also", "the", "coherent", "projectors", "used", "by", "Rawnsley"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["WeneedalsothecoherentprojectorsusedbyRawnsley?"], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["We", "need", "also", "the", "coherent", "projectors", "used", "by", "Rawnsley?"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG"]}, "BS-bid-OCR+google": {"tokens": ["Do", "we", "need", "the", "coherent", "projectors", "used", "by", "Rawnsley?"], "labels": ["WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG"]}}}, {"corrupt": {"tokens": ["Conclusions"], "labels": ["NONE"]}, "correct": {"tokens": ["Conclusions"], "labels": ["NONE"]}, "predicted": {"google": {"tokens": ["Conclusions"], "labels": ["NONE"]}, "BS-bid-OCR": {"tokens": ["Conclusions"], "labels": ["NONE"]}, "BS-bid-OCR+google": {"tokens": ["Conclusions"], "labels": ["NONE"]}}}, {"corrupt": {"tokens": ["whichshowsthatthelimildoesnotdependonx.Thisftisimsthepresoof."], "labels": ["WRONG"]}, "correct": {"tokens": ["which", "shows", "that", "the", "limit", "does", "not", "depend", "on", "x.", "This", "finishes", "the", "proof."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED"]}, "predicted": {"google": {"tokens": ["whichshowsthatthelimildoesnotdependonx.Thisftisimsthepresoof."], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["which", "shows", "that", "the", "limil", "does", "not", "depend", "on", "x.", "This", "ftisims", "the", "presoof."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG"]}, "BS-bid-OCR+google": {"tokens": ["which", "shows", "that", "the", "limit", "does", "not", "depend", "on", "x.", "This", "fits", "the", "proof."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "MIXED"]}}}, {"corrupt": {"tokens": ["ThefinalstateofapparatusAisthepartlaltraceov(:rS:"], "labels": ["WRONG"]}, "correct": {"tokens": ["The", "final", "state", "of", "apparatus", "A", "is", "the", "partial", "trace", "over", "S:"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["ThefinalstateofapparatusAisthepartlaltraceov(:rS:"], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["The", "final", "state", "of", "apparatus", "A", "is", "the", "partlal", "trace", "ov(:r", "S:"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["The", "final", "state", "of", "apparatus", "A", "is", "the", "partial", "trace", "ov(:r", "S:"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["Togetherwiththeensuingcurvatures"], "labels": ["WRONG"]}, "correct": {"tokens": ["Together", "with", "the", "ensuing", "curvatures"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["Together", "With", "The", "Ensuing", "Curvatures"], "labels": ["TOKENIZATION_ERROR", "WRONG", "WRONG", "WRONG", "WRONG"]}, "BS-bid-OCR": {"tokens": ["Together", "with", "the", "ensuing", "curvatures"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["Together", "with", "the", "ensuing", "curvatures"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["wherewehavest:tud=|zd|2andug=|zg|2.Thesolutioncanbeobtainodbymakingsomererrangemantfollowedbyanintegration.Ind(;\\e(l,bycilangingvariabfesaa"], "labels": ["WRONG"]}, "correct": {"tokens": ["where", "we", "have", "set", "ud", "=", "|", "zd", "|", "2", "and", "ug", "=", "|", "zg", "|", "2.", "The", "solution", "can", "be", "obtained", "by", "making", "some", "rearrangement", "followed", "by", "an", "integration.", "Indeed,", "by", "changing", "variables", "as"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "MIXED", "MIXED"]}, "predicted": {"google": {"tokens": ["wherewehavest:tud=|zd|2andug=|zg|2.Thesolutioncanbeobtainodbymakingsomererrangemantfollowedbyanintegration.Ind(;\\e(l,bycilangingvariabfesaa"], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["where", "we", "have", "st:tud", "=|zd", "|", "2", "and", "ug", "=", "|", "zg", "|", "2.", "The", "solution", "can", "be", "obtainod", "by", "making", "some", "rerrangemant", "followed", "by", "an", "integration.", "Ind(;\\e(l,", "by", "cilanging", "variabfes", "aa"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "WRONG", "WRONG"]}, "BS-bid-OCR+google": {"tokens": ["where", "we", "have", "st:tud", "=|zd", "|", "2", "and", "ug", "=", "|", "zg", "|", "2.", "The", "solution", "can", "be", "obtained", "by", "making", "some", "rearrangement", "followed", "by", "an", "integration.", "Ind(;\\e(l,", "by", "changing", "variables", "aa"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "MIXED", "MIXED", "WRONG"]}}}, {"corrupt": {"tokens": ["isthescreenedelectron-ele?ctronnteractiont)otentinl.ItsretaIrdedcontponentisgivenby"], "labels": ["WRONG"]}, "correct": {"tokens": ["is", "the", "screened", "electron-electron", "interaction", "potential.", "Its", "retarded", "component", "is", "given", "by"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "MIXED", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["isthescreenedelectron-ele?ctronnteractiont)otentinl.ItsretaIrdedcontponentisgivenby"], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["is", "the", "screened", "electron-ele?ctron", "nteraction", "t)otentinl.", "Its", "retaIrded", "contponent", "is", "given", "by"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "WRONG", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["is", "the", "screened", "electron-electron", "interaction", "t)potential.", "It's", "retaIrded", "continent", "is", "given", "by"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "WRONG", "WRONG", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["Aparicularformforthefunctiony(\u03c6)mooivatedbyparticlephysicsconsideratnionscouldnowbechosenandanestimatef,ortheencrgyscaleattheendofinflal;iondeduced.However,giventheenhancedaccuracyofreccntCMBmeasuements,iisofmoreinteresttocansiderwhatobservationsmayrevealabouttheunderlyingInflati()n)ary\\model.Wethereforeexpl0rethispossibilityinthefollowirgSection."], "labels": ["WRONG"]}, "correct": {"tokens": ["A", "particular", "form", "for", "the", "function", "y(\u03c6)", "motivated", "by", "particle", "physics", "considerations", "could", "now", "be", "chosen", "and", "an", "estimate", "for", "the", "energy", "scale", "at", "the", "end", "of", "inflation", "deduced.", "However,", "given", "the", "enhanced", "accuracy", "of", "recent", "CMB", "measurements,", "it", "is", "of", "more", "interest", "to", "consider", "what", "observations", "may", "reveal", "about", "the", "underlying", "inflationary", "model.", "We", "therefore", "explore", "this", "possibility", "in", "the", "following", "Section."], "labels": ["TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["Aparicularformforthefunctiony(\u03c6)mooivatedbyparticlephysicsconsideratnionscouldnowbechosenandanestimatef,ortheencrgyscaleattheendofinflal;iondeduced.However,giventheenhancedaccuracyofreccntCMBmeasuements,iisofmoreinteresttocansiderwhatobservationsmayrevealabouttheunderlyingInflati()n)ary\\model.Wethereforeexpl0rethispossibilityinthefollowirgSection."], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["A", "paricular", "form", "for", "the", "function", "y(\u03c6)", "mooivated", "by", "particle", "physics", "consideratnions", "could", "now", "be", "chosen", "and", "an", "estimate", "f,or", "the", "encrgy", "scale", "at", "the", "end", "of", "inflal;ion", "deduced.", "However,", "given", "the", "enhanced", "accuracy", "of", "reccnt", "CMB", "measuements,", "i", "is", "of", "more", "interest", "to", "cansider", "what", "observations", "may", "reveal", "about", "the", "underlying", "Inflati()n)ary", "\\model.", "We", "therefore", "expl0re", "this", "possibility", "in", "the", "followirg", "Section."], "labels": ["TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["A", "particular", "form", "for", "the", "function", "y(\u03c6)", "motivated", "by", "particle", "physics", "considerations", "could", "now", "be", "chosen", "and", "an", "estimate", "f,or", "the", "energy", "scale", "at", "the", "end", "of", "inflal;ion", "deduced.", "However,", "given", "the", "enhanced", "accuracy", "of", "recent", "CMB", "measurements,", "it", "is", "of", "more", "interest", "to", "consider", "what", "observations", "may", "reveal", "about", "the", "underlying", "Inflation()n)ary", "\\model.", "We", "therefore", "explore", "this", "possibility", "in", "the", "following", "Section."], "labels": ["TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["Two-ParticleBoundStatesintheContinuumreali7zsdintheone-dimensionalHubbardodelwithanImpurity"], "labels": ["WRONG"]}, "correct": {"tokens": ["Two-Particle", "Bound", "States", "in", "the", "Continuum", "realized", "in", "the", "one-dimensional", "Hubbard", "Model", "with", "an", "Impurity"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["Two-ParticleBoundStatesintheContinuumreali7zsdintheone-dimensionalHubbardodelwithanImpurity"], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["Two-Particle", "Bound", "States", "in", "the", "Continuum", "reali7zsd", "in", "the", "one-dimensional", "Hubbard", "odel", "with", "an", "Impurity"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["Two-Particle", "Bound", "States", "in", "the", "Continuum", "realized", "in", "the", "one-dimensional", "Hubbard", "model", "with", "an", "Impurity"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["ComputingresourcesthroaghHPCEha,IITe\\MadrasaudAnriapurna,IMScaregratefullyacknowledged.RAthankstheIndo-U?SScienceandTochnologyFo~undationfora\\['ellowshil>.TheauthorsthankM.E.Cates,P.Chaikin,S.Ghose,A.Laskav,T.E.Mallouk,H.Masud,D.Pine,M.ShelleyandR.Singhforhelpfuldscussions,S.GhoseforhelpwithfiguresandR.Mannaforsharingsimmationdatonfilamentpairs."], "labels": ["WRONG"]}, "correct": {"tokens": ["Computing", "resources", "through", "HPCE,", "IIT", "Madras", "and", "Annapurna,", "IMSc", "are", "gratefully", "acknowledged.", "RA", "thanks", "the", "Indo-US", "Science", "and", "Technology", "Foundation", "for", "a", "fellowship.", "The", "authors", "thank", "M.", "E.", "Cates,", "P.", "Chaikin,", "S.", "Ghose,", "A.", "Laskar,", "T.", "E.", "Mallouk,", "H.", "Masoud,", "D.", "Pine,", "M.", "Shelley", "and", "R.", "Singh", "for", "helpful", "discussions,", "S.", "Ghose", "for", "help", "with", "figures", "and", "R.", "Manna", "for", "sharing", "simulation", "data", "on", "filament", "pairs."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["ComputingresourcesthroaghHPCEha,IITe\\MadrasaudAnriapurna,IMScared", "gratefully", "acknowledged.RAthankstheIndo-U?SScienceandTochnologyFo~undationfora\\['ellowshil>.TheauthorsthankM.E.Cates,P.Chaikin,S.Ghose,A.Laskav,T.E.Mallouk,H.Masud,D.Pine,M.ShelleyandR.Singhforhelpfuldscussions,S.GhoseforhelpwithfiguresandR.Mannaforsharingsimmationdatonfilamentpairs."], "labels": ["WRONG", "TOKENIZATION_ERROR", "WRONG"]}, "BS-bid-OCR": {"tokens": ["Computing", "resources", "throagh", "HPC", "Eha,", "IITe\\", "Madras", "aud", "Anriapurna,", "IMSc", "are", "gratefully", "acknowledged.", "RA", "thanks", "the", "Indo-U?S", "Science", "and", "Tochnology", "Fo~undation", "for", "a", "\\['ellowshil>.", "The", "authors", "thank", "M.E.", "Cates,", "P.", "Chaikin,", "S.", "Ghose,", "A.", "Laskav,", "T.E.", "Mallouk,", "H.", "Masud,", "D.", "Pine,", "M.", "Shelley", "and", "R.", "Singh", "for", "helpful", "dscussions,", "S.", "Ghose", "for", "help", "with", "figures", "and", "R.", "Manna", "for", "sharing", "simmation", "daton", "filament", "pairs."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "WRONG", "WRONG", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["Computing", "resources", "through", "HPC", "Eha,", "IITe\\", "Madras", "aud", "Annapurna,", "IMSc", "are", "gratefully", "acknowledged.", "RA", "thanks", "the", "Indo-US", "Science", "and", "Technology", "Fo~undation", "for", "a", "\\['ellowshil>.", "The", "authors", "thank", "M.E.", "Cates,", "P.", "Chaikin,", "S.", "Ghose,", "A.", "Laskav,", "T.E.", "Mallouk,", "H.", "Masud,", "D.", "Pine,", "M.", "Shelley", "and", "R.", "Singh", "for", "helpful", "discussions,", "S.", "Ghose", "for", "help", "with", "figures", "and", "R.", "Manna", "for", "sharing", "summation", "dayton", "filament", "pairs."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "WRONG", "WRONG", "WRONG", "TOKENIZATION_ERROR", "WRONG", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["Eul'opeanoptions"], "labels": ["WRONG"]}, "correct": {"tokens": ["European", "options"], "labels": ["MIXED", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["European", "Options"], "labels": ["MIXED", "WRONG"]}, "BS-bid-OCR": {"tokens": ["Eul'opean", "options"], "labels": ["WRONG", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["European", "options"], "labels": ["MIXED", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["E-mails:"], "labels": ["NONE"]}, "correct": {"tokens": ["E-mails:"], "labels": ["NONE"]}, "predicted": {"google": {"tokens": ["E-mails:"], "labels": ["NONE"]}, "BS-bid-OCR": {"tokens": ["E-mails:"], "labels": ["NONE"]}, "BS-bid-OCR+google": {"tokens": ["E-mails:"], "labels": ["NONE"]}}}, {"corrupt": {"tokens": ["whihisobtai\\nedviathesnakelemmaapplIedonthediagram"], "labels": ["WRONG"]}, "correct": {"tokens": ["which", "is", "obtained", "via", "the", "snake", "lemma", "applied", "on", "the", "diagram"], "labels": ["MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["whihisobtai\\nedviathesnakelemmaapplIedonthediagram"], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["whih", "is", "obtai\\ned", "via", "the", "snake", "lemma", "applIed", "on", "the", "diagram"], "labels": ["WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["which", "is", "obtai\\ned", "via", "the", "snake", "lemma", "applIed", "on", "the", "diagram"], "labels": ["MIXED", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["SupposeGisaspanningsubgrphofKn?.It\\isnothardl;oseethatGisan(X)-t)jrtialHamiltoncycleofKnifandonlyif"], "labels": ["WRONG"]}, "correct": {"tokens": ["Suppose", "G", "is", "a", "spanning", "subgraph", "of", "Kn.", "It", "is", "not", "hard", "to", "see", "that", "G", "is", "an", "(X)-partial", "Hamilton", "cycle", "of", "Kn", "if", "and", "only", "if"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["SupposeGisaspanningsubgrphofKn?.It\\isnothardl;oseethatGisan(X)-t)jrtialHamiltoncycleofKnifandonlyif"], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["Suppose", "G", "is", "a", "spanning", "subgrph", "of", "Kn?.", "It", "\\is", "not", "hard", "l;o", "see", "that", "G", "is", "an", "(X)-t)jrtial", "Hamilton", "cycle", "of", "Kn", "if", "and", "only", "if"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["Suppose", "G", "is", "a", "spanning", "subgraph", "of", "Kn?.", "It", "\\is", "not", "hard", "l;o", "see", "that", "G", "is", "an", "(X)-t)jrtial", "Hamilton", "cycle", "of", "Kn", "if", "and", "only", "if"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["and"], "labels": ["NONE"]}, "correct": {"tokens": ["and"], "labels": ["NONE"]}, "predicted": {"google": {"tokens": ["and"], "labels": ["NONE"]}, "BS-bid-OCR": {"tokens": ["and"], "labels": ["NONE"]}, "BS-bid-OCR+google": {"tokens": ["and"], "labels": ["NONE"]}}}, {"corrupt": {"tokens": ["Thenextsteptoourapproachisl.oexamineeachnodeintermsofitsposibilitytobcreached.Infeasiblesituationscouldbehat)penedastheboundingboxesofobjectsinthescenemaynotbeal)letop\\erfeCtlyfitthesestructuresandtheyoftenhaveirregularnon-convexshapes.Inaddition,itispossiblesomeobdtaclesands\\tablestructuressch?asmounains,toeinsert0dbetweentheslingshotandthetiLrget.Therefore,anexaminationstepisrequiredateach.nod.esoastoenstlrethatthe\\corresi)onSingtrajectoriscanrachthetarget."], "labels": ["WRONG"]}, "correct": {"tokens": ["The", "next", "step", "to", "our", "approach", "is", "to", "examine", "each", "node", "in", "terms", "of", "its", "possibility", "to", "be", "reached.", "Infeasible", "situations", "could", "be", "happened", "as", "the", "bounding", "boxes", "of", "objects", "in", "the", "scene", "may", "not", "be", "able", "to", "perfectly", "fit", "these", "structures", "and", "they", "often", "have", "irregular", "non-convex", "shapes.", "In", "addition,", "it", "is", "possible", "some", "obstacles", "and", "stable", "structures", "such", "as", "mountains,", "to", "be", "inserted", "between", "the", "slingshot", "and", "the", "target.", "Therefore,", "an", "examination", "step", "is", "required", "at", "each", "node", "so", "as", "to", "ensure", "that", "the", "corresponding", "trajectories", "can", "reach", "the", "target."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["Thenextsteptoourapproachisl.oexamineeachnodeintermsofitsposibilitytobcreached.Infeasiblesituationscouldbehat)penedastheboundingboxesofobjectsinthescenemaynotbeal)letop\\erfeCtlyfitthesestructuresandtheyoftenhaveirregularnon-convexshapes.Inaddition,itispossiblesomeobdtaclesands\\tablestructuressch?asmounains,toeinsert0dbetweentheslingshotandthetiLrget.Therefore,anexaminationstepisrequiredateach.nod.esoastoenstlrethatthe\\corresi)onSingtrajectoriscanrachthetarget."], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["The", "next", "step", "to", "our", "approach", "is", "l.o", "examine", "each", "node", "in", "terms", "of", "its", "posibility", "to", "bc", "reached.", "Infeasible", "situations", "could", "be", "hat)pened", "as", "the", "bounding", "boxes", "of", "objects", "in", "the", "scene", "may", "not", "be", "al)le", "to", "p\\erfeCtly", "fit", "these", "structures", "and", "they", "often", "have", "irregular", "non-convex", "shapes.", "In", "addition,", "it", "is", "possible", "some", "obdtacles", "and", "s\\table", "structures", "sch?", "as", "mounains,", "toe", "insert0d", "between", "the", "slingshot", "and", "the", "tiLrget.", "Therefore,", "an", "examination", "step", "is", "required", "at", "each.", "nod.e", "so", "as", "to", "enstlre", "that", "the\\", "corresi)onSing", "trajectoris", "can", "rach", "the", "target."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "WRONG", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["The", "next", "step", "to", "our", "approach", "is", "l.o", "examine", "each", "node", "in", "terms", "of", "its", "possibility", "to", "be", "reached.", "Infeasible", "situations", "could", "be", "hat)pened", "as", "the", "bounding", "boxes", "of", "objects", "in", "the", "scene", "may", "not", "be", "al)le", "to", "p\\erfeCtly", "fit", "these", "structures", "and", "they", "often", "have", "irregular", "non-convex", "shapes.", "In", "addition,", "is", "it", "possible", "to", "have", "some", "obstacles", "and", "s\\table", "structures", "such", "as?", "as", "mountains,", "toe", "inserted", "between", "the", "slingshot", "and", "the", "target.", "Therefore,", "an", "examination", "step", "is", "required", "at", "each.", "node", "so", "as", "to", "ensure", "that", "the\\", "corresi)onSing", "trajectories", "can", "reach", "the", "target."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "MIXED", "WRONG", "TOKENIZATION_ERROR", "MIXED", "WRONG", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "WRONG", "WRONG", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["Finally,werecalltheIMBHmodelwhich?hasspectralsupportfromsomesources(Milleretal2004;l;helevelofabsorptioninNGC1275Itohighforanysoftexwesstobeobserved).l'h?ynLayformindensestarclus?ters."], "labels": ["WRONG"]}, "correct": {"tokens": ["Finally,", "we", "recall", "the", "IMBH", "model", "which", "has", "spectral", "support", "from", "some", "sources", "(Miller", "et", "al", "2004;", "the", "level", "of", "absorption", "in", "NGC", "1275", "is", "too", "high", "for", "any", "soft", "excess", "to", "be", "observed).", "They", "may", "form", "in", "dense", "star", "clusters."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED"]}, "predicted": {"google": {"tokens": ["Finally,werecalltheIMBHmodelwhich?has", "spectralsupportfromsomesources(Milleretal2004;l;helevelofabsorptioninNGC1275Itohighforanysoftexwesstobeobserved).l'h?ynLayformindensestarclus?ters."], "labels": ["WRONG", "WRONG"]}, "BS-bid-OCR": {"tokens": ["Finally,", "we", "recall", "the", "IMBH", "model", "which", "?has", "spectral", "support", "from", "some", "sources", "(Miller", "et", "al", "2004;", "l;he", "level", "of", "absorption", "in", "NGC", "1275I", "to", "high", "for", "any", "soft", "exwess", "to", "be", "observed).", "l'h?y", "nLay", "form", "in", "dense", "star", "clus?ters."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG"]}, "BS-bid-OCR+google": {"tokens": ["Finally,", "we", "recall", "the", "IMBH", "model", "which", "has", "spectral", "support", "from", "some", "sources", "(Miller", "et", "al", "2004;", "l;the", "level", "of", "absorption", "in", "NGC", "1275I", "too", "high", "for", "any", "soft", "excess", "to", "be", "observed).", "l'h?inLay", "form", "in", "dense", "star", "clusters."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED"]}}}, {"corrupt": {"tokens": ["InthesenotationsDiraeLagrangiantaukestheformsof"], "labels": ["WRONG"]}, "correct": {"tokens": ["In", "these", "notations", "Dirac", "Lagrangian", "takes", "the", "form", "of"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["InthesenotationsDiraeLagrangiantaukestheformsof"], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["In", "these", "notations", "Dirae", "Lagrangian", "taukes", "the", "forms", "of"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["In", "these", "notations", "Dirae", "Lagrangian", "takes", "the", "forms", "of"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["Ackn?wledgments"], "labels": ["WRONG"]}, "correct": {"tokens": ["Acknowledgments"], "labels": ["OCR_ERROR"]}, "predicted": {"google": {"tokens": ["Acknowledgments"], "labels": ["OCR_ERROR"]}, "BS-bid-OCR": {"tokens": ["Ackn?wledgments"], "labels": ["WRONG"]}, "BS-bid-OCR+google": {"tokens": ["Acknowledgments"], "labels": ["OCR_ERROR"]}}}, {"corrupt": {"tokens": ["Forthi'softsupersymmetrybreaAingmaspaametersw\\ekave"], "labels": ["WRONG"]}, "correct": {"tokens": ["For", "the", "soft", "supersymmetry", "breaking", "mass", "parameters", "we", "have"], "labels": ["TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "MIXED", "MIXED", "MIXED"]}, "predicted": {"google": {"tokens": ["Forthi'softsupersymmetrybreaAingmaspaametersw\\ekave"], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["For", "thi'", "soft", "supersymmetry", "breaAing", "mas", "paameters", "w\\e", "kave"], "labels": ["TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "WRONG", "WRONG", "WRONG"]}, "BS-bid-OCR+google": {"tokens": ["For", "the'", "soft", "supersymmetry", "breaKing", "mas", "parameters", "w\\e", "have"], "labels": ["TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "MIXED", "WRONG", "MIXED"]}}}, {"corrupt": {"tokens": ["Symmary"], "labels": ["WRONG"]}, "correct": {"tokens": ["Summary"], "labels": ["OCR_ERROR"]}, "predicted": {"google": {"tokens": ["Summary"], "labels": ["OCR_ERROR"]}, "BS-bid-OCR": {"tokens": ["Symmary"], "labels": ["WRONG"]}, "BS-bid-OCR+google": {"tokens": ["Summary"], "labels": ["OCR_ERROR"]}}}, {"corrupt": {"tokens": ["AnadvantageofthiSrepresentationisthatitexhibitsmanysymlnetriesofthesituationexplicitlu.Forexample,atrialityofthethreebackgroundohjectsisimmediatelyapparent.Thisba(:kgroundwillbeourmainexample."], "labels": ["WRONG"]}, "correct": {"tokens": ["An", "advantage", "of", "this", "representation", "is", "that", "it", "exhibits", "many", "symmetries", "of", "the", "situation", "explicitly.", "For", "example,", "a", "triality", "of", "the", "three", "background", "objects", "is", "immediately", "apparent.", "This", "background", "will", "be", "our", "main", "example."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["AnadvantageofthiSrepresentationisthatitexhibitsmanysymlnetriesofthesituationexplicitlu.Forexample,atrialityofthethreebackgroundohjectsisimmediatelyapparent.Thisba(:kgroundwillbeourmainexample."], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["An", "advantage", "of", "thiS", "representation", "is", "that", "it", "exhibits", "many", "symlnetries", "of", "the", "situation", "explicitlu.", "For", "example,", "a", "triality", "of", "the", "three", "background", "ohjects", "is", "immediately", "apparent.", "This", "ba(:kground", "will", "be", "our", "main", "example."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["An", "advantage", "of", "thiS", "representation", "is", "that", "it", "exhibits", "many", "symmetries", "of", "the", "situation", "explicitly.", "For", "example,", "a", "triality", "of", "the", "three", "background", "objects", "is", "immediately", "apparent.", "This", "ba(:kground", "will", "be", "our", "main", "example."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["Remarks"], "labels": ["NONE"]}, "correct": {"tokens": ["Remarks"], "labels": ["NONE"]}, "predicted": {"google": {"tokens": ["Remarks"], "labels": ["NONE"]}, "BS-bid-OCR": {"tokens": ["Remarks"], "labels": ["NONE"]}, "BS-bid-OCR+google": {"tokens": ["Remarks"], "labels": ["NONE"]}}}, {"corrupt": {"tokens": ["where"], "labels": ["NONE"]}, "correct": {"tokens": ["where"], "labels": ["NONE"]}, "predicted": {"google": {"tokens": ["where"], "labels": ["NONE"]}, "BS-bid-OCR": {"tokens": ["where"], "labels": ["NONE"]}, "BS-bid-OCR+google": {"tokens": ["where"], "labels": ["NONE"]}}}, {"corrupt": {"tokens": ["(x)WecomputetheaverageSEDforLLAGNsusingourmo(telfits.TheaverageSEDsarequitediferentfromt:quasaronesanddisplayaslightIRbump.HighspatialresolutionIRobserw~tionsarerequiredinorderbetterconstrain\\thephys|csofIRemissioninLLAGNs."], "labels": ["WRONG"]}, "correct": {"tokens": ["(x)", "We", "compute", "the", "average", "SED", "for", "LLAGNs", "using", "our", "model", "fits.", "The", "average", "SEDs", "are", "quite", "different", "from", "the", "quasar", "ones", "and", "display", "a", "slight", "IR", "bump.", "High", "spatial", "resolution", "IR", "observations", "are", "required", "in", "order", "better", "constrain", "the", "physics", "of", "IR", "emission", "in", "LLAGNs."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["(x)WecomputetheaverageSEDforLLAGNsusingourmo(telfits.TheaverageSEDsarequitediferentfromt:quasaronesanddisplayaslightIRbump.HighspatialresolutionIRobserw~tionsarerequiredinorderbetterconstrain\\thephys|csofIRemissioninLLAGNs."], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["(x)", "We", "compute", "the", "average", "SED", "for", "LLAGNs", "using", "our", "mo(tel", "fits.", "The", "average", "SEDs", "are", "quite", "diferent", "from", "t:", "quasar", "ones", "and", "display", "a", "slight", "IR", "bump.", "High", "spatial", "resolution", "IR", "obserw~tions", "are", "required", "in", "order", "better", "constrain", "\\the", "phys|cs", "of", "IR", "emission", "in", "LLAGNs."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["(x)", "We", "compute", "the", "average", "SED", "for", "LLAGNs", "using", "our", "mo(tel", "fits.", "The", "average", "SEDs", "are", "quite", "different", "from", "t:", "quasar", "ones", "and", "display", "a", "slight", "IR", "bump.", "High", "spatial", "resolution", "IR", "obserw~tions", "are", "required", "in", "order", "better", "constrain", "\\the", "phys|cs", "of", "IR", "emission", "in", "LLAGNs."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["averysmallnumberindeed."], "labels": ["WRONG"]}, "correct": {"tokens": ["a", "very", "small", "number", "indeed."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["a", "very", "small", "number", "indeed."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR": {"tokens": ["a", "very", "small", "number", "indeed."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["a", "very", "small", "number", "indeed."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["AsetofboxesBi."], "labels": ["WRONG"]}, "correct": {"tokens": ["A", "set", "of", "boxes", "Bi."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["AsetofboxesBi."], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["A", "set", "of", "boxes", "Bi."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["A", "set", "of", "boxes", "Bi."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["Step3:SuppogosewearecurrentlyaivertexAiandwe+havalreadypreparedthem-partitmaximsllyentangledstate,say"], "labels": ["WRONG"]}, "correct": {"tokens": ["Step", "3:", "Suppose", "we", "are", "currently", "at", "vertex", "Ai", "and", "we", "have", "already", "prepared", "the", "m-partite", "maximally", "entangled", "state,", "say"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["Step3:SuppogosewearecurrentlyaivertexAiandwe+havalreadypreparedthem-partitmaximsllyentangledstate,say"], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["Step", "3:", "Suppogose", "we", "are", "currently", "ai", "vertex", "Ai", "and", "we", "+hav", "already", "prepared", "the", "m-partit", "maximslly", "entangled", "state,", "say"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["Step", "3:", "Suppose", "we", "are", "currently", "ai", "vertex", "Ai", "and", "we", "+have", "already", "prepared", "the", "m-partit", "maximally", "entangled", "state,", "say"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["TheremainderofthispaperisorganizedasfollowsThesystemmodelisdescribedinSectionIT.IllSecti\\onIII,theproblemfor*mulationandsolutionisediscussed.InSe(:tionIV,thesimul\\aionreSultsareprese?ntedanda\\nalyzed.FinallythecomnclusionisdrawninSectionV."], "labels": ["WRONG"]}, "correct": {"tokens": ["The", "remainder", "of", "this", "paper", "is", "organized", "as", "follows.", "The", "system", "model", "is", "described", "in", "Section", "II.", "In", "Section", "III,", "the", "problem", "formulation", "and", "solution", "is", "discussed.", "In", "Section", "IV,", "the", "simulation", "results", "are", "presented", "and", "analyzed.", "Finally", "the", "conclusion", "is", "drawn", "in", "Section", "V."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["TheremainderofthispaperisorganizedasfollowsThesystemmodelisdescribedinSectionIT.IllSecti\\onIII,theproblemfor*mulationandsolutionisediscussed.InSe(:tionIV,thesimul\\aionreSultsareprese?ntedanda\\nalyzed.FinallythecomnclusionisdrawninSectionV."], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["The", "remainder", "of", "this", "paper", "is", "organized", "as", "follows", "The", "system", "model", "is", "described", "in", "Section", "IT.", "Ill", "Secti\\on", "III,", "the", "problem", "for*mulation", "and", "solution", "ise", "discussed.", "In", "Se(:tion", "IV,", "the", "simul\\aion", "reSults", "are", "prese?nted", "and", "a\\nalyzed.", "Finally", "the", "comnclusion", "is", "drawn", "in", "Section", "V."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "WRONG", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["The", "remainder", "of", "this", "paper", "is", "organized", "as", "follows", "The", "system", "model", "is", "described", "in", "Section", "IT.", "I'll", "Secti\\on", "III,", "the", "problem", "for*Mulation", "and", "solution", "ise", "discussed.", "In", "Se(:tion", "IV,", "the", "simul\\aion", "reSults", "are", "presented", "and", "a\\nalyzed.", "Finally", "the", "conclusion", "is", "drawn", "in", "Section", "V."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "WRONG", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["Arenewedintorestinultra-relativitic~hocksassitevs-ofilicientparticleaccelerationhasbeensparkedby;keyobservationsintwo?eas:"], "labels": ["WRONG"]}, "correct": {"tokens": ["A", "renewed", "interest", "in", "ultra-relativistic", "shocks", "as", "sites", "of", "efficient", "particle", "acceleration", "has", "been", "sparked", "by", "key", "observations", "in", "two", "areas:"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "MIXED", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED"]}, "predicted": {"google": {"tokens": ["Arenewedintorestinultra-relativitic~hocksassitevs-ofilicientparticleaccelerationhasbeensparkedby;keyobservationsintwo?eas:"], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["A", "renewed", "intorest", "in", "ultra-relativitic", "~hocks", "as", "site", "vs-ofilicient", "particle", "acceleration", "has", "been", "sparked", "by;", "key", "observations", "in", "two", "?eas:"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG"]}, "BS-bid-OCR+google": {"tokens": ["A", "renewed", "interest", "in", "ultra-relativistic", "~shocks", "as", "site", "vs-ofilicient", "particle", "acceleration", "has", "been", "sparked", "by;", "key", "observations", "in", "two", "?eas:"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "WRONG", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG"]}}}, {"corrupt": {"tokens": ["BecausethegoaloftiliworkwastodetoctfLSBsithedeepestbnd(R)anthentoinvestigatetheditribut\\]ooffLSBsinacolormagnitt~derelation,weonlyusmdtheRandBbands.Wewilluseotherhands(includingU\\])anddatathatweplantoacquire)tostudysps,ectrophotometricprl)ert~esoff.LSBsinafuturework."], "labels": ["WRONG"]}, "correct": {"tokens": ["Because", "the", "goal", "of", "this", "work", "was", "to", "detect", "fLSBs", "in", "the", "deepest", "band", "(R)", "and", "then", "to", "investigate", "the", "distribution", "of", "fLSBs", "in", "a", "color", "magnitude", "relation,", "we", "only", "used", "the", "R", "and", "B", "bands.", "We", "will", "use", "other", "bands", "(including", "U", "band", "data", "that", "we", "plan", "to", "acquire)", "to", "study", "spectrophotometric", "properties", "of", "fLSBs", "in", "a", "future", "work."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["BecausethegoaloftiliworkwastodetoctfLSBsithedeepestbnd(R)anthentoinvestigatetheditribut\\]ooffLSBsinacolormagnitt~derelation,weonlyusmdtheRandBbands.Wewilluseotherhands(includingU\\])anddatathatweplanto", "acquire)tostudysps,ectrophotometricprl)ert~esoff.LSBsinafuturework."], "labels": ["WRONG", "WRONG"]}, "BS-bid-OCR": {"tokens": ["Because", "the", "goal", "of", "tili", "work", "was", "to", "detoct", "fLSBs", "i", "the", "deepest", "bnd", "(R)", "an", "then", "to", "investigate", "the", "ditribut\\]o", "off", "LSBs", "in", "a", "color", "magnitt~de", "relation,", "we", "only", "usmd", "the", "R", "and", "B", "bands.", "We", "will", "use", "other", "hands", "(including", "U\\])", "and", "data", "that", "we", "plan", "to", "acquire)", "to", "study", "sps,ectrophotometric", "prl)ert~es", "of", "f.LSBs", "in", "a", "future", "work."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["Because", "the", "goal", "of", "tili", "work", "was", "to", "detect", "fLSBs", "in", "the", "deepest", "bnd", "(R)", "and", "then", "to", "investigate", "the", "distributor\\]o", "off", "LSBs", "in", "a", "color", "magnitt~de", "relation,", "we", "only", "usmd", "the", "R", "and", "B", "bands.", "We", "will", "use", "other", "hands", "(including", "U\\])", "and", "data", "that", "we", "plan", "to", "acquire)", "to", "study", "spectrophotometric", "prl)ert~es", "of", "f.LSBs", "in", "a", "future", "work."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["Scalingrelatioils"], "labels": ["WRONG"]}, "correct": {"tokens": ["Scaling", "relations"], "labels": ["TOKENIZATION_ERROR", "MIXED"]}, "predicted": {"google": {"tokens": ["Scaling", "Relations"], "labels": ["TOKENIZATION_ERROR", "WRONG"]}, "BS-bid-OCR": {"tokens": ["Scaling", "relatioils"], "labels": ["TOKENIZATION_ERROR", "WRONG"]}, "BS-bid-OCR+google": {"tokens": ["Scaling", "relations"], "labels": ["TOKENIZATION_ERROR", "MIXED"]}}}, {"corrupt": {"tokens": ["Tthas1)eensuggested?Sorrel1990)thatcarbonistransformedintoerapbiteitheISMbyana~nealingproceaScausedbytheinterstellar\\radiationfieicld(IsRF).TheSMCwould,inthatcase,beaprivilegiedslteforgraphitefozmation1)ecausetheISRFisgreatertherethan?'ntheGalaxy(Lequeuz1980)?Buithatdoesllotseemtbethecase,sincetheUVbumpisnotgenerjallyobserved."], "labels": ["WRONG"]}, "correct": {"tokens": ["It", "has", "been", "suggested", "(Sorrel", "1990)", "that", "carbon", "is", "transformed", "into", "graphite", "in", "the", "ISM", "by", "an", "annealing", "process", "caused", "by", "the", "interstellar", "radiation", "field", "(ISRF).", "The", "SMC", "would,", "in", "that", "case,", "be", "a", "privileged", "site", "for", "graphite", "formation", "because", "the", "ISRF", "is", "greater", "there", "than", "in", "the", "Galaxy", "(Lequeux", "1989).", "But", "that", "does", "not", "seem", "to", "be", "the", "case,", "since", "the", "UV", "bump", "is", "not", "generally", "observed."], "labels": ["MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["Tthas1)been", "suggested?Sorrel1990)thatcarbonistransformedintoerapbiteitheISMbyana~nealingproceaScausedbytheinterstellar\\radiation", "field(IsRF).TheSMCwould,inthatcase,beaprivilegiedslteforgraphitefozmation1)ecausetheISRFisgreatertherethan?'ntheGalaxy(Lequeux", "1980)?Buithatdoesllotseemtbethecase,sincetheUVbumpisnotgenerjallyobserved."], "labels": ["WRONG", "WRONG", "WRONG", "WRONG"]}, "BS-bid-OCR": {"tokens": ["Tt", "has", "1)een", "suggested", "?Sorrel", "1990)", "that", "carbon", "is", "transformed", "into", "e", "rapbite", "i", "the", "ISM", "by", "an", "a~nealing", "proceaS", "caused", "by", "the", "interstellar", "\\radiation", "fieicld", "(IsRF).", "The", "SMC", "would,", "in", "that", "case,", "be", "a", "privilegied", "slte", "for", "graphite", "fozmation", "1)ecause", "the", "ISRF", "is", "greater", "there", "than", "?'n", "the", "Galaxy", "(Lequeuz", "1980)?", "Bui", "that", "does", "llot", "seem", "t", "be", "the", "case,", "since", "the", "UV", "bump", "is", "not", "generjally", "observed."], "labels": ["WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["Tt", "has", "1)een", "suggested", "?Sorrel", "1990)", "that", "carbon", "is", "transformed", "into", "a", "rabbit", "in", "the", "ISM", "by", "an", "a~nealing", "procesS", "caused", "by", "the", "interstellar", "\\radiation", "field", "(IsRF).", "The", "SMC", "would,", "in", "that", "case,", "be", "a", "privileged", "site", "for", "graphite", "formation", "1)because", "the", "ISRF", "is", "greater", "there", "than", "?'n", "the", "Galaxy", "(Lequeux", "1980)?", "Bui", "that", "does", "not", "seem", "to", "be", "the", "case,", "since", "the", "UV", "bump", "is", "not", "generally", "observed."], "labels": ["WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "MIXED", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["Dlivisionofbothsidesby(1+\u03b1)(1+\u03b31)yields"], "labels": ["WRONG"]}, "correct": {"tokens": ["Division", "of", "both", "sides", "by", "(1", "+", "\u03b1)(1", "+", "\u03b31)", "yields"], "labels": ["MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["Division", "Both", "Sides", "By(1+\u03b1)(1+\u03b31)yields"], "labels": ["MIXED", "WRONG", "WRONG", "WRONG"]}, "BS-bid-OCR": {"tokens": ["Dlivision", "of", "both", "sides", "by", "(1", "+", "\u03b1)(1", "+", "\u03b31)", "yields"], "labels": ["WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["Division", "of", "both", "sides", "by", "(1", "+", "\u03b1)(1", "+", "\u03b31)", "yields"], "labels": ["MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["SotheHamiltonianintel'msofthevariableswithdimensi0nsaregivenby"], "labels": ["WRONG"]}, "correct": {"tokens": ["So", "the", "Hamiltonian", "in", "terms", "of", "the", "variables", "with", "dimensions", "are", "given", "by"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["SotheHamiltonianintel'msofthevariableswithdimensi0nsaregivenby"], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["So", "the", "Hamiltonian", "in", "tel'ms", "of", "the", "variables", "with", "dimensi0ns", "are", "given", "by"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["So", "the", "Hamiltonian", "in", "terms", "of", "the", "variables", "with", "dimensions", "are", "given", "by"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["Nextwecnsiderhowteperformasecondroundofcorrection.Theti,weperformmultip~leegntentsibllowedbyacorrectionasintheprevioussection,andrepeatmultipletimes,thenperformacorrection.Thistechniqueenablesthescalinggiveinthefol:lowingTheorem."], "labels": ["WRONG"]}, "correct": {"tokens": ["Next", "we", "consider", "how", "to", "perform", "a", "second", "round", "of", "correction.", "That", "is,", "we", "perform", "multiple", "segments", "followed", "by", "a", "correction", "as", "in", "the", "previous", "section,", "and", "repeat", "multiple", "times,", "then", "perform", "a", "correction.", "This", "technique", "enables", "the", "scaling", "given", "in", "the", "following", "Theorem."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["Nextwecnsiderhowteperformasecondroundofcorrection.Theti,weperformmultip~leegntentsibllowedbyacorrectionasintheprevioussection,andrepeatmultipletimes,thenperformacorrection.Thistechniqueenablesthescalinggiveinthefol:lowingTheorem."], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["Next", "we", "cnsider", "how", "te", "perform", "a", "second", "round", "of", "correction.", "Theti,", "we", "perform", "multip~le", "egntents", "ibllowed", "by", "a", "correction", "as", "in", "the", "previous", "section,", "and", "repeat", "multiple", "times,", "then", "perform", "a", "correction.", "This", "technique", "enables", "the", "scaling", "give", "in", "the", "fol:lowing", "Theorem."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["Next", "we", "consider", "how", "to", "perform", "a", "second", "round", "of", "correction.", "Theti,", "we", "perform", "multip~le", "extents", "allowed", "by", "a", "correction", "as", "in", "the", "previous", "section,", "and", "repeat", "multiple", "times,", "then", "perform", "a", "correction.", "This", "technique", "enables", "the", "scaling", "give", "in", "the", "fol:lowing", "Theorem."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["wherePR=(1+\u03b35)/2and"], "labels": ["WRONG"]}, "correct": {"tokens": ["where", "PR", "=", "(1", "+", "\u03b35)/2", "and"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["wherePR=(1+\u03b35)/2and"], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["where", "PR", "=", "(1", "+", "\u03b35)/2", "and"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["where", "PR", "=", "(1", "+", "\u03b35)/2", "and"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["Ultrafastphotoinducedphaseseparatio.ndynamlcsinPr0.6Ca0.4MnO3\\thinfilms"], "labels": ["WRONG"]}, "correct": {"tokens": ["Ultrafast", "photoinduced", "phase", "separation", "dynamics", "in", "Pr0.6Ca0.4MnO3", "thin", "films"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["Ultrafastphotoinducedphaseseparatio.ndynamlcsinPr0.6Ca0.4MnO3\\thin", "films"], "labels": ["WRONG", "TOKENIZATION_ERROR"]}, "BS-bid-OCR": {"tokens": ["Ultrafast", "photoinduced", "phase", "separatio.n", "dynamlcs", "in", "Pr0.6Ca0.4MnO3", "\\thin", "films"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["Ultrafast", "photoinduced", "phase", "separation", "dynamics", "in", "Pr0.6Ca0.4MnO3", "\\thin", "films"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["isdrol)pedinfavcorofteothertwo.ThegeneratorsTaaresum\\medoverintheadjointrepresentatio?nandtheclsubscriptnumberslabelthcfundanentalgroupindicesofthefourferrnionfieldslotswithinanyoherafor."], "labels": ["WRONG"]}, "correct": {"tokens": ["is", "dropped", "in", "favor", "of", "the", "other", "two.", "The", "generators", "Ta", "are", "summed", "over", "in", "the", "adjoint", "representation", "and", "the", "subscript", "numbers", "label", "the", "fundamental", "group", "indices", "of", "the", "four", "fermion", "field", "slots", "within", "any", "operator."], "labels": ["TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED"]}, "predicted": {"google": {"tokens": ["isdrol)pedinfavcorofteothertwo.ThegeneratorsTaaresum\\medoverintheadjointrepresentatio?nandtheclsubscriptnumberslabelthcfundanentalgroupindicesofthefourferrnionfieldslotswithinanyoherafor."], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["is", "drol)ped", "in", "favcor", "of", "te", "other", "two.", "The", "generators", "Ta", "are", "sum\\med", "over", "in", "the", "adjoint", "representatio?n", "and", "thecl", "subscript", "numbers", "label", "thc", "fundanental", "group", "indices", "of", "the", "four", "ferrnion", "field", "slots", "within", "any", "oherafor."], "labels": ["TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG"]}, "BS-bid-OCR+google": {"tokens": ["is", "drol)ped", "in", "favor", "of", "the", "other", "two.", "The", "generators", "Ta", "are", "sum\\med", "over", "in", "the", "adjoint", "representation", "and", "the", "subscript", "numbers", "label", "the", "fundamental", "group", "indices", "of", "the", "four", "fermion", "field", "slots", "within", "any", "okafor."], "labels": ["TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG"]}}}, {"corrupt": {"tokens": ["where\u03bbisadimensionlesscouplincgconsta~t.Weareinterestedinthevolul,ionoltheenergyofeachoscillator,"], "labels": ["WRONG"]}, "correct": {"tokens": ["where", "\u03bb", "is", "a", "dimensionless", "coupling", "constant.", "We", "are", "interested", "in", "the", "evolution", "of", "the", "energy", "of", "each", "oscillator,"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["where\u03bbisadimensionlesscouplincgconsta~t.Weareinterestedinthevolul,ionoltheenergyofeachoscillator,"], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["where", "\u03bb", "is", "a", "dimensionless", "couplincg", "consta~t.", "We", "are", "interested", "in", "th", "evolul,ion", "ol", "the", "energy", "of", "each", "oscillator,"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["where", "\u03bb", "is", "a", "dimensionless", "coupling", "consta~t.", "We", "are", "interested", "in", "the", "evolution", "of", "the", "energy", "of", "each", "oscillator,"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["StatisticofGi~ntRadloHalosfrom?ElectronR~eaccelerationModels"], "labels": ["WRONG"]}, "correct": {"tokens": ["Statistics", "of", "Giant", "Radio", "Halos", "from", "Electron", "Reacceleration", "Models"], "labels": ["MIXED", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["Statistic", "Gi~RadioHalos", "from?ElectronR~acceleration", "Models"], "labels": ["WRONG", "WRONG", "WRONG", "TOKENIZATION_ERROR"]}, "BS-bid-OCR": {"tokens": ["Statistic", "of", "Gi~nt", "Radlo", "Halos", "from?", "Electron", "R~e", "acceleration", "Models"], "labels": ["WRONG", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["Statistics", "of", "Gi~nt", "Radio", "Halos", "from?", "Electron", "R~e", "acceleration", "Models"], "labels": ["MIXED", "TOKENIZATION_ERROR", "WRONG", "MIXED", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["Observmtiona--lmate?ial~ndphotometry"], "labels": ["WRONG"]}, "correct": {"tokens": ["Observational", "material", "and", "photometry"], "labels": ["MIXED", "MIXED", "MIXED", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["Observmtiona--lmate?ial~and", "photometry"], "labels": ["WRONG", "TOKENIZATION_ERROR"]}, "BS-bid-OCR": {"tokens": ["Observmtiona--l", "mate?ial", "~nd", "photometry"], "labels": ["WRONG", "WRONG", "WRONG", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["Observmtiona--l", "kate?ial", "~and", "photometry"], "labels": ["WRONG", "WRONG", "WRONG", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["Integranumbercounth.sfromasurveywithhomogeneoussensitivityarecalculatedbysummihgupthenumbdrofsourcestoagivenfluxllilnit,andthendivldi?gbythesrweyarea:"], "labels": ["WRONG"]}, "correct": {"tokens": ["Integral", "number", "counts", "from", "a", "survey", "with", "homogeneous", "sensitivity", "are", "calculated", "by", "summing", "up", "the", "number", "of", "sources", "to", "a", "given", "flux", "limit,", "and", "then", "dividing", "by", "the", "survey", "area:"], "labels": ["MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["Integranumbercounth.sfromasurveywithhomogeneoussensitivityarecalculatedbysummihgupthenumbdrofsourcestoagivenfluxllilnit,andthendivldi?gbythesrweyarea:"], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["Integra", "number", "counth.s", "from", "a", "survey", "with", "homogeneous", "sensitivity", "are", "calculated", "by", "summihg", "up", "the", "numbdr", "of", "sources", "to", "a", "given", "flux", "llilnit,", "and", "then", "divldi?g", "by", "the", "srwey", "area:"], "labels": ["WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["Integra", "number", "counts", "from", "a", "survey", "with", "homogeneous", "sensitivity", "are", "calculated", "by", "summing", "up", "the", "number", "of", "sources", "to", "a", "given", "flux", "limit,", "and", "then", "dividing", "by", "the", "survey", "area:"], "labels": ["WRONG", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["2.1.Episod\\]cAccretionOuringStarFormatios"], "labels": ["WRONG"]}, "correct": {"tokens": ["2.1.", "Episodic", "Accretion", "During", "Star", "Formation"], "labels": ["TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED"]}, "predicted": {"google": {"tokens": ["2.1.Episod\\]cAccretionOuringStarFormatios"], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["2.1.", "Episod\\]c", "Accretion", "Ouring", "Star", "Formatios"], "labels": ["TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG"]}, "BS-bid-OCR+google": {"tokens": ["2.1.", "Episod\\]c", "Accretion", "During", "Star", "Formation"], "labels": ["TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED"]}}}, {"corrupt": {"tokens": ["Introdu?ction"], "labels": ["WRONG"]}, "correct": {"tokens": ["Introduction"], "labels": ["OCR_ERROR"]}, "predicted": {"google": {"tokens": ["Introduction"], "labels": ["OCR_ERROR"]}, "BS-bid-OCR": {"tokens": ["Introdu?ction"], "labels": ["WRONG"]}, "BS-bid-OCR+google": {"tokens": ["Introduction"], "labels": ["OCR_ERROR"]}}}, {"corrupt": {"tokens": ["Howeverwhatwearedealingwithinrealityinsteadis"], "labels": ["WRONG"]}, "correct": {"tokens": ["However", "what", "we", "are", "dealing", "with", "in", "reality", "instead", "is"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["However", "What", "We", "Are", "Dealing", "With", "In", "Reality", "Instead", "Is"], "labels": ["TOKENIZATION_ERROR", "WRONG", "WRONG", "WRONG", "WRONG", "WRONG", "WRONG", "WRONG", "WRONG", "WRONG"]}, "BS-bid-OCR": {"tokens": ["However", "what", "we", "are", "dealing", "with", "in", "reality", "instead", "is"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["However", "what", "we", "are", "dealing", "with", "in", "reality", "instead", "is"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["Acknowledgements"], "labels": ["NONE"]}, "correct": {"tokens": ["Acknowledgements"], "labels": ["NONE"]}, "predicted": {"google": {"tokens": ["Acknowledgements"], "labels": ["NONE"]}, "BS-bid-OCR": {"tokens": ["Acknowledgements"], "labels": ["NONE"]}, "BS-bid-OCR+google": {"tokens": ["Acknowledgements"], "labels": ["NONE"]}}}, {"corrupt": {"tokens": ["whichisagenerc~lizationofBoltzmann-Shannonentropy(10).Itis,infact,amegsureojrelativeentropydefined?verthenon.negativeintegels.SinceP(N1,N2;..,Rn)\u22641theqantity(1r)is,however,~egative.Weshallcal.lthenegativeof(17)thatis,theguantity"], "labels": ["WRONG"]}, "correct": {"tokens": ["which", "is", "a", "generalization", "of", "Boltzmann-Shannon", "entropy", "(10).", "It", "is,", "in", "fact,", "a", "measure", "of", "relative", "entropy", "defined", "over", "the", "non-negative", "integers.", "Since", "P(N1,", "N2,", "..,", "Nn)", "\u2264", "1", "the", "quantity", "(17)", "is,", "however", ",", "negative.", "We", "shall", "call", "the", "negative", "of", "(17)", "that", "is", ",", "the", "quantity"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED"]}, "predicted": {"google": {"tokens": ["whichisagenerc~lizationofBoltzmann-Shannonentropy(10).Itis,in", "fact,measures", "relative", "entropy", "defined?verthenon.negativeintegels.SinceP(N1,N2;..,Rn)\u22641theqantity(1r)is,however,~negative.We", "Shall", "Call.the", "negative", "of(17)that", "is,the", "quantity"], "labels": ["WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "WRONG", "TOKENIZATION_ERROR", "WRONG", "WRONG", "MIXED"]}, "BS-bid-OCR": {"tokens": ["which", "is", "a", "generc~lization", "of", "Boltzmann-Shannon", "entropy", "(10).", "It", "is,", "in", "fact,", "a", "megsure", "oj", "relative", "entropy", "defined", "?ver", "the", "non.negative", "integels.", "Since", "P(N1,", "N2;", "..,", "Rn)", "\u2264", "1", "the", "qantity", "(1r)", "is,", "however,", "~egative.", "We", "shall", "cal.l", "the", "negative", "of", "(17)", "that", "is,", "the", "guantity"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG"]}, "BS-bid-OCR+google": {"tokens": ["which", "is", "a", "generic~lization", "of", "Boltzmann-Shannon", "entropy", "(10).", "It", "is,", "in", "fact,", "a", "measure", "of", "relative", "entropy", "defined", "over", "the", "non.negative", "integers.", "Since", "P(N1,", "N2;", "..,", "Rn)", "\u2264", "1", "the", "quantity", "(1r)", "is,", "however,", "~negative.", "We", "shall", "call", "the", "negative", "of", "(17)", "that", "is,", "the", "quantity"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "WRONG", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "WRONG", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "MIXED"]}}}, {"corrupt": {"tokens": ["1)Theresultspresentedinthiswork,inicatethal,thestatisticaldescriptionofanisolatedquantumsystemsuhject_toafixedenergycoaslraintandunrestrictedparticipationofeigenstatesconfra\\dicts(atlestintheimits(:olisiderext)totheBoltzmann-GibbsstaCtieticsderivahlenrithebasisoftireconventionalmicrocanonicalassum:ption."], "labels": ["WRONG"]}, "correct": {"tokens": ["1)", "The", "results", "presented", "in", "this", "work,", "indicate", "that", "the", "statistical", "description", "of", "an", "isolated", "quantum", "system", "subject", "to", "a", "fixed", "energy", "constraint", "and", "unrestricted", "participation", "of", "eigenstates", "contradicts", "(at", "least", "in", "the", "limits", "considered)", "to", "the", "Boltzmann-Gibbs", "statistics", "derivable", "on", "the", "basis", "of", "the", "conventional", "microcanonical", "assumption."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED"]}, "predicted": {"google": {"tokens": ["1)Theresultspresentedinthiswork,inicatethal,thestatisticaldescriptionofanisolatedquantumsystemsuhject_toafixedenergycoaslraintandunrestrictedparticipationofeigenstatesconfra\\dicts(atlestintheimits(:olisiderext)totheBoltzmann-GibbsstaCtieticsderivahlenrithebasisoftireconventionalmicrocanonicalassum:ption."], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["1)", "The", "results", "presented", "in", "this", "work,", "inicate", "thal,", "the", "statistical", "description", "of", "an", "isolated", "quantum", "system", "suhject_", "to", "a", "fixed", "energy", "coaslraint", "and", "unrestricted", "participation", "of", "eigenstates", "confra\\dicts", "(at", "lest", "in", "the", "imits", "(:olisiderext)", "to", "the", "Boltzmann-Gibbs", "staCtietics", "derivahle", "nri", "the", "basis", "of", "tire", "conventional", "microcanonical", "assum:ption."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG"]}, "BS-bid-OCR+google": {"tokens": ["1)", "The", "results", "presented", "in", "this", "work,", "indicate", "that,", "the", "statistical", "description", "of", "an", "isolated", "quantum", "system", "suhject_", "to", "a", "fixed", "energy", "constraint", "and", "unrestricted", "participation", "of", "eigenstates", "confra\\dicts", "(at", "least", "in", "the", "limits", "(:olisiderext)", "to", "the", "Boltzmann-Gibbs", "statistics", "derivable", "nri", "the", "basis", "of", "tire", "conventional", "microcanonical", "assum:ption."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG"]}}}, {"corrupt": {"tokens": ["and"], "labels": ["NONE"]}, "correct": {"tokens": ["and"], "labels": ["NONE"]}, "predicted": {"google": {"tokens": ["and"], "labels": ["NONE"]}, "BS-bid-OCR": {"tokens": ["and"], "labels": ["NONE"]}, "BS-bid-OCR+google": {"tokens": ["and"], "labels": ["NONE"]}}}, {"corrupt": {"tokens": ["whetrewehavedefined"], "labels": ["WRONG"]}, "correct": {"tokens": ["where", "we", "have", "defined"], "labels": ["MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["where", "we've", "defined"], "labels": ["MIXED", "WRONG", "TOKENIZATION_ERROR"]}, "BS-bid-OCR": {"tokens": ["whetre", "we", "have", "defined"], "labels": ["WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["where", "we", "have", "defined"], "labels": ["MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["where"], "labels": ["NONE"]}, "correct": {"tokens": ["where"], "labels": ["NONE"]}, "predicted": {"google": {"tokens": ["where"], "labels": ["NONE"]}, "BS-bid-OCR": {"tokens": ["where"], "labels": ["NONE"]}, "BS-bid-OCR+google": {"tokens": ["where"], "labels": ["NONE"]}}}, {"corrupt": {"tokens": ["Hence,"], "labels": ["NONE"]}, "correct": {"tokens": ["Hence,"], "labels": ["NONE"]}, "predicted": {"google": {"tokens": ["Hence,"], "labels": ["NONE"]}, "BS-bid-OCR": {"tokens": ["Hence,"], "labels": ["NONE"]}, "BS-bid-OCR+google": {"tokens": ["Hence,"], "labels": ["NONE"]}}}, {"corrupt": {"tokens": ["2.Firstconsierthequ~rIkl)zopagatorinanexternalnon-Abemmliangauga.field.Inthe-firstquantizedth\\eory,thepropagtorfromxtcyinMinkowaklspacereads"], "labels": ["WRONG"]}, "correct": {"tokens": ["2.", "First", "consider", "the", "quark", "propagator", "in", "an", "external", "non-Abelian", "gauge", "field.", "In", "the", "first", "quantized", "theory,", "the", "propagator", "from", "x", "to", "y", "in", "Minkowski", "space", "reads"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["2.Firstconsierthequ~rIkl)zopagatorinanexternalnon-Abemmliangauga.field.Inthe-firstquantizedth\\eory,thepropagtorfromxtcyinMinkowaklspacereads"], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["2.", "First", "consier", "the", "qu~rIk", "l)zopagator", "in", "an", "external", "non-Abemmlian", "gauga", ".field.", "In", "the-", "first", "quantized", "th\\eory,", "the", "propagtor", "from", "x", "tc", "y", "in", "Minkowakl", "space", "reads"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["2.", "First", "consider", "the", "qu~rIk", "l)zopagator", "in", "an", "external", "non-Abelian", "gauge", "field.", "In", "the-", "first", "quantized", "th\\eory,", "the", "propagator", "from", "x", "to", "y", "in", "Minkowski", "space", "reads"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["PROPOSEDS~RATEGY"], "labels": ["WRONG"]}, "correct": {"tokens": ["PROPOSED", "STRATEGY"], "labels": ["TOKENIZATION_ERROR", "MIXED"]}, "predicted": {"google": {"tokens": ["PROPOSEDS~RATEGY"], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["PROPOSEDS", "~RATEGY"], "labels": ["WRONG", "WRONG"]}, "BS-bid-OCR+google": {"tokens": ["PROPOSEDS", "~RATEGY"], "labels": ["WRONG", "WRONG"]}}}, {"corrupt": {"tokens": ["suchthatthegaugeinvariantderivativeis"], "labels": ["WRONG"]}, "correct": {"tokens": ["such", "that", "the", "gauge", "invariant", "derivative", "is"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["such", "that", "the", "gauge", "invariant", "derivative", "is"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR": {"tokens": ["such", "that", "the", "gauge", "invariant", "derivative", "is"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["such", "that", "the", "gauge", "invariant", "derivative", "is"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["withsymbolt0denotingin?itieltimeofevolution."], "labels": ["WRONG"]}, "correct": {"tokens": ["with", "symbol", "t0", "denoting", "initial", "time", "of", "evolution."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["withsymbolt0denotingin?itieltimeofevolution."], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["with", "symbol", "t0", "denoting", "in?itiel", "time", "of", "evolution."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["with", "symbol", "t0", "denoting", "in?itiel", "time", "of", "evolution."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["whichgivesthefollowing?resultfrthetrace:"], "labels": ["WRONG"]}, "correct": {"tokens": ["which", "gives", "the", "following", "result", "for", "the", "trace:"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["which", "gives", "the", "following?result", "for", "the", "trace:"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR": {"tokens": ["which", "gives", "the", "following?", "result", "fr", "the", "trace:"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["which", "gives", "the", "following?", "result", "for", "the", "trace:"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["WehaveproposedatechniquelorfeatureselectionandextractionusingClasSDependentEeatures(C\\])Fs).OurtechniqueasbeentestedontheMNISTandUSPSdatasetsfrhandwrittendigitrecognitionaswellasontheReuters-21578andWeI)KBdatasetsfortextclmategorization.WehaobtainedstrongcomdetitiveDiresultsusinganSVMwithadegee-2polynomlaiket'nelandtheseresultsalonwiththoseofcontempraryteehniqu6shavebeentat)ulated.Ourresultshrecomparablettllecurrentstte-of-the-art,and\\onparwiththeeurrentbestgenericalgorithms."], "labels": ["WRONG"]}, "correct": {"tokens": ["We", "have", "proposed", "a", "technique", "for", "feature", "selection", "and", "extraction", "using", "Class", "Dependent", "Features", "(CDFs).", "Our", "technique", "has", "been", "tested", "on", "the", "MNIST", "and", "USPS", "datasets", "for", "handwritten", "digit", "recognition", "as", "well", "as", "on", "the", "Reuters-21578", "and", "WebKB", "datasets", "for", "text", "categorization.", "We", "have", "obtained", "strong", "competitive", "results", "using", "an", "SVM", "with", "a", "degree-2", "polynomial", "kernel", "and", "these", "results", "along", "with", "those", "of", "contemporary", "techniques", "have", "been", "tabulated.", "Our", "results", "are", "comparable", "to", "the", "current", "state-of-the-art,", "and", "on", "par", "with", "the", "current", "best", "generic", "algorithms."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["WehaveproposedatechniquelorfeatureselectionandextractionusingClasSDependentEeatures(C\\])Fs).OurtechniqueasbeentestedontheMNISTandUSPSdatasetsfrhandwrittendigitrecognitionaswellasontheReuters-21578andWeI)KBdatasetsfortextclmategorization.WehaobtainedstrongcomdetitiveDiresultsusinganSVMwithadegee-2polynomlaiket'nelandtheseresultsalonwiththoseofcontempraryteehniqu6shavebeentat)ulated.Ourresultshrecomparablettllecurrentstte-of-the-art,and\\onparwiththeeurrentbestgenericalgorithms."], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["We", "have", "proposed", "a", "technique", "lor", "feature", "selection", "and", "extraction", "using", "ClasS", "Dependent", "Eeatures", "(C\\])Fs).", "Our", "technique", "as", "been", "tested", "on", "the", "MNIST", "and", "USPS", "datasets", "fr", "handwritten", "digit", "recognition", "as", "well", "as", "on", "the", "Reuters-21578", "and", "WeI)KB", "datasets", "for", "text", "clmategorization.", "We", "ha", "obtained", "strong", "comdetitiveDiresults", "using", "an", "SVM", "with", "a", "degee-2", "polynomlai", "ket'nel", "and", "these", "results", "alon", "with", "those", "of", "contemprary", "teehniqu6s", "have", "been", "tat)ulated.", "Our", "results", "hre", "comparable", "t", "tlle", "current", "stte-of-the-art,", "and\\", "on", "par", "with", "the", "eurrent", "best", "generic", "algorithms."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["We", "have", "proposed", "a", "technique", "for", "feature", "selection", "and", "extraction", "using", "ClasS", "Dependent", "Features", "(C\\])Fs).", "Our", "technique", "has", "been", "tested", "on", "the", "MNIST", "and", "USPS", "datasets", "for", "handwritten", "digit", "recognition", "as", "well", "as", "on", "the", "Reuters-21578", "and", "WeI)KB", "datasets", "for", "text", "categorization.", "We", "have", "obtained", "strong", "comdetitiveDiresults", "using", "an", "SVM", "with", "a", "degree-2", "polynomial", "kernel", "and", "these", "results", "along", "with", "those", "of", "contemporary", "techniques", "have", "been", "tat)ulated.", "Our", "results", "are", "comparable", "to", "the", "current", "state-of-the-art,", "and\\", "on", "par", "with", "the", "current", "best", "generic", "algorithms."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "MIXED", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "MIXED", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["with\u03b3etheigyromagneticratioofthefreeeIectron.Fortheangulardependenceoftherelaxationrate,weobtain"], "labels": ["WRONG"]}, "correct": {"tokens": ["with", "\u03b3e", "the", "gyromagnetic", "ratio", "of", "the", "free", "electron.", "For", "the", "angular", "dependence", "of", "the", "relaxation", "rate,", "we", "obtain"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["with\u03b3etheigyromagneticratioofthefreeeIectron.For", "The", "Angular", "Dependence", "Of", "The", "Relaxation", "Rate,we", "obtain"], "labels": ["WRONG", "WRONG", "WRONG", "WRONG", "WRONG", "WRONG", "WRONG", "WRONG", "TOKENIZATION_ERROR"]}, "BS-bid-OCR": {"tokens": ["with", "\u03b3e", "thei", "gyromagnetic", "ratio", "of", "the", "free", "eIectron.", "For", "the", "angular", "dependence", "of", "the", "relaxation", "rate,", "we", "obtain"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["with", "\u03b3e", "their", "gyromagnetic", "ratio", "of", "the", "free", "eLectron.", "For", "the", "angular", "dependence", "of", "the", "relaxation", "rate,", "we", "obtain"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["Hei\\senbergequationofmotionforlheatomicoperators"], "labels": ["WRONG"]}, "correct": {"tokens": ["Heisenberg", "equations", "of", "motion", "for", "the", "atomic", "operators"], "labels": ["MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["Heisenberg", "Equation", "Of", "Motion", "For", "Lhe", "Atomic", "Operators"], "labels": ["MIXED", "WRONG", "WRONG", "WRONG", "WRONG", "WRONG", "WRONG", "WRONG"]}, "BS-bid-OCR": {"tokens": ["Hei\\senberg", "equation", "of", "motion", "for", "lhe", "atomic", "operators"], "labels": ["WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["Hei\\senberg", "equation", "of", "motion", "for", "lhe", "atomic", "operators"], "labels": ["WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["Usingtheaboveproceduretoextendthesolutionstothepriorl'egionswithu<0orv<0,itcanbeseenthattheinitialiavesbe.foretheircollisionareeachacombinationofanimpidsiveandashockwave.Thsearegivenext)licit}yl)y"], "labels": ["WRONG"]}, "correct": {"tokens": ["Using", "the", "above", "procedure", "to", "extend", "the", "solutions", "to", "the", "prior", "regions", "with", "u", "<", "0", "or", "v", "<", "0,", "it", "can", "be", "seen", "that", "the", "initial", "waves", "before", "their", "collision", "are", "each", "a", "combination", "of", "an", "impulsive", "and", "a", "shock", "wave.", "These", "are", "given", "explicitly", "by"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED"]}, "predicted": {"google": {"tokens": ["Usingtheaboveproceduretoextendthesolutionstothepriorl'egionswithu<0orv<0,itcanbeseenthattheinitialiavesbe.foretheircollisionareeachacombinationofanimpidsiveandashockwave.Thsearegivenext)licit}yl)y"], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["Using", "the", "above", "procedure", "to", "extend", "the", "solutions", "to", "the", "prior", "l'egions", "with", "u", "<", "0", "or", "v", "<", "0,", "it", "can", "be", "seen", "that", "the", "initial", "iaves", "be.fore", "their", "collision", "are", "each", "a", "combination", "of", "an", "impidsive", "and", "a", "shock", "wave.", "Thse", "are", "given", "ext)licit}y", "l)y"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG"]}, "BS-bid-OCR+google": {"tokens": ["Using", "the", "above", "procedure", "to", "extend", "the", "solutions", "to", "the", "prior", "l'egions", "with", "u", "<", "0", "or", "v", "<", "0,", "it", "can", "be", "seen", "that", "the", "initial", "leaves", "before", "their", "collision", "are", "each", "a", "combination", "of", "an", "impulsive", "and", "a", "shock", "wave.", "These", "are", "given", "ext)licit}y", "l)y"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG"]}}}, {"corrupt": {"tokens": ["Thisdefinitionisanaruralgeneralizatio\\oftheRiemanniannormalhomgn?eousspace.Althoughinmostcasesthenormalhomogeneityisonlyfreferredtoac\\om?pactcosetspaceM=G/HofacompactLiegroupG,the?theorycanbeappliedtosomespeci~ilnon-cempactcosetcspaceswithveryminortechnicaladjustment.NotethatifGisacompactsimpeLiegroup,thenthereexistsauniquebi-invariantRiemannianmetriconG(u~toh<>motheties).However,thereusuallyexistsinfintelymanybi-invariantFinslermetricsonacompactLiegroup(uptohomotheties),evenforacompasctsimpleLiegroupi.Thisimpliest\\hatno;rlnalhomogeneousFinslermetricsarenotelate(ItothegroupGasclosclyasin{,heRiemanniancase.Hencethe.problemlofthispaperismuchmoredifficuWltthanthesameproblemintheRlemanniancase."], "labels": ["WRONG"]}, "correct": {"tokens": ["This", "definition", "is", "a", "natural", "generalization", "of", "the", "Riemannian", "normal", "homogeneous", "space.", "Although", "in", "most", "cases", "the", "normal", "homogeneity", "is", "only", "referred", "to", "a", "compact", "coset", "space", "M", "=", "G/H", "of", "a", "compact", "Lie", "group", "G,", "the", "theory", "can", "be", "applied", "to", "some", "special", "non-compact", "coset", "spaces", "with", "very", "minor", "technical", "adjustment.", "Note", "that", "if", "G", "is", "a", "compact", "simple", "Lie", "group,", "then", "there", "exists", "a", "unique", "bi-invariant", "Riemannian", "metric", "on", "G", "(up", "to", "homotheties).", "However,", "there", "usually", "exists", "infinitely", "many", "bi-invariant", "Finsler", "metrics", "on", "a", "compact", "Lie", "group", "(up", "to", "homotheties),", "even", "for", "a", "compact", "simple", "Lie", "group.", "This", "implies", "that", "normal", "homogeneous", "Finsler", "metrics", "are", "not", "related", "to", "the", "group", "G", "as", "closely", "as", "in", "the", "Riemannian", "case.", "Hence", "the", "problem", "of", "this", "paper", "is", "much", "more", "difficult", "than", "the", "same", "problem", "in", "the", "Riemannian", "case."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["Thisdefinitionisanaruralgeneralizatio\\oftheRiemanniannormalhomgn?eousspace.Althoughinmostcasesthenormalhomogeneityisonlyfreferredtoac\\om?pactcosetspaceM=G/HofacompactLiegroupG,the?theorycanbeappliedtosomespeci~ilnon-cempactcosetcspaceswithveryminortechnicaladjustment.NotethatifGisacompactsimpeLiegroup,thenthereexistsauniquebi-invariantRiemannianmetriconG(u~toh<>motheties).However,thereusuallyexistsinfintelymanybi-invariantFinslermetricsonacompactLiegroup(upto", "homotheties),evenforacompasctsimpleLiegroupi.Thisimpliest\\hatno;rlnalhomogeneousFinslermetricsarenotelate(ItothegroupGasclosclyasin{,heRiemanniancase.Hencethe.problemlofthispaperismuchmoredifficuWltthanthesameproblemintheRlemanniancase."], "labels": ["WRONG", "WRONG"]}, "BS-bid-OCR": {"tokens": ["This", "definition", "is", "a", "narural", "generalizatio\\", "of", "the", "Riemannian", "normal", "homgn?eous", "space.", "Although", "in", "most", "cases", "the", "normal", "homogeneity", "is", "only", "freferred", "to", "a", "c\\om?pact", "coset", "space", "M", "=", "G/H", "of", "a", "compact", "Lie", "group", "G,", "the", "?theory", "can", "be", "applied", "to", "some", "speci~il", "non-cempact", "cosetc", "spaces", "with", "very", "minor", "technical", "adjustment.", "Note", "that", "if", "G", "is", "a", "compact", "simpe", "Lie", "group,", "then", "there", "exists", "a", "unique", "bi-invariant", "Riemannian", "metric", "on", "G", "(u~", "to", "h<>motheties).", "However,", "there", "usually", "exists", "infintely", "many", "bi-invariant", "Finsler", "metrics", "on", "a", "compact", "Lie", "group", "(up", "to", "homotheties),", "even", "for", "a", "compasct", "simple", "Lie", "groupi.", "This", "implies", "t\\hat", "no;rlnal", "homogeneous", "Finsler", "metrics", "are", "not", "elate(I", "to", "the", "group", "G", "as", "closcly", "as", "in", "{,he", "Riemannian", "case.", "Hence", "the", ".problem", "lof", "this", "paper", "is", "much", "more", "difficuWlt", "than", "the", "same", "problem", "in", "the", "Rlemannian", "case."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["This", "definition", "is", "a", "natural", "generalization\\", "of", "the", "Riemannian", "normal", "homogeneous", "space.", "Although", "in", "most", "cases", "the", "normal", "homogeneity", "is", "only", "referred", "to", "as\\compact", "coset", "space", "M", "=", "G/H", "of", "a", "compact", "Lie", "group", "G,", "the", "?theory", "can", "be", "applied", "to", "some", "speci~il", "non-compact", "coset", "spaces", "with", "very", "minor", "technical", "adjustment.", "Note", "that", "if", "G", "is", "a", "compact", "simple", "Lie", "group,", "then", "there", "exists", "a", "unique", "bi-invariant", "Riemannian", "metric", "on", "G", "(u~", "to", "h<>motheties).", "However,", "there", "usually", "exists", "infinitely", "many", "bi-invariant", "Finsler", "metrics", "on", "a", "compact", "Lie", "group", "(up", "to", "homotheties),", "even", "for", "a", "compact", "simple", "Lie", "group.", "This", "implies", "t\\hat", "normal", "homogeneous", "Finsler", "metrics", "are", "not", "related(I", "to", "the", "group", "G", "as", "closely", "as", "in", "{,he", "Riemannian", "case.", "Hence", "the", "problem", "of", "this", "paper", "is", "much", "more", "difficult", "than", "the", "same", "problem", "in", "the", "Rlemannian", "case."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["Moreover,itiseasilyseentobetotallyrealandmaybesmoothedtoC2+\u03b1."], "labels": ["WRONG"]}, "correct": {"tokens": ["Moreover,", "it", "is", "easily", "seen", "to", "be", "totally", "real", "and", "may", "be", "smoothed", "to", "C2", "+", "\u03b1."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["Moreover,itiseasilyseentobetotallyrealandmaybesmoothedtoC2+\u03b1."], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["Moreover,", "it", "is", "easily", "seen", "to", "be", "totally", "real", "and", "may", "be", "smoothed", "to", "C2", "+", "\u03b1."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["Moreover,", "it", "is", "easily", "seen", "to", "be", "totally", "real", "and", "may", "be", "smoothed", "to", "C2", "+", "\u03b1."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["Intro(luctlon"], "labels": ["WRONG"]}, "correct": {"tokens": ["Introduction"], "labels": ["OCR_ERROR"]}, "predicted": {"google": {"tokens": ["Intro(lucton"], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["Intro(luctlon"], "labels": ["WRONG"]}, "BS-bid-OCR+google": {"tokens": ["Intro(lucton"], "labels": ["WRONG"]}}}, {"corrupt": {"tokens": ["Eirst.observethatJn,2canbewrittenas"], "labels": ["WRONG"]}, "correct": {"tokens": ["First,", "observe", "that", "Jn,", "2", "can", "be", "written", "as"], "labels": ["MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["First.observation,2canbewrittenas"], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["Eirst.", "observe", "that", "Jn,", "2", "can", "be", "written", "as"], "labels": ["WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["Eirst.", "observe", "that", "Jn,", "2", "can", "be", "written", "as"], "labels": ["WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["Theraisingandlowerin~operatorsoftheO(3)subgroupsglve"], "labels": ["WRONG"]}, "correct": {"tokens": ["The", "raising", "and", "lowering", "operators", "of", "the", "O(3)", "subgroups", "give"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED"]}, "predicted": {"google": {"tokens": ["Theraisingandlowerin~operatorsoftheO(3)subgroups", "glove"], "labels": ["WRONG", "WRONG"]}, "BS-bid-OCR": {"tokens": ["The", "raising", "and", "lowerin~", "operators", "of", "the", "O(3)", "subgroups", "glve"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG"]}, "BS-bid-OCR+google": {"tokens": ["The", "raising", "and", "lowering~", "operators", "of", "the", "O(3)", "subgroups", "glove"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG"]}}}, {"corrupt": {"tokens": ["aresetlsf?ied"], "labels": ["WRONG"]}, "correct": {"tokens": ["are", "satisfied."], "labels": ["TOKENIZATION_ERROR", "MIXED"]}, "predicted": {"google": {"tokens": ["aresetlsf?ied"], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["are", "setlsf?ied"], "labels": ["TOKENIZATION_ERROR", "WRONG"]}, "BS-bid-OCR+google": {"tokens": ["are", "satisfied"], "labels": ["TOKENIZATION_ERROR", "WRONG"]}}}, {"corrupt": {"tokens": ["whchwhencomposedwiththecuppo\\duc|;aboveyieldsacupprodnct:"], "labels": ["WRONG"]}, "correct": {"tokens": ["which", "when", "composed", "with", "the", "cup", "product", "above", "yields", "a", "cup", "product:"], "labels": ["MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED"]}, "predicted": {"google": {"tokens": ["whchwhencomposedwiththecuppo\\duc|;aboveyieldsacupprodnct:"], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["whch", "when", "composed", "with", "the", "cup", "po\\duc|;", "above", "yields", "a", "cup", "prodnct:"], "labels": ["WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG"]}, "BS-bid-OCR+google": {"tokens": ["which", "when", "composed", "with", "the", "cup", "po\\duc|;", "above", "yields", "a", "cup", "product:"], "labels": ["MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED"]}}}, {"corrupt": {"tokens": ["Inthisseci;ionweusethepreviousresultsosowhdowandwhxthelistof^.Sevencan\\beobtainedfromtheHappel-Vossiecklist."], "labels": ["WRONG"]}, "correct": {"tokens": ["In", "this", "section", "we", "use", "the", "previous", "results", "to", "show", "how", "and", "why", "the", "list", "of", "A.", "Seven", "can", "be", "obtained", "from", "the", "Happel-Vossieck", "list."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["Inthisseci;ionweusethepreviousresultsosowhdowandwhxthelistof^.Sevencan\\beobtainedfromtheHappel-Vossiecklist."], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["In", "this", "seci;ion", "we", "use", "the", "previous", "results", "o", "sowhdow", "and", "whx", "the", "list", "of", "^.", "Seven", "can\\", "be", "obtained", "from", "the", "Happel-Vossieck", "list."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["In", "this", "seci;ion", "we", "use", "the", "previous", "results", "of", "showdown", "and", "whx", "the", "list", "of", "^.", "Seven", "can\\", "be", "obtained", "from", "the", "Happel-Vossiek", "list."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["whichcanbeintegratedtogive"], "labels": ["WRONG"]}, "correct": {"tokens": ["which", "can", "be", "integrated", "to", "give"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["which", "can", "be", "integrated", "to", "give"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR": {"tokens": ["which", "can", "be", "integrated", "to", "give"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["which", "can", "be", "integrated", "to", "give"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["Conclusion"], "labels": ["NONE"]}, "correct": {"tokens": ["Conclusion"], "labels": ["NONE"]}, "predicted": {"google": {"tokens": ["Conclusion"], "labels": ["NONE"]}, "BS-bid-OCR": {"tokens": ["Conclusion"], "labels": ["NONE"]}, "BS-bid-OCR+google": {"tokens": ["Conclusion"], "labels": ["NONE"]}}}, {"corrupt": {"tokens": ["Inparticular,therootofTis~nappedto\u03a30"], "labels": ["WRONG"]}, "correct": {"tokens": ["In", "particular,", "the", "root", "of", "T", "is", "mapped", "to", "\u03a30."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED"]}, "predicted": {"google": {"tokens": ["In", "Particular,therootofTis~nappedto\u03a30"], "labels": ["TOKENIZATION_ERROR", "WRONG"]}, "BS-bid-OCR": {"tokens": ["In", "particular,", "the", "root", "of", "T", "is", "~napped", "to", "\u03a30"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG"]}, "BS-bid-OCR+google": {"tokens": ["In", "particular,", "the", "root", "of", "T", "is", "~napped", "to", "\u03a30"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG"]}}}, {"corrupt": {"tokens": ["Therefore,foreachp\u2208Pn,"], "labels": ["WRONG"]}, "correct": {"tokens": ["Therefore,", "for", "each", "p", "\u2208", "Pn,"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["Therefore,foreach\u2208Pn,"], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["Therefore,", "for", "each", "p", "\u2208", "Pn,"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["Therefore,", "for", "each", "p", "\u2208", "Pn,"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["SymmetryofM-graphs"], "labels": ["WRONG"]}, "correct": {"tokens": ["Symmetry", "of", "M-graphs"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["Symmetry", "of-graphs"], "labels": ["TOKENIZATION_ERROR", "WRONG"]}, "BS-bid-OCR": {"tokens": ["Symmetry", "of", "M-graphs"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["Symmetry", "of", "M-graphs"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["Protonradiographyofmagneticfieldproducedbyul~ra-intenselaserirradiatingapacity-coiltarget"], "labels": ["WRONG"]}, "correct": {"tokens": ["Proton", "radiography", "of", "magnetic", "field", "produced", "by", "ultra-intense", "laser", "irradiating", "capacity-coil", "target"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["Protonradiographyofmagneticfieldproducedbyul~ra-intenselaserirradiatingapacity-coiltarget"], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["Proton", "radiography", "of", "magnetic", "field", "produced", "by", "ul~ra-intense", "laser", "irradiating", "apacity-coil", "target"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["Proton", "radiography", "of", "magnetic", "field", "produced", "by", "ul~ra-intense", "laser", "irradiating", "capacity-coil", "target"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["withquadratm'eansnihilationoperators"], "labels": ["WRONG"]}, "correct": {"tokens": ["with", "quadrature", "annihilation", "operators"], "labels": ["TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["withquadratm'eansnihilationoperators"], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["with", "quadratm'e", "ansnihilation", "operators"], "labels": ["TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["with", "quadrate", "annihilation", "operators"], "labels": ["TOKENIZATION_ERROR", "WRONG", "MIXED", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["Furthermore,wealsohave"], "labels": ["WRONG"]}, "correct": {"tokens": ["Furthermore,", "we", "also", "have"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["Furthermore,we", "also", "have"], "labels": ["WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR": {"tokens": ["Furthermore,", "we", "also", "have"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["Furthermore,", "we", "also", "have"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["where"], "labels": ["NONE"]}, "correct": {"tokens": ["where"], "labels": ["NONE"]}, "predicted": {"google": {"tokens": ["where"], "labels": ["NONE"]}, "BS-bid-OCR": {"tokens": ["where"], "labels": ["NONE"]}, "BS-bid-OCR+google": {"tokens": ["where"], "labels": ["NONE"]}}}, {"corrupt": {"tokens": ["Numerousexl)licitsolutionsarepossiblcifwespecifythefunctions\u03c9(t),m(t)."], "labels": ["WRONG"]}, "correct": {"tokens": ["Numerous", "explicit", "solutions", "are", "possible", "if", "we", "specify", "the", "functions", "\u03c9(t),", "m(t)."], "labels": ["TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["Numerous", "Xl)licitsolutionsarepossiblcifwespecifythefunctions\u03c9(t),m(t)."], "labels": ["TOKENIZATION_ERROR", "WRONG"]}, "BS-bid-OCR": {"tokens": ["Numerous", "exl)licit", "solutions", "are", "possiblc", "if", "we", "specify", "the", "functions", "\u03c9(t),", "m(t)."], "labels": ["TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["Numerous", "exl)licit", "solutions", "are", "possible", "if", "we", "specify", "the", "functions", "\u03c9(t),", "m(t)."], "labels": ["TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["Inordertostudylocally\\biholomorphimaps,weneedtlfefol1owing"], "labels": ["WRONG"]}, "correct": {"tokens": ["In", "order", "to", "study", "locally", "biholomorphic", "maps,", "we", "need", "the", "following"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED"]}, "predicted": {"google": {"tokens": ["Inordertostudylocally\\biholomorphimaps,whistleblowing"], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["In", "order", "to", "study", "locally\\", "biholomorphi", "maps,", "we", "need", "tlfe", "fol1owing"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG"]}, "BS-bid-OCR+google": {"tokens": ["In", "order", "to", "study", "locally\\", "biholomorphic", "maps,", "we", "need", "the", "following"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED"]}}}, {"corrupt": {"tokens": ["Scalingrelationsundhediss,ipat\\i\\onlessomerginghypatheis"], "labels": ["WRONG"]}, "correct": {"tokens": ["Scaling", "relations", "and", "the", "dissipationless", "merging", "hypothesis"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "MIXED", "TOKENIZATION_ERROR", "MIXED"]}, "predicted": {"google": {"tokens": ["Scalingrelationsundhediss,ipat\\i\\onlessomerginghypatheis"], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["Scaling", "relations", "und", "he", "diss,ipat\\i\\onless", "omerging", "hypatheis"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "WRONG", "WRONG", "WRONG"]}, "BS-bid-OCR+google": {"tokens": ["Scaling", "relations", "und", "he", "diss,ipat\\i\\unless", "emerging", "hypothesis"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "WRONG", "WRONG", "MIXED"]}}}, {"corrupt": {"tokens": ["Then,inthelarge-klimi?t,theexponentlalbecomes"], "labels": ["WRONG"]}, "correct": {"tokens": ["Then,", "in", "the", "large-k", "limit,", "the", "exponential", "becomes"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["Then,in", "the", "large-klimt,the", "exponent", "lal", "becomes"], "labels": ["WRONG", "TOKENIZATION_ERROR", "WRONG", "WRONG", "WRONG", "TOKENIZATION_ERROR"]}, "BS-bid-OCR": {"tokens": ["Then,", "in", "the", "large-k", "limi?t,", "the", "exponentlal", "becomes"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["Then,", "in", "the", "large-k", "limit,", "the", "exponential", "becomes"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["and\\"], "labels": ["WRONG"]}, "correct": {"tokens": ["and"], "labels": ["NONE"]}, "predicted": {"google": {"tokens": ["and\\"], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["and\\"], "labels": ["WRONG"]}, "BS-bid-OCR+google": {"tokens": ["and\\"], "labels": ["WRONG"]}}}, {"corrupt": {"tokens": ["Finally,fromLileanalysisofseueralstarformingregionsinawiderangeofages,Flaccomioetal.(2003)haveconcludedt\\]laxX-rayactivilyitcreasoswlthage,astheenvelopesanddisksofstarsprogressivelydissapear.Also$t?ssunetaL.(2004)st?tethattheemissionofX-rayscanbeobscuredormodulatedbyaccretionprocesses,batthesearenotthe(irtuinoftheX-rayactivity"], "labels": ["WRONG"]}, "correct": {"tokens": ["Finally,", "from", "the", "analysis", "of", "several", "star", "forming", "regions", "in", "a", "wide", "range", "of", "ages,", "Flaccomio", "et", "al.", "(2003)", "have", "concluded", "thax", "X-ray", "activity", "increases", "with", "age,", "as", "the", "envelopes", "and", "disks", "of", "stars", "progressively", "dissapear.", "Also", "Stassun", "et", "al.", "(2004)", "state", "that", "the", "emission", "of", "X-rays", "can", "be", "obscured", "or", "modulated", "by", "accretion", "processes,", "but", "these", "are", "not", "the", "origin", "of", "the", "X-ray", "activity."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED"]}, "predicted": {"google": {"tokens": ["Finally,fromLileanalysisofseueralstarformingregionsinawiderangeofages,Flaccomioetal.(2003)have", "concluded", "to\\]laxX-rayactivilyitcreasoswlthage,astheenvelopesanddisksofstarsprogressivelydissapear.Also$t?ssunetaL.(2004)st?tethattheemissionofX-rayscanbeobscuredormodulatedbyaccretionprocesses,batthesearenotthe(irtuinoftheX-rayactivity"], "labels": ["WRONG", "TOKENIZATION_ERROR", "WRONG"]}, "BS-bid-OCR": {"tokens": ["Finally,", "from", "Lile", "analysis", "of", "seueral", "star", "forming", "regions", "in", "a", "wide", "range", "of", "ages,", "Flaccomio", "et", "al.", "(2003)", "have", "concluded", "t\\]lax", "X-ray", "activily", "itcreasos", "wlth", "age,", "as", "the", "envelopes", "and", "disks", "of", "stars", "progressively", "dissapear.", "Also", "$t?ssun", "et", "aL.", "(2004)", "st?te", "that", "the", "emission", "of", "X-rays", "can", "be", "obscured", "or", "modulated", "by", "accretion", "processes,", "bat", "these", "are", "not", "the", "(irtuin", "of", "the", "X-ray", "activity"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG"]}, "BS-bid-OCR+google": {"tokens": ["Finally,", "from", "Lile", "analysis", "of", "several", "star", "forming", "regions", "in", "a", "wide", "range", "of", "ages,", "Flaccomio", "et", "al.", "(2003)", "have", "concluded", "t\\]lax", "X-ray", "actively", "increases", "with", "age,", "as", "the", "envelopes", "and", "disks", "of", "stars", "progressively", "disappear.", "Also", "$t?ssun", "et", "aL.", "(2004)", "state", "that", "the", "emission", "of", "X-rays", "can", "be", "obscured", "or", "modulated", "by", "accretion", "processes,", "bat", "these", "are", "not", "the", "(sirtuin", "of", "the", "X-ray", "activity"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG"]}}}, {"corrupt": {"tokens": ["Trade-off"], "labels": ["NONE"]}, "correct": {"tokens": ["Trade-off"], "labels": ["NONE"]}, "predicted": {"google": {"tokens": ["Trade-off"], "labels": ["NONE"]}, "BS-bid-OCR": {"tokens": ["Trade-off"], "labels": ["NONE"]}, "BS-bid-OCR+google": {"tokens": ["Trade-off"], "labels": ["NONE"]}}}, {"corrupt": {"tokens": ["Additionalmodelsysternaticuncertaintiesateattri~butedtotheSMbackgrodMLgeneratorsdescribedinsection3.Anerrorof20%onthenorlisationofNCDIS,CCD1SandphotoproductionprocesseswithatleasttwohighPTjetsi,qconsideredoaccountfortheuncertaintyonhiglmrorderQCDci~rrectionsTheerrorontheelasticandquasi-elasticQEDComptoncross\\seetionsisconservativelyestimatedtoI)e5%.TheerrorontheinelasticQEDComptolI.crosssecionis10%.Theerrorsattri1)utedtoleoptonpairandW#roductionarc3%ond15%,respectively.Thetotalerror0ntheSMhackgroundpredictionisdeterminedbyaddingtheeffectsofalimodelandGexperimontalsystematcuncertaintiesinquadratue."], "labels": ["WRONG"]}, "correct": {"tokens": ["Additional", "model", "systematic", "uncertainties", "are", "attributed", "to", "the", "SM", "background", "MC", "generators", "described", "in", "section", "3.", "An", "error", "of", "20%", "on", "the", "normalisation", "of", "NC", "DIS,", "CC", "DIS", "and", "photoproduction", "processes", "with", "at", "least", "two", "high", "PT", "jets", "is", "considered", "to", "account", "for", "the", "uncertainty", "on", "higher", "order", "QCD", "corrections.", "The", "error", "on", "the", "elastic", "and", "quasi-elastic", "QED", "Compton", "cross", "sections", "is", "conservatively", "estimated", "to", "be", "5%.", "The", "error", "on", "the", "inelastic", "QED", "Compton", "cross", "section", "is", "10%.", "The", "errors", "attributed", "to", "lepton", "pair", "and", "W", "production", "are", "3%", "and", "15%,", "respectively.", "The", "total", "error", "on", "the", "SM", "background", "prediction", "is", "determined", "by", "adding", "the", "effects", "of", "all", "model", "and", "experimental", "systematic", "uncertainties", "in", "quadrature."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED"]}, "predicted": {"google": {"tokens": ["Additionalmodelsysternaticuncertaintiesateattri~butedtotheSMbackgrodMLgeneratorsdescribedinsection3.Anerrorof20%onthenorlisationofNCDIS,CCD1SandphotoproductionprocesseswithatleasttwohighPTjetsi,qconsideredoaccountfortheuncertaintyonhiglmrorderQCDci~rrectionsTheerrorontheelasticandquasi-elasticQEDComptoncross\\seetionsisconservativelyestimatedtoI)e5%.TheerrorontheinelasticQEDComptolI.crosssecionis10%.Theerrorsattri1)utedtoleoptonpairandW#roductionarc3%ond15%,respectively.Thetotalerror0ntheSMhackgroundpredictionisdeterminedbyaddingtheeffectsofalimodelandGexperimontalsystematcuncertaintiesinquadratue."], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["Additional", "model", "systernatic", "uncertainties", "ate", "attri~buted", "to", "the", "SM", "backgrod", "ML", "generators", "described", "in", "section", "3.", "An", "error", "of", "20%", "on", "the", "norlisation", "of", "NCDIS,", "CCD1S", "and", "photoproduction", "processes", "with", "at", "least", "two", "high", "PT", "jets", "i,q", "considered", "o", "account", "for", "the", "uncertainty", "on", "higlmr", "order", "QCD", "ci~rrections", "The", "error", "on", "the", "elastic", "and", "quasi-elastic", "QED", "Compton", "cross", "\\seetions", "is", "conservatively", "estimated", "to", "I)e", "5%.", "The", "error", "on", "the", "inelastic", "QED", "ComptolI.", "cross", "secion", "is", "10%.", "The", "errors", "attri1)uted", "to", "leopton", "pair", "and", "W", "#roduction", "arc", "3%", "ond", "15%,", "respectively.", "The", "total", "error", "0n", "the", "SM", "hackground", "prediction", "is", "determined", "by", "adding", "the", "effects", "of", "ali", "model", "and", "G", "experimontal", "systematc", "uncertainties", "in", "quadratue."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG"]}, "BS-bid-OCR+google": {"tokens": ["Additional", "model", "systematic", "uncertainties", "are", "attri~buted", "to", "the", "SM", "backgrod", "ML", "generators", "described", "in", "section", "3.", "An", "error", "of", "20%", "on", "the", "normalisation", "of", "NCDIS,", "CCD1S", "and", "photoproduction", "processes", "with", "at", "least", "two", "high", "PT", "jets", "i,q", "considered", "to", "account", "for", "the", "uncertainty", "on", "higlmr", "order", "QCD", "ci~rrections", "The", "error", "on", "the", "elastic", "and", "quasi-elastic", "QED", "Compton", "cross", "\\sections", "is", "conservatively", "estimated", "to", "I)e", "5%.", "The", "error", "on", "the", "inelastic", "QED", "ComptolI.", "cross", "section", "is", "10%.", "The", "errors", "attri1)uted", "to", "leopton", "pair", "and", "W", "#production", "arc", "3%", "and", "15%,", "respectively.", "The", "total", "error", "0n", "the", "SM", "hackground", "prediction", "is", "determined", "by", "adding", "the", "effects", "of", "ali", "model", "and", "G", "experimental", "systematic", "uncertainties", "in", "quadrature."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED"]}}}, {"corrupt": {"tokens": ["ExamplesforA1"], "labels": ["WRONG"]}, "correct": {"tokens": ["Examples", "for", "A1"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["ExamplesforA1"], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["Examples", "for", "A1"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["Examples", "for", "A1"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["~herc"], "labels": ["WRONG"]}, "correct": {"tokens": ["where"], "labels": ["OCR_ERROR"]}, "predicted": {"google": {"tokens": ["~herc"], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["~herc"], "labels": ["WRONG"]}, "BS-bid-OCR+google": {"tokens": ["~herc"], "labels": ["WRONG"]}}}, {"corrupt": {"tokens": ["Introduction"], "labels": ["NONE"]}, "correct": {"tokens": ["Introduction"], "labels": ["NONE"]}, "predicted": {"google": {"tokens": ["Introduction"], "labels": ["NONE"]}, "BS-bid-OCR": {"tokens": ["Introduction"], "labels": ["NONE"]}, "BS-bid-OCR+google": {"tokens": ["Introduction"], "labels": ["NONE"]}}}, {"corrupt": {"tokens": ["NumericalMethods"], "labels": ["WRONG"]}, "correct": {"tokens": ["Numerical", "Methods"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["NumericalMethods"], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["Numerical", "Methods"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["Numerical", "Methods"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["Theospectrafortheredgiant#13414werepresentedinKM11an(tarebasedonubscrvationswiththeMagellanInamoriKykoceraE\\chelle(MIKE)spectrogra1)hattile6.5-mMagcl{an2/ClayTelescope~yieldingveryhighsgnal-to-noise(S/N)ratios.Thistargetistheonlyofthesampletocomprisethereddestechelleordercontainingsuitableand/orullcontaminatedSI-\\lines(Sect.2.1?."], "labels": ["WRONG"]}, "correct": {"tokens": ["The", "spectra", "for", "the", "red", "giant", "#13414", "were", "presented", "in", "KM11", "and", "are", "based", "on", "observations", "with", "the", "Magellan", "Inamori", "Kyocera", "Echelle", "(MIKE)", "spectrograph", "at", "the", "6.5-m", "Magellan2/Clay", "Telescope,", "yielding", "very", "high", "signal-to-noise", "(S/N)", "ratios.", "This", "target", "is", "the", "only", "of", "the", "sample", "to", "comprise", "the", "reddest", "echelle", "order", "containing", "suitable", "and/or", "uncontaminated", "S", "I-lines", "(Sect.", "2.1)."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED"]}, "predicted": {"google": {"tokens": ["Theospectrafortheredgiant#13414werepresentedinKM11an(tarebasedonubscrvationswiththeMagellanInamoriKykoceraE\\chelle(MIKE)spectrogra1)hattile6.5-mMagcl{an2/ClayTelescope~yieldingveryhighsgnal-to-noise(S/N)ratios.Thistargetistheonlyofthesampletocomprisethereddestechelleordercontainingsuitableand/orullcontaminatedSI-\\lines(Sect.2.1?."], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["Theo", "spectra", "for", "the", "red", "giant", "#13414", "were", "presented", "in", "KM11", "an(t", "are", "based", "on", "ubscrvations", "with", "the", "Magellan", "Inamori", "Kykocera", "E\\chelle", "(MIKE)", "spectrogra1)h", "at", "tile", "6.5-m", "Magcl{an2/Clay", "Telescope~", "yielding", "very", "high", "sgnal-to-noise", "(S/N)", "ratios.", "This", "target", "is", "the", "only", "of", "the", "sample", "to", "comprise", "the", "reddest", "echelle", "order", "containing", "suitable", "and/or", "ullcontaminated", "SI-\\lines", "(Sect.", "2.1?."], "labels": ["WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "WRONG"]}, "BS-bid-OCR+google": {"tokens": ["Theo", "spectra", "for", "the", "red", "giant", "#13414", "were", "presented", "in", "KM11", "an(t", "are", "based", "on", "observations", "with", "the", "Magellan", "Inamori", "Kyocera", "E\\chelle", "(MIKE)", "spectrogra1)h", "at", "tile", "6.5-m", "Magcl{an2/Clay", "Telescope~", "yielding", "very", "high", "signal-to-noise", "(S/N)", "ratios.", "This", "target", "is", "the", "only", "of", "the", "sample", "to", "comprise", "the", "reddest", "echelle", "order", "containing", "suitable", "and/or", "all", "contaminated", "SI-\\lines", "(Sect.", "2.1?."], "labels": ["WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "WRONG", "TOKENIZATION_ERROR", "WRONG"]}}}, {"corrupt": {"tokens": ["WeusedatafomOp\\enStr.eetMaps(OSM)toientifypossibleroutesandloeationsofturnsanrdwefindtheroutethatbestfitsthegivenspeeddata.OSMdataisititheform3fnodesthahet\\areassociatedwithdiff(!rentroadssoapathwillheasequenceofnode~.Eahnodehasaphysica\\llocation,.qivenbyalatitudeandlongitu\\de,allowingustodeterminedisl,ancesbetweensegmentsofroadandheturningangleoefapathofnode."], "labels": ["WRONG"]}, "correct": {"tokens": ["We", "use", "data", "from", "Open", "Street", "Maps", "(OSM)", "to", "identify", "possible", "routes", "and", "locations", "of", "turns", "and", "we", "find", "the", "route", "that", "best", "fits", "the", "given", "speed", "data.", "OSM", "data", "is", "in", "the", "form", "of", "nodes", "that", "are", "associated", "with", "different", "roads", "so", "a", "path", "will", "be", "a", "sequence", "of", "nodes.", "Each", "node", "has", "a", "physical", "location,", "given", "by", "a", "latitude", "and", "longitude,", "allowing", "us", "to", "determine", "distances", "between", "segments", "of", "road", "and", "the", "turning", "angle", "of", "a", "path", "of", "nodes."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED"]}, "predicted": {"google": {"tokens": ["WeusedatafomOp\\enStr.eetMaps(OSM)toientifypossibleroutesandloeationsofturnsanrdwefindtheroutethatbestfitsthegivenspeeddata.OSMdataisititheform3fnodesthahet\\areassociatedwithdiff(!rentroadssoapathwillheasequenceofnode~.Enode", "Hasaphysica\\location,.qivenbyalatitudeandlongitu\\de,allowingustodeterminedisl,ancesbetweensegmentsofroadandheturningangleoefapathofnode."], "labels": ["WRONG", "WRONG"]}, "BS-bid-OCR": {"tokens": ["We", "use", "data", "fom", "Op\\en", "Str.eet", "Maps", "(OSM)", "to", "ientify", "possible", "routes", "and", "loeations", "of", "turns", "anrd", "we", "find", "the", "route", "that", "best", "fits", "the", "given", "speed", "data.", "OSM", "data", "is", "iti", "the", "form", "3f", "nodes", "thahet\\", "are", "associated", "with", "diff(!rent", "roads", "so", "a", "path", "will", "he", "a", "sequence", "of", "node~.", "Eah", "node", "has", "a", "physica\\l", "location,", ".qiven", "by", "a", "latitude", "and", "longitu\\de,", "allowing", "us", "to", "determine", "disl,ances", "between", "segments", "of", "road", "and", "he", "turning", "angle", "oef", "a", "path", "of", "node."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG"]}, "BS-bid-OCR+google": {"tokens": ["We", "use", "data", "from", "Op\\en", "Street", "Maps", "(OSM)", "to", "identify", "possible", "routes", "and", "locations", "of", "turns", "and", "we", "find", "the", "route", "that", "best", "fits", "the", "given", "speed", "data.", "OSM", "data", "is", "iti", "the", "form", "3f", "nodes", "that\\", "are", "associated", "with", "diff(!rent", "roads", "so", "a", "path", "will", "he", "a", "sequence", "of", "node~.", "Each", "node", "has", "a", "physica\\l", "location,", "given", "by", "a", "latitude", "and", "longitu\\de,", "allowing", "us", "to", "determine", "diskances", "between", "segments", "of", "road", "and", "the", "turning", "angle", "of", "a", "path", "of", "node."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "WRONG", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG"]}}}, {"corrupt": {"tokens": ["Whileitiseertainlyles\\]srestrictivetoassumetnfiniteprecisionfortheaveragevaluesofthccoeftlcAcntsratherthanthecoefficientsth(;mselves,tisstillunclearwhetherthisassumptionotheavera~evaluescouldb?esatisfied.(Thein-priucipleunsatisflabilityoft?his,ontheotherhand,wouldimplythatwecannever,asamatteroffundamentals,getridofsystemaotic,asopposedlostatistical,errors.)Notealsothatinorderto\\applythecentrallimittheoremweneedtohaveafinitevarianceforthealgorithmotputs.But,astheotttputs(xi,yi)forrandomydistributedinpnts(uJ,vi)lnaynotbeboundedfromabove,itisyettobeshownthatthe,formercouldhaveafiniteva~'ianceevenifthelaterdoes."], "labels": ["WRONG"]}, "correct": {"tokens": ["While", "it", "is", "certainly", "less", "restrictive", "to", "assume", "infinite", "precision", "for", "the", "average", "values", "of", "the", "coefficients", "rather", "than", "the", "coefficients", "themselves,", "it", "is", "still", "unclear", "whether", "this", "assumption", "on", "the", "average", "values", "could", "be", "satisfied.", "(The", "in-principle", "unsatisfiability", "of", "this,", "on", "the", "other", "hand,", "would", "imply", "that", "we", "can", "never,", "as", "a", "matter", "of", "fundamentals,", "get", "rid", "of", "systematic,", "as", "opposed", "to", "statistical,", "errors.)", "Note", "also", "that", "in", "order", "to", "apply", "the", "central", "limit", "theorem", "we", "need", "to", "have", "a", "finite", "variance", "for", "the", "algorithm", "outputs.", "But,", "as", "the", "outputs", "(xi,", "yi)", "for", "randomly", "distributed", "inputs", "(ui,", "vi)", "may", "not", "be", "bounded", "from", "above,", "it", "is", "yet", "to", "be", "shown", "that", "the", "former", "could", "have", "a", "finite", "variance", "even", "if", "the", "latter", "does."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["Whileitiseertainlyles\\]srestrictivetoassumetnfiniteprecisionfortheaveragevaluesofthccoeftlcAcntsratherthanthecoefficientsth(;mselves,tisstillunclearwhetherthisassumptionotheavera~evaluescouldb?esatisfied.(Thein-priucipleunsatisflabilityoft?his,ontheotherhand,wouldimplythatwecannever,asamattero", "fundamentals,getridofsystemaotic,supposedly", "statistical,errors.)Notealsothatinorderto\\applythecentrallimittheoremweneedtohaveafinitevarianceforthealgorithmotputs.But,astheotttputs(xi,yi)forrando", "distributed", "pants(uJ,vi)lnaynotbeboundedfromabove,itisyettobeshownthatthe,formercouldhaveafiniteva~'ianceevenifthelaterdoes."], "labels": ["WRONG", "WRONG", "WRONG", "TOKENIZATION_ERROR", "WRONG"]}, "BS-bid-OCR": {"tokens": ["While", "it", "is", "eertainly", "les\\]s", "restrictive", "to", "assume", "tn", "finite", "precision", "for", "the", "average", "values", "of", "thc", "coeftlcAcnts", "rather", "than", "the", "coefficients", "th(;mselves,", "t", "is", "still", "unclear", "whether", "this", "assumption", "o", "the", "avera~e", "values", "could", "b?e", "satisfied.", "(The", "in-priuciple", "unsatisflability", "of", "t?his,", "on", "the", "other", "hand,", "would", "imply", "that", "we", "can", "never,", "as", "a", "matter", "of", "fundamentals,", "get", "rid", "of", "systemaotic,", "as", "opposed", "lo", "statistical,", "errors.)", "Note", "also", "that", "in", "order", "to", "\\apply", "the", "central", "limit", "theorem", "we", "need", "to", "have", "a", "finite", "variance", "for", "the", "algorithm", "otputs.", "But,", "as", "the", "otttputs", "(xi,", "yi)", "for", "randomy", "distributed", "inpnts", "(uJ,", "vi)", "lnay", "not", "be", "bounded", "from", "above,", "it", "is", "yet", "to", "be", "shown", "that", "the,", "former", "could", "have", "a", "finite", "va~'iance", "even", "if", "the", "later", "does."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["While", "it", "is", "certainly", "les\\]s", "restrictive", "to", "assume", "tn", "finite", "precision", "for", "the", "average", "values", "of", "thc", "coeftlcAcnts", "rather", "than", "the", "coefficients", "th(;mselves,", "it", "is", "still", "unclear", "whether", "this", "assumption", "of", "the", "avera~e", "values", "could", "be", "satisfied.", "(The", "in-principle", "unsatisfiability", "of", "this,", "on", "the", "other", "hand,", "would", "imply", "that", "we", "can", "never,", "as", "a", "matter", "of", "fundamentals,", "get", "rid", "of", "systematic,", "as", "opposed", "to", "statistical,", "errors.)", "Note", "also", "that", "in", "order", "to", "\\apply", "the", "central", "limit", "theorem", "we", "need", "to", "have", "a", "finite", "variance", "for", "the", "algorithm", "outputs.", "But,", "as", "the", "outputs", "(xi,", "yi)", "for", "randomly", "distributed", "inputs", "(uJ,", "vi)", "may", "not", "be", "bounded", "from", "above,", "it", "is", "yet", "to", "be", "shown", "that", "the", "former", "could", "have", "a", "finite", "va~'iance", "even", "if", "the", "later", "does."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "WRONG", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["Matching"], "labels": ["NONE"]}, "correct": {"tokens": ["Matching"], "labels": ["NONE"]}, "predicted": {"google": {"tokens": ["Matching"], "labels": ["NONE"]}, "BS-bid-OCR": {"tokens": ["Matching"], "labels": ["NONE"]}, "BS-bid-OCR+google": {"tokens": ["Matching"], "labels": ["NONE"]}}}, {"corrupt": {"tokens": ["thenthischangeinucesthefoIlowiltgvari;ttions:"], "labels": ["WRONG"]}, "correct": {"tokens": ["then", "this", "change", "induces", "the", "following", "variations:"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "MIXED"]}, "predicted": {"google": {"tokens": ["thenthischangeinucesthefoIlowiltgvari;ttions:"], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["then", "this", "change", "inuces", "the", "foIlowiltg", "vari;ttions:"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "WRONG"]}, "BS-bid-OCR+google": {"tokens": ["then", "this", "change", "induces", "the", "foIlowiltg", "vari;ttions:"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "WRONG", "WRONG"]}}}, {"corrupt": {"tokens": ["InitializingtheMind-Map"], "labels": ["WRONG"]}, "correct": {"tokens": ["Initializing", "the", "Mind-Map"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["InitializingtheMind-Map"], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["Initializing", "the", "Mind-Map"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["Initializing", "the", "Mind-Map"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["wheretheone-qual'kspatialwavefunction\u03c6isanS-wave.Lat,eron,theadmixtureinthegroundstateofutherspatalwavefunctionswillbeaddressed(e.g.D-wavecomponents)an~showntobeasub-l?eadingeffect.Thespin-flavormaefunctionmuctbencheretotallysymmetric,thisbeingindicatedbytileu#perlabelS."], "labels": ["WRONG"]}, "correct": {"tokens": ["where", "the", "one-quark", "spatial", "wave", "function", "\u03c6", "is", "an", "S-wave.", "Later", "on,", "the", "admixture", "in", "the", "ground", "state", "of", "other", "spatial", "wave", "functions", "will", "be", "addressed", "(e.g.", "D-wave", "components)", "and", "shown", "to", "be", "a", "sub-leading", "effect.", "The", "spin-flavor", "wave", "function", "must", "be", "here", "totally", "symmetric,", "this", "being", "indicated", "by", "the", "upper", "label", "S."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["wheretheone-qual'kspatialwavefunction\u03c6isanS-wave.Lat,eron,theadmixtureinthegroundstateofutherspatalwavefunctionswillbeaddressed(e.g.D-wave", "components)an~showntobeasub-l?eadingeffect.Thespin-flavormaefunctionmuctbencheretotallysymmetric,thisbeingindicatedbytileu#perlabelS."], "labels": ["WRONG", "WRONG"]}, "BS-bid-OCR": {"tokens": ["where", "the", "one-qual'k", "spatial", "wave", "function", "\u03c6", "is", "an", "S-wave.", "Lat,er", "on,", "the", "admixture", "in", "the", "ground", "state", "of", "uther", "spatal", "wave", "functions", "will", "be", "addressed", "(e.g.", "D-wave", "components)", "an~", "shown", "to", "be", "a", "sub-l?eading", "effect.", "The", "spin-flavor", "mae", "function", "muct", "be", "nchere", "totally", "symmetric,", "this", "being", "indicated", "by", "tile", "u#per", "label", "S."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["where", "the", "one-qual'k", "spatial", "wave", "function", "\u03c6", "is", "an", "S-wave.", "Later", "on,", "the", "admixture", "in", "the", "ground", "state", "of", "uther", "spatial", "wave", "functions", "will", "be", "addressed", "(e.g.", "D-wave", "components)", "an~", "shown", "to", "be", "a", "sub-leading", "effect.", "The", "spin-flavor", "main", "function", "must", "be", "there", "totally", "symmetric,", "this", "being", "indicated", "by", "tile", "u#per", "label", "S."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["UncertaintiesofBlackHoeMassalndStellarVelocityDisp~rsion"], "labels": ["WRONG"]}, "correct": {"tokens": ["Uncertainties", "of", "Black", "Hole", "Mass", "and", "Stellar", "Velocity", "Dispersion"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED"]}, "predicted": {"google": {"tokens": ["UncertaintiesofBlackHoeMassalndStellarVelocityDisp~rsion"], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["Uncertainties", "of", "Black", "Hoe", "Mass", "alnd", "Stellar", "Velocity", "Disp~rsion"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG"]}, "BS-bid-OCR+google": {"tokens": ["Uncertainties", "of", "Black", "Hoe", "Mass", "and", "Stellar", "Velocity", "Disp~rsion"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG"]}}}, {"corrupt": {"tokens": ["The\\root\\systemaloco.ntainsasctofofdpos*tiveroots,whichare:"], "labels": ["WRONG"]}, "correct": {"tokens": ["The", "root", "system", "also", "contains", "a", "set", "of", "odd", "positive", "roots,", "which", "are:"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["The\\root\\systemaloco.ntainsasctofofdpos*tiveroots,which", "are:"], "labels": ["WRONG", "TOKENIZATION_ERROR"]}, "BS-bid-OCR": {"tokens": ["The\\", "root", "\\system", "alo", "co.ntains", "a", "sct", "of", "ofd", "pos*tive", "roots,", "which", "are:"], "labels": ["WRONG", "TOKENIZATION_ERROR", "WRONG", "WRONG", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["The\\", "root", "\\system", "also", "contains", "a", "set", "of", "ofd", "pos*tive", "roots,", "which", "are:"], "labels": ["WRONG", "TOKENIZATION_ERROR", "WRONG", "MIXED", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["ApplithctionofRMFTtoneutronichnuclci"], "labels": ["WRONG"]}, "correct": {"tokens": ["Application", "of", "RMFT", "to", "neutron", "rich", "nuclei"], "labels": ["MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED"]}, "predicted": {"google": {"tokens": ["ApplithctionofRMFTtoneutronichnuclci"], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["Applithction", "of", "RMFT", "to", "neutron", "ich", "nuclci"], "labels": ["WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG"]}, "BS-bid-OCR+google": {"tokens": ["Application", "of", "RMFT", "to", "neutron", "rich", "nuclei"], "labels": ["MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED"]}}}, {"corrupt": {"tokens": ["acknowledgments"], "labels": ["NONE"]}, "correct": {"tokens": ["acknowledgments"], "labels": ["NONE"]}, "predicted": {"google": {"tokens": ["acknowledgments"], "labels": ["NONE"]}, "BS-bid-OCR": {"tokens": ["acknowledgments"], "labels": ["NONE"]}, "BS-bid-OCR+google": {"tokens": ["acknowledgments"], "labels": ["NONE"]}}}, {"corrupt": {"tokens": ["Nowwesumovertheoddp~trameter,b,andobta?inatwo-?variableo?rdnarygeneratingfunctionexpressibleas:"], "labels": ["WRONG"]}, "correct": {"tokens": ["Now", "we", "sum", "over", "the", "odd", "parameter,", "b,", "and", "obtain", "a", "two-variable", "ordinary", "generating", "function", "expressible", "as:"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["Nowwesumovertheoddp~trameter,b,andobta?inatwo-?variableo?rdnarygeneratingfunctionexpressibleas:"], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["Now", "we", "sum", "over", "the", "odd", "p~trameter,", "b,", "and", "obta?in", "a", "two-?variable", "o?rdnary", "generating", "function", "expressible", "as:"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["Now", "we", "sum", "over", "the", "odd", "p~trameter,", "b,", "and", "obtain", "a", "two-?variable", "or?ordinary", "generating", "function", "expressible", "as:"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["Equationofmotionfo'isotropichelicoids"], "labels": ["WRONG"]}, "correct": {"tokens": ["Equation", "of", "motion", "for", "isotropic", "helicoids"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["Equation", "Of", "Motion", "For", "Isotropic", "Helicoids"], "labels": ["TOKENIZATION_ERROR", "WRONG", "WRONG", "WRONG", "WRONG", "WRONG"]}, "BS-bid-OCR": {"tokens": ["Equation", "of", "motion", "fo'", "isotropic", "helicoids"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["Equation", "of", "motion", "for'", "isotropic", "helicoids"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["sothatforE0=0,"], "labels": ["WRONG"]}, "correct": {"tokens": ["so", "that", "for", "E0", "=", "0,"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["sothatforE0=0,"], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["so", "that", "for", "E0", "=", "0,"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["so", "that", "for", "E0", "=", "0,"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["rNoisydynam_icswithinthetrap"], "labels": ["WRONG"]}, "correct": {"tokens": ["Noisy", "dynamics", "within", "the", "trap"], "labels": ["TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["rNoisydynam_icswithinthetrap"], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["rNoisy", "dynam_ics", "within", "the", "trap"], "labels": ["WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["rNoisy", "dynam_ics", "within", "the", "trap"], "labels": ["WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["F.WGehring,L.MaclaehlanandG.J.Martinl~rovedasimilarreultinthecaseofKleiniangroul>s."], "labels": ["WRONG"]}, "correct": {"tokens": ["F.", "W", "Gehring,", "C.", "Maclachlan", "and", "G.", "J.", "Martin", "proved", "a", "similar", "result", "in", "the", "case", "of", "Kleinian", "groups."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED"]}, "predicted": {"google": {"tokens": ["FW", "Gehring,L.MaclaehlanandG.J.Martinl~rovedasimilarreultinthecaseofKleiniangroul>s."], "labels": ["WRONG", "WRONG"]}, "BS-bid-OCR": {"tokens": ["F.W", "Gehring,", "L.", "Maclaehlan", "and", "G.", "J.", "Martin", "l~roved", "a", "similar", "reult", "in", "the", "case", "of", "Kleinian", "groul>s."], "labels": ["WRONG", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG"]}, "BS-bid-OCR+google": {"tokens": ["F.W", "Gehring,", "L.", "Maclaehlan", "and", "G.", "J.", "Martin", "l~roved", "a", "similar", "result", "in", "the", "case", "of", "Kleinian", "groul>s."], "labels": ["WRONG", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG"]}}}, {"corrupt": {"tokens": ["DF"], "labels": ["NONE"]}, "correct": {"tokens": ["DF"], "labels": ["NONE"]}, "predicted": {"google": {"tokens": ["DF"], "labels": ["NONE"]}, "BS-bid-OCR": {"tokens": ["DF"], "labels": ["NONE"]}, "BS-bid-OCR+google": {"tokens": ["DF"], "labels": ["NONE"]}}}, {"corrupt": {"tokens": ["For\u03c9obtain"], "labels": ["WRONG"]}, "correct": {"tokens": ["For", "\u03c9", "obtain"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["For\u03c9obtain"], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["For", "\u03c9", "obtain"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["For", "\u03c9", "obtain"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["E~idenceshowsthattheevolutionotblackholesandthatoftheirhostgaarlaxiesappeartobecloselycouple.Itwasfoundthatthereis?stronflcorrelat~onbetweethecentralblackholemasses,Mbh,andtheirbulgestellarvelocitydispersion,\u03c3.Tremaineetal.(2002)investigatedthisrelatinshipinasampleof31nearby1inactivegalaxiesandgnw~'~t)etterexpressinas,"], "labels": ["WRONG"]}, "correct": {"tokens": ["Evidence", "shows", "that", "the", "evolution", "of", "black", "holes", "and", "that", "of", "their", "host", "galaxies", "appear", "to", "be", "closely", "coupled.", "It", "was", "found", "that", "there", "is", "strong", "correlation", "between", "the", "central", "black", "hole", "masses,", "Mbh,", "and", "their", "bulge", "stellar", "velocity", "dispersion,", "\u03c3.", "Tremaine", "et", "al.", "(2002)", "investigated", "this", "relationship", "in", "a", "sample", "of", "31", "nearby", "inactive", "galaxies", "and", "gave", "a", "better", "expression", "as,"], "labels": ["MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "MIXED", "MIXED", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["E~idenceshowsthattheevolutionotblackholesandthatoftheirhostgaarlaxiesappeartobecloselycouple.Itwasfoundthatthereis?stronflcorrelat~onbetweethecentralblackholemasses,Mbh,andtheirbulgestellarvelocitydispersion,\u03c3.Tremaineetal.(2002)investigatedthisrelatinshipinasampleof31nearby1inactivegalaxiesandgnw~'~t)etterexpressinas,"], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["E~idence", "shows", "that", "the", "evolution", "ot", "black", "holes", "and", "that", "of", "their", "host", "gaarlaxies", "appear", "to", "be", "closely", "couple.", "It", "was", "found", "that", "there", "is", "?", "stronfl", "correlat~on", "betwee", "the", "central", "black", "hole", "masses,", "Mbh,", "and", "their", "bulge", "stellar", "velocity", "dispersion,", "\u03c3.", "Tremaine", "et", "al.", "(2002)", "investigated", "this", "relatinship", "in", "a", "sample", "of", "31", "nearby", "1", "inactive", "galaxies", "and", "gnw~'~", "t)etter", "expressin", "as,"], "labels": ["WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "WRONG", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["E~idence", "shows", "that", "the", "evolution", "ot", "black", "holes", "and", "that", "of", "their", "host", "galaxies", "appear", "to", "be", "closely", "coupled.", "It", "was", "found", "that", "there", "is", "?", "strong", "correlat~on", "between", "the", "central", "black", "hole", "masses,", "Mbh,", "and", "their", "bulge", "stellar", "velocity", "dispersion,", "\u03c3.", "Tremaine", "et", "al.", "(2002)", "investigated", "this", "relationship", "in", "a", "sample", "of", "31", "nearby", "1", "inactive", "galaxies", "and", "gnw~'~", "t)letter", "expressing", "as,"], "labels": ["WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "MIXED", "WRONG", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "WRONG", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["Wegetfor\\eth('bosonicgraphs(a):"], "labels": ["WRONG"]}, "correct": {"tokens": ["We", "get", "for", "the", "bosonic", "graphs", "(a):"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["Wegetfor\\eth('bosonic", "graphs(a):"], "labels": ["WRONG", "WRONG"]}, "BS-bid-OCR": {"tokens": ["We", "get", "for\\", "eth('", "bosonic", "graphs", "(a):"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["We", "get", "for\\", "eth('", "bosonic", "graphs", "(a):"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["Moinresults"], "labels": ["WRONG"]}, "correct": {"tokens": ["Main", "results"], "labels": ["MIXED", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["Moin", "Results"], "labels": ["WRONG", "WRONG"]}, "BS-bid-OCR": {"tokens": ["Moin", "results"], "labels": ["WRONG", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["Moin", "results"], "labels": ["WRONG", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["Thesum?oftheabovetermsyieldstherosulofourcalculation:"], "labels": ["WRONG"]}, "correct": {"tokens": ["The", "sum", "of", "the", "above", "terms", "yields", "the", "result", "of", "our", "calculation:"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["The", "Sun?ofthe", "abovetermsyieldstherosulofourcalculation:"], "labels": ["TOKENIZATION_ERROR", "WRONG", "WRONG"]}, "BS-bid-OCR": {"tokens": ["The", "sum?", "of", "the", "above", "terms", "yields", "the", "rosul", "of", "our", "calculation:"], "labels": ["TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["The", "sum?", "of", "the", "above", "terms", "yields", "the", "rosul", "of", "our", "calculation:"], "labels": ["TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["K.M.wassupportedbytheMarieCurieFP7-PEOPLE-2009-IEFprgram,=-Bothauthorsthan~M.?Drozforuefuldiscussionsatthdearlystageofthiswork."], "labels": ["WRONG"]}, "correct": {"tokens": ["K.", "M.", "was", "supported", "by", "the", "Marie", "Curie", "FP7-PEOPLE-2009-IEF", "program.", "Both", "authors", "thank", "M.", "Droz", "for", "useful", "discussions", "at", "the", "early", "stage", "of", "this", "work."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["K.M.wassupportedbytheMarieCurieFP7-PEOPLE-2009-IEFprgram,=-Bothauthorsthan~M.?Drozforuefuldiscussionsatthdearlystageofthiswork."], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["K.M.", "was", "supported", "by", "the", "Marie", "Curie", "FP7-PEOPLE-2009-IEF", "prgram,=-", "Both", "authors", "than~", "M.", "?Droz", "for", "ueful", "discussions", "at", "thd", "early", "stage", "of", "this", "work."], "labels": ["WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["K.M.", "was", "supported", "by", "the", "Marie", "Curie", "FP7-PEOPLE-2009-IEF", "program,=-", "Both", "authors", "than~", "M.", "?Droz", "for", "useful", "discussions", "at", "the", "early", "stage", "of", "this", "work."], "labels": ["WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["Hei,erodyriedetection"], "labels": ["WRONG"]}, "correct": {"tokens": ["Heterodyne", "detection"], "labels": ["MIXED", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["Hei,erodyriedetection"], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["Hei,erodyrie", "detection"], "labels": ["WRONG", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["Hei,erodyrie", "detection"], "labels": ["WRONG", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["foralgt>0."], "labels": ["WRONG"]}, "correct": {"tokens": ["for", "all", "t", ">", "0."], "labels": ["TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["ford", "gt>0."], "labels": ["WRONG", "WRONG"]}, "BS-bid-OCR": {"tokens": ["for", "alg", "t", ">", "0."], "labels": ["TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["for", "alg", "t", ">", "0."], "labels": ["TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["Introduction"], "labels": ["NONE"]}, "correct": {"tokens": ["Introduction"], "labels": ["NONE"]}, "predicted": {"google": {"tokens": ["Introduction"], "labels": ["NONE"]}, "BS-bid-OCR": {"tokens": ["Introduction"], "labels": ["NONE"]}, "BS-bid-OCR+google": {"tokens": ["Introduction"], "labels": ["NONE"]}}}, {"corrupt": {"tokens": ["ModelPotential"], "labels": ["WRONG"]}, "correct": {"tokens": ["Model", "Potentials"], "labels": ["TOKENIZATION_ERROR", "MIXED"]}, "predicted": {"google": {"tokens": ["ModelPotential"], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["Model", "Potential"], "labels": ["TOKENIZATION_ERROR", "WRONG"]}, "BS-bid-OCR+google": {"tokens": ["Model", "Potential"], "labels": ["TOKENIZATION_ERROR", "WRONG"]}}}, {"corrupt": {"tokens": ["ForlargeN\\,thisbec()mes"], "labels": ["WRONG"]}, "correct": {"tokens": ["For", "large", "N,", "this", "becomes"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED"]}, "predicted": {"google": {"tokens": ["ForlargeN\\,thisbec()mes"], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["For", "large", "N\\,", "this", "bec()mes"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG"]}, "BS-bid-OCR+google": {"tokens": ["For", "large", "N\\,", "this", "bec()mes"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG"]}}}, {"corrupt": {"tokens": ["ItiswideSybelievedthottoconstructthecompletetheoryofst.rongprocessesoneneedstomaketwostcps:"], "labels": ["WRONG"]}, "correct": {"tokens": ["It", "is", "widely", "believed", "that", "to", "construct", "the", "complete", "theory", "of", "strong", "processes", "one", "needs", "to", "make", "two", "steps:"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED"]}, "predicted": {"google": {"tokens": ["ItiswideSybelievedthottoconstructthecompletetheoryofst.rongprocessesoneneedstomaketwostcps:"], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["It", "is", "wideSy", "believed", "thot", "to", "construct", "the", "complete", "theory", "of", "st.rong", "processes", "one", "needs", "to", "make", "two", "stcps:"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG"]}, "BS-bid-OCR+google": {"tokens": ["It", "is", "wideSy", "believed", "thot", "to", "construct", "the", "complete", "theory", "of", "strong", "processes", "one", "needs", "to", "make", "two", "stcps:"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG"]}}}, {"corrupt": {"tokens": ["WW\u03b3/Zp?roductionintheRandallSundruramodelattheZHCahdCLIC"], "labels": ["WRONG"]}, "correct": {"tokens": ["WW\u03b3/Z", "production", "in", "the", "Randall-Sundrum", "model", "at", "the", "LHC", "and", "CLIC"], "labels": ["TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["WW\u03b3/Zp?roductionintheRandallSundruramodelattheZHCahdCLIC"], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["WW\u03b3/Z", "p?roduction", "in", "the", "Randall", "Sundrura", "model", "at", "the", "ZHC", "ahd", "CLIC"], "labels": ["TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["WW\u03b3/Z", "production", "in", "the", "Randall", "Sundrura", "model", "at", "the", "ZHC", "ahd", "CLIC"], "labels": ["TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["Acivelayer"], "labels": ["WRONG"]}, "correct": {"tokens": ["Active", "layer"], "labels": ["MIXED", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["Active", "Layer"], "labels": ["MIXED", "WRONG"]}, "BS-bid-OCR": {"tokens": ["Acive", "layer"], "labels": ["WRONG", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["Active", "layer"], "labels": ["MIXED", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["Thefollowingshouldbewellknown,butweprovideaproof."], "labels": ["WRONG"]}, "correct": {"tokens": ["The", "following", "should", "be", "well", "known,", "but", "we", "provide", "a", "proof."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["Thefollowingshouldbewellknown,butweprovideaproof."], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["The", "following", "should", "be", "well", "known,", "but", "we", "provide", "a", "proof."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["The", "following", "should", "be", "well", "known,", "but", "we", "provide", "a", "proof."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["Inthispaper,wefocus~donapproachesforcleanin.ginconsistentwebdata.Weshowedtha\\tthecurrentstteofth(',artapproaches,whichlearnanduseconditionalfunctionaldependen('ies(CFDs)torecltifydat\\a,donotworkyellwIthwebdataastheydsmandcleanmasterdataR)rtraining.Weproposedafullyprobabilisticfralneworkforc.leaningdatathatinvotvedlearningboththegenerativ&anderrEo.r(corruption)modelsofthedaaandns/ngthemtocleanthedata.Forgenerativemodels,welearnBayesnetworksfromthdata.Forexi'ormodels,weconsitieramaximumentropyframeworkforcombingmultipleer:corprocesses.Tilegenefativeanderrormodelsarelear.ueddire?ctlytromtlienoisydata.Pr.eiimcinaryexperimentalresultsonwetlbdatashowedthatourprobabilis??ticapproachlsabletoreduceerrorsin~hedtalongafte?.CFD-basedmethodsfailtobee1fective."], "labels": ["WRONG"]}, "correct": {"tokens": ["In", "this", "paper,", "we", "focused", "on", "approaches", "for", "cleaning", "inconsistent", "web", "data.", "We", "showed", "that", "the", "current", "state", "of", "the", "art", "approaches,", "which", "learn", "and", "use", "conditional", "functional", "dependencies", "(CFDs)", "to", "rectify", "data,", "do", "not", "work", "well", "with", "web", "data", "as", "they", "demand", "clean", "master", "data", "for", "training.", "We", "proposed", "a", "fully", "probabilistic", "framework", "for", "cleaning", "data", "that", "involved", "learning", "both", "the", "generative", "and", "error", "(corruption)", "models", "of", "the", "data", "and", "using", "them", "to", "clean", "the", "data.", "For", "generative", "models,", "we", "learn", "Bayes", "networks", "from", "the", "data.", "For", "error", "models,", "we", "consider", "a", "maximum", "entropy", "framework", "for", "combing", "multiple", "error", "processes.", "The", "generative", "and", "error", "models", "are", "learned", "directly", "from", "the", "noisy", "data.", "Preliminary", "experimental", "results", "on", "web", "data", "showed", "that", "our", "probabilistic", "approach", "is", "able", "to", "reduce", "errors", "in", "the", "data", "long", "after", "CFD-based", "methods", "fail", "to", "be", "effective."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED"]}, "predicted": {"google": {"tokens": ["Inthispaper,wefocus~donapproachesforcleanin.ginconsistentwebdata.Weshowedtha\\tthecurrentstteofth(',art", "approaches,which", "learn", "and", "use", "conditional", "functional", "dependency('ies(CFDs)torecltifydat\\a,donotworkyellwIthwebdataastheydsmandcleanmasterdataR)rtraining.Weproposedafullyprobabilisticfralneworkforc.leaningdatathatinvotvedlearningboththegenerativ&anderrEo.r(corruption)modelsofthedaaandns/ngthemtocleanthedata.Forgenerativemodels,welearnBayesnetworksfromthdata.Forexi'ormodels,weconsitieramaximumentropyframeworkforcombingmultipleer:corprocesses.Tilegenefativeanderrormodelsarelear.ueddire?ctlytromtlienoisydata.Pr.eiimcinaryexperimentalresultsonwetlbdatashowedthatourprobabilis??ticapproachlsabletoreduceerrorsin~hedtalongafte?.CFD-basedmethodsfailtobee1fective."], "labels": ["WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG"]}, "BS-bid-OCR": {"tokens": ["In", "this", "paper,", "we", "focus~d", "on", "approaches", "for", "cleanin.g", "inconsistent", "web", "data.", "We", "showed", "tha\\t", "the", "current", "stte", "of", "th(',", "art", "approaches,", "which", "learn", "and", "use", "conditional", "functional", "dependen('ies", "(CFDs)", "to", "recltify", "dat\\a,", "do", "not", "work", "yell", "wIth", "web", "data", "as", "they", "dsmand", "clean", "master", "data", "R)r", "training.", "We", "proposed", "a", "fully", "probabilistic", "fralnework", "for", "c.leaning", "data", "that", "invotved", "learning", "both", "the", "generativ&", "and", "errEo.r", "(corruption)", "models", "of", "the", "daa", "and", "ns/ng", "them", "to", "clean", "the", "data.", "For", "generative", "models,", "we", "learn", "Bayes", "networks", "from", "th", "data.", "For", "exi'or", "models,", "we", "consitier", "a", "maximum", "entropy", "framework", "for", "combing", "multiple", "er:cor", "processes.", "Tile", "genefative", "and", "error", "models", "are", "lear.ued", "dire?ctly", "trom", "tlie", "noisy", "data.", "Pr.eiimcinary", "experimental", "results", "on", "wetlb", "data", "showed", "that", "our", "probabilis??tic", "approach", "ls", "able", "to", "reduce", "errors", "in", "~he", "dta", "long", "afte?.", "CFD-based", "methods", "fail", "to", "be", "e1fective."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG"]}, "BS-bid-OCR+google": {"tokens": ["In", "this", "paper,", "we", "focus~d", "on", "approaches", "for", "cleaning", "inconsistent", "web", "data.", "We", "showed", "tha\\t", "the", "current", "state", "of", "th(',", "art", "approaches,", "which", "learn", "and", "use", "conditional", "functional", "dependency('ies", "(CFDs)", "to", "rectify", "dat\\a,", "do", "not", "work", "well", "wIth", "web", "data", "as", "they", "dsmand", "clean", "master", "data", "R)r", "training.", "We", "proposed", "a", "fully", "probabilistic", "framework", "for", "cleaning", "data", "that", "involves", "learning", "both", "the", "generative", "and", "errEo.r", "(corruption)", "models", "of", "the", "daa", "and", "ns/ng", "them", "to", "clean", "the", "data.", "For", "generative", "models,", "we", "learn", "Bayes", "networks", "from", "the", "data.", "For", "export", "models,", "we", "consider", "a", "maximum", "entropy", "framework", "for", "combining", "multiple", "er:core", "processes.", "Tile", "generative", "and", "error", "models", "are", "lear.used", "directly", "from", "tile", "noisy", "data.", "Pre.preliminary", "experimental", "results", "on", "web", "data", "showed", "that", "our", "probabilistic", "approach", "is", "able", "to", "reduce", "errors", "in", "the", "data", "long", "after?.", "CFD-based", "methods", "fail", "to", "be", "effective."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "MIXED", "MIXED", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED"]}}}, {"corrupt": {"tokens": ["Forafei'mionfieldtheresultfrtheffectivescalefactorisalmostidenlicaltoth@scalarcane"], "labels": ["WRONG"]}, "correct": {"tokens": ["For", "a", "fermion", "field", "the", "result", "for", "the", "effective", "scale", "factor", "is", "almost", "identical", "to", "the", "scalar", "case"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED"]}, "predicted": {"google": {"tokens": ["Forafei'mionfieldtheresultfrtheffectivescalefactorisalmostidenlicaltoth@scalarcane"], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["For", "a", "fei'mion", "field", "the", "result", "fr", "th", "effective", "scale", "factor", "is", "almost", "idenlical", "to", "th@", "scalar", "cane"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG"]}, "BS-bid-OCR+google": {"tokens": ["For", "a", "fermion", "field", "the", "result", "fr", "th", "effective", "scale", "factor", "is", "almost", "identical", "to", "th@", "scalar", "cane"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG"]}}}, {"corrupt": {"tokens": ["whereN~sanormalizationconstant,la\u03b2theinveretemperature,Pol(X(t))apolynomialintheapositionoperatorandTaprescripionoftimeordering."], "labels": ["WRONG"]}, "correct": {"tokens": ["where", "N", "is", "a", "normalization", "constant,", "\u03b2", "the", "inverse", "temperature,", "Pol(X(t))", "a", "polynomial", "in", "the", "position", "operator", "and", "T", "a", "prescription", "of", "time", "ordering."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["whereN~a", "normalization", "constant,la\u03b2theinveretemperature,Pol(X(t))apolynomialintheapositionoperatorandTaprescripionoftimeordering."], "labels": ["WRONG", "TOKENIZATION_ERROR", "WRONG"]}, "BS-bid-OCR": {"tokens": ["where", "N", "~s", "a", "normalization", "constant,", "la\u03b2", "the", "invere", "temperature,", "Pol(X(t))", "a", "polynomial", "in", "the", "a", "position", "operator", "and", "T", "a", "prescripion", "of", "time", "ordering."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["where", "N", "~s", "a", "normalization", "constant,", "la\u03b2", "the", "inverse", "temperature,", "Pol(X(t))", "a", "polynomial", "in", "the", "a", "position", "operator", "and", "T", "a", "prescription", "of", "time", "ordering."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["and"], "labels": ["NONE"]}, "correct": {"tokens": ["and"], "labels": ["NONE"]}, "predicted": {"google": {"tokens": ["and"], "labels": ["NONE"]}, "BS-bid-OCR": {"tokens": ["and"], "labels": ["NONE"]}, "BS-bid-OCR+google": {"tokens": ["and"], "labels": ["NONE"]}}}, {"corrupt": {"tokens": ["Inonclusi(m7,weneelthatitisdifficulttoaccountforatransversepolarizationwithinthecontextoftheminimalesupersymmetrcextensionofthestadar(lmodelevenaftermakngallorenceforfamilymixlllgandflavorviolations'"], "labels": ["WRONG"]}, "correct": {"tokens": ["In", "conclusion,", "we", "feel", "that", "it", "is", "difficult", "to", "account", "for", "a", "transverse", "polarization", "within", "the", "context", "of", "the", "minimal", "supersymmetric", "extension", "of", "the", "standard", "model", "even", "after", "making", "allowence", "for", "family", "mixing", "and", "flavor", "violations."], "labels": ["TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED"]}, "predicted": {"google": {"tokens": ["Inonclusi(m7,weneelthatitisdifficulttoaccountforatransversepolarizationwithinthecontextoftheminimalesupersymmetrcextensionofthestadar(lmodelevenaftermakngallorenceforfamilymixlllgandflavorviolations'"], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["In", "onclusi(m7,", "we", "neel", "that", "it", "is", "difficult", "to", "account", "for", "a", "transverse", "polarization", "within", "the", "context", "of", "the", "minimale", "supersymmetrc", "extension", "of", "the", "stadar(l", "model", "even", "after", "makng", "allorence", "for", "family", "mixlllg", "and", "flavor", "violations'"], "labels": ["TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG"]}, "BS-bid-OCR+google": {"tokens": ["In", "conclusion(m7,", "we", "neel", "that", "it", "is", "difficult", "to", "account", "for", "a", "transverse", "polarization", "within", "the", "context", "of", "the", "minimal", "supersymmetric", "extension", "of", "the", "standard(l", "model", "even", "after", "making", "allowance", "for", "family", "milling", "and", "flavor", "violations'"], "labels": ["TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG"]}}}, {"corrupt": {"tokens": ["where\u03be1,\u03be2asciidcopiesof\u03be."], "labels": ["WRONG"]}, "correct": {"tokens": ["where", "\u03be1,", "\u03be2", "are", "iid", "copies", "of", "\u03be."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["where\u03be1,\u03be2asciidcopiesof\u03be."], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["where", "\u03be1,", "\u03be2", "as", "ciid", "copies", "of", "\u03be."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["where", "\u03be1,", "\u03be2", "as", "ciid", "copies", "of", "\u03be."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["Ourgamehasawiderangeofapplications,e.g.,whencompanieschoosetimestotakeactions,andeg.,wheninvestorswhobothshort;rodlongAmericanoptiontrytomaximizetheirutilities."], "labels": ["WRONG"]}, "correct": {"tokens": ["Our", "game", "has", "a", "wide", "range", "of", "applications,", "e.g.,", "when", "companies", "choose", "times", "to", "take", "actions,", "and", "e.g.,", "when", "investors", "who", "both", "short", "and", "long", "American", "options", "try", "to", "maximize", "their", "utilities."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["Our", "Game", "Has", "A", "Wide", "Range", "Of", "Applications,e.g.,whencompanieschoosetimestotakeactions,andeg.,wheninvestorswhobothshort;rodlongAmericanoptiontrytomaximizetheirutilities."], "labels": ["TOKENIZATION_ERROR", "WRONG", "WRONG", "WRONG", "WRONG", "WRONG", "WRONG", "WRONG"]}, "BS-bid-OCR": {"tokens": ["Our", "game", "has", "a", "wide", "range", "of", "applications,", "e.g.,", "when", "companies", "choose", "times", "to", "take", "actions,", "and", "eg.,", "when", "investors", "who", "both", "short", ";rod", "long", "American", "option", "try", "to", "maximize", "their", "utilities."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["Our", "game", "has", "a", "wide", "range", "of", "applications,", "e.g.,", "when", "companies", "choose", "times", "to", "take", "actions,", "and", "eg.,", "when", "investors", "who", "both", "short", ";rod", "long", "American", "options", "try", "to", "maximize", "their", "utilities."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["Tht:energyemittedatradiusrandLorentzfactor\u03b3(r)willbeobservedaroundatlme:"], "labels": ["WRONG"]}, "correct": {"tokens": ["The", "energy", "emitted", "at", "radius", "r", "and", "Lorentz", "factor", "\u03b3(r)", "will", "be", "observed", "around", "a", "time:"], "labels": ["MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED"]}, "predicted": {"google": {"tokens": ["Tht:energyemittedatradiusrandLorentzfactor\u03b3(r)will", "be", "observed", "around", "at", "me:"], "labels": ["WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG"]}, "BS-bid-OCR": {"tokens": ["Tht:", "energy", "emitted", "at", "radius", "r", "and", "Lorentz", "factor", "\u03b3(r)", "will", "be", "observed", "around", "a", "tlme:"], "labels": ["WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG"]}, "BS-bid-OCR+google": {"tokens": ["Tht:", "energy", "emitted", "at", "radius", "r", "and", "Lorentz", "factor", "\u03b3(r)", "will", "be", "observed", "around", "a", "time:"], "labels": ["WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED"]}}}, {"corrupt": {"tokens": ["WethushaveforeachEatWodImensional~paceofeig\\ensolutions,whichareoftheform:"], "labels": ["WRONG"]}, "correct": {"tokens": ["We", "thus", "have", "for", "each", "E", "a", "two", "dimensional", "space", "of", "eigensolutions,", "which", "are", "of", "the", "form:"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["WethushaveforeachEatWo", "dImensional~pace", "eigensolutions,whichareoftheform:"], "labels": ["WRONG", "WRONG", "WRONG"]}, "BS-bid-OCR": {"tokens": ["We", "thus", "have", "for", "each", "E", "a", "tWo", "dImensional", "~pace", "of", "eig\\ensolutions,", "which", "are", "of", "the", "form:"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["We", "thus", "have", "for", "each", "E", "a", "tWo", "dImensional", "~pace", "of", "eig\\ensolutions,", "which", "are", "of", "the", "form:"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["Wenow?define"], "labels": ["WRONG"]}, "correct": {"tokens": ["We", "now", "define"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["Wenow?define"], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["We", "now", "?define"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG"]}, "BS-bid-OCR+google": {"tokens": ["We", "now", "?define"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG"]}}}, {"corrupt": {"tokens": ["Asprviouslymentioned,Eobtainsasmallgainforeachtime-stepanhonestnodeiswithinthenetwork,andasmalllossforeachtime-tepo~minliciousnoderemainsinhenetwork.Formally,wcanwritethatthetctalgainGweobtainfr(msotoenodei,whichEremavesattimeN,andwhichwouldvoluntarilyleave\\attimrHi:"], "labels": ["WRONG"]}, "correct": {"tokens": ["As", "previously", "mentioned,", "E", "obtains", "a", "small", "gain", "for", "each", "time-step", "an", "honest", "node", "is", "within", "the", "network,", "and", "a", "small", "loss", "for", "each", "time-step", "a", "malicious", "node", "remains", "in", "the", "network.", "Formally,", "we", "can", "write", "that", "the", "total", "gain", "G", "we", "obtain", "from", "some", "node", "i,", "which", "E", "removes", "at", "time", "N,", "and", "which", "would", "voluntarily", "leave", "at", "time", "H", "is:"], "labels": ["TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED"]}, "predicted": {"google": {"tokens": ["Asprviouslymentioned,Eobtainsasmallgainforeachtime-stepanhonestnodeiswithinthenetwork,andasmalllossforeachtime-tepo~minliciousnoderemainsinhenetwork.Formally,wcanwritethatthetctalgainGweobtainfr(msotoenodei,whichEremavesattimeN,andwhichwouldvoluntarilyleave\\attimrHi:"], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["As", "prviously", "mentioned,", "E", "obtains", "a", "small", "gain", "for", "each", "time-step", "an", "honest", "node", "is", "within", "the", "network,", "and", "a", "small", "loss", "for", "each", "time-tep", "o~", "minlicious", "node", "remains", "in", "he", "network.", "Formally,", "w", "can", "write", "that", "the", "tctal", "gain", "G", "we", "obtain", "fr(m", "sotoe", "node", "i,", "which", "Eremaves", "at", "time", "N,", "and", "which", "would", "voluntarily", "leave", "\\at", "timr", "H", "i:"], "labels": ["TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "WRONG"]}, "BS-bid-OCR+google": {"tokens": ["As", "previously", "mentioned,", "E", "obtains", "a", "small", "gain", "for", "each", "time-step", "an", "honest", "node", "is", "within", "the", "network,", "and", "a", "small", "loss", "for", "each", "time-tep", "o~", "malicious", "node", "remains", "in", "the", "network.", "Formally,", "we", "can", "write", "that", "the", "total", "gain", "G", "we", "obtain", "fr(m", "sotoe", "node", "i,", "which", "Eremaves", "at", "time", "N,", "and", "which", "would", "voluntarily", "leave", "\\at", "time", "H", "i:"], "labels": ["TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "MIXED", "TOKENIZATION_ERROR", "WRONG"]}}}, {"corrupt": {"tokens": ["Thus,theambiguityinthechoiceofthehadroniccontinuumhres\\holdandtheparameterofthesumruleschemeesenliallyreducesthereliabilityoftheQcDsumru'le1)redictioufortheleptoniceonstantsofthevectorandpseudoscalarRcstates."], "labels": ["WRONG"]}, "correct": {"tokens": ["Thus,", "the", "ambiguity", "in", "the", "choice", "of", "the", "hadronic", "continuum", "threshold", "and", "the", "parameter", "of", "the", "sum", "rule", "scheme", "essentially", "reduces", "the", "reliability", "of", "the", "QCD", "sum", "rule", "predictions", "for", "the", "leptonic", "constants", "of", "the", "vector", "and", "pseudoscalar", "Bc", "states."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["Thus,theambiguityinthechoiceofthehadroniccontinuumhres\\holdandtheparameterofthesumruleschemeesenliallyreducesthereliabilityoftheQcDsumru'le1)redictioufortheleptoniceonstantsofthevectorandpseudoscalarRcstates."], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["Thus,", "the", "ambiguity", "in", "the", "choice", "of", "the", "hadronic", "continuum", "hres\\hold", "and", "the", "parameter", "of", "the", "sum", "rule", "scheme", "esenlially", "reduces", "the", "reliability", "of", "the", "QcD", "sum", "ru'le", "1)redictiou", "for", "the", "leptonic", "eonstants", "of", "the", "vector", "and", "pseudoscalar", "Rc", "states."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["Thus,", "the", "ambiguity", "in", "the", "choice", "of", "the", "hadronic", "continuum", "hres\\hold", "and", "the", "parameter", "of", "the", "sum", "rule", "scheme", "essentially", "reduces", "the", "reliability", "of", "the", "QcD", "sum", "rule", "1)redictiou", "for", "the", "leptonic", "constants", "of", "the", "vector", "and", "pseudoscalar", "Rc", "states."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "MIXED", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["Introduction"], "labels": ["NONE"]}, "correct": {"tokens": ["Introduction"], "labels": ["NONE"]}, "predicted": {"google": {"tokens": ["Introduction"], "labels": ["NONE"]}, "BS-bid-OCR": {"tokens": ["Introduction"], "labels": ["NONE"]}, "BS-bid-OCR+google": {"tokens": ["Introduction"], "labels": ["NONE"]}}}, {"corrupt": {"tokens": ["GoingovertothSM4,weobtain"], "labels": ["WRONG"]}, "correct": {"tokens": ["Going", "over", "to", "the", "SM4,", "we", "obtain"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["GoingovertothSM4,we", "obtain"], "labels": ["WRONG", "TOKENIZATION_ERROR"]}, "BS-bid-OCR": {"tokens": ["Going", "over", "to", "th", "SM4,", "we", "obtain"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["Going", "over", "to", "th", "SM4,", "we", "obtain"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["with"], "labels": ["NONE"]}, "correct": {"tokens": ["with"], "labels": ["NONE"]}, "predicted": {"google": {"tokens": ["with"], "labels": ["NONE"]}, "BS-bid-OCR": {"tokens": ["with"], "labels": ["NONE"]}, "BS-bid-OCR+google": {"tokens": ["with"], "labels": ["NONE"]}}}, {"corrupt": {"tokens": ["Le(;Pb(~asimplepolygonintheplnane,t\\hatis,aclosedregionboundedbyapiece-wiselimear,simplecyeJe.AtriangulationTofPisageometrit(straight-line)maximaloulerplana?rgiaphwhoseouterfaceisthecomplementofPandwhosevertexs(tconsistsoftheverticesorfP.I'heedgesofTthatarenotontheouterfacearecalleddiagonal.LetdbeadiaqonalwhoseremovalcreatesaconveXquadrilateral(.Replacingdwnththeothe,'diagonaloffyIeldsanothertriangulationofP.Thisoperatlolliscalledaflip..The\\flipgrapilofPir,heabstractgraphwhoseverti?cesarethetriangulationsofPandin~whichtwotriangulationsareadjaccntifandonlyiftheydifferbyasingle1'lp.Westudytheflipdista\\ncesi.e.,theminimumnum1)erofflipsrequiredtotransformagi\\vensourcctriangulationintoatargotrisngulaion."], "labels": ["WRONG"]}, "correct": {"tokens": ["Let", "P", "be", "a", "simple", "polygon", "in", "the", "plane,", "that", "is,", "a", "closed", "region", "bounded", "by", "a", "piece-wise", "linear,", "simple", "cycle.", "A", "triangulation", "T", "of", "P", "is", "a", "geometric", "(straight-line)", "maximal", "outerplanar", "graph", "whose", "outer", "face", "is", "the", "complement", "of", "P", "and", "whose", "vertex", "set", "consists", "of", "the", "vertices", "of", "P.", "The", "edges", "of", "T", "that", "are", "not", "on", "the", "outer", "face", "are", "called", "diagonals.", "Let", "d", "be", "a", "diagonal", "whose", "removal", "creates", "a", "convex", "quadrilateral", "f.", "Replacing", "d", "with", "the", "other", "diagonal", "of", "f", "yields", "another", "triangulation", "of", "P.", "This", "operation", "is", "called", "a", "flip.", "The", "flip", "graph", "of", "P", "is", "the", "abstract", "graph", "whose", "vertices", "are", "the", "triangulations", "of", "P", "and", "in", "which", "two", "triangulations", "are", "adjacent", "if", "and", "only", "if", "they", "differ", "by", "a", "single", "flip.", "We", "study", "the", "flip", "distance,", "i.e.,", "the", "minimum", "number", "of", "flips", "required", "to", "transform", "a", "given", "source", "triangulation", "into", "a", "target", "triangulation."], "labels": ["MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED"]}, "predicted": {"google": {"tokens": ["Le(;Pb(~asimplepolygonintheplnane,t\\hatis,aclosedregionboundedbyapiece-wiselimear,simplecyeJe.AtriangulationTofPisageometrit(straight-line)maximaloulerplana?rgiaphwhoseouterfaceisthecomplementofPandwhosevertexs(tconsistsoftheverticesorfP.I'heedgesofTthatarenotontheouterfacearecalleddiagonal.LetdbeadiaqonalwhoseremovalcreatesaconveXquadrilateral(.Replacingdwnththeothe,'diagonaloffyIeldsanothertriangulationofP.Thisoperatlolliscalledaflip..The\\flipgrapilofPir,heabstractgraphwhoseverti?cesarethetriangulationsofPandin~whichtwotriangulationsareadjaccntifandonlyiftheydifferbyasingle1'lp.Westudytheflipdista\\ncesi.e.,theminimumnum1)erofflipsrequiredtotransformagi\\vensourcctriangulationintoatargotrisngulaion."], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["Le(;", "P", "b(~", "a", "simple", "polygon", "in", "the", "plnane,", "t\\hat", "is,", "a", "closed", "region", "bounded", "by", "a", "piece-wise", "limear,", "simple", "cyeJe.", "A", "triangulation", "T", "of", "P", "is", "a", "geometrit", "(straight-line)", "maximal", "ouler", "plana?r", "giaph", "whose", "outer", "face", "is", "the", "complement", "of", "P", "and", "whose", "vertex", "s(t", "consists", "of", "the", "vertices", "orf", "P.", "I'he", "edges", "of", "T", "that", "are", "not", "on", "the", "outer", "face", "are", "called", "diagonal.", "Let", "d", "be", "a", "diaqonal", "whose", "removal", "creates", "a", "conveX", "quadrilateral", "(.", "Replacing", "d", "wnth", "the", "othe,'", "diagonal", "of", "f", "yIelds", "another", "triangulation", "of", "P.", "This", "operatloll", "is", "called", "a", "flip..", "The\\", "flip", "grapil", "of", "P", "ir,", "he", "abstract", "graph", "whose", "verti?ces", "are", "the", "triangulations", "of", "P", "and", "in", "~which", "two", "triangulations", "are", "adjaccnt", "if", "and", "only", "if", "they", "differ", "by", "a", "single", "1'lp.", "We", "study", "the", "flip", "dista\\nces", "i.e.,", "the", "minimum", "num1)er", "of", "flips", "required", "to", "transform", "a", "gi\\ven", "sourcc", "triangulation", "into", "a", "targo", "trisngulaion."], "labels": ["WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG"]}, "BS-bid-OCR+google": {"tokens": ["Le(;", "P", "b(~", "a", "simple", "polygon", "in", "the", "plane,", "t\\hat", "is,", "a", "closed", "region", "bounded", "by", "a", "piecewise", "linear,", "simple", "coJe.", "A", "triangulation", "T", "of", "P", "is", "a", "geometric", "(straight-line)", "maximal", "euler", "planar", "graph", "whose", "outer", "face", "is", "the", "complement", "of", "P", "and", "whose", "vertex", "s(t", "consists", "of", "the", "vertices", "of", "P.", "I've", "edges", "of", "T", "that", "are", "not", "on", "the", "outer", "face", "are", "called", "diagonal.", "Let", "d", "be", "a", "diagonal", "whose", "removal", "creates", "a", "conveX", "quadrilateral", "(.", "Replacing", "d", "with", "the", "other,'", "diagonal", "of", "f", "yIelds", "another", "triangulation", "of", "P.", "This", "operation", "is", "called", "a", "flip..", "The\\", "flip", "grapil", "of", "P", "ir,", "the", "abstract", "graph", "whose", "vertices", "are", "the", "triangulations", "of", "P", "and", "in", "~which", "two", "triangulations", "are", "adjacent", "if", "and", "only", "if", "they", "differ", "by", "a", "single", "1'lp.", "We", "study", "the", "flip", "dista\\nces", "i.e.,", "the", "minimum", "num1)er", "of", "flips", "required", "to", "transform", "a", "gi\\ven", "source", "triangulation", "into", "a", "targo", "triangulation."], "labels": ["WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "MIXED", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "MIXED"]}}}, {"corrupt": {"tokens": ["Proof:Astraightfo~wardcomputationshowMsthat"], "labels": ["WRONG"]}, "correct": {"tokens": ["Proof:", "A", "straight", "forward", "computation", "shows", "that"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["Proof:Astraightfo~wardcomputationshowMsthat"], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["Proof:", "A", "straightfo~ward", "computation", "showMs", "that"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["Proof:", "A", "straightfo~ward", "computation", "showMs", "that"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["So,"], "labels": ["NONE"]}, "correct": {"tokens": ["So,"], "labels": ["NONE"]}, "predicted": {"google": {"tokens": ["So,"], "labels": ["NONE"]}, "BS-bid-OCR": {"tokens": ["So,"], "labels": ["NONE"]}, "BS-bid-OCR+google": {"tokens": ["So,"], "labels": ["NONE"]}}}, {"corrupt": {"tokens": ["where"], "labels": ["NONE"]}, "correct": {"tokens": ["where"], "labels": ["NONE"]}, "predicted": {"google": {"tokens": ["where"], "labels": ["NONE"]}, "BS-bid-OCR": {"tokens": ["where"], "labels": ["NONE"]}, "BS-bid-OCR+google": {"tokens": ["where"], "labels": ["NONE"]}}}, {"corrupt": {"tokens": ["J.Ftacnik,P.Lic\\hardandJ.Pitsul.,Phys\u0003Lett.B207(1988)194."], "labels": ["WRONG"]}, "correct": {"tokens": ["J.", "Ftacnik,", "P.", "Lichard", "and", "J.", "Pitsut,", "Phys.", "Lett.", "B207", "(1988)", "194."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["J.Ftacnik,P.Lic\\hardandJ.Pitsul.,PhysLett.B207(1988)194."], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["J.", "Ftacnik,", "P.", "Lic\\hard", "and", "J.", "Pitsul.,", "Phys\u0003", "Lett.", "B207", "(1988)", "194."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["J.", "Ftacnik,", "P.", "Lic\\hard", "and", "J.", "Pitsul.,", "Phys", "Lett.", "B207", "(1988)", "194."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["Generalk-gons"], "labels": ["WRONG"]}, "correct": {"tokens": ["General", "k-gons"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["General-gons"], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["General", "k-gons"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["General", "k-gons"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["Amongthem,rixraayberelatedtothetheoryofocto.nions:cases(1),(2)andtheirrealforms."], "labels": ["WRONG"]}, "correct": {"tokens": ["Among", "them,", "six", "may", "be", "related", "to", "the", "theory", "of", "octonions:", "cases", "(1),", "(2)", "and", "their", "real", "forms."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["Amongthem,rixraayberelatedtothetheoryofocto.nions:cases(1),(2)and", "their", "real", "forms."], "labels": ["WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR": {"tokens": ["Among", "the", "m,rix", "raay", "be", "related", "to", "the", "theory", "of", "octo.nions:", "cases", "(1),", "(2)", "and", "their", "real", "forms."], "labels": ["TOKENIZATION_ERROR", "WRONG", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["Among", "them,rix", "raay", "be", "related", "to", "the", "theory", "of", "octonions:", "cases", "(1),", "(2)", "and", "their", "real", "forms."], "labels": ["TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["Thescatteri~gamplitudecomputatiouivesfoPNMG:"], "labels": ["WRONG"]}, "correct": {"tokens": ["The", "scattering", "amplitude", "computation", "gives", "for", "NMG:"], "labels": ["TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "MIXED", "MIXED", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["Thescatteri~gamplitudecomputatiouivesfoPNMG:"], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["The", "scatteri~g", "amplitude", "computatiou", "ives", "foP", "NMG:"], "labels": ["TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "WRONG", "WRONG", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["The", "scatteri~g", "amplitude", "computation", "ives", "foP", "NMG:"], "labels": ["TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "MIXED", "WRONG", "WRONG", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["StarFormati<)nfromurbulenFragmentation"], "labels": ["WRONG"]}, "correct": {"tokens": ["Star", "Formation", "from", "Turbulent", "Fragmentation"], "labels": ["TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["StarFormati<)nfromurbulenFragmentation"], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["Star", "Formati<)n", "from", "urbulen", "Fragmentation"], "labels": ["TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["Star", "Formati<)n", "from", "turbulent", "Fragmentation"], "labels": ["TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["Therelationshipbetweenb,thefly-byeccentricityeaudth8pericentredistancer0is"], "labels": ["WRONG"]}, "correct": {"tokens": ["The", "relationship", "between", "b,", "the", "fly-by", "eccentricity", "e", "and", "the", "pericentre", "distance", "r0", "is"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["Therelationshipbetweenb,the", "fly-by", "eccentricity", "aud", "th8", "pericentredistancer0is"], "labels": ["WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "WRONG"]}, "BS-bid-OCR": {"tokens": ["The", "relationship", "between", "b,", "the", "fly-by", "eccentricity", "e", "aud", "th8", "pericentre", "distance", "r0", "is"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["The", "relationship", "between", "b,", "the", "fly-by", "eccentricity", "e", "aud", "th8", "pericentre", "distance", "r0", "is"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["Inordertocomputenon-reversiblefunctionsbyreversiblecircuitsweapplythefol?lowingconvention."], "labels": ["WRONG"]}, "correct": {"tokens": ["In", "order", "to", "compute", "non-reversible", "functions", "by", "reversible", "circuits", "we", "apply", "the", "following", "convention."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["Inordertocomputenon-reversiblefunctionsbyreversiblecircuitsweapplythefol?lowingconvention."], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["In", "order", "to", "compute", "non-reversible", "functions", "by", "reversible", "circuits", "we", "apply", "the", "fol?lowing", "convention."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["In", "order", "to", "compute", "non-reversible", "functions", "by", "reversible", "circuits", "we", "apply", "the", "following", "convention."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["Thesealeonlytwoexamplesoftlieinnumerablediscussionswet~c~donphysicsandotherthiilgsaswell,lnyostlyinwritJng,becauselifedidnommakeourtra~ectorisinteoorsectsooften.ThelastlongseriesofdiscussionsIhadwithhimtookl)laceinTurku,Finland,atthemeetingofthes\\p,riflg1991.Almosteveryevening\\,weueream1)ulatingaroundthebiglawninfrontofthedirtingroom,tryingi.oreconstruct,athisrequest,thcargumentswhichproducetheexistenceof27straightlinesonanunruledthirddegreesurfac~e.That?wasapreIudetohislal.erwOrkonenumerativegeometry."], "labels": ["WRONG"]}, "correct": {"tokens": ["These", "are", "only", "two", "examples", "of", "the", "innumerable", "discussions", "we", "had", "on", "physics", "and", "other", "things", "as", "well,", "mostly", "in", "writing,", "because", "life", "did", "not", "make", "our", "trajectories", "intersect", "so", "often.", "The", "last", "long", "series", "of", "discussions", "I", "had", "with", "him", "took", "place", "in", "Turku,", "Finland,", "at", "the", "meeting", "of", "the", "spring", "1991.", "Almost", "every", "evening,", "we", "were", "ambulating", "around", "the", "big", "lawn", "in", "front", "of", "the", "dining", "room,", "trying", "to", "reconstruct,", "at", "his", "request,", "the", "arguments", "which", "produce", "the", "existence", "of", "27", "straight", "lines", "on", "an", "unruled", "third", "degree", "surface.", "That", "was", "a", "prelude", "to", "his", "later", "work", "on", "enumerative", "geometry."], "labels": ["TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["Thesealeonlytwoexamplesoftlieinnumerablediscussionswet~c~donphysicsandotherthiilgsaswell,lnyostlyinwritJng,becauselifedidnommakeourtra~ectorisinteoorsectsooften.ThelastlongseriesofdiscussionsIhadwithhimtookl)lace", "Turku,Finland,atthemeetingofthes\\p,rifle", "1991.Almost", "Every", "Evening\\,weueream1)ulatingaroundthebiglawninfrontofthedirtingroom,tryingi.oreconstruct,athisrequest,thcargumentswhichproducetheexistenceof27straightlinesonanunruledthirddegreesurfac~e.That?wasapreIudetohislal.erwOrkonenumerativegeometry."], "labels": ["WRONG", "WRONG", "WRONG", "WRONG", "WRONG"]}, "BS-bid-OCR": {"tokens": ["These", "ale", "only", "two", "examples", "of", "tlie", "innumerable", "discussions", "we", "t~c~d", "on", "physics", "and", "other", "thiilgs", "as", "well,", "lnyostly", "in", "writJng,", "because", "life", "did", "nom", "make", "our", "tra~ectoris", "inteoorsects", "o", "often.", "The", "last", "long", "series", "of", "discussions", "I", "had", "with", "him", "took", "l)lace", "in", "Turku,", "Finland,", "at", "the", "meeting", "of", "the", "s\\p,riflg", "1991.", "Almost", "every", "evening\\,", "we", "uere", "am1)ulating", "around", "the", "big", "lawn", "in", "front", "of", "the", "dirting", "room,", "trying", "i.o", "reconstruct,", "at", "his", "request,", "thc", "arguments", "which", "produce", "the", "existence", "of", "27", "straight", "lines", "on", "an", "unruled", "third", "degree", "surfac~e.", "That", "?was", "a", "preIude", "to", "his", "lal.er", "wOrk", "on", "enumerative", "geometry."], "labels": ["TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["These", "are", "only", "two", "examples", "of", "innumerable", "discussions", "we", "t~c~d", "on", "physics", "and", "other", "things", "as", "well,", "lastly", "in", "writIng,", "because", "life", "didn't", "make", "our", "tra~pectoris", "intersect", "so", "often.", "The", "last", "long", "series", "of", "discussions", "I", "had", "with", "him", "took", "l)lace", "in", "Turku,", "Finland,", "at", "the", "meeting", "of", "the", "s\\p,riflg", "1991.", "Almost", "every", "evening\\,", "we", "were", "am1)ulating", "around", "the", "big", "lawn", "in", "front", "of", "the", "dirting", "room,", "trying", "t.o", "reconstruct,", "at", "his", "request,", "thc", "arguments", "which", "produce", "the", "existence", "of", "27", "straight", "lines", "on", "an", "unruled", "third", "degree", "surface.", "That", "?was", "a", "preLude", "to", "his", "lal.er", "wOrk", "on", "enumerative", "geometry."], "labels": ["TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "MIXED", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["Proc~ssing:"], "labels": ["WRONG"]}, "correct": {"tokens": ["Processing:"], "labels": ["OCR_ERROR"]}, "predicted": {"google": {"tokens": ["Proc~ssing:"], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["Proc~ssing:"], "labels": ["WRONG"]}, "BS-bid-OCR+google": {"tokens": ["Proc~ssing:"], "labels": ["WRONG"]}}}, {"corrupt": {"tokens": ["11i12223333"], "labels": ["WRONG"]}, "correct": {"tokens": ["1", "1", "1", "1", "2", "2", "2", "3", "3", "3", "3"], "labels": ["MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["11i12223333"], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["11i12223333"], "labels": ["WRONG"]}, "BS-bid-OCR+google": {"tokens": ["11i12223333"], "labels": ["WRONG"]}}}, {"corrupt": {"tokens": ["Cal)tions"], "labels": ["WRONG"]}, "correct": {"tokens": ["Captions"], "labels": ["OCR_ERROR"]}, "predicted": {"google": {"tokens": ["Cal)tions"], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["Cal)tions"], "labels": ["WRONG"]}, "BS-bid-OCR+google": {"tokens": ["Cal)tions"], "labels": ["WRONG"]}}}, {"corrupt": {"tokens": ["Coarse-gr\\ainedhydrody?namicequation"], "labels": ["WRONG"]}, "correct": {"tokens": ["Coarse-grained", "hydrodynamic", "equation"], "labels": ["MIXED", "MIXED", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["Coarse-gr\\ainedhydrody?namicequation"], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["Coarse-gr\\ained", "hydrody?namic", "equation"], "labels": ["WRONG", "WRONG", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["Coarse-gr\\ained", "hydrodynamic", "equation"], "labels": ["WRONG", "MIXED", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["Ifweusetheconstraint"], "labels": ["WRONG"]}, "correct": {"tokens": ["If", "we", "use", "the", "constraint"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["Ifweusetheconstraint"], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["If", "we", "use", "the", "constraint"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["If", "we", "use", "the", "constraint"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["Webeginwiththevetrys\\impletabieforazero-welghtedscalarT,"], "labels": ["WRONG"]}, "correct": {"tokens": ["We", "begin", "with", "the", "very", "simple", "table", "for", "a", "zero-weighted", "scalar", "T,"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["Webeginwiththevetrys\\impletabieforazero-welghtedscalarT,"], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["We", "begin", "with", "the", "vetry", "s\\imple", "tabie", "for", "a", "zero-welghted", "scalar", "T,"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["We", "begin", "with", "the", "very", "s\\imple", "table", "for", "a", "zero-weighted", "scalar", "T,"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "WRONG", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["D-cohomologyOroupsforHormalSheof"], "labels": ["WRONG"]}, "correct": {"tokens": ["D-cohomology", "Groups", "for", "Normal", "Sheaf"], "labels": ["TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "MIXED"]}, "predicted": {"google": {"tokens": ["D-cohomologyOroupsforHormalSheof"], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["D-cohomology", "Oroups", "for", "Hormal", "Sheof"], "labels": ["TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "WRONG"]}, "BS-bid-OCR+google": {"tokens": ["D-cohomology", "Groups", "for", "Hormonal", "Shelf"], "labels": ["TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "WRONG", "WRONG"]}}}, {"corrupt": {"tokens": ["\u03b8runsftom0to\u03c0,aud\u03c6an(l\u03b1rurfrom0to2\u03c0.Underthisparametrizal;ion.wefindtiatthenletricbecomes"], "labels": ["WRONG"]}, "correct": {"tokens": ["\u03b8", "runs", "from", "0", "to", "\u03c0,", "and", "\u03c6", "and", "\u03b1", "run", "from", "0", "to", "2\u03c0.", "Under", "this", "parametrization", "we", "find", "that", "the", "metric", "becomes"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["\u03b8runsftom0to\u03c0,aud\u03c6an(l\u03b1rurfrom0to2\u03c0.Underthisparametrizal;ion.wefindtiatthenletricbecomes"], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["\u03b8", "runs", "ftom", "0", "to", "\u03c0,", "aud", "\u03c6", "an(l", "\u03b1", "rur", "from", "0", "to", "2\u03c0.", "Under", "this", "parametrizal;ion.", "we", "find", "tiat", "the", "nletric", "becomes"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["\u03b8", "runs", "from", "0", "to", "\u03c0,", "aud", "\u03c6", "an(l", "\u03b1", "rur", "from", "0", "to", "2\u03c0.", "Under", "this", "parametrizar;ion.", "we", "find", "that", "the", "metric", "becomes"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["TheUVllghts(o9urce"], "labels": ["WRONG"]}, "correct": {"tokens": ["The", "UV", "light", "source"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED"]}, "predicted": {"google": {"tokens": ["The", "Lights(o9urce"], "labels": ["TOKENIZATION_ERROR", "WRONG"]}, "BS-bid-OCR": {"tokens": ["The", "UV", "llght", "s(o9urce"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG"]}, "BS-bid-OCR+google": {"tokens": ["The", "UV", "lights(o9urce"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG"]}}}, {"corrupt": {"tokens": ["then"], "labels": ["NONE"]}, "correct": {"tokens": ["then"], "labels": ["NONE"]}, "predicted": {"google": {"tokens": ["then"], "labels": ["NONE"]}, "BS-bid-OCR": {"tokens": ["then"], "labels": ["NONE"]}, "BS-bid-OCR+google": {"tokens": ["then"], "labels": ["NONE"]}}}, {"corrupt": {"tokens": ["PACSnumber(s):04.50.+h,98.80.Hw,04.60.Kz"], "labels": ["WRONG"]}, "correct": {"tokens": ["PACS", "number(s):", "04.50.+h,", "98.80.Hw,", "04.60.Kz"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["PACSnumber(s):04.50.+h,98.80.Hw,04.60.Kz"], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["PACS", "number(s):", "04.50.+h,", "98.80.Hw,", "04.60.Kz"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["PACS", "number(s):", "04.50.+h,", "98.80.Hw,", "04.60.Kz"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["Henceinparcicular,forRsufficientlybig:"], "labels": ["WRONG"]}, "correct": {"tokens": ["Hence", "in", "particular,", "for", "R", "sufficiently", "big:"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["Hence", "In", "Particular,for", "sufficiently", "big:"], "labels": ["TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR": {"tokens": ["Hence", "in", "parcicular,", "for", "R", "sufficiently", "big:"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["Hence", "in", "particular,", "for", "R", "sufficiently", "big:"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["Noticefirstthat"], "labels": ["WRONG"]}, "correct": {"tokens": ["Notice", "first", "that"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["Notice", "First", "That"], "labels": ["TOKENIZATION_ERROR", "WRONG", "WRONG"]}, "BS-bid-OCR": {"tokens": ["Notice", "first", "that"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["Notice", "first", "that"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["InthefolZowinqwecomparethepropertiesofNS2andNS3withthose?ofpuresilicawhichwehaveinvestigatedinrecentsimulation.ThedetailsofthelatlercanbefoundinHorbachandKob(1999a).Weonlymentionherethattt)hesesimulations~reredonealsoattliedensity2.B7g/cmsillthetemperaturerange6100K\u2265T\u22653750Kfor~asyst~maf?016l)articlcs.~letwoproductionrunsattlmlowesttemperat~urewereove~about\\20usrenltime,andthepl'e6sureatthistemper,atureis0.9GPa."], "labels": ["WRONG"]}, "correct": {"tokens": ["In", "the", "following", "we", "compare", "the", "properties", "of", "NS2", "and", "NS3", "with", "those", "of", "pure", "silica", "which", "we", "have", "investigated", "in", "recent", "simulation.", "The", "details", "of", "the", "latter", "can", "be", "found", "in", "Horbach", "and", "Kob", "(1999a).", "We", "only", "mention", "here", "that", "these", "simulations", "were", "done", "also", "at", "the", "density", "2.37g/cm3", "in", "the", "temperature", "range", "6100", "K", "\u2265", "T", "\u2265", "2750", "K", "for", "a", "system", "of", "8016", "particles.", "The", "two", "production", "runs", "at", "the", "lowest", "temperature", "were", "over", "about", "20", "ns", "real", "time,", "and", "the", "pressure", "at", "this", "temperature", "is", "0.9", "GPa."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "MIXED", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["InthefolZowinqwecomparethepropertiesofNS2andNS3withthose?ofpuresilicawhichwehaveinvestigatedinrecentsimulation.ThedetailsofthelatlercanbefoundinHorbachandKob(1999a).We", "Only", "Mention", "Here", "That)hesesimulations~reredonealsoattliedensity2.B7g/cmsillthetemperaturerange6100K\u2265T\u22653750Kfor~asyst~maf?016l)articlcs.~letwoproductionrunsattlmlowesttemperat~urewereove~about\\20usrenltime,andthepl'e6sureatthistemper,atureis0.9GPa."], "labels": ["WRONG", "WRONG", "WRONG", "WRONG", "WRONG"]}, "BS-bid-OCR": {"tokens": ["In", "the", "folZowinq", "we", "compare", "the", "properties", "of", "NS2", "and", "NS3", "with", "those?", "of", "pure", "silica", "which", "we", "have", "investigated", "in", "recent", "simulation.", "The", "details", "of", "the", "latler", "can", "be", "found", "in", "Horbach", "and", "Kob", "(1999a).", "We", "only", "mention", "here", "that", "tt)hese", "simulations", "~rere", "done", "also", "at", "tlie", "density", "2.B7", "g/cms", "ill", "the", "temperature", "range", "6100", "K", "\u2265", "T", "\u2265", "3750", "K", "for", "~a", "syst~m", "af", "?016", "l)articlcs.", "~le", "two", "production", "runs", "at", "tlm", "lowest", "temperat~ure", "were", "ove~", "about", "\\20", "usrenl", "time,", "and", "the", "pl'e6sure", "at", "this", "temper,ature", "is", "0.9", "GPa."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "WRONG", "WRONG", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["In", "the", "folZowinq", "we", "compare", "the", "properties", "of", "NS2", "and", "NS3", "with", "those", "of", "pure", "silica", "which", "we", "have", "investigated", "in", "recent", "simulation.", "The", "details", "of", "the", "latter", "can", "be", "found", "in", "Horbach", "and", "Kob", "(1999a).", "We", "only", "mention", "here", "that", "tt)these", "simulations", "~were", "done", "also", "at", "tile", "density", "2.B7", "g/cms.", "Will", "the", "temperature", "range", "6100", "K", "\u2265", "T", "\u2265", "3750", "K", "for", "~a", "syst~m", "af", "?016", "l)articles.", "~le", "two", "production", "runs", "at", "tlm", "lowest", "temperat~ure", "were", "ove~", "about", "\\20", "israel", "time,", "and", "the", "pl'e6sure", "at", "this", "temperature", "is", "0.9", "GPa."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "WRONG", "WRONG", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["NeLxtdefine"], "labels": ["WRONG"]}, "correct": {"tokens": ["Next", "define"], "labels": ["MIXED", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["Next", "define"], "labels": ["MIXED", "TOKENIZATION_ERROR"]}, "BS-bid-OCR": {"tokens": ["NeLxt", "define"], "labels": ["WRONG", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["Next", "define"], "labels": ["MIXED", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["AcknowledgmentsS.F.,A.P.andJ.Z.aresupportedinp(artbytheMinisl;ryolEducati()n,Scie\"nceandSportofthc\\RepublicofSlovenia."], "labels": ["WRONG"]}, "correct": {"tokens": ["Acknowledgments", "S.F.,", "A.P.", "and", "J.Z.", "are", "supported", "in", "part", "by", "the", "Ministry", "of", "Education,", "Science", "and", "Sport", "of", "the", "Republic", "of", "Slovenia."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["AcknowledgmentsS.F.,A.P.andJ.Z.aresupportedinp(artbytheMinisl;ryolEducati()n,Scie\"nceandSportofthc\\RepublicofSlovenia."], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["Acknowledgments", "S.F.,", "A.P.", "and", "J.Z.", "are", "supported", "in", "p(art", "by", "the", "Minisl;ry", "ol", "Educati()n,", "Scie\"nce", "and", "Sport", "of", "thc", "\\Republic", "of", "Slovenia."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["Acknowledgments", "S.F.,", "A.P.", "and", "J.Z.", "are", "supported", "in", "p(art", "by", "the", "Minish;ry", "ol", "Education()n,", "Scie\"nce", "and", "Sport", "of", "thc", "\\Republic", "of", "Slovenia."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["Therearet?wofilestobeedited:ateztfileparam*inputwheretheparametersareet,andaMathematicafiletemplate*.mwherenthetuntion(s)tebeintegratedaredefined.Inmoredetail:"], "labels": ["WRONG"]}, "correct": {"tokens": ["There", "are", "two", "files", "to", "be", "edited:", "a", "text", "file", "param*.input", "where", "the", "parameters", "are", "set,", "and", "a", "Mathematica", "file", "template*.m", "where", "the", "funtion(s)", "to", "be", "integrated", "are", "defined.", "In", "more", "detail:"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["Therearet?filestube", "edited:latest", "fileparam*input", "wheretheparametersareet,and", "Mathematica", "file", "template*.mwherenthetuntion(s)tebe", "integrated", "are", "defined.In", "More", "Detail:"], "labels": ["WRONG", "WRONG", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "WRONG"]}, "BS-bid-OCR": {"tokens": ["There", "are", "t?wo", "files", "to", "be", "edited:", "a", "tezt", "file", "param*input", "where", "the", "parameters", "are", "et,", "and", "a", "Mathematica", "file", "template*.m", "wheren", "the", "tuntion", "(s)", "te", "be", "integrated", "are", "defined.", "In", "more", "detail:"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["There", "are", "two", "files", "to", "be", "edited:", "a", "text", "file", "param*input", "where", "the", "parameters", "are", "et,", "and", "a", "Mathematica", "file", "template*.m", "wherein", "the", "tuntion", "(s)", "to", "be", "integrated", "are", "defined.", "In", "more", "detail:"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "WRONG", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["Onend\u00e9duitaussildr\u00e9sultat:"], "labels": ["WRONG"]}, "correct": {"tokens": ["On", "en", "d\u00e9duit", "aussi", "le", "r\u00e9sultat:"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["Onend\u00e9duitaussildr\u00e9sultat:"], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["On", "en", "d\u00e9duit", "aussild", "r\u00e9sultat:"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["On", "en", "d\u00e9duit", "aussi", "le", "r\u00e9sultat:"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["Then,wehavethatw(z)isanalyticbin|z|<|z0|,w(0)=0,|w(z)|<1for|z|<|z0|;rod"], "labels": ["WRONG"]}, "correct": {"tokens": ["Then,", "we", "have", "that", "w(z)", "is", "analytic", "in", "|z", "|", "<|z0", "|,", "w(0)", "=", "0,", "|w(z)", "|", "<1", "for", "|z", "|", "<|z0", "|", "and"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED"]}, "predicted": {"google": {"tokens": ["Then,wehavethatw(z)isanalyticbin|z|<|z0|,w(0)=0,|w(z)|<1", "for|z|<|z0|;rod"], "labels": ["WRONG", "WRONG"]}, "BS-bid-OCR": {"tokens": ["Then,", "we", "have", "that", "w(z)", "is", "analytic", "bin", "|z", "|", "<|z0", "|,", "w(0)", "=", "0,", "|w(z)", "|", "<1", "for", "|z", "|", "<|z0", "|", ";rod"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG"]}, "BS-bid-OCR+google": {"tokens": ["Then,", "we", "have", "that", "w(z)", "is", "analytic", "bin", "|z", "|", "<|z0", "|,", "w(0)", "=", "0,", "|w(z)", "|", "<1", "for", "|z", "|", "<|z0", "|", ";rod"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG"]}}}, {"corrupt": {"tokens": ["Obtainedresu\\[ts"], "labels": ["WRONG"]}, "correct": {"tokens": ["Obtained", "results"], "labels": ["TOKENIZATION_ERROR", "MIXED"]}, "predicted": {"google": {"tokens": ["Obtained", "Resu\\[ts"], "labels": ["TOKENIZATION_ERROR", "WRONG"]}, "BS-bid-OCR": {"tokens": ["Obtained", "resu\\[ts"], "labels": ["TOKENIZATION_ERROR", "WRONG"]}, "BS-bid-OCR+google": {"tokens": ["Obtained", "resu\\[ts"], "labels": ["TOKENIZATION_ERROR", "WRONG"]}}}, {"corrupt": {"tokens": ["Theproofiscomplete."], "labels": ["WRONG"]}, "correct": {"tokens": ["The", "proof", "is", "complete."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["The", "Proof", "Is", "Complete."], "labels": ["TOKENIZATION_ERROR", "WRONG", "WRONG", "WRONG"]}, "BS-bid-OCR": {"tokens": ["The", "proof", "is", "complete."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["The", "proof", "is", "complete."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["ApplicationtoPhysicalproblensivolvingmuterialpoints"], "labels": ["WRONG"]}, "correct": {"tokens": ["Application", "to", "physical", "problems", "involving", "material", "points"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "MIXED", "MIXED", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["ApplicationtoPhysicalproblensivolvingmuterialpoints"], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["Application", "to", "Physical", "problens", "ivolving", "muterial", "points"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "WRONG", "WRONG", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["Application", "to", "Physical", "problems", "involving", "material", "points"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "MIXED", "MIXED", "MIXED", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["SoonafterGeneralRelativity(?R)wasfirstint,rodnced,,severalattemptstoformalternatiw'~theoriesofgravitywheremade.Someofth4\\mostinterestingwerethosebasedonaneffort,tobuildamoregeneralheorybydr1oppingoneormoreofthesevera|assumptionsofGR,lilcthefactthattheonlydeKreesoffreedomofthegravitationalfieldarethoseofthemnetric,ortsimplicitychoiCethatthegravitational.Lagrangianshouldbealinearfunctiono'thescalarcur\\vature."], "labels": ["WRONG"]}, "correct": {"tokens": ["Soon", "after", "General", "Relativity", "(GR)", "was", "first", "introduced,", "several", "attempts", "to", "form", "alternative", "theories", "of", "gravity", "where", "made.", "Some", "of", "the", "most", "interesting", "were", "those", "based", "on", "an", "effort", "to", "build", "a", "more", "general", "theory", "by", "dropping", "one", "or", "more", "of", "the", "several", "assumptions", "of", "GR,", "like", "the", "fact", "that", "the", "only", "degrees", "of", "freedom", "of", "the", "gravitational", "field", "are", "those", "of", "the", "metric,", "or", "the", "simplicity", "choice", "that", "the", "gravitational", "Lagrangian", "should", "be", "a", "linear", "function", "of", "the", "scalar", "curvature."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED"]}, "predicted": {"google": {"tokens": ["SoonafterGeneralRelativity(?R)wasfirstint,rodnced,,severalattemptstoformalternatiw'~theoriesofgravitywheremade.Someofth4\\mostinterestingwerethosebasedonaneffort,tobuildamoregeneralheorybydr1oppingoneormoreofthesevera|assumptionsofGR,lilcthefactthattheonlydeKreesoffreedomofthegravitationalfieldarethoseofthemnetric,ortsimplicitychoiCethatthegravitational.Lagrangianshouldbealinearfunctiono'thescalarcur\\vature."], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["Soon", "after", "General", "Relativity", "(?R)", "was", "first", "int,rodnced,,", "several", "attempts", "to", "form", "alternatiw'~", "theories", "of", "gravity", "where", "made.", "Some", "of", "th4\\", "most", "interesting", "were", "those", "based", "on", "an", "effort,", "to", "build", "a", "more", "general", "heory", "by", "dr1opping", "one", "or", "more", "of", "the", "severa|", "assumptions", "of", "GR,", "lilc", "the", "fact", "that", "the", "only", "deKrees", "of", "freedom", "of", "the", "gravitational", "field", "are", "those", "of", "the", "mnetric,", "or", "t", "simplicity", "choiCe", "that", "the", "gravitational", ".Lagrangian", "should", "be", "a", "linear", "function", "o'", "the", "scalar", "cur\\vature."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG"]}, "BS-bid-OCR+google": {"tokens": ["Soon", "after", "General", "Relativity", "(?R)", "was", "first", "into,produced,", "several", "attempts", "to", "form", "alternative'~", "theories", "of", "gravity", "where", "made.", "Some", "of", "th4\\", "most", "interesting", "were", "those", "based", "on", "an", "effort,", "to", "build", "a", "more", "general", "theory", "by", "dropping", "one", "or", "more", "of", "the", "several|", "assumptions", "of", "GR,", "lilc", "the", "fact", "that", "the", "only", "deKrees", "of", "freedom", "of", "the", "gravitational", "field", "are", "those", "of", "the", "metric,", "or", "to", "simply", "choose", "that", "the", "gravitational", "Lagrangian", "should", "be", "a", "linear", "function", "o'", "the", "scalar", "cur\\vature."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "WRONG", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG"]}}}, {"corrupt": {"tokens": ["Thisstudywasmadewitirtwocomplementatyapproaches.\"CMDfittingandfullspectrumfitting.ThefirstmehoduesCMDsusuallyobtainedwithHST/ACS~whilethelastuseslongsltspectrathatcanbeacquiredonagroundbasedt\\eleescop.ThetwomethodsareconsistentandilisnotablethatthefullspecEtrmfittingcangivefinerconstrainsonthemetallicity.Infullspectrumfitting,themetallicltyisdirectlycons\\trainedbythemetalabs<)rpl;ion\\[ineslromthestars,whileCMDsrelyonConbroadbandscoloursandonstellarevolutlonmodels.ItlsthefirsttimetilatadetailedspectroseopicdeterminationoftheSFHwassuccessfullyappliefdtolowsurfacebriht,nessgalaxy(withlowS/Ndata}."], "labels": ["WRONG"]}, "correct": {"tokens": ["This", "study", "was", "made", "with", "two", "complementary", "approaches:", "CMD", "fitting", "and", "full", "spectrum", "fitting.", "The", "first", "method", "uses", "CMDs", "usually", "obtained", "with", "HST/ACS,", "while", "the", "last", "uses", "long", "slit", "spectra", "that", "can", "be", "acquired", "on", "a", "ground", "based", "telescope.", "The", "two", "methods", "are", "consistent", "and", "it", "is", "notable", "that", "the", "full", "spectrum", "fitting", "can", "give", "finer", "constrains", "on", "the", "metallicity.", "In", "full", "spectrum", "fitting,", "the", "metallicity", "is", "directly", "constrained", "by", "the", "metal", "absorption", "lines", "from", "the", "stars,", "while", "CMDs", "rely", "on", "broad", "bands", "colours", "and", "on", "stellar", "evolution", "models.", "It", "is", "the", "first", "time", "that", "a", "detailed", "spectroscopic", "determination", "of", "the", "SFH", "was", "successfully", "applied", "to", "low", "surface", "brightness", "galaxy", "(with", "low", "S/N", "data)."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED"]}, "predicted": {"google": {"tokens": ["This", "Study", "Was", "Made", "Witir", "Two", "Complement", "Aty", "Approaches.\"CMDfittingandfullspectrumfitting.ThefirstmehoduesCMDsusuallyobtainedwithHST/ACS~whilethelastuseslongsltspectrathatcanbeacquiredonagroundbasedt\\eleescop.ThetwomethodsareconsistentandilisnotablethatthefullspecEtrmfittingcangivefinerconstrainsonthemetallicity.Infullspectrumfitting,themetallicltyisdirectlycons\\trainedbythemetalabs<)rpl;ion\\[ineslromthestars,whileCMDsrelyonConbroadbandscoloursandonstellarevolutlonmodels.ItlsthefirsttimetilatadetailedspectroseopicdeterminationoftheSFHwassuccessfullyappliefdtolowsurfacebriht,nessgalaxy(whitlowS/Data}."], "labels": ["TOKENIZATION_ERROR", "WRONG", "WRONG", "WRONG", "WRONG", "WRONG", "WRONG", "WRONG", "WRONG"]}, "BS-bid-OCR": {"tokens": ["This", "study", "was", "made", "witir", "two", "complementaty", "approaches.", "\"CMD", "fitting", "and", "full", "spectrum", "fitting.", "The", "first", "mehod", "ues", "CMDs", "usually", "obtained", "with", "HST/ACS~", "while", "the", "last", "uses", "longslt", "spectra", "that", "can", "be", "acquired", "on", "a", "groundbased", "t\\eleescop.", "The", "two", "methods", "are", "consistent", "and", "il", "is", "notable", "that", "the", "full", "specEtrm", "fitting", "can", "give", "finer", "constrains", "on", "the", "metallicity.", "In", "full", "spectrum", "fitting,", "the", "metalliclty", "is", "directly", "cons\\trained", "by", "the", "metal", "abs<)rpl;ion", "\\[ines", "lrom", "the", "stars,", "while", "CMDs", "rely", "on", "Con", "broadbands", "colours", "and", "on", "stellar", "evolutlon", "models.", "It", "ls", "the", "first", "time", "tilat", "a", "detailed", "spectroseopic", "determination", "of", "the", "SFH", "was", "successfully", "appliefd", "to", "low", "surface", "briht,ness", "galaxy", "(with", "low", "S/N", "data}."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG"]}, "BS-bid-OCR+google": {"tokens": ["This", "study", "was", "made", "witir", "two", "complementary", "approaches.", "\"CMD", "fitting", "and", "full", "spectrum", "fitting.", "The", "first", "method", "used", "CMDs", "usually", "obtained", "with", "HST/ACS~", "while", "the", "last", "uses", "long", "slit", "spectra", "that", "can", "be", "acquired", "on", "a", "ground", "based", "t\\eleescop.", "The", "two", "methods", "are", "consistent", "and", "it", "is", "notable", "that", "the", "full", "spectrum", "fitting", "can", "give", "finer", "constraints", "on", "the", "metallicity.", "In", "full", "spectrum", "fitting,", "the", "metallicity", "is", "directly", "cons\\trained", "by", "the", "metal", "abs<)rpl;ion", "\\[lines", "from", "the", "stars,", "while", "CMDs", "rely", "on", "Con", "broadband", "colours", "and", "on", "stellar", "evolution", "models.", "It", "is", "the", "first", "time", "a", "detailed", "spectroscopic", "determination", "of", "the", "SFH", "was", "successfully", "applied", "to", "a", "low", "surface", "brightness", "galaxy", "(with", "low", "S/N", "data}."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "MIXED", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG"]}}}, {"corrupt": {"tokens": ["therefre,wecanconc?entrateonC+?(B).Ourmainresultisslatedasfollows."], "labels": ["WRONG"]}, "correct": {"tokens": ["therefore,", "we", "can", "concentrate", "on", "C", "+", "(B).", "Our", "main", "result", "is", "stated", "as", "follows."], "labels": ["MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["Therefore,wean", "concentration?(B).Our", "Main", "Result", "Is", "Slated", "As", "Follows."], "labels": ["WRONG", "WRONG", "WRONG", "WRONG", "WRONG", "WRONG", "WRONG", "WRONG"]}, "BS-bid-OCR": {"tokens": ["therefre,", "we", "can", "conc?entrate", "on", "C", "+", "?(B).", "Our", "main", "result", "is", "slated", "as", "follows."], "labels": ["WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["Therefore,", "can", "we", "concentrate", "on", "C", "+", "+", "?(B).", "Our", "main", "result", "is", "slated", "as", "follows."], "labels": ["WRONG", "TOKENIZATION_ERROR", "WRONG", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["Inthisscction,weinvestigatetheirrotationalflogforthetl'ajectoryfield."], "labels": ["WRONG"]}, "correct": {"tokens": ["In", "this", "section,", "we", "investigate", "the", "irrotational", "flow", "for", "the", "trajectory", "field."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["Inthisscction,weinvestigatetheirrotationalflogforthetl'ajectoryfield."], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["In", "this", "scction,", "we", "investigate", "their", "rotational", "flog", "for", "the", "tl'ajectory", "field."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["In", "this", "section,", "we", "investigate", "their", "rotational", "flog", "for", "the", "trajectory", "field."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["Letghefunctionw(z)defindedby"], "labels": ["WRONG"]}, "correct": {"tokens": ["Let", "the", "function", "w(z)", "definded", "by"], "labels": ["MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["Length", "Function(z)defindedby"], "labels": ["WRONG", "WRONG"]}, "BS-bid-OCR": {"tokens": ["Let", "ghe", "function", "w(z)", "definded", "by"], "labels": ["MIXED", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["Let", "the", "function", "w(z)", "defined", "by"], "labels": ["MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["whereg(x,~)isacomplexn\u00d7nmatrix."], "labels": ["WRONG"]}, "correct": {"tokens": ["where", "g(x,", "y)", "is", "a", "complex", "n", "\u00d7", "n", "matrix."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["whereg(x,~)is", "a", "complex", "matrix."], "labels": ["WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR": {"tokens": ["where", "g(x,", "~)", "is", "a", "complex", "n", "\u00d7", "n", "matrix."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["where", "g(x,", "~)", "is", "a", "complex", "n", "\u00d7", "n", "matrix."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["Studyoftl~ermalmonopolesinla|,ticeQCD"], "labels": ["WRONG"]}, "correct": {"tokens": ["Study", "of", "thermal", "monopoles", "in", "lattice", "QCD"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["Studyoftl~ermalmonopolesinla|,ticeQCD"], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["Study", "of", "tl~ermal", "monopoles", "in", "la|,tice", "QCD"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["Study", "of", "tl~ermal", "monopoles", "in", "la|,tice", "QCD"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["Oursecondargumcntinfavorofourprogramhastwoparts:firstWeshowthtanecessaryrequivementforself-conslstencyoftherenormalizationprogramisthatall,oftheinternalpropagatorshavetobeofthesameform.SecondmeshowthatinthepocessOfconnecingtheinternalandexternalpropagntorsthroughtheinterna!points:iInmediatelyad:jacenttotheextenalones,therequirementofconsistencymandatesthatallofthepropagatorshavetobeofthesameform.\\Sh~cetheexternalpropagatorsbydefinitionhaveltobeconsistentwiththenon-perturbativeconditionsonthesystem,weconcl\\udethatallofthcpropagatorsandtheresultingcounter-termshavetobeofsuch\\form."], "labels": ["WRONG"]}, "correct": {"tokens": ["Our", "second", "argument", "in", "favor", "of", "our", "program", "has", "two", "parts:", "first", "we", "show", "that", "a", "necessary", "requirement", "for", "self-consistency", "of", "the", "renormalization", "program", "is", "that", "all", "of", "the", "internal", "propagators", "have", "to", "be", "of", "the", "same", "form.", "Second", "we", "show", "that", "in", "the", "process", "of", "connecting", "the", "internal", "and", "external", "propagators", "through", "the", "internal", "points", "immediately", "adjacent", "to", "the", "external", "ones,", "the", "requirement", "of", "consistency", "mandates", "that", "all", "of", "the", "propagators", "have", "to", "be", "of", "the", "same", "form.", "Since", "the", "external", "propagators", "by", "definition", "have", "to", "be", "consistent", "with", "the", "non-perturbative", "conditions", "on", "the", "system,", "we", "conclude", "that", "all", "of", "the", "propagators", "and", "the", "resulting", "counter-terms", "have", "to", "be", "of", "such", "form."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["Oursecondargumcntinfavorofourprogramhastwoparts:firstWeshowthtanecessaryrequivementforself-conslstencyoftherenormalizationprogramisthatall,oftheinternalpropagatorshavetobeofthesameform.SecondmeshowthatinthepocessOfconnecingtheinternalandexternalpropagntorsthroughtheinterna!points:iInmediatelyad:jacenttotheextenalones,therequirementofconsistencymandatesthatallofthepropagatorshavetobeofthesameform.\\Sh~cetheexternalpropagatorsbydefinitionhaveltobeconsistentwiththenon-perturbativeconditionsonthesystem,weconcl\\udethatallofthcpropagatorsandtheresultingcounter-termshavetobeofsuch\\form."], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["Our", "second", "argumcnt", "in", "favor", "of", "our", "program", "has", "two", "parts:", "first", "We", "show", "tht", "a", "necessary", "requivement", "for", "self-conslstency", "of", "the", "renormalization", "program", "is", "that", "all,", "of", "the", "internal", "propagators", "have", "to", "be", "of", "the", "same", "form.", "Second", "me", "show", "that", "in", "the", "pocess", "Of", "connecing", "the", "internal", "and", "external", "propagntors", "through", "the", "interna!", "points:", "iInmediately", "ad:jacent", "to", "the", "extenal", "ones,", "the", "requirement", "of", "consistency", "mandates", "that", "all", "of", "the", "propagators", "have", "to", "be", "of", "the", "same", "form.", "\\Sh~ce", "the", "external", "propagators", "by", "definition", "havel", "to", "be", "consistent", "with", "the", "non-perturbative", "conditions", "on", "the", "system,", "we", "concl\\ude", "that", "all", "of", "thc", "propagators", "and", "the", "resulting", "counter-terms", "have", "to", "be", "of", "such", "\\form."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG"]}, "BS-bid-OCR+google": {"tokens": ["Our", "second", "argument", "in", "favor", "of", "our", "program", "has", "two", "parts:", "first", "We", "show", "that", "a", "necessary", "requirement", "for", "self-consistency", "of", "the", "renormalization", "program", "is", "that", "all", "of", "the", "internal", "propagators", "have", "to", "be", "of", "the", "same", "form.", "Second,", "I", "show", "that", "in", "the", "process", "Of", "connecting", "the", "internal", "and", "external", "propagators", "through", "the", "interna!", "points:", "iMmediately", "ad:jacent", "to", "the", "external", "ones,", "the", "requirement", "of", "consistency", "mandates", "that", "all", "of", "the", "propagators", "have", "to", "be", "of", "the", "same", "form.", "\\Sh~ce", "the", "external", "propagators", "by", "definition", "havel", "to", "be", "consistent", "with", "the", "non-perturbative", "conditions", "on", "the", "system,", "we", "concl\\ude", "that", "all", "of", "thc", "propagators", "and", "the", "resulting", "counter-terms", "have", "to", "be", "of", "such", "\\form."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "WRONG", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG"]}}}, {"corrupt": {"tokens": ["Insumma~y,thecontribution\\softhispaperaretilree-fold."], "labels": ["WRONG"]}, "correct": {"tokens": ["In", "summary,", "the", "contributions", "of", "this", "paper", "are", "three-fold."], "labels": ["TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED"]}, "predicted": {"google": {"tokens": ["Insumma~y,thecontribution\\softhispaperaretilree-fold."], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["In", "summa~y,", "the", "contribution\\s", "of", "this", "paper", "are", "tilree-fold."], "labels": ["TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG"]}, "BS-bid-OCR+google": {"tokens": ["In", "summa~y,", "the", "contribution\\s", "of", "this", "paper", "are", "threefold."], "labels": ["TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG"]}}}, {"corrupt": {"tokens": ["Intralayeranisotropies."], "labels": ["WRONG"]}, "correct": {"tokens": ["Intralayer", "anisotropies."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["Intralayer", "Anisotropies."], "labels": ["TOKENIZATION_ERROR", "WRONG"]}, "BS-bid-OCR": {"tokens": ["Intralayer", "anisotropies."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["Intralayer", "anisotropies."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["Dynamics"], "labels": ["NONE"]}, "correct": {"tokens": ["Dynamics"], "labels": ["NONE"]}, "predicted": {"google": {"tokens": ["Dynamics"], "labels": ["NONE"]}, "BS-bid-OCR": {"tokens": ["Dynamics"], "labels": ["NONE"]}, "BS-bid-OCR+google": {"tokens": ["Dynamics"], "labels": ["NONE"]}}}, {"corrupt": {"tokens": ["CoirelatedSubsequences:SigilarityDetectionandParameterDependence"], "labels": ["WRONG"]}, "correct": {"tokens": ["Correlated", "Subsequences:", "Similarity", "Detection", "and", "Parameter", "Dependence"], "labels": ["MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["CoirelatedSubsequences:SigilarityDetectionandParameterDependence"], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["Coirelated", "Subsequences:", "Sigilarity", "Detection", "and", "Parameter", "Dependence"], "labels": ["WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["Correlated", "Subsequences:", "Singularity", "Detection", "and", "Parameter", "Dependence"], "labels": ["MIXED", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["where*"], "labels": ["WRONG"]}, "correct": {"tokens": ["where"], "labels": ["NONE"]}, "predicted": {"google": {"tokens": ["where*"], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["where*"], "labels": ["WRONG"]}, "BS-bid-OCR+google": {"tokens": ["where*"], "labels": ["WRONG"]}}}, {"corrupt": {"tokens": ["ThevisualIzat/onofpedestrianan~mobilitydynamicsprovidedbysmepedestriansimulationsoftwrccanbeextremelyadvancedbutithastobeunde\\rline(lthattheaccuracyotther~produeeddynamics,andtheconsequentpredictionoftheperformacceoftheenvironmentandofth:eproceduresandot)erationsunderstudy,reliesontheaccurate\\informationofthesimulatioum<)del,ontheezattreprodutionofthel?ayoutunderstu(lyandonapropercalibra??tionandvalid~ttionofthemodel."], "labels": ["WRONG"]}, "correct": {"tokens": ["The", "visualization", "of", "pedestrian", "and", "mobility", "dynamics", "provided", "by", "some", "pedestrian", "simulation", "software", "can", "be", "extremely", "advanced", "but", "it", "has", "to", "be", "underlined", "that", "the", "accuracy", "of", "the", "reproduced", "dynamics,", "and", "the", "consequent", "prediction", "of", "the", "performance", "of", "the", "environment", "and", "of", "the", "procedures", "and", "operations", "under", "study,", "relies", "on", "the", "accurate", "information", "of", "the", "simulation", "model,", "on", "the", "exact", "reproduction", "of", "the", "layout", "under", "study", "and", "on", "a", "proper", "calibration", "and", "validation", "of", "the", "model."], "labels": ["TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["ThevisualIzat/onofpedestrianan~mobilitydynamicsprovidedbysmepedestriansimulationsoftwrccanbeextremelyadvancedbutithastobeunde\\rline(lthattheaccuracyotther~produeeddynamics,andtheconsequentpredictionoftheperformacceoftheenvironmentandofth:eproceduresandot)erationsunderstudy,relies", "on", "accurate\\information", "thesimulatioum<)del,ontheezattreprodutionofthel?ayoutunderstu(lyandonapropercalibra??tionandvalid~ttionofthemodel."], "labels": ["WRONG", "TOKENIZATION_ERROR", "WRONG", "WRONG"]}, "BS-bid-OCR": {"tokens": ["The", "visualIzat/on", "of", "pedestrian", "an~", "mobility", "dynamics", "provided", "by", "sme", "pedestrian", "simulation", "softwrc", "can", "be", "extremely", "advanced", "but", "it", "has", "to", "be", "unde\\rline(l", "that", "the", "accuracy", "ot", "the", "r~produeed", "dynamics,", "and", "the", "consequent", "prediction", "of", "the", "performacce", "of", "the", "environment", "and", "of", "th:e", "procedures", "and", "ot)erations", "under", "study,", "relies", "on", "the", "accurate", "\\information", "of", "the", "simulatiou", "m<)del,", "on", "the", "ezatt", "reprodution", "of", "the", "l?ayout", "under", "stu(ly", "and", "on", "a", "proper", "calibra??tion", "and", "valid~ttion", "of", "the", "model."], "labels": ["TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["The", "visualIzation", "of", "pedestrian", "and~", "mobility", "dynamics", "provided", "by", "sme", "pedestrian", "simulation", "software", "can", "be", "extremely", "advanced", "but", "it", "has", "to", "be", "unde\\rline(l", "that", "the", "accuracy", "of", "the", "r~produeed", "dynamics,", "and", "the", "consequent", "prediction", "of", "the", "performance", "of", "the", "environment", "and", "of", "th:e", "procedures", "and", "ot)erations", "under", "study,", "relies", "on", "the", "accurate", "\\information", "of", "the", "simulation", "m<)del,", "on", "the", "ezzat", "reproduction", "of", "the", "layout", "under", "stu(ly", "and", "on", "a", "proper", "calibration", "and", "valid~ttion", "of", "the", "model."], "labels": ["TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["witth"], "labels": ["WRONG"]}, "correct": {"tokens": ["with"], "labels": ["OCR_ERROR"]}, "predicted": {"google": {"tokens": ["with"], "labels": ["OCR_ERROR"]}, "BS-bid-OCR": {"tokens": ["witth"], "labels": ["WRONG"]}, "BS-bid-OCR+google": {"tokens": ["with"], "labels": ["OCR_ERROR"]}}}, {"corrupt": {"tokens": ["Acknowledgment"], "labels": ["NONE"]}, "correct": {"tokens": ["Acknowledgment"], "labels": ["NONE"]}, "predicted": {"google": {"tokens": ["Acknowledgment"], "labels": ["NONE"]}, "BS-bid-OCR": {"tokens": ["Acknowledgment"], "labels": ["NONE"]}, "BS-bid-OCR+google": {"tokens": ["Acknowledgment"], "labels": ["NONE"]}}}, {"corrupt": {"tokens": ["MassDistributionmo(x)=a2/(rrb+x2)2"], "labels": ["WRONG"]}, "correct": {"tokens": ["Mass", "Distribution", "m(x)", "=", "a2/(b", "+", "x2)2"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["MassDistributionmo(x)=a2/(rrb+x2)2"], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["Mass", "Distribution", "mo(x)", "=", "a2/(rrb", "+", "x2)2"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["Mass", "Distribution", "mo(x)", "=", "a2/(rrb", "+", "x2)2"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["Hencethecorrectlynormalizedintegrationmeasureisgivenby"], "labels": ["WRONG"]}, "correct": {"tokens": ["Hence", "the", "correctly", "normalized", "integration", "measure", "is", "given", "by"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["Hencethecorrectlynormalizedintegrationmeasureisgivenby"], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["Hence", "the", "correctly", "normalized", "integration", "measure", "is", "given", "by"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["Hence", "the", "correctly", "normalized", "integration", "measure", "is", "given", "by"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["MoreeXplicltlyanRBM\u03b1,\u03b2inTmaybedefinedasfollows.\\LetBbe'~t\"andardtwo-dimensionalBrownianmotion.Thena?nRBM\u03b1,\u03b2inTistheurliqueprocessZsuchthat"], "labels": ["WRONG"]}, "correct": {"tokens": ["More", "explicitly,", "an", "RBM\u03b1,", "\u03b2", "in", "T", "may", "be", "defined", "as", "follows.", "Let", "B", "be", "standard", "two-dimensional", "Brownian", "motion.", "Then", "an", "RBM\u03b1,", "\u03b2", "in", "T", "is", "the", "unique", "process", "Z", "such", "that"], "labels": ["TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["MoreeXplicltlyanRBM\u03b1,\u03b2inTmaybedefinedasfollows.\\Let", "be'~t\"andardtwo-dimensionalBrownianmotion.Thena?nRBM\u03b1,\u03b2inTistheurliqueprocessZsuchthat"], "labels": ["WRONG", "WRONG"]}, "BS-bid-OCR": {"tokens": ["More", "eXplicltly", "an", "RBM", "\u03b1,", "\u03b2", "in", "T", "may", "be", "defined", "as", "follows.", "\\Let", "B", "be", "'~t\"andard", "two-dimensional", "Brownian", "motion.", "Then", "a?n", "RBM", "\u03b1,", "\u03b2", "in", "T", "is", "the", "urlique", "process", "Z", "such", "that"], "labels": ["TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["More", "eXplicitly", "an", "RBM", "\u03b1,", "\u03b2", "in", "T", "may", "be", "defined", "as", "follows.", "\\Let", "B", "be", "'~t\"standard", "two-dimensional", "Brownian", "motion.", "Then", "a?n", "RBM", "\u03b1,", "\u03b2", "in", "T", "is", "the", "urlique", "process", "Z", "such", "that"], "labels": ["TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["Wefurthermakethefoll0winghypotheses:"], "labels": ["WRONG"]}, "correct": {"tokens": ["We", "further", "make", "the", "following", "hypotheses:"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["Wefurthermakethefoll0winghypotheses:"], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["We", "further", "make", "the", "foll0wing", "hypotheses:"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["We", "further", "make", "the", "following", "hypotheses:"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["Ontheotherhand,thespectrumofscalarperturbationsbecomes"], "labels": ["WRONG"]}, "correct": {"tokens": ["On", "the", "other", "hand,", "the", "spectrum", "of", "scalar", "perturbations", "becomes"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["On", "The", "Other", "Hand,the", "spectrum", "of", "scalar", "perturbations", "becomes"], "labels": ["TOKENIZATION_ERROR", "WRONG", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR": {"tokens": ["On", "the", "other", "hand,", "the", "spectrum", "of", "scalar", "perturbations", "becomes"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["On", "the", "other", "hand,", "the", "spectrum", "of", "scalar", "perturbations", "becomes"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["HerearesomebasicpropertiesoftheScbwarzderiuative:"], "labels": ["WRONG"]}, "correct": {"tokens": ["Here", "are", "some", "basic", "properties", "of", "the", "Schwarz", "derivative:"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED"]}, "predicted": {"google": {"tokens": ["HerearesomebasicpropertiesoftheScbwarzderiuative:"], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["Here", "are", "some", "basic", "properties", "of", "the", "Scbwarz", "deriuative:"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG"]}, "BS-bid-OCR+google": {"tokens": ["Here", "are", "some", "basic", "properties", "of", "the", "Schwarz", "derivative:"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED"]}}}, {"corrupt": {"tokens": ["nnd"], "labels": ["WRONG"]}, "correct": {"tokens": ["and"], "labels": ["OCR_ERROR"]}, "predicted": {"google": {"tokens": ["nnd"], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["nnd"], "labels": ["WRONG"]}, "BS-bid-OCR+google": {"tokens": ["nnd"], "labels": ["WRONG"]}}}, {"corrupt": {"tokens": ["ThisworkwassupportedbytheKorcaScienceandEngineeringFoudat,ion(KOSEF)glantfendedbytheKoreagovernment\\[MEST),R01-2008-000-21026-0(E.C.-Y.andD.L.),an(lbythKoreaResearchFoundationgrantfundedbytheKoreaGovernment(MEST),KRF-2008-314-C00063(Y.L.)."], "labels": ["WRONG"]}, "correct": {"tokens": ["This", "work", "was", "supported", "by", "the", "Korea", "Science", "and", "Engineering", "Foundation(KOSEF)", "grant", "funded", "by", "the", "Korea", "government(MEST),", "R01-2008-000-21026-0(E.", "C.-Y.", "and", "D.", "L.),", "and", "by", "the", "Korea", "Research", "Foundation", "grant", "funded", "by", "the", "Korea", "Government(MEST),", "KRF-2008-314-C00063(Y.", "L.)."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["ThisworkwassupportedbytheKorcaScienceandEngineeringFoudat,ion(KOSEF)glantfendedbytheKoreagovernment\\[MEST),R01-2008-000-21026-0(E.C.-Y.andD.L.),an(lbythKoreaResearchFoundationgrantfundedbytheKoreaGovernment(MEST),KRF-2008-314-C00063(Y.L.)."], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["This", "work", "was", "supported", "by", "the", "Korca", "Science", "and", "Engineering", "Foudat,ion", "(KOSEF)", "glant", "fended", "by", "the", "Korea", "government", "\\[MEST),", "R01-2008-000-21026-0", "(E.C.-Y.", "and", "D.L.),", "an(l", "by", "th", "Korea", "Research", "Foundation", "grant", "funded", "by", "the", "Korea", "Government", "(MEST),", "KRF-2008-314-C00063", "(Y.L.)."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "WRONG", "WRONG", "MIXED", "WRONG", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "WRONG", "WRONG"]}, "BS-bid-OCR+google": {"tokens": ["This", "work", "was", "supported", "by", "the", "Korca", "Science", "and", "Engineering", "Foundation", "(KOSEF)", "glant", "funded", "by", "the", "Korea", "government", "\\[MEST),", "R01-2008-000-21026-0", "(E.C.-Y.", "and", "D.L.),", "an(l", "by", "th", "Korea", "Research", "Foundation", "grant", "funded", "by", "the", "Korea", "Government", "(MEST),", "KRF-2008-314-C00063", "(Y.L.)."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "WRONG", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "WRONG", "WRONG", "MIXED", "WRONG", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "WRONG", "WRONG"]}}}, {"corrupt": {"tokens": ["I-Introductio.n"], "labels": ["WRONG"]}, "correct": {"tokens": ["I", "-", "Introduction"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED"]}, "predicted": {"google": {"tokens": ["I-Introduction"], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["I-Introductio.n"], "labels": ["WRONG"]}, "BS-bid-OCR+google": {"tokens": ["I-Introduction"], "labels": ["WRONG"]}}}, {"corrupt": {"tokens": ["Itfollowsthattheresoln\\tionofOXisgivenbyC0.ThisisthewellknownEagon-Nol'thcottcomplexwihBeti1tableasfollows:"], "labels": ["WRONG"]}, "correct": {"tokens": ["It", "follows", "that", "the", "resolution", "of", "OX", "is", "given", "by", "C0.", "This", "is", "the", "well", "known", "Eagon-Northcott", "complex", "with", "Betti", "table", "as", "follows:"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["Itfollowsthattheresoln\\tionofOXisgivenbyC0.ThisisthewellknownEagon-Nol'thcottcomplexwihBeti1tableasfollows:"], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["It", "follows", "that", "the", "resoln\\tion", "of", "OX", "is", "given", "by", "C0.", "This", "is", "the", "well", "known", "Eagon-Nol'thcott", "complex", "wih", "Beti1", "table", "as", "follows:"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["It", "follows", "that", "the", "resoln\\tion", "of", "OX", "is", "given", "by", "C0.", "This", "is", "the", "well", "known", "Eagon-Northcott", "complex", "with", "Beta", "1", "table", "as", "follows:"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["(5)InorderthatextaI)olationofasymptoticseriescouldbecocrrectlvreformulatcdasforecaslingfortimeseries,thelatteraretobepresentdasabackwardrecursion."], "labels": ["WRONG"]}, "correct": {"tokens": ["(5)", "In", "order", "that", "extrapolation", "of", "asymptotic", "series", "could", "be", "correctly", "reformulated", "as", "forecasting", "for", "time", "series,", "the", "latter", "are", "to", "be", "presented", "as", "a", "backward", "recursion."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["(5)InorderthatextaI)olationofasymptoticseriescouldbecocrrectlvreformulatcdasforecaslingfortimeseries,thelatteraretobepresentdasabackwardrecursion."], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["(5)", "In", "order", "that", "extaI)olation", "of", "asymptotic", "series", "could", "be", "cocrrectlv", "reformulatcd", "as", "forecasling", "for", "time", "series,", "the", "latter", "are", "to", "be", "presentd", "as", "a", "backward", "recursion."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["(5)", "In", "order", "that", "extaI)olation", "of", "asymptotic", "series", "could", "be", "reformulated", "as", "forecasting", "for", "time", "series,", "the", "latter", "are", "to", "be", "presented", "as", "a", "backward", "recursion."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["Thisexpressioncanberoarrangedusingintegrati\\onbypartsasfotows."], "labels": ["WRONG"]}, "correct": {"tokens": ["This", "expression", "can", "be", "rearranged", "using", "integration", "by", "parts", "as", "follows."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED"]}, "predicted": {"google": {"tokens": ["Thisexpressioncanberoarrangedusingintegrati\\onbypartsasfotows."], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["This", "expression", "can", "be", "roarranged", "using", "integrati\\on", "by", "parts", "as", "fotows."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG"]}, "BS-bid-OCR+google": {"tokens": ["This", "expression", "can", "be", "rearranged", "using", "integrati\\on", "by", "parts", "as", "follows."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED"]}}}, {"corrupt": {"tokens": ["SoweiDfer"], "labels": ["WRONG"]}, "correct": {"tokens": ["So", "we", "infer"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED"]}, "predicted": {"google": {"tokens": ["SwiFfer"], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["So", "we", "iDfer"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG"]}, "BS-bid-OCR+google": {"tokens": ["So", "we", "offer"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG"]}}}, {"corrupt": {"tokens": ["Expandingtheintegrandinpowersofzandsolvingtheelementargintegralsgives"], "labels": ["WRONG"]}, "correct": {"tokens": ["Expanding", "the", "integrand", "in", "powers", "of", "z", "and", "solving", "the", "elementary", "integrals", "gives"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["Expandingtheintegrandinpowersofzandsolvingtheelementargintegralsgives"], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["Expanding", "the", "integrand", "in", "powers", "of", "z", "and", "solving", "the", "elementarg", "integrals", "gives"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["Expanding", "the", "integrand", "in", "powers", "of", "z", "and", "solving", "the", "elementary", "integrals", "gives"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["where~RR(U)andfNS(U)arepolynomialfunctio.nsofU.WewritevaluesofSa?ndUattheminimumaeS0andU0.Theal)oveconditiognsrequirs"], "labels": ["WRONG"]}, "correct": {"tokens": ["where", "fRR(U)", "and", "fNS(U)", "are", "polynomial", "functions", "of", "U.", "We", "write", "values", "of", "S", "and", "U", "at", "the", "minimum", "as", "S0", "and", "U0.", "The", "above", "conditions", "requires"], "labels": ["TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "MIXED"]}, "predicted": {"google": {"tokens": ["where~RR(U)andfNS(U)arepolynomialfunctio.nsofU.WewritevaluesofSa?ndUattheminimumaeS0andU0.Theal)uv", "conditions", "required"], "labels": ["WRONG", "MIXED", "WRONG"]}, "BS-bid-OCR": {"tokens": ["where", "~RR(U)", "and", "fNS(U)", "are", "polynomial", "functio.ns", "of", "U.", "We", "write", "values", "of", "S", "a?nd", "U", "at", "the", "minimum", "ae", "S0", "and", "U0.", "The", "al)ove", "conditiogns", "requirs"], "labels": ["TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "WRONG"]}, "BS-bid-OCR+google": {"tokens": ["where", "~RR(U)", "and", "fNS(U)", "are", "polynomial", "functions", "of", "U.", "We", "write", "values", "of", "S", "and", "U", "at", "the", "minimum", "ae", "S0", "and", "U0.", "The", "al)ove", "conditions", "required"], "labels": ["TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "MIXED", "WRONG"]}}}, {"corrupt": {"tokens": ["Sincelbz)=Ezf(Z\u03c31),thisldentifiestheexitdensityas"], "labels": ["WRONG"]}, "correct": {"tokens": ["Since", "l(z)", "=", "Ezf(Z\u03c31),", "this", "identifies", "the", "exit", "density", "as"], "labels": ["TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["Sincelbz)=Ezf(Z\u03c31),thisldentifiestheexitdensityas"], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["Since", "lbz)", "=", "Ezf(Z\u03c31),", "this", "ldentifies", "the", "exit", "density", "as"], "labels": ["TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["Since", "lbz)", "=", "Ezf(Z\u03c31),", "this", "identifies", "the", "exit", "density", "as"], "labels": ["TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["WewillfirstshowhowthemodelaccouatsforthecolumkndensityandvelocitywidthdistributionofDLAs,andtheconstrainttchat~treplacedontheparametersofthemodel."], "labels": ["WRONG"]}, "correct": {"tokens": ["We", "will", "first", "show", "how", "the", "model", "accounts", "for", "the", "column", "density", "and", "velocity", "width", "distribution", "of", "DLAs,", "and", "the", "constraints", "that", "are", "placed", "on", "the", "parameters", "of", "the", "model."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["WewillfirstshowhowthemodelaccouatsforthecolumkndensityandvelocitywidthdistributionofDLAs,andtheconstrainttchat~treplacedontheparametersofthemodel."], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["We", "will", "first", "show", "how", "the", "model", "accouats", "for", "the", "columkn", "density", "and", "velocity", "width", "distribution", "of", "DLAs,", "and", "the", "constraint", "tchat", "~tre", "placed", "on", "the", "parameters", "of", "the", "model."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["We", "will", "first", "show", "how", "the", "model", "accounts", "for", "the", "column", "density", "and", "velocity", "width", "distribution", "of", "DLAs,", "and", "the", "constraint", "tchat", "~tre", "placed", "on", "the", "parameters", "of", "the", "model."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["Consideramultipthchannelbetweenatransmitterandareceiverwithanimnpulseresponse"], "labels": ["WRONG"]}, "correct": {"tokens": ["Consider", "a", "multipath", "channel", "between", "a", "transmitter", "and", "a", "receiver", "with", "an", "impulse", "response"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["Consideramultipthchannelbetweenatransmitterandareceiverwithanimnpulseresponse"], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["Consider", "a", "multipth", "channel", "between", "a", "transmitter", "and", "a", "receiver", "with", "an", "imnpulse", "response"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["Consider", "a", "multipath", "channel", "between", "a", "transmitter", "and", "a", "receiver", "with", "an", "impulse", "response"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["TheHerizontalBranch"], "labels": ["WRONG"]}, "correct": {"tokens": ["The", "Horizontal", "Branch"], "labels": ["TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["The", "Horizontal", "Branch"], "labels": ["TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR"]}, "BS-bid-OCR": {"tokens": ["The", "Herizontal", "Branch"], "labels": ["TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["The", "Horizontal", "Branch"], "labels": ["TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["Thisnon-uniquenessofthemedianisonesourceofnon-uniquenessofinimize>rsofthe?discreteandconlinuou,s)L1-pottsfunctional.Bes~desthis,therearetwoothersourcesofnon-uniquenssasitcanbe~eent)yl;hefollowingexample."], "labels": ["WRONG"]}, "correct": {"tokens": ["This", "non-uniqueness", "of", "the", "median", "is", "one", "source", "of", "non-uniqueness", "of", "minimizers", "of", "the", "(discrete", "and", "continuous)", "L1-Potts", "functional.", "Besides", "this,", "there", "are", "two", "other", "sources", "of", "non-uniqueness", "as", "it", "can", "be", "seen", "by", "the", "following", "example."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["This", "Non-uniqueness", "of", "themedianisonesourceofnon-uniquenessofinimize>rsofthe?discrete", "andconlinuou,s)L1-pottsfunctional.Bes~desthis,therearetwoothersourcesofnon-uniquenssasitcanbe~eent)yl;he", "following", "example."], "labels": ["TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR": {"tokens": ["This", "non-uniqueness", "of", "the", "median", "is", "one", "source", "of", "non-uniqueness", "of", "inimize>rs", "of", "the", "?discrete", "and", "conlinuou,s)", "L1-potts", "functional.", "Bes~des", "this,", "there", "are", "two", "other", "sources", "of", "non-uniquenss", "as", "it", "can", "be", "~een", "t)y", "l;he", "following", "example."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["This", "non-uniqueness", "of", "the", "median", "is", "one", "source", "of", "non-uniqueness", "of", "inimize>rs", "of", "the", "?discrete", "and", "continuous)", "L1-potts", "functional.", "Bes~des", "this,", "there", "are", "two", "other", "sources", "of", "non-uniqueness", "as", "it", "can", "be", "~een", "t)y", "l;he", "following", "example."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "MIXED", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["TosLudthedynalnicsofthetield$duringinflationwestartwiththeactionforthescalarfieldscoupledto9ravity:"], "labels": ["WRONG"]}, "correct": {"tokens": ["To", "study", "the", "dynamics", "of", "the", "fields", "during", "inflation", "we", "start", "with", "the", "action", "for", "the", "scalar", "fields", "coupled", "to", "gravity:"], "labels": ["TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED"]}, "predicted": {"google": {"tokens": ["TosLudthedynalnicsofthetield$duringinflationwestartwiththeactionforthescalarfieldscoupledto9ravity:"], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["To", "sLud", "the", "dynalnics", "of", "the", "tield$", "during", "inflation", "we", "start", "with", "the", "action", "for", "the", "scalar", "fields", "coupled", "to", "9ravity:"], "labels": ["TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG"]}, "BS-bid-OCR+google": {"tokens": ["To", "sLug", "the", "dynamics", "of", "the", "field$", "during", "inflation", "we", "start", "with", "the", "action", "for", "the", "scalar", "fields", "coupled", "to", "9ravity:"], "labels": ["TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG"]}}}, {"corrupt": {"tokens": ["MultifractalAnalysis"], "labels": ["WRONG"]}, "correct": {"tokens": ["Multifractal", "Analysis"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["MultifractalAnalysis"], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["Multifractal", "Analysis"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["Multifractal", "Analysis"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["LEtusassumewestartwi\\thasystemofN0cell,withaninitialbound?ryl)ositionatcellN1.Inthedeterministiccasere=0,Itisstraight-forwardtoseethattheasymptoti(:boundar.ypositioninthelimitoflargetimestisgivenby"], "labels": ["WRONG"]}, "correct": {"tokens": ["Let", "us", "assume", "we", "start", "with", "a", "system", "of", "N0", "cells,", "with", "an", "initial", "boundary", "position", "at", "cell", "N1.", "In", "the", "deterministic", "case", "re", "=", "0,", "it", "is", "straight-forward", "to", "see", "that", "the", "asymptotic", "boundary", "position", "in", "the", "limit", "of", "large", "times", "t", "is", "given", "by"], "labels": ["MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["LEtusassumewestartwi\\thasystemofN0cell,withaninitialbound?ryl)ositionatcellN1.In", "Deterministic", "Case", "Re=0,Itisstraight-forwardtoseethattheasymptoti(:boundary", "position", "thelimitoflargetimestisgivenby"], "labels": ["WRONG", "WRONG", "WRONG", "WRONG", "TOKENIZATION_ERROR", "WRONG"]}, "BS-bid-OCR": {"tokens": ["LEt", "us", "assume", "we", "start", "wi\\th", "a", "system", "of", "N0", "cell,", "with", "an", "initial", "bound?ry", "l)osition", "at", "cell", "N1.", "In", "the", "deterministic", "case", "re", "=", "0,", "It", "is", "straight-forward", "to", "see", "that", "the", "asymptoti(:", "boundar.y", "position", "in", "the", "limit", "of", "large", "times", "t", "is", "given", "by"], "labels": ["WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["LEt", "us", "assume", "we", "start", "wi\\th", "a", "system", "of", "N0", "cell,", "with", "an", "initial", "bound?ry", "l)position", "at", "cell", "N1.", "In", "the", "deterministic", "case", "re", "=", "0,", "It", "is", "straight-forward", "to", "see", "that", "the", "asymptotic(:", "boundary", "position", "in", "the", "limit", "of", "large", "times", "t", "is", "given", "by"], "labels": ["WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["Cendid\\aeStarsforCosmochronometry"], "labels": ["WRONG"]}, "correct": {"tokens": ["Candidate", "Stars", "for", "Cosmochronometry"], "labels": ["MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["Cendid\\aeStarsforCosmochronometry"], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["Cendid\\ae", "Stars", "for", "Cosmochronometry"], "labels": ["WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["Candid\\ae", "Stars", "for", "Cosmo", "Chronometry"], "labels": ["WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG"]}}}, {"corrupt": {"tokens": ["NowpehaveLinguiafamilyo\\fsurfacesSx0t0inx--\u03c6planerepresentedby\u03c6(x,t;x0,t0)withx0andt0bcingthaparameterm.Werepeattheprocedureofthepreviussectionto?obtaintheenvelopeEofthefamilyofthesurfaces:WefirstnotethatAmaydependox0andt0,i.e.,~=A(x0,t0).Thenfixinpx0,wefirstobtaint\\heenvelopeofSx0t0witht0beingtheparameters.The(;nvelopcE1isobtainedby"], "labels": ["WRONG"]}, "correct": {"tokens": ["Now", "we", "have", "a", "family", "of", "surfaces", "Sx0t0", "in", "x-t-\u03c6", "plane", "represented", "by", "\u03c6(x,", "t;", "x0,", "t0)", "with", "x0", "and", "t0", "being", "the", "parameters.", "We", "repeat", "the", "procedure", "of", "the", "previous", "section", "to", "obtain", "the", "envelope", "E", "of", "the", "family", "of", "the", "surfaces:", "We", "first", "note", "that", "A", "may", "depend", "on", "x0", "and", "t0,", "i.e.,", "A", "=", "A(x0,", "t0).", "Then", "fixing", "x0,", "we", "first", "obtain", "the", "envelope", "of", "Sx0t0", "with", "t0", "being", "the", "parameters.", "The", "envelope", "E1", "is", "obtained", "by"], "labels": ["MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["NowpehaveLinguiafamilyo\\fsurfacesSx0t0inx--\u03c6planerepresentedby\u03c6(x,t;x0,t0)withx0andt0bcingthaparameterm.Werepeattheprocedureofthepreviussectionto?obtaintheenvelopeEofthefamilyofthesurfaces:WefirstnotethatAmaydependox0andt0,i.e.,~=A(x0,t0).Thenfixinpx0,wefirstobtaint\\envelopeS", "0t0witht0beingthe", "parameters.The(;nvelopcE1isobtainedby"], "labels": ["WRONG", "WRONG", "WRONG"]}, "BS-bid-OCR": {"tokens": ["Now", "pe", "have", "Lingui", "a", "family", "o\\f", "surfaces", "Sx0t0", "in", "x", "--", "\u03c6", "plane", "represented", "by", "\u03c6(x,", "t;", "x0,", "t0)", "with", "x0", "and", "t0", "bcing", "tha", "parameter", "m.", "We", "repeat", "the", "procedure", "of", "the", "previus", "section", "to?", "obtain", "the", "envelope", "E", "of", "the", "family", "of", "the", "surfaces:", "We", "first", "note", "that", "A", "may", "depend", "o", "x0", "and", "t0,", "i.e.,", "~", "=", "A(x0,", "t0).", "Then", "fixinp", "x0,", "we", "first", "obtain", "t\\he", "envelope", "of", "Sx0t0", "with", "t0", "being", "the", "parameters.", "The", "(;nvelopc", "E1", "is", "obtained", "by"], "labels": ["MIXED", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["Now", "we", "have", "Lingui,", "a", "family", "o\\f", "surfaces", "Sx0t0", "in", "the", "x", "--", "\u03c6", "plane", "represented", "by", "\u03c6(x,", "t;", "x0,", "t0)", "with", "x0", "and", "t0", "bcing", "tha", "parameter", "m.", "Do", "we", "repeat", "the", "procedure", "of", "the", "previous", "section", "too?", "obtain", "the", "envelope", "E", "of", "the", "family", "of", "the", "surfaces:", "We", "first", "note", "that", "A", "may", "depend", "on", "x0", "and", "t0,", "i.e.,", "~", "=", "A(x0,", "t0).", "Then", "fixinp", "x0,", "we", "first", "obtain", "t\\he", "envelope", "of", "Sx0t0", "with", "t0", "being", "the", "parameters.", "The", "(;nvelope", "E1", "is", "obtained", "by"], "labels": ["MIXED", "MIXED", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "WRONG", "WRONG", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["Inthissubsection,washowthataDiracfi(~ldcancausethedeSitterexpanslonofthebackgroun\\duniverseonthbaisofthecosmologicalequationscollectedintheprevioussection."], "labels": ["WRONG"]}, "correct": {"tokens": ["In", "this", "subsection,", "we", "show", "that", "a", "Dirac", "field", "can", "cause", "the", "de", "Sitter", "expansion", "of", "the", "background", "universe", "on", "the", "basis", "of", "the", "cosmological", "equations", "collected", "in", "the", "previous", "section."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["Inthi", "Subsection,washowthataDiracfi(~ldcancausethedeSitterexpanslonofthebackgroun\\duniverseonthbaisofthecosmologicalequationscollectedintheprevioussection."], "labels": ["WRONG", "WRONG"]}, "BS-bid-OCR": {"tokens": ["In", "this", "subsection,", "wa", "show", "that", "a", "Dirac", "fi(~ld", "can", "cause", "the", "de", "Sitter", "expanslon", "of", "the", "backgroun\\d", "universe", "on", "th", "bais", "of", "the", "cosmological", "equations", "collected", "in", "the", "previous", "section."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["In", "this", "subsection,", "we", "show", "that", "a", "Dirac", "fi(~ld", "can", "cause", "the", "de", "Sitter", "expansion", "of", "the", "backgroun\\d", "universe", "on", "the", "basis", "of", "the", "cosmological", "equations", "collected", "in", "the", "previous", "section."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["ioanf.m.basisofu(L)."], "labels": ["WRONG"]}, "correct": {"tokens": ["is", "an", "f.m.", "basis", "of", "u(L)."], "labels": ["MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["ioan.m.basisofu(L)."], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["io", "an", "f.m.", "basis", "of", "u(L)."], "labels": ["WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["io", "an", "f.m.", "basis", "of", "u(L)."], "labels": ["WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["GraVityandQuantumGravity:"], "labels": ["WRONG"]}, "correct": {"tokens": ["Gravity", "and", "Quantum", "Gravity:"], "labels": ["MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["GraVityandQuantumGravity:"], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["GraVity", "and", "Quantum", "Gravity:"], "labels": ["WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["GraVity", "and", "Quantum", "Gravity:"], "labels": ["WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["SimilaroheSMHig\\gsh,\u03a00tcanalsodecatotwophotons(gluons)throughthechaPged(colored)fermiontriangleloops.Andthecorrespondinsdecaywd(,karegivenby"], "labels": ["WRONG"]}, "correct": {"tokens": ["Similar", "to", "the", "SM", "Higgs", "h,", "\u03a00t", "can", "also", "decay", "to", "two", "photons", "(gluons)", "through", "the", "charged", "(colored)", "fermion", "triangle", "loops.", "And", "the", "corresponding", "decay", "widths", "are", "given", "by"], "labels": ["TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["Similar", "oneS", "High\\gsh,\u03a00tcanalsodecatotwophotons(gluons)throughthegaPs(colored)fermion", "triangle", "loops.And", "The", "Corresponding", "Decay", "Wd(,karegivenby"], "labels": ["TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "WRONG", "WRONG", "WRONG", "WRONG", "WRONG"]}, "BS-bid-OCR": {"tokens": ["Similar", "o", "he", "SM", "Hig\\gsh,", "\u03a00t", "can", "also", "deca", "to", "two", "photons", "(gluons)", "through", "the", "chaPged", "(colored)", "fermion", "triangle", "loops.", "And", "the", "correspondins", "decay", "wd(,k", "are", "given", "by"], "labels": ["TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["Similar", "to", "the", "SM", "High\\gsh,", "\u03a00t", "can", "also", "deca", "to", "two", "photons", "(gluons)", "through", "the", "chaRged", "(colored)", "fermion", "triangle", "loops.", "And", "the", "corresponding", "decay", "wd(,k", "are", "given", "by"], "labels": ["TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["a?ndsimilarlythat"], "labels": ["WRONG"]}, "correct": {"tokens": ["and", "similarly", "that"], "labels": ["MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["and", "similarly", "that"], "labels": ["MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR": {"tokens": ["a?nd", "similarly", "that"], "labels": ["WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["and", "similarly", "that"], "labels": ["MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["Inl.r()duction"], "labels": ["WRONG"]}, "correct": {"tokens": ["Introduction"], "labels": ["OCR_ERROR"]}, "predicted": {"google": {"tokens": ["Inl.r()duction"], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["Inl.r()duction"], "labels": ["WRONG"]}, "BS-bid-OCR+google": {"tokens": ["Inl.r()duction"], "labels": ["WRONG"]}}}, {"corrupt": {"tokens": ["Lrgespnlimit"], "labels": ["WRONG"]}, "correct": {"tokens": ["Large", "spin", "limit"], "labels": ["MIXED", "MIXED", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["Lrgespnlimit"], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["Lrge", "spn", "limit"], "labels": ["WRONG", "WRONG", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["Large", "span", "limit"], "labels": ["MIXED", "WRONG", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["Similarly,\\wedenote"], "labels": ["WRONG"]}, "correct": {"tokens": ["Similarly,", "we", "denote"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["Similarly,\\we", "denote"], "labels": ["WRONG", "TOKENIZATION_ERROR"]}, "BS-bid-OCR": {"tokens": ["Similarly,", "\\we", "denote"], "labels": ["TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["Similarly,", "\\we", "denote"], "labels": ["TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["weo1)tainasecondorderODEforu(r):"], "labels": ["WRONG"]}, "correct": {"tokens": ["we", "obtain", "a", "second-order", "ODE", "for", "u(r):"], "labels": ["TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["weo1)tainasecondorderODEforu(r):"], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["we", "o1)tain", "a", "second", "order", "ODE", "for", "u(r):"], "labels": ["TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["we", "o1)tain", "a", "second", "order", "ODE", "for", "u(r):"], "labels": ["TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["MITCHELL,P.(19b1).CouplingoFphosphorlaiontoelectronandhydroKentransferbyachemi-omlsmotictypemechanism.Nature(L\\ondsn)~191,l44-148."], "labels": ["WRONG"]}, "correct": {"tokens": ["MITCHELL,", "P.", "(1961).", "Coupling", "of", "phosphorylation", "to", "electron", "and", "hydrogen", "transfer", "by", "a", "chemi-osmotic", "type", "mechanism.", "Nature", "(London),", "191,", "144-148."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED"]}, "predicted": {"google": {"tokens": ["MITCHELL,P.(19b1).CouplingoFphosphorlaiontoelectronandhydroKentransferbyachemi-omlsmotictypemechanism.Nature(L\\ondsn)~191,l44-148."], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["MITCHELL,", "P.", "(19b1).", "Coupling", "oF", "phosphorlaion", "to", "electron", "and", "hydroKen", "transfer", "by", "a", "chemi-omlsmotic", "type", "mechanism.", "Nature", "(L\\ondsn)~", "191,", "l44-148."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG"]}, "BS-bid-OCR+google": {"tokens": ["MITCHELL,", "P.", "(19b1).", "Coupling", "oF", "phosphorylation", "to", "electron", "and", "hydroKen", "transfer", "by", "a", "chemi-osmotic", "type", "mechanism.", "Nature", "(L\\ondsn)~", "191,", "l44-148."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG"]}}}, {"corrupt": {"tokens": ["where"], "labels": ["NONE"]}, "correct": {"tokens": ["where"], "labels": ["NONE"]}, "predicted": {"google": {"tokens": ["where"], "labels": ["NONE"]}, "BS-bid-OCR": {"tokens": ["where"], "labels": ["NONE"]}, "BS-bid-OCR+google": {"tokens": ["where"], "labels": ["NONE"]}}}, {"corrupt": {"tokens": ["I.JackandS.Parsons"], "labels": ["WRONG"]}, "correct": {"tokens": ["I.", "Jack", "and", "S.", "Parsons"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["I.JackandS.Parsons"], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["I.", "Jack", "and", "S.", "Parsons"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["I.", "Jack", "and", "S.", "Parsons"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["Itfollowsthat"], "labels": ["WRONG"]}, "correct": {"tokens": ["It", "follows", "that"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["It", "Follows", "That"], "labels": ["TOKENIZATION_ERROR", "WRONG", "WRONG"]}, "BS-bid-OCR": {"tokens": ["It", "follows", "that"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["It", "follows", "that"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["ItisseenthaaMESsdef.inedbyapairofcomplexnumbers(\u03b1,\u03b2).TovisualizeaMFS,\u03b1and\u03b2canbep?rameteri~edto"], "labels": ["WRONG"]}, "correct": {"tokens": ["It", "is", "seen", "that", "a", "MES", "is", "defined", "by", "a", "pair", "of", "complex", "numbers", "(\u03b1,", "\u03b2).", "To", "visualize", "a", "MES,", "\u03b1", "and", "\u03b2", "can", "be", "parameterized", "to"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["ItisseenthaaMESsdef.inedbyapairofcomplexnumbers(\u03b1,\u03b2).TovisualizeaMFS,\u03b1and\u03b2canbep?rameteri~edto"], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["It", "is", "seen", "tha", "a", "MES", "s", "def.ined", "by", "a", "pair", "of", "complex", "numbers", "(\u03b1,", "\u03b2).", "To", "visualize", "a", "MFS,", "\u03b1", "and", "\u03b2", "can", "be", "p?rameteri~ed", "to"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["It", "is", "seen", "that", "a", "MESs", "defined", "by", "a", "pair", "of", "complex", "numbers", "(\u03b1,", "\u03b2).", "To", "visualize", "a", "MFS,", "\u03b1", "and", "\u03b2", "can", "be", "p?rameteri~ed", "to"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "WRONG", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["ReductiontNCZakharovsysteni"], "labels": ["WRONG"]}, "correct": {"tokens": ["Reduction", "to", "NC", "Zakharov", "system"], "labels": ["TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED"]}, "predicted": {"google": {"tokens": ["ReductiontNCZakharovsysteni"], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["Reduction", "t", "NC", "Zakharov", "systeni"], "labels": ["TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG"]}, "BS-bid-OCR+google": {"tokens": ["Reduction", "t", "NC", "Zakharov", "systeni"], "labels": ["TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG"]}}}, {"corrupt": {"tokens": ["whereYcorrespondstothmatrixotltheembed\\dingveclors.Ourproblenthenbecomes"], "labels": ["WRONG"]}, "correct": {"tokens": ["where", "Y", "corresponds", "to", "the", "matrix", "of", "the", "embedding", "vectors.", "Our", "problem", "then", "becomes"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["whereYcorrespondstothmatrixotltheembed\\dingveclors.Ourproblenthenbecomes"], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["where", "Y", "corresponds", "to", "th", "matrix", "otl", "the", "embed\\ding", "veclors.", "Our", "problen", "then", "becomes"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["where", "Y", "corresponds", "to", "the", "matrix", "of", "the", "embed\\ding", "vectors.", "Our", "problem", "then", "becomes"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "WRONG", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["SincetheCDMbehavesadust,i.e.pM\u226adi\u03c1M,wefind"], "labels": ["WRONG"]}, "correct": {"tokens": ["Since", "the", "CDM", "behaves", "as", "dust,", "i.e.", "pM", "\u226a", "\u03c1M,", "we", "find"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["SincetheCDMbehavesadust,i.e.pM\u226adi\u03c1M,wefind"], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["Since", "the", "CDM", "behaves", "a", "dust,", "i.e.", "pM", "\u226a", "di\u03c1M,", "we", "find"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["Since", "the", "CDM", "behaves", "a", "dust,", "i.e.", "pM", "\u226a", "di\u03c1M,", "we", "find"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["onegctstheequa~/tionsfortheseries"], "labels": ["WRONG"]}, "correct": {"tokens": ["one", "gets", "the", "equations", "for", "the", "series"], "labels": ["TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["onegctstheequa~/tionsfortheseries"], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["one", "gcts", "the", "equa~/tions", "for", "the", "series"], "labels": ["TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["one", "gcts", "the", "equa~/tions", "for", "the", "series"], "labels": ["TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["Immedialyfromthedefinitio~ofpolardivisorsweget"], "labels": ["WRONG"]}, "correct": {"tokens": ["Immediately", "from", "the", "definition", "of", "polar", "divisors", "we", "get"], "labels": ["MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["Immedial", "From", "Definition~of", "polardivisorsweget"], "labels": ["WRONG", "WRONG", "WRONG", "WRONG"]}, "BS-bid-OCR": {"tokens": ["Immedialy", "from", "the", "definitio~", "of", "polar", "divisors", "we", "get"], "labels": ["WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["Immediately", "from", "the", "definition~", "of", "polar", "divisors", "we", "get"], "labels": ["MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["\\Wenowgiveanexampleofagamefamilywithdetermi~nisticpayo,ffswhereguaranteedBL-WoLFlear~ingisimpossiblebecausetheoppOnentmightbeluck?yeoughtokeepwinningwithoutrevealinganyofthestructureofthegame"], "labels": ["WRONG"]}, "correct": {"tokens": ["We", "now", "give", "an", "example", "of", "a", "game", "family", "with", "deterministic", "payoffs", "where", "guaranteed", "BL-WoLF", "learning", "is", "impossible", "because", "the", "opponent", "might", "be", "lucky", "enough", "to", "keep", "winning", "without", "revealing", "any", "of", "the", "structure", "of", "the", "game."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED"]}, "predicted": {"google": {"tokens": ["\\Wenowgiveanexampleofagamefamilywithdetermi~nisticpayo,ffswhereguaranteedBL-WoLFlear~ingisimpossiblebecausetheoppOnentmightbeluck?yeoughtokeepwinningwithoutrevealinganyofthestructureofthegame"], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["\\We", "now", "give", "an", "example", "of", "a", "game", "family", "with", "determi~nistic", "payo,ffs", "where", "guaranteed", "BL-WoLF", "lear~ing", "is", "impossible", "because", "the", "oppOnent", "might", "be", "luck?y", "eough", "to", "keep", "winning", "without", "revealing", "any", "of", "the", "structure", "of", "the", "game"], "labels": ["WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG"]}, "BS-bid-OCR+google": {"tokens": ["\\We", "now", "give", "an", "example", "of", "a", "game", "family", "with", "determi~nistic", "payoffs", "were", "guaranteed", "BL-WoLF", "lear~ing", "is", "impossible", "because", "the", "oppOnent", "might", "be", "lucky", "enough", "to", "keep", "winning", "without", "revealing", "any", "of", "the", "structure", "of", "the", "game"], "labels": ["WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "MIXED", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG"]}}}, {"corrupt": {"tokens": ["Now?wcarreadytoproveourgeneraltheorem,whichlstightuptoanaddlti.veconstant.Letusemphasize,however,thatsinceourmethodsdonotgivetheexactresult,wewillnotmakeanyefstforttooptimizttheconstanterrorterm."], "labels": ["WRONG"]}, "correct": {"tokens": ["Now", "we", "are", "ready", "to", "prove", "our", "general", "theorem,", "which", "is", "tight", "up", "to", "an", "additive", "constant.", "Let", "us", "emphasize,", "however,", "that", "since", "our", "methods", "do", "not", "give", "the", "exact", "result,", "we", "will", "not", "make", "any", "effort", "to", "optimize", "the", "constant", "error", "term."], "labels": ["TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["Now?wcarreadytoproveourgeneraltheorem,whichlstightuptoanaddlti.veconstant.Letusemphasize,however,thatsinceourmethodsdonotgivetheexactresult,wewillnotmakeanyefstforttooptimizttheconstanterrorterm."], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["Now", "?wc", "ar", "ready", "to", "prove", "our", "general", "theorem,", "which", "ls", "tight", "up", "to", "an", "addlti.ve", "constant.", "Let", "us", "emphasize,", "however,", "that", "since", "our", "methods", "do", "not", "give", "the", "exact", "result,", "we", "will", "not", "make", "any", "efstfort", "to", "optimizt", "the", "constant", "error", "term."], "labels": ["TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["Now", "we", "are", "ready", "to", "prove", "our", "general", "theorem,", "which", "is", "tight", "up", "to", "an", "addlti.ve", "constant.", "Let", "us", "emphasize,", "however,", "that", "since", "our", "methods", "do", "not", "give", "the", "exact", "result,", "we", "will", "not", "make", "any", "effort", "to", "optimize", "the", "constant", "error", "term."], "labels": ["TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["Totalcrosssectlons"], "labels": ["WRONG"]}, "correct": {"tokens": ["Total", "cross", "sections"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED"]}, "predicted": {"google": {"tokens": ["Total", "Cross", "Sections"], "labels": ["TOKENIZATION_ERROR", "WRONG", "WRONG"]}, "BS-bid-OCR": {"tokens": ["Total", "cross", "sectlons"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG"]}, "BS-bid-OCR+google": {"tokens": ["Total", "cross", "sections"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED"]}}}, {"corrupt": {"tokens": ["and"], "labels": ["NONE"]}, "correct": {"tokens": ["and"], "labels": ["NONE"]}, "predicted": {"google": {"tokens": ["and"], "labels": ["NONE"]}, "BS-bid-OCR": {"tokens": ["and"], "labels": ["NONE"]}, "BS-bid-OCR+google": {"tokens": ["and"], "labels": ["NONE"]}}}, {"corrupt": {"tokens": ["Furtherdevelopmentofdsscriptionsofgeometricshapeandtopoli)gicalst,'uctur~,aswellastaalgorithmsfortheircomputationwillprovideasolidfoundatio?nforstudyingmanyimportantbiologicalproblems.Theotherilnportanttasksaxefilentoshowhowthes(~descriptorsmaybceffectivelyusedtodeepenourl)iologicnlinightsandtodevelopaccuratepredictivemodelsofbiologicll)henOmena.Forexample,ineomput?ingprotein-proteininterfaces,achallengingtaskistodisrrimimftesurfacesthatareinvolngdinproteinl)indingfromotherrton-bin(Iingsurfacerecions,amdtaund.erstandinwhatfashionthisdependsonthepropertiesOftebindingpartnerectprotein."], "labels": ["WRONG"]}, "correct": {"tokens": ["Further", "development", "of", "descriptions", "of", "geometric", "shape", "and", "topological", "structure,", "as", "well", "as", "algorithms", "for", "their", "computation", "will", "provide", "a", "solid", "foundation", "for", "studying", "many", "important", "biological", "problems.", "The", "other", "important", "tasks", "are", "then", "to", "show", "how", "these", "descriptors", "may", "be", "effectively", "used", "to", "deepen", "our", "biological", "insights", "and", "to", "develop", "accurate", "predictive", "models", "of", "biological", "phenomena.", "For", "example,", "in", "computing", "protein-protein", "interfaces,", "a", "challenging", "task", "is", "to", "discriminate", "surfaces", "that", "are", "involved", "in", "protein", "binding", "from", "other", "non-binding", "surface", "regions,", "and", "to", "understand", "in", "what", "fashion", "this", "depends", "on", "the", "properties", "of", "the", "binding", "partner", "protein."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "MIXED", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["Furtherdevelopmentofdsscriptionsofgeometricshapeandtopoli)gicalst,'uctur~,aswellastaalgorithmsfortheircomputationwillprovideasolidfoundatio?nforstudyingmanyimportantbiologicalproblems.Theotherilnportanttasksaxefilentoshowhowthes(~descriptors", "may", "be", "effectively", "used", "to", "deepen", "our", "l)iologicnlinightsandtodevelopaccuratepredictivemodelsofbiologicll)henOmena.Forexample,input?ingprotein-proteininterfaces,achallengingtaskistodisrrimimftesurfacesthatareinvolngdinproteinl)indingfromotherrton-bin(Iingsurfacerecions,amdtaund.erstandinwhatfashionthisdependsonthepropertiesOftebindingpartnerectprotein."], "labels": ["WRONG", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG"]}, "BS-bid-OCR": {"tokens": ["Further", "development", "of", "dsscriptions", "of", "geometric", "shape", "and", "topoli)gical", "st,'uctur~,", "as", "well", "as", "ta", "algorithms", "for", "their", "computation", "will", "provide", "a", "solid", "foundatio?n", "for", "studying", "many", "important", "biological", "problems.", "The", "other", "ilnportant", "tasks", "axe", "filen", "to", "show", "how", "thes(~", "descriptors", "may", "bc", "effectively", "used", "to", "deepen", "our", "l)iologicnl", "inights", "and", "to", "develop", "accurate", "predictive", "models", "of", "biologicl", "l)henOmena.", "For", "example,", "in", "eomput?ing", "protein-protein", "interfaces,", "a", "challenging", "task", "is", "to", "disrrimimfte", "surfaces", "that", "are", "involngd", "in", "protein", "l)inding", "from", "other", "rton-bin(Iing", "surface", "recions,", "amd", "ta", "und.erstand", "in", "what", "fashion", "this", "depends", "on", "the", "properties", "Of", "te", "binding", "partnerect", "protein."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "WRONG", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["Further", "development", "of", "descriptions", "of", "geometric", "shape", "and", "topoli)gical", "st,'uctur~,", "as", "well", "as", "ta", "algorithms", "for", "their", "computation", "will", "provide", "a", "solid", "foundation", "for", "studying", "many", "important", "biological", "problems.", "The", "other", "important", "tasks", "are", "axe", "files", "to", "show", "how", "these(~", "descriptors", "may", "be", "effectively", "used", "to", "deepen", "our", "l)biological", "insights", "and", "to", "develop", "accurate", "predictive", "models", "of", "biological", "l)phenOmena.", "For", "example,", "in", "computing", "protein-protein", "interfaces,", "a", "challenging", "task", "is", "to", "discriminate", "surfaces", "that", "are", "involved", "in", "protein", "l)inding", "from", "other", "rton-bin(Ing", "surface", "regions,", "and", "to", "understand", "in", "what", "fashion", "this", "depends", "on", "the", "properties", "Of", "the", "binding", "partners", "protein."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "MIXED", "MIXED", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "MIXED", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["Belowwewillderiv~tileactua?lqu?antitativerelationb-etweenHall\\bar\\an(l.anliwirecharactcrisucs.Wewillfindthat"], "labels": ["WRONG"]}, "correct": {"tokens": ["Below", "we", "will", "derive", "the", "actual", "quantitative", "relation", "between", "Hall", "bar", "and", "antiwire", "characteristics.", "We", "will", "find", "that"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "MIXED", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["Belowwewillderiv~tileactua?lqu?antitativerelationb-etweenHall\\bar\\an(l.anli", "wirecharact", "cris", "ucs.We", "Will", "Find", "That"], "labels": ["WRONG", "WRONG", "WRONG", "WRONG", "WRONG", "WRONG", "WRONG"]}, "BS-bid-OCR": {"tokens": ["Below", "we", "will", "deriv~", "tile", "actua?l", "qu?antitative", "relation", "b-etween", "Hall\\bar\\", "an(l", ".anliwire", "charactcrisucs.", "We", "will", "find", "that"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "WRONG", "WRONG", "TOKENIZATION_ERROR", "WRONG", "WRONG", "WRONG", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["Below", "we", "will", "derive~", "tile", "actual", "quantitative", "relation", "b-etween", "Hall\\bar\\", "an(l", ".onlywire", "characteristics.", "We", "will", "find", "that"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "MIXED", "MIXED", "TOKENIZATION_ERROR", "WRONG", "WRONG", "WRONG", "WRONG", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["Wewillcalculatetheshearvicosityoftheb~undarytheoryusingtheKuboformula:"], "labels": ["WRONG"]}, "correct": {"tokens": ["We", "will", "calculate", "the", "shear", "viscosity", "of", "the", "boundary", "theory", "using", "the", "Kubo", "formula:"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["Wewillcalculatetheshearvicosityoftheb~undarytheoryusingtheKuboformula:"], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["We", "will", "calculate", "the", "shear", "vicosity", "of", "the", "b~undary", "theory", "using", "the", "Kubo", "formula:"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["We", "will", "calculate", "the", "shear", "viscosity", "of", "the", "b~undary", "theory", "using", "the", "Kubo", "formula:"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["Weset:"], "labels": ["WRONG"]}, "correct": {"tokens": ["We", "set:"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["Weset:"], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["We", "set:"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["We", "set:"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["Exactan(lapproximatedresults"], "labels": ["WRONG"]}, "correct": {"tokens": ["Exact", "and", "approximated", "results"], "labels": ["TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["Exactan(approximate", "results"], "labels": ["WRONG", "TOKENIZATION_ERROR"]}, "BS-bid-OCR": {"tokens": ["Exact", "an(l", "approximated", "results"], "labels": ["TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["Exact", "an(l", "approximated", "results"], "labels": ["TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["aglanceoverthetablesilluminatesthefollowingfeature:"], "labels": ["WRONG"]}, "correct": {"tokens": ["A", "glance", "over", "the", "tables", "illuminates", "the", "following", "features:"], "labels": ["MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED"]}, "predicted": {"google": {"tokens": ["aglanceoverthetablesilluminatesthefollowingfeature:"], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["a", "glance", "over", "the", "tables", "illuminates", "the", "following", "feature:"], "labels": ["WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG"]}, "BS-bid-OCR+google": {"tokens": ["a", "glance", "over", "the", "tables", "illuminates", "the", "following", "feature:"], "labels": ["WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG"]}}}, {"corrupt": {"tokens": ["Apolyhedralcmplex\u03a0iscalledrational(respectivelystronglyconvex,conic)ifallofltselementsarerational(respectivelystronglyconvex,c(mes).Astronglyconvexconicpolyhedralcomplexiscaledafan.Forshorthand,stronglyconvezrtionalwillbeabbreviatedtoSCR."], "labels": ["WRONG"]}, "correct": {"tokens": ["A", "polyhedral", "complex", "\u03a0", "is", "called", "rational", "(respectively", "strongly", "convex,", "conic)", "if", "all", "of", "its", "elements", "are", "rational", "(respectively", "strongly", "convex,", "cones).", "A", "strongly", "convex", "conic", "polyhedral", "complex", "is", "called", "a", "fan.", "For", "shorthand,", "strongly", "convex", "rational", "will", "be", "abbreviated", "to", "SCR."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["Apolyhedralcmplex\u03a0iscalledrational(respectively", "strongly", "convex,conic)ifallofltselementsarerational(respectively", "strongly", "convex,c(mes).Astronglyconvexconicpolyhedralcomplexiscaledafan.Forshorthand,stronglyconvezrtionalwillbeabbreviatedtoSCR."], "labels": ["WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG"]}, "BS-bid-OCR": {"tokens": ["A", "polyhedral", "cmplex", "\u03a0", "is", "called", "rational", "(respectively", "strongly", "convex,", "conic)", "if", "all", "of", "lts", "elements", "are", "rational", "(respectively", "strongly", "convex,", "c(mes).", "A", "strongly", "convex", "conic", "polyhedral", "complex", "is", "caled", "a", "fan.", "For", "shorthand,", "strongly", "convez", "rtional", "will", "be", "abbreviated", "to", "SCR."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["A", "polyhedral", "complex", "\u03a0", "is", "called", "rational", "(respectively", "strongly", "convex,", "conic)", "if", "all", "of", "lts", "elements", "are", "rational", "(respectively", "strongly", "convex,", "c(mes).", "A", "strongly", "convex", "conic", "polyhedral", "complex", "is", "called", "a", "fan.", "For", "shorthand,", "strongly", "convex", "rational", "will", "be", "abbreviated", "to", "SCR."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["which,writl;enexplicitlyfo,rthccorresponringentries,gives"], "labels": ["WRONG"]}, "correct": {"tokens": ["which,", "written", "explicitly", "for", "the", "corresponding", "entries,", "gives"], "labels": ["TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["which,writl;enexplicitlyfo,rthccorresponringentries,gives"], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["which,", "writl;en", "explicitly", "fo,r", "thc", "corresponring", "entries,", "gives"], "labels": ["TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["which,", "writl;en", "explicitly", "for", "the", "corresponding", "entries,", "gives"], "labels": ["TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "MIXED", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["isthcquanumpotentialand"], "labels": ["WRONG"]}, "correct": {"tokens": ["is", "the", "quantum", "potential", "and"], "labels": ["TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["is", "the", "quantum", "potential", "n"], "labels": ["TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "WRONG"]}, "BS-bid-OCR": {"tokens": ["is", "thc", "quanum", "potential", "and"], "labels": ["TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["is", "thc", "quanum", "potential", "and"], "labels": ["TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["Webeginwiththefollowingfemma."], "labels": ["WRONG"]}, "correct": {"tokens": ["We", "begin", "with", "the", "following", "lemma."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED"]}, "predicted": {"google": {"tokens": ["Webeginwiththefollowingfemma."], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["We", "begin", "with", "the", "following", "femma."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG"]}, "BS-bid-OCR+google": {"tokens": ["We", "begin", "with", "the", "following", "femma."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG"]}}}, {"corrupt": {"tokens": ["IfthesuppressedGEpotentialisused,henth~partialwidth\u03931increases,bein.gverysensitivetoth\\evalueofthemmixin9pa~ametercX.ForcX=0.215wefmd\u0393I=3?.Sk(',V,\u03932=73.2keV,andthecalculatedratiooftaepar-ialwidthsR\u03c8\u03b3(max)=2.38is?in.qoodagreementwithi;heLtICbresult?.Thepredictedminimalvalue,R\u03c8\u03b3(min)=i.?65,doesnotcoutradicttheBellemeasurem?entswithR\u03c8\u03b3(Bellei)<2.1."], "labels": ["WRONG"]}, "correct": {"tokens": ["If", "the", "suppressed", "GE", "potential", "is", "used,", "then", "the", "partial", "width", "\u03931", "increases,", "being", "very", "sensitive", "to", "the", "value", "of", "the", "mixing", "parameter", "cX.", "For", "cX", "=", "0.215", "we", "find", "\u03931", "=", "30.8", "keV,", "\u03932", "=", "73.2", "keV,", "and", "the", "calculated", "ratio", "of", "the", "partial", "widths", "R\u03c8\u03b3(max", ")", "=", "2.38", "is", "in", "good", "agreement", "with", "the", "LHCb", "result.", "The", "predicted", "minimal", "value,", "R\u03c8\u03b3(min", ")", "=", "1.65,", "does", "not", "contradict", "the", "Belle", "measurements", "with", "R\u03c8\u03b3(Belle)", "<", "2.1."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["IfthesuppressedGEpotentialisused,henth~partialwidth\u03931increases,bein.gverysensitivetoth\\evalueofthemmixin9pa~ametercX.ForcX=0.215wefmd\u0393I=3?.Sk(',V,\u03932=73.2keV,andthecalculatedratiooftaepar-ialwidthsR\u03c8\u03b3(max)=2.38is?in.qoodagreementwithi;heLtICbresult?.Thepredictedminimalvalue,R\u03c8\u03b3(min)=i.?65,doesnotcoutradicttheBellemeasurem?entswithR\u03c8\u03b3(Bellei)<2.1."], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["If", "the", "suppressed", "GE", "potential", "is", "used,", "hen", "th~", "partial", "width", "\u03931", "increases,", "bein.g", "very", "sensitive", "to", "th\\e", "value", "of", "them", "mixin9", "pa~ameter", "cX.", "For", "cX", "=", "0.215", "we", "fmd", "\u0393I", "=", "3?.S", "k(',V,", "\u03932", "=", "73.2", "keV,", "and", "the", "calculated", "ratio", "of", "tae", "par-ial", "widths", "R\u03c8\u03b3(max)", "=", "2.38", "is", "?in", ".qood", "agreement", "with", "i;he", "LtICb", "result?.", "The", "predicted", "minimal", "value,", "R\u03c8\u03b3(min)", "=", "i.?65,", "does", "not", "coutradict", "the", "Belle", "measurem?ents", "with", "R\u03c8\u03b3(Bellei)", "<", "2.1."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["If", "the", "suppressed", "GE", "potential", "is", "used,", "then", "the~", "partial", "width", "\u03931", "increases,", "being", "very", "sensitive", "to", "th\\e", "value", "of", "them", "mixin9", "pa~ameter", "cX.", "For", "cX", "=", "0.215", "we", "fmd", "\u0393I", "=", "3?.S", "k(',V,", "\u03932", "=", "73.2", "keV,", "and", "the", "calculated", "ratio", "of", "tae", "par-ial", "widths", "R\u03c8\u03b3(max)", "=", "2.38", "is", "in", "good", "agreement", "with", "i;he", "LtICb", "result?.", "The", "predicted", "minimal", "value,", "R\u03c8\u03b3(min)", "=", "i.?65,", "does", "not", "contradict", "the", "Belle", "measurements", "with", "R\u03c8\u03b3(Bellei)", "<", "2.1."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["SjngletsinCompos?iteHiggsBodelsinlightofiheLHCdi-photonsearches"], "labels": ["WRONG"]}, "correct": {"tokens": ["Singlets", "in", "Composite", "Higgs", "Models", "in", "light", "of", "the", "LHC", "di-photon", "searches"], "labels": ["MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["SjngletsinCompos?iteHiggsBodelsinlightofiheLHCdi-photonsearches"], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["Sjnglets", "in", "Compos?ite", "Higgs", "Bodels", "in", "light", "of", "ihe", "LHC", "di-photon", "searches"], "labels": ["WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["Singlets", "in", "Composite", "Higgs", "Models", "in", "light", "of", "the", "LHC", "di-photon", "searches"], "labels": ["MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["Inparticu\\lar,the(SWC)ieequivalenttoR(1)\u22650."], "labels": ["WRONG"]}, "correct": {"tokens": ["In", "particular,", "the", "(SWC)", "is", "equivalent", "to", "R(1)", "\u2265", "0."], "labels": ["TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["Inparticu\\lar,the(SWC)is", "equivalent", "to(1)\u22650."], "labels": ["WRONG", "TOKENIZATION_ERROR", "WRONG"]}, "BS-bid-OCR": {"tokens": ["In", "particu\\lar,", "the", "(SWC)", "ie", "equivalent", "to", "R(1)", "\u2265", "0."], "labels": ["TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["In", "particu\\lar,", "the", "(SWC)", "is", "equivalent", "to", "R(1)", "\u2265", "0."], "labels": ["TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["dSmodelI:O6planesinD.6"], "labels": ["WRONG"]}, "correct": {"tokens": ["dS", "model", "I:", "O6", "planes", "in", "D", "=", "6"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["dSmodelI:O6planesinD.6"], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["dS", "model", "I:", "O6", "planes", "in", "D.6"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG"]}, "BS-bid-OCR+google": {"tokens": ["dS", "model", "I:", "O6", "planes", "in", "D.6"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG"]}}}, {"corrupt": {"tokens": ["ThisSQAVdoesnotdependontheform\u03c40asallthe3=hdiHmS2(H1)choicesarekilledbythe3=dimC1choicesfor(ek,ek)."], "labels": ["WRONG"]}, "correct": {"tokens": ["This", "SQAV", "does", "not", "depend", "on", "the", "form", "\u03c40", "as", "all", "the", "3", "=", "dim", "S2(H1)", "choices", "are", "killed", "by", "the", "3", "=", "dim", "C1", "choices", "for", "(ek,", "ek)."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["ThisSQAVdoesnotdependontheform\u03c40asallthe3=dhimS2(H1)choicesarekilledbythe3=dimC1choicesfor(ek,ek)."], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["This", "SQAV", "does", "not", "depend", "on", "the", "form", "\u03c40", "as", "all", "the", "3", "=h", "diHm", "S2(H1)", "choices", "are", "killed", "by", "the", "3", "=", "dim", "C1", "choices", "for", "(ek,", "ek)."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["This", "SQAV", "does", "not", "depend", "on", "the", "form", "\u03c40", "as", "all", "the", "3", "=h", "diHm", "S2(H1)", "choices", "are", "killed", "by", "the", "3", "=", "dim", "C1", "choices", "for", "(ek,", "ek)."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["and"], "labels": ["NONE"]}, "correct": {"tokens": ["and"], "labels": ["NONE"]}, "predicted": {"google": {"tokens": ["and"], "labels": ["NONE"]}, "BS-bid-OCR": {"tokens": ["and"], "labels": ["NONE"]}, "BS-bid-OCR+google": {"tokens": ["and"], "labels": ["NONE"]}}}, {"corrupt": {"tokens": ["Ourapproachisfairly\\algorithmicwandassuchwePhopethatitwillbeusablealsoforothermodelswithmultidimenionalconsistency.Oneinterestingfeatureisthatinsomecasesweneedseveralbilineareqations,som.afwhichseemtohav\\ethesamecontinuumlimit.ThisisaremainderthatthereareseveraLwaystod.iscrctizeadertvative."], "labels": ["WRONG"]}, "correct": {"tokens": ["Our", "approach", "is", "fairly", "algorithmic,", "and", "as", "such", "we", "hope", "that", "it", "will", "be", "usable", "also", "for", "other", "models", "with", "multidimensional", "consistency.", "One", "interesting", "feature", "is", "that", "in", "some", "cases", "we", "need", "several", "bilinear", "equations,", "some", "of", "which", "seem", "to", "have", "the", "same", "continuum", "limit.", "This", "is", "a", "remainder", "that", "there", "are", "several", "ways", "to", "discretize", "a", "derivative."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED"]}, "predicted": {"google": {"tokens": ["Ourapproachisfairly\\algorithmicwandassuchwePhopethatitwillbeusablealsoforothermodelswithmultidimenionalconsistency.Oneinterestingfeatureisthatinsomecasesweneedseveralbilineareqations,som.afwhichseemtohav\\ethesamecontinuumlimit.ThisisaremainderthatthereareseveraLwaystod.iscrctizeadertvative."], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["Our", "approach", "is", "fairly\\", "algorithmic", "wand", "as", "such", "weP", "hope", "that", "it", "will", "be", "usable", "also", "for", "other", "models", "with", "multidimenional", "consistency.", "One", "interesting", "feature", "is", "that", "in", "some", "cases", "we", "need", "several", "bilinear", "eqations,", "som.af", "which", "seem", "to", "hav\\e", "the", "same", "continuum", "limit.", "This", "is", "a", "remainder", "that", "there", "are", "severaL", "ways", "to", "d.iscrctize", "a", "dertvative."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG"]}, "BS-bid-OCR+google": {"tokens": ["Our", "approach", "is", "fairly\\", "algorithmic", "and", "as", "such", "weP", "hope", "that", "it", "will", "be", "usable", "also", "for", "other", "models", "with", "multi", "dimensional", "consistency.", "One", "interesting", "feature", "is", "that", "in", "some", "cases", "we", "need", "several", "bilinear", "equations,", "som.af", "which", "seem", "to", "hav\\e", "the", "same", "continuum", "limit.", "This", "is", "a", "reminder", "that", "there", "are", "severaL", "ways", "to", "discretize", "a", "derivative."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED"]}}}, {"corrupt": {"tokens": ["whereD0(E;m)isthenornlalizedleptonenergydistribtttionintherestframeofthetopquarkwhosemassism."], "labels": ["WRONG"]}, "correct": {"tokens": ["where", "D0(E;", "m)", "is", "the", "normalized", "lepton", "energy", "distribution", "in", "the", "rest", "frame", "of", "the", "top", "quark", "whose", "mass", "is", "m."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["whereD0(E;m)isthenornlalizedleptonenergydistribtttionintherestframeofthetopquarkwhosemassism."], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["where", "D0(E;", "m)", "is", "the", "nornlalized", "lepton", "energy", "distribtttion", "in", "the", "rest", "frame", "of", "the", "top", "quark", "whose", "mass", "is", "m."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["where", "D0(E;", "m)", "is", "the", "normalized", "lepton", "energy", "distribution", "in", "the", "rest", "frame", "of", "the", "top", "quark", "whose", "mass", "is", "m."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["OnecaninprinciplalsodeTivemAuslng(standardnotations3:"], "labels": ["WRONG"]}, "correct": {"tokens": ["One", "can", "in", "principle", "also", "derive", "mA", "using", "(standard", "notations):"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED"]}, "predicted": {"google": {"tokens": ["Onecan", "principal", "sodeTivemAuslng(standardnotations3:"], "labels": ["WRONG", "WRONG", "WRONG"]}, "BS-bid-OCR": {"tokens": ["One", "can", "in", "principl", "also", "deTive", "mA", "uslng", "(standard", "notations3:"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG"]}, "BS-bid-OCR+google": {"tokens": ["One", "can", "in", "principle", "also", "deRive", "mA", "using", "(standard", "notations3:"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "WRONG"]}}}, {"corrupt": {"tokens": ["THEBETAFUNCTIONS"], "labels": ["WRONG"]}, "correct": {"tokens": ["THE", "BETA", "FUNCTIONS"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["THE", "BETA", "FUNCTIONS"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR": {"tokens": ["THE", "BETA", "FUNCTIONS"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["THE", "BETA", "FUNCTIONS"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["onefindsexactly"], "labels": ["WRONG"]}, "correct": {"tokens": ["one", "finds", "exactly"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["one", "finds", "exactly"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR": {"tokens": ["one", "finds", "exactly"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["one", "finds", "exactly"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["Classicaly!heparafermionsarepl'lmaryfieldsefweightone.Quantummecha?icalcytialhecommutator"], "labels": ["WRONG"]}, "correct": {"tokens": ["Classically", "the", "parafermions", "are", "primary", "fields", "of", "weight", "one.", "Quantum", "mechanically", "the", "commutator"], "labels": ["MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["Classically!heparafermionsarepl'lmaryfieldsefweightone.Quantummecha?icalcytialhecommutator"], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["Classicaly", "!he", "parafermions", "are", "pl'lmary", "fields", "ef", "weight", "one.", "Quantum", "mecha?ical", "cytial", "he", "commutator"], "labels": ["WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "WRONG", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["Classically,", "the", "parafermions", "are", "primary", "fields", "of", "weight", "one.", "Quantum", "mechanical", "cyteal", "he", "commutator"], "labels": ["WRONG", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "WRONG", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["2.3.Parameters"], "labels": ["WRONG"]}, "correct": {"tokens": ["2.3.", "Parameters"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["2.3.Parameters"], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["2.3.", "Parameters"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["2.3.", "Parameters"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["EffectsofosmicStringsonPreeStreaming"], "labels": ["WRONG"]}, "correct": {"tokens": ["Effects", "of", "Cosmic", "Strings", "on", "Free", "Streaming"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["EffectsofosmicStringsonPreeStreaming"], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["Effects", "of", "osmic", "Strings", "on", "Pree", "Streaming"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["Effects", "of", "cosmic", "Strings", "on", "Free", "Streaming"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["forallnsufficientlylarge,wherewetitkeintoac?counteigenvaluemultiplicities."], "labels": ["WRONG"]}, "correct": {"tokens": ["for", "all", "n", "sufficiently", "large,", "where", "we", "take", "into", "account", "eigenvalue", "multiplicities."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["for", "all", "sufficiently", "large,wherewetitke", "into", "account", "eigenvalue", "multiplicities."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR": {"tokens": ["for", "all", "n", "sufficiently", "large,", "where", "we", "titke", "into", "ac?count", "eigenvalue", "multiplicities."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["for", "all", "n", "sufficiently", "large,", "where", "we", "take", "into", "account", "eigenvalue", "multiplicities."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["Ordinaryleastsquares"], "labels": ["WRONG"]}, "correct": {"tokens": ["Ordinary", "least", "squares"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["Ordinary", "Least", "Squares"], "labels": ["TOKENIZATION_ERROR", "WRONG", "WRONG"]}, "BS-bid-OCR": {"tokens": ["Ordinary", "least", "squares"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["Ordinary", "least", "squares"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["Thjsimmediatelyrim\\pliesthe"], "labels": ["WRONG"]}, "correct": {"tokens": ["This", "immediately", "implies", "the"], "labels": ["MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["Thjsimmediatelyrim\\pliesthe"], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["Thjs", "immediatelyr", "im\\plies", "the"], "labels": ["WRONG", "WRONG", "WRONG", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["This", "immediately", "im\\plies", "the"], "labels": ["MIXED", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["Results"], "labels": ["NONE"]}, "correct": {"tokens": ["Results"], "labels": ["NONE"]}, "predicted": {"google": {"tokens": ["Results"], "labels": ["NONE"]}, "BS-bid-OCR": {"tokens": ["Results"], "labels": ["NONE"]}, "BS-bid-OCR+google": {"tokens": ["Results"], "labels": ["NONE"]}}}, {"corrupt": {"tokens": ["TherepresentatiouofOCshouldbesuchthattheouterautomorphismsofUEarerepresentedviaunitaryoperatorsasinnetatomorphismsi.e."], "labels": ["WRONG"]}, "correct": {"tokens": ["The", "representation", "of", "UE", "should", "be", "such", "that", "the", "outer", "automorphisms", "of", "UE", "are", "represented", "via", "unitary", "operators", "as", "inner", "automorphisms.", "i.e."], "labels": ["TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["TherepresentatiouofOCshouldbesuchthattheouterautomorphismsofUEarerepresentedviaunitaryoperatorsasinnetatomorphismsi.e."], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["The", "representatiou", "of", "OC", "should", "be", "such", "that", "the", "outer", "automorphisms", "of", "UE", "are", "represented", "via", "unitary", "operators", "as", "innet", "atomorphisms", "i.e."], "labels": ["TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["The", "representation", "of", "OC", "should", "be", "such", "that", "the", "outer", "automorphisms", "of", "UE", "are", "represented", "via", "unitary", "operators", "as", "innet", "atomorphisms", "i.e."], "labels": ["TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["\u03a0N(q)?\u03a0ph(q)+\u03a0NN\u0304(q),"], "labels": ["WRONG"]}, "correct": {"tokens": ["\u03a0N(q)", "=", "\u03a0ph(q)", "+", "\u03a0NN\u0304(q),"], "labels": ["TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["\u03a0N(q)?\u03a0ph(q)+\u03a0NN\u0304(q),"], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["\u03a0N(q)", "?", "\u03a0ph(q)", "+", "\u03a0NN\u0304(q),"], "labels": ["TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["\u03a0N(q)", "?", "\u03a0ph(q)", "+", "\u03a0NN\u0304(q),"], "labels": ["TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["Lety3=\u03c8i(x3).SimilartoCase1,wehave"], "labels": ["WRONG"]}, "correct": {"tokens": ["Let", "y3", "=", "\u03c8i(x3).", "Similar", "to", "Case", "1,", "we", "have"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["Lety3=\u03c8i(x3).SimilartoCase1,wehave"], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["Let", "y3", "=", "\u03c8i(x3).", "Similar", "to", "Case", "1,", "we", "have"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["Let", "y3", "=", "\u03c8i(x3).", "Similar", "to", "Case", "1,", "we", "have"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["Quantnmd.namicsofaparticleconstraindtolieanasurface"], "labels": ["WRONG"]}, "correct": {"tokens": ["Quantum", "dynamics", "of", "a", "particle", "constrained", "to", "lie", "on", "a", "surface"], "labels": ["MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["Quantnmd.namicsofaparticleconstraindtolieanasurface"], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["Quantnm", "d.namics", "of", "a", "particle", "constraind", "to", "lie", "an", "a", "surface"], "labels": ["WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["Quantum", "d.namics", "of", "a", "particle", "constrained", "to", "lie", "on", "a", "surface"], "labels": ["MIXED", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["Next,weconsoderaccretiondiskeft~ctsinmorere;~listicwaveformmod;el,s.EMRIGWsarehighlyrelativistic,withvelocitie\\sclosetothespeedaflightndsometimesskimmingtheSMBHhorizon.Asuch,HewtonisnwaveformestimatesforeWdataanalysisareinaccu,ratc.HereweinverstigatetherelativLsticcrrectiontotheEMRI\\dynalnicsusing|;heextcnded-nebodyframework,andmakesimpleestimatesontheimprintofaccretion?dis~:effectsontheGWwo~veform.Thisanalysis,however,continestonalectre1ativisticcorrectionstoaccretiandi~;kelfects."], "labels": ["WRONG"]}, "correct": {"tokens": ["Next,", "we", "consider", "accretion", "disk", "effects", "in", "more", "realistic", "waveform", "models.", "EMRI", "GWs", "are", "highly", "relativistic,", "with", "velocities", "close", "to", "the", "speed", "of", "light", "and", "sometimes", "skimming", "the", "SMBH", "horizon.", "As", "such,", "Newtonian", "waveform", "estimates", "for", "GW", "data", "analysis", "are", "inaccurate.", "Here", "we", "investigate", "the", "relativistic", "correction", "to", "the", "EMRI", "dynamics", "using", "the", "extended", "one", "body", "framework,", "and", "make", "simple", "estimates", "on", "the", "imprint", "of", "accretion", "disk", "effects", "on", "the", "GW", "waveform.", "This", "analysis,", "however,", "continues", "to", "neglect", "relativistic", "corrections", "to", "accretion", "disk", "effects."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "MIXED"]}, "predicted": {"google": {"tokens": ["Next,weconsoderaccretiondiskeft~ctsinmorere;~listicwaveformmod;el,s.EMRIGWsarehighlyrelativistic,withvelocitie\\sclosetothespeedaflightndsometimesskimmingtheSMBHhorizon.Asuch,HewtonisnwaveformestimatesforeWdataanalysisareinaccu,ratc.HereweinverstigatetherelativLsticcrrectiontotheEMRI\\dynalnicsusing|;heextcnded-nebodyframework,andmakesimpleestimatesontheimprintofaccretion?dis~:effectsontheGWwo~veform.Thisanalysis,however,continestonalectre1ativisticcorrectionstoaccretiandi~;kelfects."], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["Next,", "we", "consoder", "accretion", "disk", "eft~cts", "in", "more", "re;~listic", "waveform", "mod;el,s.", "EMRIGWs", "are", "highly", "relativistic,", "with", "velocitie\\s", "close", "to", "the", "speed", "af", "light", "nd", "sometimes", "skimming", "the", "SMBH", "horizon.", "A", "such,", "Hewtonisn", "waveform", "estimates", "for", "eW", "data", "analysis", "are", "inaccu,ratc.", "Here", "we", "inverstigate", "the", "relativLstic", "crrection", "to", "the", "EMRI\\", "dynalnics", "using", "|;he", "extcnded-nebody", "framework,", "and", "make", "simple", "estimates", "on", "the", "imprint", "of", "accretion?", "dis~:", "effects", "on", "the", "GW", "wo~veform.", "This", "analysis,", "however,", "contines", "to", "nalect", "re1ativistic", "corrections", "to", "accretian", "di~;k", "elfects."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "WRONG"]}, "BS-bid-OCR+google": {"tokens": ["Next,", "we", "consider", "accretion", "disk", "eft~cts", "in", "more", "re;~listic", "waveform", "mod;el,s.", "EMIRATEs", "are", "highly", "relativistic,", "with", "velocitie\\s", "close", "to", "the", "speed", "of", "light", "and", "sometimes", "skimming", "the", "SMBH", "horizon.", "As", "such,", "Hewtonisn", "waveform", "estimates", "for", "eW", "data", "analysis", "are", "inaccu,ratc.", "Here", "we", "investigate", "the", "relativIstic", "correction", "to", "the", "EMRI\\", "dynamics", "using", "|;he", "extended-nobody", "framework,", "and", "made", "simple", "estimates", "on", "the", "imprint", "of", "accretion?", "dis~:", "effects", "on", "the", "GW", "waveform.", "This", "analysis,", "however,", "continues", "to", "select", "relativistic", "corrections", "to", "accretia", "di~;k", "effects."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "WRONG", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "MIXED", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "WRONG", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "MIXED"]}}}, {"corrupt": {"tokens": ["AttheAdSminimum,thegravitinomass,oforderAdScurvature,isalsosetbytheperturbationf."], "labels": ["WRONG"]}, "correct": {"tokens": ["At", "the", "AdS", "minimum,", "the", "gravitino", "mass,", "of", "order", "AdS", "curvature,", "is", "also", "set", "by", "the", "perturbation", "f,"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED"]}, "predicted": {"google": {"tokens": ["AttheAdSminimum,thegravitinomass,oforderAdScurvature,isalsosetbytheperturbationf."], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["At", "the", "AdS", "minimum,", "the", "gravitino", "mass,", "of", "order", "AdS", "curvature,", "is", "also", "set", "by", "the", "perturbation", "f."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG"]}, "BS-bid-OCR+google": {"tokens": ["At", "the", "AdS", "minimum,", "the", "gravitino", "mass,", "of", "order", "AdS", "curvature,", "is", "also", "set", "by", "the", "perturbation", "f."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG"]}}}, {"corrupt": {"tokens": ["Proof:Infirststepa\\llthecoefficientswi\\[lbecomenegativeofthemselvessolhemeauwillbeneEativeandiuverionaroundthemeanwillleavetheminnegativecoefficients.Insecondstep~llthecoefficielltswiIlbecomenegativeofthemselvessomeanwillbep,ositiveandthecoefficientswillberotatedbacktotheiroriginalplacearoundthe?mea,"], "labels": ["WRONG"]}, "correct": {"tokens": ["Proof", ":", "In", "first", "step", "all", "the", "coefficients", "will", "become", "negative", "of", "themselves", "so", "the", "mean", "will", "be", "negative", "and", "inversion", "around", "the", "mean", "will", "leave", "them", "in", "negative", "coefficients.", "In", "second", "step", "all", "the", "coefficients", "will", "become", "negative", "of", "themselves", "so", "mean", "will", "be", "positive", "and", "the", "coefficients", "will", "be", "rotated", "back", "to", "their", "original", "places", "around", "the", "mean."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED"]}, "predicted": {"google": {"tokens": ["Proof:Infirststepa\\llthecoefficientswi\\[lbecomenegativeofthemselvessolhemeauwillbeneEativeandiuverionaroundthemeanwillleavetheminnegativecoefficients.Insecondstep~llthecoefficielltswiIlbecomenegativeofthemselvessomeanwillbep,ositiveandthecoefficientswillberotatedbacktotheiroriginalplacearoundthe?mea,"], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["Proof:", "In", "first", "step", "a\\ll", "the", "coefficients", "wi\\[l", "become", "negative", "of", "themselves", "so", "lhe", "meau", "will", "be", "neEative", "and", "iuverion", "around", "the", "mean", "will", "leave", "them", "in", "negative", "coefficients.", "In", "second", "step", "~ll", "the", "coefficiellts", "wiIl", "become", "negative", "of", "themselves", "so", "mean", "will", "be", "p,ositive", "and", "the", "coefficients", "will", "be", "rotated", "back", "to", "their", "original", "place", "around", "the", "?mea,"], "labels": ["WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG"]}, "BS-bid-OCR+google": {"tokens": ["Proof:", "In", "first", "step", "a\\ll", "the", "coefficients", "wi\\[l", "become", "negative", "of", "themselves", "so", "the", "menu", "will", "be", "neGative", "and", "iuverion", "around", "the", "mean", "will", "leave", "them", "in", "negative", "coefficients.", "In", "the", "second", "step", "~all", "the", "coefficients", "wiIl", "become", "negative", "of", "themselves", "so", "the", "mean", "will", "be", "positive", "and", "the", "coefficients", "will", "be", "rotated", "back", "to", "their", "original", "place", "around", "the", "?mea,"], "labels": ["WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "MIXED", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG"]}}}, {"corrupt": {"tokens": ["TheauthorwouldliketothankT.p.Spill0r,\\\\W.Munro,J.F.Ralph,T.~.Clark,J.3amsonand,S.Kahlilforinformativeandsti?muatingdiscussioandLoughboroughUnivetsityHPCserviceforuseoftheirfacllities."], "labels": ["WRONG"]}, "correct": {"tokens": ["The", "author", "would", "like", "to", "thank", "T.", "P.", "Spiller,", "W.", "Munro,", "J.F.", "Ralph,", "T.", "D.", "Clark,", "J.", "Samson", "and", ",", "S.", "Kahlil", "for", "informative", "and", "stimulating", "discussion", "and", "Loughborough", "University", "HPC", "service", "for", "use", "of", "their", "facilities."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED"]}, "predicted": {"google": {"tokens": ["The", "authors", "would", "like", "to", "thank.p.Spill", "0r,\\\\W.Munro,J.F.Ralph,T.~.Clark,J.3amsonand,S.Kahlil", "For", "Informative", "Sti?muatingdiscussioandLoughboroughUnivetsityHPCserviceforuseoftheirfacllities."], "labels": ["TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "WRONG", "WRONG", "WRONG"]}, "BS-bid-OCR": {"tokens": ["The", "author", "would", "like", "to", "thank", "T.", "p.", "Spill0r,\\", "\\W.", "Munro,", "J.", "F.", "Ralph,", "T.~.", "Clark,", "J.", "3amson", "and,", "S.", "Kahlil", "for", "informative", "and", "sti?muating", "discussio", "and", "Loughborough", "Univetsity", "HPC", "service", "for", "use", "of", "their", "facllities."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "WRONG", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG"]}, "BS-bid-OCR+google": {"tokens": ["The", "author", "would", "like", "to", "thank", "T.", "p.", "Spill0r,\\", "\\W.", "Munro,", "J.", "F.", "Ralph,", "T.~.", "Clark,", "J.", "3amson", "and,", "S.", "Kahlil", "for", "informative", "and", "sti?muating", "discussion", "and", "Loughborough", "University", "HPC", "service", "for", "use", "of", "their", "facilities."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "WRONG", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED"]}}}, {"corrupt": {"tokens": ["Notethat,whenk=1,theassumptionthatDisaset.(andnotallmultiset)forcesD=Gandwehavc\u03c7(D)=0foreverynon-trivialcharacter\u03c7ofG.Soouranalysisdoesnotapplyinthecasek=l."], "labels": ["WRONG"]}, "correct": {"tokens": ["Note", "that,", "when", "k", "=", "1,", "the", "assumption", "that", "D", "is", "a", "set", "(and", "not", "a", "multiset)", "forces", "D", "=", "G", "and", "we", "have", "\u03c7(D)", "=", "0", "for", "every", "non-trivial", "character", "\u03c7", "of", "G.", "So", "our", "analysis", "does", "not", "apply", "in", "the", "case", "k", "=", "1."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED"]}, "predicted": {"google": {"tokens": ["Note", "That,when", "k=1,theassumptionthatDisaset.(andnotallmultiset)forcesD=Gandwehavc\u03c7(D)=0foreverynon-trivialcharacter\u03c7ofG.Soouranalysisdoesnotapplyinthecasek=l."], "labels": ["TOKENIZATION_ERROR", "WRONG", "WRONG"]}, "BS-bid-OCR": {"tokens": ["Note", "that,", "when", "k", "=", "1,", "the", "assumption", "that", "D", "is", "a", "set.", "(and", "not", "all", "multiset)", "forces", "D", "=", "G", "and", "we", "havc", "\u03c7(D)", "=", "0", "for", "every", "non-trivial", "character", "\u03c7", "of", "G.", "So", "our", "analysis", "does", "not", "apply", "in", "the", "case", "k", "=", "l."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG"]}, "BS-bid-OCR+google": {"tokens": ["Note", "that,", "when", "k", "=", "1,", "the", "assumption", "that", "D", "is", "a", "set.", "(and", "not", "all", "multiset)", "forces", "D", "=", "G", "and", "we", "hvac", "\u03c7(D)", "=", "0", "for", "every", "non-trivial", "character", "\u03c7", "of", "G.", "So", "our", "analysis", "does", "not", "apply", "in", "the", "case", "k", "=", "l."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG"]}}}, {"corrupt": {"tokens": ["Usingtilemaximumpriciple,wededu(:ethat"], "labels": ["WRONG"]}, "correct": {"tokens": ["Using", "the", "maximum", "principle,", "we", "deduce", "that"], "labels": ["TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["Using", "Tile", "Maximum", "Principle,wededu(:ethat"], "labels": ["TOKENIZATION_ERROR", "WRONG", "WRONG", "WRONG"]}, "BS-bid-OCR": {"tokens": ["Using", "tile", "maximum", "priciple,", "we", "dedu(:e", "that"], "labels": ["TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["Using", "tile", "maximum", "principle,", "we", "dedu(:e", "that"], "labels": ["TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["Thus,thedecayratcremainsoforder\u03930solongas\u039bisnotlargerthanMl'.Tfiisstilleemslikeacomfortab1eresult."], "labels": ["WRONG"]}, "correct": {"tokens": ["Thus,", "the", "decay", "rate", "remains", "of", "order", "\u03930", "so", "long", "as", "\u039b", "is", "not", "larger", "than", "MP.", "This", "still", "seems", "like", "a", "comfortable", "result."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["Thus,thedecayratcremainsoforder\u03930solongas\u039bisnotlargerthanMl'.Tfiisstilleemslikeacomfortab1eresult."], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["Thus,", "the", "decay", "ratc", "remains", "of", "order", "\u03930", "so", "long", "as", "\u039b", "is", "not", "larger", "than", "Ml'.", "Tfiis", "still", "eems", "like", "a", "comfortab1e", "result."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["Thus,", "the", "decay", "rate", "remains", "of", "order", "\u03930", "so", "long", "as", "\u039b", "is", "not", "larger", "than", "Ml'.", "Tfiis", "still", "seems", "like", "a", "comfortable", "result."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["andintegratingagainandsettingx1(0)=0\u0005weobtain/,hbodyposition,"], "labels": ["WRONG"]}, "correct": {"tokens": ["and", "integrating", "again", "and", "setting", "x1(0)", "=", "0,", "we", "obtain", "the", "body", "position,"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["andintegratingagainandsettingx1(0)=0weobtain/,hbodyposition,"], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["and", "integrating", "again", "and", "setting", "x1(0)", "=", "0\u0005", "we", "obtain", "/,h", "body", "position,"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["and", "integrating", "again", "and", "setting", "x1(0)", "=", "0", "we", "obtain", "/,h", "body", "position,"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["Duringsleady-statedatataking,thecalibrationwillbeperforme(lsoversltimempsinadaytotheelectronicssystemviafullyautomaticBoftware."], "labels": ["WRONG"]}, "correct": {"tokens": ["During", "steady-state", "data", "taking,", "the", "calibration", "will", "be", "performed", "several", "times", "in", "a", "day", "to", "the", "electronics", "system", "via", "fully", "automatic", "software."], "labels": ["TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED"]}, "predicted": {"google": {"tokens": ["Duringsleady-statedatataking,thecalibrationwillbeperforme(lsoversltimempsinadaytotheelectronicssystemviafullyautomaticBoftware."], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["During", "sleady-state", "data", "taking,", "the", "calibration", "will", "be", "performe(l", "soversl", "timemps", "in", "a", "day", "to", "the", "electronics", "system", "via", "fully", "automatic", "Boftware."], "labels": ["TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG"]}, "BS-bid-OCR+google": {"tokens": ["During", "steady-state", "data", "taking,", "the", "calibration", "will", "be", "performed(l", "several", "times", "in", "a", "day", "to", "the", "electronics", "system", "via", "fully", "automatic", "Software."], "labels": ["TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG"]}}}, {"corrupt": {"tokens": ["andalso"], "labels": ["WRONG"]}, "correct": {"tokens": ["and", "also"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["andalso"], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["and", "also"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["and", "also"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["$tructuralpropertiesofthetoplayer"], "labels": ["WRONG"]}, "correct": {"tokens": ["Structural", "properties", "of", "the", "top", "layer"], "labels": ["MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["$structural", "properties", "of", "the", "player"], "labels": ["WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG"]}, "BS-bid-OCR": {"tokens": ["$tructural", "properties", "of", "the", "top", "layer"], "labels": ["WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["$structural", "properties", "of", "the", "top", "layer"], "labels": ["WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["wherewehaveitroducedi~hedimenaionlessparam\\eter"], "labels": ["WRONG"]}, "correct": {"tokens": ["where", "we", "have", "introduced", "the", "dimensionless", "parameter"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "MIXED", "MIXED"]}, "predicted": {"google": {"tokens": ["wherewehaveitroducedi~hedimenaionlessparam\\eter"], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["where", "we", "have", "itroduced", "i~he", "dimenaionless", "param\\eter"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "WRONG", "WRONG"]}, "BS-bid-OCR+google": {"tokens": ["where", "we", "have", "introduced", "i~the", "dimensionless", "param\\eter"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "WRONG", "MIXED", "WRONG"]}}}, {"corrupt": {"tokens": ["whichcompletestheproof."], "labels": ["WRONG"]}, "correct": {"tokens": ["which", "completes", "the", "proof."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["which", "completes", "the", "proof."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR": {"tokens": ["which", "completes", "the", "proof."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["which", "completes", "the", "proof."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["where"], "labels": ["NONE"]}, "correct": {"tokens": ["where"], "labels": ["NONE"]}, "predicted": {"google": {"tokens": ["where"], "labels": ["NONE"]}, "BS-bid-OCR": {"tokens": ["where"], "labels": ["NONE"]}, "BS-bid-OCR+google": {"tokens": ["where"], "labels": ["NONE"]}}}, {"corrupt": {"tokens": ["Indeed,bytileefinitionofapolarizedfunction,we\\have"], "labels": ["WRONG"]}, "correct": {"tokens": ["Indeed,", "by", "the", "definition", "of", "a", "polarized", "function,", "we", "have"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["Indeed,bytileefinitionofa", "polarized", "function,we\\have"], "labels": ["WRONG", "TOKENIZATION_ERROR", "WRONG"]}, "BS-bid-OCR": {"tokens": ["Indeed,", "by", "tile", "efinition", "of", "a", "polarized", "function,", "we", "\\have"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG"]}, "BS-bid-OCR+google": {"tokens": ["Indeed,", "by", "tile", "definition", "of", "a", "polarized", "function,", "we", "\\have"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG"]}}}, {"corrupt": {"tokens": ["TheMovieLensrecommendaliondatasethasaquitediFfel'entm.rphol\\ogythanthatofthenleta?mini,,g.Thedescriptiosoftheusersandtheztemaremuchmorelimited;usersaredescribedonlybyfourfeaturo.si:sex,agc,ccu-pationandlocation,andmoviest)ytheirgenrewhichtakes19d?ifflerentvalnes,suchascomedy,sci-fitothriller,etc.WemodelthesedescriDtorsusingon-of-Nrepresentation."], "labels": ["WRONG"]}, "correct": {"tokens": ["The", "MovieLens", "recommendation", "dataset", "has", "a", "quite", "different", "morphology", "than", "that", "of", "the", "meta-mining.", "The", "descriptions", "of", "the", "users", "and", "the", "items", "are", "much", "more", "limited;", "users", "are", "described", "only", "by", "four", "features:", "sex,", "age,", "occupation", "and", "location,", "and", "movies", "by", "their", "genre", "which", "takes", "19", "different", "values,", "such", "as", "comedy,", "sci-fi", "to", "thriller,", "etc.", "We", "model", "these", "descriptors", "using", "one-of-N", "representation."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["TheMovieLensrecommendaliondatasethasaquitediFfel'entm.rphol\\ogythanthatofthenleta?mini,,g.Thedescriptiosoftheusersandtheztemaremuchmorelimited;usersaredescribedonlybyfourfeaturo.si:sex,agc,ccu-pationandlocation,andmoviest)ytheirgenrewhichtakes19d?ifflerentvalnes,suchascomedy,sci-fitothriller,etc.WemodelthesedescriDtorsusingon-of-Nrepresentation."], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["The", "Movie", "Lens", "recommendalion", "dataset", "has", "a", "quite", "diFfel'ent", "m.rphol\\ogy", "than", "that", "of", "the", "nleta?mini,,g.", "The", "descriptios", "of", "the", "users", "and", "the", "ztem", "are", "much", "more", "limited;", "users", "are", "described", "only", "by", "four", "featuro.si:", "sex,", "agc,", "ccu-pation", "and", "location,", "and", "movies", "t)y", "their", "genre", "which", "takes", "19", "d?ifflerent", "valnes,", "such", "as", "comedy,", "sci-fito", "thriller,", "etc.", "We", "model", "these", "descriDtors", "using", "on-of-N", "representation."], "labels": ["TOKENIZATION_ERROR", "WRONG", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["The", "Movie", "Lens", "recommendation", "dataset", "has", "a", "quite", "diFfel'ent", "m.rphol\\ogy", "than", "that", "of", "the", "nlra?mini,,g.", "The", "descriptios", "of", "the", "users", "and", "the", "ztem", "are", "much", "more", "limited;", "users", "are", "described", "only", "by", "four", "featuro.si:", "sex,", "agc,", "ccu-pation", "and", "location,", "and", "movies", "t)y", "their", "genre", "which", "takes", "19", "d?ifflerent", "valnes,", "such", "as", "comedy,", "sci-fito", "thriller,", "etc.", "We", "model", "these", "descriPtors", "using", "on-of-N", "representation."], "labels": ["TOKENIZATION_ERROR", "WRONG", "WRONG", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["b)A.DonnachieandP.V.Landshoff,Phys.;Lett.B296(1992)22?;"], "labels": ["WRONG"]}, "correct": {"tokens": ["b)", "A.", "Donnachie", "and", "P.", "V.", "Landshoff,", "Phys.", "Lett.", "B296", "(1992)", "227;"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED"]}, "predicted": {"google": {"tokens": ["b)A.DonnachieandP.V.Landshoff,Phys.;Lett.B296(1992)22?;"], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["b)", "A.", "Donnachie", "and", "P.V.", "Landshoff,", "Phys.;", "Lett.", "B296", "(1992)", "22?;"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG"]}, "BS-bid-OCR+google": {"tokens": ["b)", "A.", "Donnachie", "and", "P.V.", "Landshoff,", "Phys.;", "Lett.", "B296", "(1992)", "22?;"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG"]}}}, {"corrupt": {"tokens": ["ThctheoryofVassilievinvariantsalsoappliestoFramedknots.ainsomesensemorenaturally.Ithiscase,theframingforasingularknotisall1owedtohavesimplezerosawayfromthedoublepo1ns."], "labels": ["WRONG"]}, "correct": {"tokens": ["The", "theory", "of", "Vassiliev", "invariants", "also", "applies", "to", "framed", "knots,", "and", "in", "some", "sense", "more", "naturally.", "In", "this", "case,", "the", "framing", "for", "a", "singular", "knot", "is", "allowed", "to", "have", "simple", "zeros", "away", "from", "the", "double", "points."], "labels": ["MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED"]}, "predicted": {"google": {"tokens": ["ThctheoryofVassilievinvariantsalsoappliestoFramedknots.ainsomesensemorenaturally.Ithiscase,theframingforasingularknotisall1owedtohavesimplezerosawayfromthedoublepo1ns."], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["Thc", "theory", "of", "Vassiliev", "invariants", "also", "applies", "to", "Framed", "knots.", "a", "in", "some", "sense", "more", "naturally.", "I", "this", "case,", "the", "framing", "for", "a", "singular", "knot", "is", "all1owed", "to", "have", "simple", "zeros", "away", "from", "the", "double", "po1ns."], "labels": ["WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG"]}, "BS-bid-OCR+google": {"tokens": ["The", "theory", "of", "Vassiliev", "invariants", "also", "applies", "to", "Framed", "knots.", "a", "in", "some", "sense", "more", "naturally.", "In", "this", "case,", "the", "framing", "for", "a", "singular", "knot", "is", "allowed", "to", "have", "simple", "zeros", "away", "from", "the", "double", "po1ns."], "labels": ["MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG"]}}}, {"corrupt": {"tokens": ["and"], "labels": ["NONE"]}, "correct": {"tokens": ["and"], "labels": ["NONE"]}, "predicted": {"google": {"tokens": ["and"], "labels": ["NONE"]}, "BS-bid-OCR": {"tokens": ["and"], "labels": ["NONE"]}, "BS-bid-OCR+google": {"tokens": ["and"], "labels": ["NONE"]}}}, {"corrupt": {"tokens": ["alld"], "labels": ["WRONG"]}, "correct": {"tokens": ["and"], "labels": ["OCR_ERROR"]}, "predicted": {"google": {"tokens": ["alld"], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["alld"], "labels": ["WRONG"]}, "BS-bid-OCR+google": {"tokens": ["alld"], "labels": ["WRONG"]}}}, {"corrupt": {"tokens": ["Inshort,mostofthel,ashtagso.rerelatedtosup~ortfortheArabSpring,oppositio.ntoexiBtingregimesinthemiddleEast,solitharityorconcernoverhotspotsintheMuslimworld\\,anddisillusionnrentwitl~thecurrentlstatusquo."], "labels": ["WRONG"]}, "correct": {"tokens": ["In", "short,", "most", "of", "the", "hashtags", "are", "related", "to", "support", "for", "the", "Arab", "Spring,", "opposition", "to", "existing", "regimes", "in", "the", "Middle", "East,", "solidarity", "or", "concern", "over", "hotspots", "in", "the", "Muslim", "worlds,", "and", "disillusionment", "with", "the", "current", "status", "quo."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["Inshort,mostofthel,ashtagso.rerelatedtosup~ortfortheArabSpring,oppositio.ntoexiBtingregimesinthemiddleEast,solitharityorconcernoverhotspotsintheMuslimworld\\,anddisillusionnrentwitl~thecurrentlstatusquo."], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["In", "short,", "most", "of", "the", "l,ashtags", "o.re", "related", "to", "sup~ort", "for", "the", "Arab", "Spring,", "oppositio.n", "to", "exiBting", "regimes", "in", "the", "middle", "East,", "solitharity", "or", "concern", "over", "hotspots", "in", "the", "Muslim", "world\\,", "and", "disillusionnrent", "witl~", "the", "currentl", "status", "quo."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["In", "short,", "most", "of", "the", "l,ashtags", "o.re", "related", "to", "sup~ort", "for", "the", "Arab", "Spring,", "oppositio.n", "to", "exiBting", "regimes", "in", "the", "middle", "East,", "solitharity", "or", "concern", "over", "hotspots", "in", "the", "Muslim", "world\\,", "and", "disillusionnrent", "witl~", "the", "currentl", "status", "quo."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["Thuswehave"], "labels": ["WRONG"]}, "correct": {"tokens": ["Thus", "we", "have"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["Thuswehave"], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["Thus", "we", "have"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["Thus", "we", "have"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["Wefirstdiscusstheostationarysolution.Weseethatforlargey,thehigherharmoicsaresuppressedexponentiallywitirrespecttothefuudamelltalmoden=1,hichgivestilefollowingcontribution:"], "labels": ["WRONG"]}, "correct": {"tokens": ["We", "first", "discuss", "the", "stationary", "solution.", "We", "see", "that", "for", "large", "y,", "the", "higher", "harmonics", "are", "suppressed", "exponentially", "with", "respect", "to", "the", "fundamental", "mode", "n", "=", "1,", "which", "gives", "the", "following", "contribution:"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["Wefirstdiscusstheostationarysolution.Weseethatforlargey,thehigherharmoicsaresuppressedexponentiallywitirrespecttothefuudamelltalmoden=1,which", "gives", "tile", "following", "contribution:"], "labels": ["WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR": {"tokens": ["We", "first", "discuss", "theo", "stationary", "solution.", "We", "see", "that", "for", "large", "y,", "the", "higher", "harmoics", "are", "suppressed", "exponentially", "witir", "respect", "to", "the", "fuudamelltal", "mode", "n", "=", "1,", "hich", "gives", "tile", "following", "contribution:"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["We", "first", "discuss", "theo", "stationary", "solution.", "We", "see", "that", "for", "large", "y,", "the", "higher", "harmonics", "are", "suppressed", "exponentially", "with", "respect", "to", "the", "fuudamelltal", "mode", "n", "=", "1,", "which", "gives", "tile", "following", "contribution:"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["Preliminaricsa~tdPrev~ousWork"], "labels": ["WRONG"]}, "correct": {"tokens": ["Preliminaries", "and", "Previous", "Work"], "labels": ["MIXED", "MIXED", "MIXED", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["Preliminaricsa~tdPrev~ousWork"], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["Preliminarics", "a~td", "Prev~ous", "Work"], "labels": ["WRONG", "WRONG", "WRONG", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["Preliminaries", "a~td", "Prev~ous", "Work"], "labels": ["MIXED", "WRONG", "WRONG", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["Additional(informtion"], "labels": ["WRONG"]}, "correct": {"tokens": ["Additional", "information"], "labels": ["TOKENIZATION_ERROR", "MIXED"]}, "predicted": {"google": {"tokens": ["Additional(information"], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["Additional", "(informtion"], "labels": ["TOKENIZATION_ERROR", "WRONG"]}, "BS-bid-OCR+google": {"tokens": ["Additional", "(information"], "labels": ["TOKENIZATION_ERROR", "WRONG"]}}}, {"corrupt": {"tokens": ["LetconsiderthefollewinggeneralizedBSDE"], "labels": ["WRONG"]}, "correct": {"tokens": ["Let", "consider", "the", "following", "generalized", "BSDE"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["LetconsiderthefollewinggeneralizedBSDE"], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["Let", "consider", "the", "follewing", "generalized", "BSDE"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["Let", "consider", "the", "following", "generalized", "BSDE"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["Nextweintoducethefunctions"], "labels": ["WRONG"]}, "correct": {"tokens": ["Next,", "we", "introduce", "the", "functions"], "labels": ["MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["Nextweintoducethe", "Functions"], "labels": ["WRONG", "WRONG"]}, "BS-bid-OCR": {"tokens": ["Next", "we", "intoduce", "the", "functions"], "labels": ["WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["Next", "we", "introduce", "the", "functions"], "labels": ["WRONG", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["Wefirstconsiderthedisjunctionofmean-payoffandparityobjectives,andthendisju'uctionofenergyandparityoblectives."], "labels": ["WRONG"]}, "correct": {"tokens": ["We", "first", "consider", "the", "disjunction", "of", "mean-payoff", "and", "parity", "objectives,", "and", "then", "disjunction", "of", "energy", "and", "parity", "objectives."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED"]}, "predicted": {"google": {"tokens": ["Wefirstconsiderthe", "Disjunction", "Mean-payoffandparity", "objectives,and", "thendisju'uctionofenergyandparityoblectives."], "labels": ["WRONG", "WRONG", "WRONG", "WRONG", "WRONG"]}, "BS-bid-OCR": {"tokens": ["We", "first", "consider", "the", "disjunction", "of", "mean-payoff", "and", "parity", "objectives,", "and", "then", "disju'uction", "of", "energy", "and", "parity", "oblectives."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG"]}, "BS-bid-OCR+google": {"tokens": ["We", "first", "consider", "the", "disjunction", "of", "mean-payoff", "and", "parity", "objectives,", "and", "then", "disjunction", "of", "energy", "and", "parity", "objectives."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED"]}}}, {"corrupt": {"tokens": ["Afte\\rseeingafewexamplesonemight{wonderifeverythinEthatcanbeIdonebyaqfstcanbedonebyapfst.Tha1.thisisnotsoisshownasfoilows:"], "labels": ["WRONG"]}, "correct": {"tokens": ["After", "seeing", "a", "few", "examples", "one", "might", "wonder", "if", "everything", "that", "can", "be", "done", "by", "a", "qfst", "can", "be", "done", "by", "a", "pfst.", "That", "this", "is", "not", "so", "is", "shown", "as", "follows:"], "labels": ["MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED"]}, "predicted": {"google": {"tokens": ["Afte\\rseeingafewexamplesonemight{wonderifeverythinEthatcanbeIdonebyaqfstcanbedonebyapfst.Tha1.thisisnotsoisshownasfoilows:"], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["Afte\\r", "seeing", "a", "few", "examples", "one", "might{", "wonder", "if", "everythinE", "that", "can", "beI", "done", "by", "a", "qfst", "can", "be", "done", "by", "a", "pfst.", "Tha1.", "this", "is", "not", "so", "is", "shown", "as", "foilows:"], "labels": ["WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG"]}, "BS-bid-OCR+google": {"tokens": ["Afte\\r", "seeing", "a", "few", "examples", "one", "might{", "wonder", "if", "everythinG", "that", "can", "beI", "done", "by", "a", "qfst", "can", "be", "done", "by", "a", "pfst.", "Tha1.", "this", "is", "not", "so", "is", "shown", "as", "follows:"], "labels": ["WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED"]}}}, {"corrupt": {"tokens": ["A?lsointh\\[scaseweexpandthegaugelinkuptethenext-toleadingorder,and?followingthesamemthodweused?nthecalculationoftheSiversfunction,wefindfortheBoer-Mnldersfunction"], "labels": ["WRONG"]}, "correct": {"tokens": ["Also", "in", "this", "case", "we", "expand", "the", "gauge", "link", "up", "to", "the", "next-to", "leading", "order,", "and", "following", "the", "same", "method", "we", "used", "in", "the", "calculation", "of", "the", "Sivers", "function,", "we", "find", "for", "the", "Boer-Mulders", "function"], "labels": ["MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["A?sloth\\[scaseweexpandthegaugelinkuptethenext-toleadingorder,and?followingthesamemthodweused?nthecalculationoftheSiversfunction,wefindfortheBoer-Mnldersfunction"], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["A?lso", "in", "th\\[s", "case", "we", "expand", "the", "gauge", "link", "up", "te", "the", "next-to", "leading", "order,", "and", "?following", "the", "same", "mthod", "we", "used", "?n", "the", "calculation", "of", "the", "Sivers", "function,", "we", "find", "for", "the", "Boer-Mnlders", "function"], "labels": ["WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["A?lso", "in", "th\\[s", "case", "we", "expand", "the", "gauge", "link", "up", "te", "the", "next-to", "leading", "order,", "and", "?following", "the", "same", "method", "we", "used", "?n", "the", "calculation", "of", "the", "Sivers", "function,", "we", "find", "for", "the", "Boer-Mnlders", "function"], "labels": ["WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["M.Anselminoa,V.\\Baroneb,A.Kol;ziniana:c"], "labels": ["WRONG"]}, "correct": {"tokens": ["M.", "Anselminoa,", "V.", "Baroneb,", "A.", "Kotziniana,", "c"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["M.Anselmino,V.\\Barone", "Ba.Kol;ziniana:c"], "labels": ["WRONG", "WRONG"]}, "BS-bid-OCR": {"tokens": ["M.", "Anselminoa,", "V.\\", "Baroneb,", "A.", "Kol;ziniana:c"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG"]}, "BS-bid-OCR+google": {"tokens": ["M.", "Anselminoa,", "V.\\", "Barone,", "A.", "Kol;ziniana:c"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "WRONG"]}}}, {"corrupt": {"tokens": ["6.V.Be\\rnal'd,N.Kaiser,J.KamborandUlf-G.Mei\u00dfn?et,Nucl.Phys.B388(1992)315."], "labels": ["WRONG"]}, "correct": {"tokens": ["6.V.", "Bernard,", "N.", "Kaiser,", "J.", "Kambor", "and", "Ulf-G.", "Mei\u00dfner,", "Nucl.", "Phys.", "B388", "(1992)", "315."], "labels": ["TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["6.V.Be\\rnal'd,N.Kaiser,J.KamborandUlf-G.Mei\u00dfn?et,Nucl.Phys.B388(1992)315."], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["6.", "V.", "Be\\rnal'd,", "N.", "Kaiser,", "J.", "Kambor", "and", "Ulf-G.", "Mei\u00dfn?et,", "Nucl.", "Phys.", "B388", "(1992)", "315."], "labels": ["WRONG", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["6.", "V.", "Be\\rnal'd,", "N.", "Kaiser,", "J.", "Kambor", "and", "Ulf-G.", "Mei\u00dfn?et,", "Nucl.", "Phys.", "B388", "(1992)", "315."], "labels": ["WRONG", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["Wealsoaddress\\l.hevalidityof?usinganoffectiw~theory.WefindthatforlightDMmassex(belo~aft?whundredGdV),theboultdderiuedusinganeffectivetheorymaybeac?curatetoabout10%.Ifthemediatorisheavy,burbelowacoupleTeV,thelimitderivedfromeffectivetheorycisinfactonservatiue,%ndth('truelimitisstronger.\\But,ifthemediatoristoolighttoccaytodarkmati,erpairsthetruelimitisfarweakerthantheonede,rivedfComeffectiveWheorcy.Inaddition,wefindthattheeffectivetheorybreaksdwnatDMma.ssesthatarehe?yenoughsuchthttheDMproduct\\ionikinematicall.ysuppresscdbyPDFs,andwemusttakeintoaccounttheUVphysicsinthesecases."], "labels": ["WRONG"]}, "correct": {"tokens": ["We", "also", "address", "the", "validity", "of", "using", "an", "effective", "theory.", "We", "find", "that", "for", "light", "DM", "masses", "(below", "a", "few", "hundred", "GeV),", "the", "bound", "derived", "using", "an", "effective", "theory", "may", "be", "accurate", "to", "about", "10%.", "If", "the", "mediator", "is", "heavy,", "but", "below", "a", "couple", "TeV,", "the", "limit", "derived", "from", "effective", "theory", "is", "in", "fact", "conservative,", "and", "the", "true", "limit", "is", "stronger.", "But,", "if", "the", "mediator", "is", "too", "light", "to", "decay", "to", "dark", "matter", "pairs", "the", "true", "limit", "is", "far", "weaker", "than", "the", "one", "derived", "from", "effective", "theory.", "In", "addition,", "we", "find", "that", "the", "effective", "theory", "breaks", "down", "at", "DM", "masses", "that", "are", "heavy", "enough", "such", "that", "the", "DM", "production", "is", "kinematically", "suppressed", "by", "PDFs,", "and", "we", "must", "take", "into", "account", "the", "UV", "physics", "in", "these", "cases."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["Wealsoaddress\\l.hevalidityof?usinganoffectiw~theory.WefindthatforlightDMmassex(belo~aft?hundred", "GdV),theboultdderiuedusinganeffectivetheorymaybeac?curatetoabout10%.Ifthemediatorisheavy,burbelowacoupleTeV,thelimitderivedfromeffectivetheorycisinfactonservatiue,%ndth('truelimitisstronger.\\But,ifthemediatoristoolighttoccaytodarkmati,erpairsthetruelimitisfarweakerthantheonede,rivedfComeffectiveWheorcy.Inaddition,wefindthattheeffectivetheorybreaksdwnatDMma.ssesthatarehe?yenoughsuchthttheDMproduct\\ionikinematicall.ysuppresscdbyPDFs,andwemusttakeintoaccounttheUVphysicsinthesecases."], "labels": ["WRONG", "WRONG"]}, "BS-bid-OCR": {"tokens": ["We", "also", "address\\", "l.he", "validity", "of?", "using", "an", "offectiw~", "theory.", "We", "find", "that", "for", "light", "DM", "massex", "(belo~", "a", "ft?w", "hundred", "GdV),", "the", "boultd", "deriued", "using", "an", "effective", "theory", "may", "be", "ac?curate", "to", "about", "10%.", "If", "the", "mediator", "is", "heavy,", "bur", "below", "a", "couple", "TeV,", "the", "limit", "derived", "from", "effective", "theoryc", "is", "in", "fact", "onservatiue", ",%nd", "th('", "true", "limit", "is", "stronger.\\", "But,", "if", "the", "mediator", "is", "too", "light", "to", "ccay", "to", "dark", "mati,er", "pairs", "the", "true", "limit", "is", "far", "weaker", "than", "the", "one", "de,rived", "fCom", "effective", "Wheorcy.", "In", "addition,", "we", "find", "that", "the", "effective", "theory", "breaks", "dwn", "at", "DM", "ma.sses", "that", "are", "he?y", "enough", "such", "tht", "the", "DM", "product\\ion", "i", "kinematicall.y", "suppresscd", "by", "PDFs,", "and", "we", "must", "take", "into", "account", "the", "UV", "physics", "in", "these", "cases."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["We", "also", "address\\", "l.he", "validity", "of?", "using", "an", "offectiw~", "theory.", "We", "find", "that", "for", "light", "DM", "massex", "(belo~", "a", "ft?w", "hundred", "GdV),", "the", "bold", "derived", "using", "an", "effective", "theory", "may", "be", "accurate", "to", "about", "10%.", "If", "the", "mediator", "is", "heavy,", "bur", "below", "a", "couple", "TeV,", "the", "limit", "derived", "from", "effective", "theory", "is", "in", "fact", "onservatiue", ",%nd", "th('", "true", "limit", "is", "stronger.\\", "But,", "if", "the", "mediator", "is", "too", "light", "to", "say", "to", "dark", "matter", "pairs", "the", "true", "limit", "is", "far", "weaker", "than", "the", "one", "de,rived", "fCom", "effective", "Wheorcy.", "In", "addition,", "we", "find", "that", "the", "effective", "theory", "breaks", "down", "at", "DM", "masses", "that", "are", "high", "enough", "such", "that", "the", "DM", "product\\ion", "i", "kinematically", "suppressed", "by", "PDFs,", "and", "we", "must", "take", "into", "account", "the", "UV", "physics", "in", "these", "cases."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["Acknowledgments"], "labels": ["NONE"]}, "correct": {"tokens": ["Acknowledgments"], "labels": ["NONE"]}, "predicted": {"google": {"tokens": ["Acknowledgments"], "labels": ["NONE"]}, "BS-bid-OCR": {"tokens": ["Acknowledgments"], "labels": ["NONE"]}, "BS-bid-OCR+google": {"tokens": ["Acknowledgments"], "labels": ["NONE"]}}}, {"corrupt": {"tokens": ["Thcsourceorienta?tionandextontioncant)cevaluaedbyhfittingtheintensityImageswitha2DGussianithseparatewidthsalongeachaxisandafreerot,ationangle,Tocomparewithtrno.point-sourcethesmefithasbeenappliedtotheXTEJ1550sourceinthesamefieldofview\u0002"], "labels": ["WRONG"]}, "correct": {"tokens": ["The", "source", "orientation", "and", "extension", "can", "be", "evaluated", "by", "fitting", "the", "intensity", "images", "with", "a", "2D", "Gaussian", "with", "separate", "widths", "along", "each", "axis", "and", "a", "free", "rotation", "angle.", "To", "compare", "with", "a", "true", "point-source", "the", "same", "fit", "has", "been", "applied", "to", "the", "XTE", "J1550", "source", "in", "the", "same", "field", "of", "view."], "labels": ["MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED"]}, "predicted": {"google": {"tokens": ["Thcsourceorienta?tionandextontioncant)cevaluaedbyhfittingtheintensityImageswitha2DGussianithseparatewidthsalongeachaxisandafreerot,ationangle,Tocomparewithtrno.point-sourcethesmefithasbeenappliedtotheXTEJ1550sourceinthesamefieldofview"], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["Thc", "source", "orienta?tion", "and", "extontion", "can", "t)c", "evaluaed", "byh", "fitting", "the", "intensity", "Images", "with", "a", "2D", "Gussian", "ith", "separate", "widths", "along", "each", "axis", "and", "a", "free", "rot,ation", "angle,", "To", "compare", "with", "trno.", "point-source", "the", "sme", "fit", "has", "been", "applied", "to", "the", "XTE", "J1550", "source", "in", "the", "same", "field", "of", "view\u0002"], "labels": ["WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG"]}, "BS-bid-OCR+google": {"tokens": ["Thc", "source", "orientation", "and", "extortion", "can't)c", "evaluated", "by", "fitting", "the", "intensity", "Images", "with", "a", "2D", "Gussian", "with", "separate", "widths", "along", "each", "axis", "and", "a", "free", "rotation", "angle,", "To", "compare", "with", "trno.", "point-source", "the", "same", "fit", "has", "been", "applied", "to", "the", "XTE", "J1550", "source", "in", "the", "same", "field", "of", "view"], "labels": ["WRONG", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "WRONG", "WRONG", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG"]}}}, {"corrupt": {"tokens": ["Therefore,theeffectivepolarizabilityoftheaoln\\intheprese~ceoftheplateis"], "labels": ["WRONG"]}, "correct": {"tokens": ["Therefore,", "the", "effective", "polarizability", "of", "the", "atom", "in", "the", "presence", "of", "the", "plate", "is"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["Therefore,theeffectivepolarizabilityoftheaoln\\intheprese~ceoftheplateis"], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["Therefore,", "the", "effective", "polarizability", "of", "the", "aoln\\", "in", "the", "prese~ce", "of", "the", "plate", "is"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["Therefore,", "the", "effective", "polarizability", "of", "the", "aoln\\", "in", "the", "prese~ce", "of", "the", "plate", "is"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["TunnelField-EffectTransis?torsin2DTransitionMetalDi(:halco.qenideMaterials"], "labels": ["WRONG"]}, "correct": {"tokens": ["Tunnel", "Field-Effect", "Transistors", "in", "2D", "Transition", "Metal", "Dichalcogenide", "Materials"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["TunnelField-Effect", "Transistor?torsin2DTransitionMetalDi(:halco.qenideMaterials"], "labels": ["WRONG", "WRONG"]}, "BS-bid-OCR": {"tokens": ["Tunnel", "Field-Effect", "Transis?tors", "in", "2D", "Transition", "Metal", "Di(:halco.qenide", "Materials"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["Tunnel", "Field-Effect", "Transistors", "in", "2D", "Transition", "Metal", "Di(:halco.qenide", "Materials"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["Acknowledgements"], "labels": ["NONE"]}, "correct": {"tokens": ["Acknowledgements"], "labels": ["NONE"]}, "predicted": {"google": {"tokens": ["Acknowledgements"], "labels": ["NONE"]}, "BS-bid-OCR": {"tokens": ["Acknowledgements"], "labels": ["NONE"]}, "BS-bid-OCR+google": {"tokens": ["Acknowledgements"], "labels": ["NONE"]}}}, {"corrupt": {"tokens": ["ThentheEtler-Lagrangi'anequationsfortheLagrangianL()leadtothefollowingeguationmfortthewidm(tha(t)andchirpb(t):"], "labels": ["WRONG"]}, "correct": {"tokens": ["Then", "the", "Euler-Lagrangian", "equations", "for", "the", "Lagrangian", "L(t)", "lead", "to", "the", "following", "equations", "for", "the", "width", "a(t)", "and", "chirp", "b(t):"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["ThentheEtler-Lagrangi'anequationsfortheLagrangianL()leadtothefollowingeguation", "fortthewidm(tha(t)andchirpb(t):"], "labels": ["WRONG", "WRONG"]}, "BS-bid-OCR": {"tokens": ["Then", "the", "Etler-Lagrangi'an", "equations", "for", "the", "Lagrangian", "L()", "lead", "to", "the", "following", "eguationm", "for", "tthe", "widm(th", "a(t)", "and", "chirp", "b(t):"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["Then", "the", "Etler-Lagrangi'an", "equations", "for", "the", "Lagrangian", "L()", "lead", "to", "the", "following", "equation", "for", "the", "widm(th", "a(t)", "and", "chirp", "b(t):"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["Similarly,"], "labels": ["NONE"]}, "correct": {"tokens": ["Similarly,"], "labels": ["NONE"]}, "predicted": {"google": {"tokens": ["Similarly,"], "labels": ["NONE"]}, "BS-bid-OCR": {"tokens": ["Similarly,"], "labels": ["NONE"]}, "BS-bid-OCR+google": {"tokens": ["Similarly,"], "labels": ["NONE"]}}}, {"corrupt": {"tokens": ["Externalelectrode?sa,somodifytheCou1omI>interationofelectrons.Sesides?tilat,theiinagechargeeffectmakestheself-energyofthesitesdependentontheirlocation,leadingtononuniformtransport(:ondinions.Sinceinthepresentpaperweconcentl\"ateonuniformarrays,wewilllimit\\ourselvestothecaseofnegligibleCoulombinteraction."], "labels": ["WRONG"]}, "correct": {"tokens": ["External", "electrodes", "also", "modify", "the", "Coulomb", "interaction", "of", "electrons.", "Besides", "that,", "the", "image", "charge", "effect", "makes", "the", "self-energy", "of", "the", "sites", "dependent", "on", "their", "location,", "leading", "to", "nonuniform", "transport", "conditions.", "Since", "in", "the", "present", "paper", "we", "concentrate", "on", "uniform", "arrays,", "we", "will", "limit", "ourselves", "to", "the", "case", "of", "negligible", "Coulomb", "interaction."], "labels": ["TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["External", "Electrode?sa,somodifytheCou1omI>interaction", "of", "electrons.Seasides?tilat,theiinagechargeeffectmakestheself-energyofthesitesdependentontheirlocation,leadingtononuniformtransport(:conditions.Since", "The", "Present", "Paperweconcentl\"ateonuniformarrays,wewilllimit\\ourselvestothecaseofnegligibleCoulombinteraction."], "labels": ["TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "WRONG", "WRONG", "WRONG"]}, "BS-bid-OCR": {"tokens": ["External", "electrode?s", "a,so", "modify", "the", "Cou1omI>", "interation", "of", "electrons.", "Sesides", "?tilat,", "the", "iinage", "charge", "effect", "makes", "the", "self-energy", "of", "the", "sites", "dependent", "on", "their", "location,", "leading", "to", "nonuniform", "transport", "(:ondinions.", "Since", "in", "the", "present", "paper", "we", "concentl\"ate", "on", "uniform", "arrays,", "we", "will", "limit\\", "ourselves", "to", "the", "case", "of", "negligible", "Coulomb", "interaction."], "labels": ["TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["External", "electrodes,so", "modify", "the", "Cou1omI>", "interaction", "of", "electrons.", "Sesides", "?tilat,", "the", "image", "charge", "effect", "makes", "the", "self-energy", "of", "the", "sites", "dependent", "on", "their", "location,", "leading", "to", "nonuniform", "transport", "(:conditions.", "Since", "in", "the", "present", "paper", "we", "concentl\"ate", "on", "uniform", "arrays,", "we", "will", "limit\\", "ourselves", "to", "the", "case", "of", "negligible", "Coulomb", "interaction."], "labels": ["TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["Requiringthatthisnewformoftheactiopib?estaationaryproducesthecla:;sicaltieldequation"], "labels": ["WRONG"]}, "correct": {"tokens": ["Requiring", "that", "this", "new", "form", "of", "the", "action", "be", "stationary", "produces", "the", "classical", "field", "equation"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["Requiringthatthisnewformoftheactiopib?stationary", "produces", "thecla:;sicaltieldequation"], "labels": ["WRONG", "TOKENIZATION_ERROR", "WRONG"]}, "BS-bid-OCR": {"tokens": ["Requiring", "that", "this", "new", "form", "of", "the", "actiopi", "b?e", "staationary", "produces", "the", "cla:;sical", "tield", "equation"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["Requiring", "that", "this", "new", "form", "of", "the", "actiopi", "be", "stationary", "produces", "the", "cla:;sical", "yield", "equation"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["RuaDr.XavierSigaIld150,RiodeJaneiro,Srazil"], "labels": ["WRONG"]}, "correct": {"tokens": ["Rua", "Dr.", "Xavier", "Sigaud", "150,", "Rio", "de", "Janeiro,", "Brazil"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED"]}, "predicted": {"google": {"tokens": ["Rua", "Dr.Xavier", "SigIl", "d150,RiodeJaneiro,Brazil"], "labels": ["TOKENIZATION_ERROR", "WRONG", "WRONG", "WRONG"]}, "BS-bid-OCR": {"tokens": ["Rua", "Dr.", "Xavier", "SigaIld", "150,", "Rio", "de", "Janeiro,", "Srazil"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG"]}, "BS-bid-OCR+google": {"tokens": ["Rua", "Dr.", "Xavier", "SigaUd", "150,", "Rio", "de", "Janeiro,", "Brazil"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED"]}}}, {"corrupt": {"tokens": ["10129,Torino,Itthely"], "labels": ["WRONG"]}, "correct": {"tokens": ["10129,", "Torino,", "Italy"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED"]}, "predicted": {"google": {"tokens": ["10129,Torino,Italy"], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["10129,", "Torino,", "Itthely"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG"]}, "BS-bid-OCR+google": {"tokens": ["10129,", "Torino,", "Italy"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED"]}}}, {"corrupt": {"tokens": ["whilethenewcontributionstosupersymmetrybreakiiigsofttrilinearterms"], "labels": ["WRONG"]}, "correct": {"tokens": ["while", "the", "new", "contributions", "to", "supersymmetry", "breaking", "soft", "trilinear", "terms"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["whilethenewcontributionstosupersymmetrybreakiiigsofttrilinearterms"], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["while", "the", "new", "contributions", "to", "supersymmetry", "breakiiig", "soft", "trilinear", "terms"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["while", "the", "new", "contributions", "to", "supersymmetry", "breaking", "soft", "trilinear", "terms"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["thenthefnctionalSisalwayspositiveoutsideone-pointc;urvoesandthenumberofi.tsextremalscanbeestimatedfrombelowbyusingtheclassicalMorsetheory.Forinstance,ifallextremalsarenndegenerate(intheMossesense)wehavetheslmplestversionoftheM\\orsein~(lualities:"], "labels": ["WRONG"]}, "correct": {"tokens": ["then", "the", "functional", "S", "is", "always", "positive", "outside", "one-point", "curves", "and", "the", "number", "of", "its", "extremals", "can", "be", "estimated", "from", "below", "by", "using", "the", "classical", "Morse", "theory.", "For", "instance,", "if", "all", "extremals", "are", "nondegenerate", "(in", "the", "Morse", "sense)", "we", "have", "the", "simplest", "version", "of", "the", "Morse", "inequalities:"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED"]}, "predicted": {"google": {"tokens": ["thenthefnctionalSisalwayspositiveoutsideone-pointc;urvoesandthenumberofi.tsextremalscanbeestimatedfrombelowbyusingtheclassicalMorsetheory.Forinstance,ifallextremalsarenndegenerate(intheMossesense)we", "have", "the", "simplest", "version", "of", "theM\\or", "sein~(qualities:"], "labels": ["WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG"]}, "BS-bid-OCR": {"tokens": ["then", "the", "fnctional", "S", "is", "always", "positive", "outside", "one-point", "c;urvoes", "and", "the", "number", "of", "i.ts", "extremals", "can", "be", "estimated", "from", "below", "by", "using", "the", "classical", "Morse", "theory.", "For", "instance,", "if", "all", "extremals", "are", "nndegenerate", "(in", "the", "Mosse", "sense)", "we", "have", "the", "slmplest", "version", "of", "the", "M\\orse", "in~(lualities:"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG"]}, "BS-bid-OCR+google": {"tokens": ["Then", "the", "function", "S", "is", "always", "positive", "outside", "one-point", "c;urvoes", "and", "the", "number", "of", "i.ts", "extremals", "can", "be", "estimated", "from", "below", "by", "using", "the", "classical", "Morse", "theory.", "For", "instance,", "if", "all", "extremals", "are", "non", "degenerate", "(in", "the", "Mosse", "sense)", "we", "have", "the", "simplest", "version", "of", "the", "M\\orse", "in~(qualities:"], "labels": ["WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG"]}}}, {"corrupt": {"tokens": ["Finallyweanswerthefollowingquesion:isthisconstruedction(anonical,atleastinsomesense?Weneedonemoredefinition."], "labels": ["WRONG"]}, "correct": {"tokens": ["Finally", "we", "answer", "the", "following", "question:", "is", "this", "construction", "canonical,", "at", "least", "in", "some", "sense?", "We", "need", "one", "more", "definition."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["Finally", "We", "Answer", "The", "Following", "Question:is", "this", "construction(anonical,atleastinsomesense?Weneedonemoredefinition."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "WRONG", "WRONG", "WRONG", "WRONG"]}, "BS-bid-OCR": {"tokens": ["Finally", "we", "answer", "the", "following", "quesion:", "is", "this", "construedction", "(anonical,", "at", "least", "in", "some", "sense?", "We", "need", "one", "more", "definition."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["Finally", "we", "answer", "the", "following", "question:", "is", "this", "construction", "(anonical,", "at", "least", "in", "some", "sense?", "We", "need", "one", "more", "definition."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["IntohepneresentSectionwdecalculhtethevalueotfBCindifferentways."], "labels": ["WRONG"]}, "correct": {"tokens": ["In", "the", "present", "Section", "we", "calculate", "the", "value", "of", "fBC", "in", "different", "ways."], "labels": ["TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["IntohepneresentSectionwdecalculhtethevalueotfBCindifferentways."], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["In", "tohe", "pneresent", "Section", "wde", "calculhte", "the", "value", "otf", "BC", "in", "different", "ways."], "labels": ["TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["In", "the", "present", "Section", "we", "calculate", "the", "value", "of", "BC", "in", "different", "ways."], "labels": ["TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["Sodiumreturnflux"], "labels": ["WRONG"]}, "correct": {"tokens": ["Sodium", "return", "flux"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["Sodium", "Return", "Flux"], "labels": ["TOKENIZATION_ERROR", "WRONG", "WRONG"]}, "BS-bid-OCR": {"tokens": ["Sodium", "return", "flux"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["Sodium", "return", "flux"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["withthecOmplexFourircoefficients\u03b1n,definedatharmonicorOernas"], "labels": ["WRONG"]}, "correct": {"tokens": ["with", "the", "complex", "Fourier", "coefficients", "\u03b1n,", "defined", "at", "harmonic", "order", "n", "as"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["withthecOmplexFourircoefficients\u03b1n,definedatharmonicorOernas"], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["with", "the", "cOmplex", "Fourir", "coefficients", "\u03b1n,", "defined", "at", "harmonic", "orOern", "as"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["with", "the", "cOmplex", "Fourier", "coefficients", "\u03b1n,", "defined", "at", "harmonic", "orOern", "as"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["andtheenergyconservationequationrcads,"], "labels": ["WRONG"]}, "correct": {"tokens": ["and", "the", "energy", "conservation", "equation", "reads,"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED"]}, "predicted": {"google": {"tokens": ["and", "the", "energy", "conservation", "equation", "rcads,"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG"]}, "BS-bid-OCR": {"tokens": ["and", "the", "energy", "conservation", "equation", "rcads,"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG"]}, "BS-bid-OCR+google": {"tokens": ["and", "the", "energy", "conservation", "equation", "rcads,"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG"]}}}, {"corrupt": {"tokens": ["then?etdk=qk."], "labels": ["WRONG"]}, "correct": {"tokens": ["then", "let", "dk", "=", "qk."], "labels": ["TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["then?etdk=qk."], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["then", "?et", "dk", "=", "qk."], "labels": ["TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["then", "?et", "dk", "=", "qk."], "labels": ["TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["and"], "labels": ["NONE"]}, "correct": {"tokens": ["and"], "labels": ["NONE"]}, "predicted": {"google": {"tokens": ["and"], "labels": ["NONE"]}, "BS-bid-OCR": {"tokens": ["and"], "labels": ["NONE"]}, "BS-bid-OCR+google": {"tokens": ["and"], "labels": ["NONE"]}}}, {"corrupt": {"tokens": ["where"], "labels": ["NONE"]}, "correct": {"tokens": ["where"], "labels": ["NONE"]}, "predicted": {"google": {"tokens": ["where"], "labels": ["NONE"]}, "BS-bid-OCR": {"tokens": ["where"], "labels": ["NONE"]}, "BS-bid-OCR+google": {"tokens": ["where"], "labels": ["NONE"]}}}, {"corrupt": {"tokens": ["Inthispaperweuse,~ummpericalsimu.lationstotudythetrans1)ortofdibfferen?tlypreparedvortexs~stems.Ourfirstmainresultisthat,incontrasttothetem,peraturecyclind,ifthevortexsystemiscyeledWithatransportcurrent,thentheZFCstateismorestafletilanthcFCstal.e.Inpart~cuar,theZFCstatecanbereached'fromtheFCstat(?bycurrentcycling,l)utnotvice?vcrso.Oursecondmainresultisthat,withincreasingcurrents,allvortexstates,FC,ZFC,orpreparedinanyintermediateway,?acquireanuniquedencityofdefectsatdepinning."], "labels": ["WRONG"]}, "correct": {"tokens": ["In", "this", "paper", "we", "use", "numerical", "simulations", "to", "study", "the", "transport", "of", "differently", "prepared", "vortex", "systems.", "Our", "first", "main", "result", "is", "that,", "in", "contrast", "to", "the", "temperature", "cycling,", "if", "the", "vortex", "system", "is", "cycled", "with", "a", "transport", "current,", "then", "the", "ZFC", "state", "is", "more", "stable", "than", "the", "FC", "state.", "In", "particular,", "the", "ZFC", "state", "can", "be", "reached", "from", "the", "FC", "state", "by", "current", "cycling,", "but", "not", "vice", "versa.", "Our", "second", "main", "result", "is", "that,", "with", "increasing", "currents,", "all", "vortex", "states,", "FC,", "ZFC,", "or", "prepared", "in", "any", "intermediate", "way,", "acquire", "an", "unique", "density", "of", "defects", "at", "depinning."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["Inthispaperweuse,~ummpericalsimu.lationstotudythetrans1)ortofdibfferen?tlypreparedvortexs~stems.Ourfirstmainresultisthat,incontrasttothetem,peraturecyclind,ifthevortexsystemiscyeledWithatransportcurrent,thentheZFCstateismorestafletilanthcFCstal.e.Impart~cua,theZFCstatecanbereached", "from", "the", "FCstat(?by", "current", "cycling,l)ut", "novice?vcrso.Oursecondmainresultisthat,withincreasingcurrents,allvortexstates,FC,ZFC,orpreparedinanyintermediateway,?acquireanuniquedencityofdefectsatdepinning."], "labels": ["WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "WRONG"]}, "BS-bid-OCR": {"tokens": ["In", "this", "paper", "we", "use", ",~ummperical", "simu.lations", "to", "tudy", "the", "trans1)ort", "of", "dibfferen?tly", "prepared", "vortex", "s~stems.", "Our", "first", "main", "result", "is", "that,", "in", "contrast", "to", "the", "tem,perature", "cyclind,", "if", "the", "vortex", "system", "is", "cyeled", "With", "a", "transport", "current,", "then", "the", "ZFC", "state", "is", "more", "stafle", "tilan", "thc", "FC", "stal.e.", "In", "part~cuar,", "the", "ZFC", "state", "can", "be", "reached", "'from", "the", "FC", "stat(?", "by", "current", "cycling,", "l)ut", "not", "vice?vcrso.", "Our", "second", "main", "result", "is", "that,", "with", "increasing", "currents,", "all", "vortex", "states,", "FC,", "ZFC,", "or", "prepared", "in", "any", "intermediate", "way,?", "acquire", "an", "unique", "dencity", "of", "defects", "at", "depinning."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["In", "this", "paper", "we", "use", ",~numerical", "simulations", "to", "study", "the", "trans1)ort", "of", "differently", "prepared", "vortex", "s~stems.", "Our", "first", "main", "result", "is", "that,", "in", "contrast", "to", "the", "temperature", "cycling,", "if", "the", "vortex", "system", "is", "cycled", "With", "a", "transport", "current,", "then", "the", "ZFC", "state", "is", "more", "stable", "than", "FC", "stal.e.", "In", "part~cuar,", "the", "ZFC", "state", "can", "be", "reached", "'from", "the", "FC", "stat(?", "by", "current", "cycling,", "l)ut", "not", "vice", "versa.", "Our", "second", "main", "result", "is", "that,", "with", "increasing", "currents,", "all", "vortex", "states,", "FC,", "ZFC,", "or", "prepared", "in", "any", "intermediate", "way,acquire", "a", "unique", "density", "of", "defects", "at", "depinning."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["Sineethisistrueforeach\u03b5,?thelernmaholds."], "labels": ["WRONG"]}, "correct": {"tokens": ["Since", "this", "is", "true", "for", "each", "\u03b5,", "the", "lemma", "holds."], "labels": ["MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["Sineethisistrueforeach\u03b5,?thelernmaholds."], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["Sinee", "this", "is", "true", "for", "each", "\u03b5,", "?the", "lernma", "holds."], "labels": ["WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["Sinee", "this", "true", "for", "each", "\u03b5", "?The", "lemma", "holds."], "labels": ["WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "MIXED", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["Step9:Fromthedecisiousetxk=maxF(xi)isselectedasoptim\\aldeci.qion."], "labels": ["WRONG"]}, "correct": {"tokens": ["Step", "9:", "From", "the", "decision", "set,", "xk", "=", "max", "F(xi)", "is", "selected", "as", "optimal", "decision."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED"]}, "predicted": {"google": {"tokens": ["Step9:From", "Decisiousetxk=maxF(xi)isselected", "soptim\\aldeci.qion."], "labels": ["WRONG", "WRONG", "WRONG"]}, "BS-bid-OCR": {"tokens": ["Step", "9:", "From", "the", "decisiou", "set", "xk", "=", "max", "F(xi)", "is", "selected", "as", "optim\\al", "deci.qion."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG"]}, "BS-bid-OCR+google": {"tokens": ["Step", "9:", "From", "the", "decision", "set", "xk", "=", "max", "F(xi)", "is", "selected", "as", "optim\\al", "decision."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "MIXED"]}}}, {"corrupt": {"tokens": ["Writirkgdown~theWZactionoftheexo.ticbraneinvolvestheT-ualizationofB6,themagneticdualofB,thetoccur\\sintheWZactionoftheNS8-brane.LetusecallthatB6isefinedbythenon-localexpression"], "labels": ["WRONG"]}, "correct": {"tokens": ["Writing", "down", "the", "WZ", "action", "of", "the", "exotic", "brane", "involves", "the", "T-dualization", "of", "B6,", "the", "magnetic", "dual", "of", "B,", "that", "occurs", "in", "the", "WZ", "action", "of", "the", "NS5-brane.", "Let", "us", "recall", "that", "B6", "is", "defined", "by", "the", "non-local", "expression"], "labels": ["MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["Writirkgdown~theWZactionoftheexo.ticbraneinvolvestheT-ualizationofB6,themagneticdualofB,thetoccur\\sintheWZactionoftheNS8-brane.LetusecallthatB6isefinedbythenon-localexpression"], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["Writirkg", "down~", "the", "WZ", "action", "of", "the", "exo.tic", "brane", "involves", "the", "T-ualization", "of", "B6,", "the", "magnetic", "dual", "of", "B,", "thet", "occur\\s", "in", "the", "WZ", "action", "of", "the", "NS8-brane.", "Let", "us", "ecall", "that", "B6", "is", "efined", "by", "the", "non-local", "expression"], "labels": ["WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["Writirkg", "down~", "the", "WZ", "action", "of", "the", "exo.tic", "brane", "involves", "the", "T-ualization", "of", "B6,", "the", "magnetic", "dual", "of", "B,", "thet", "occur\\s", "in", "the", "WZ", "action", "of", "the", "NS8-brane.", "Let", "us", "recall", "that", "B6", "is", "defined", "by", "the", "non-local", "expression"], "labels": ["WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["Wlriting"], "labels": ["WRONG"]}, "correct": {"tokens": ["Writing"], "labels": ["OCR_ERROR"]}, "predicted": {"google": {"tokens": ["Writing"], "labels": ["OCR_ERROR"]}, "BS-bid-OCR": {"tokens": ["Wlriting"], "labels": ["WRONG"]}, "BS-bid-OCR+google": {"tokens": ["Writing"], "labels": ["OCR_ERROR"]}}}, {"corrupt": {"tokens": ["P12denotes,heoperatorofpermutationofx1andx2.WeusethenotationD1=x12\u22021andD2=x92\u22022."], "labels": ["WRONG"]}, "correct": {"tokens": ["P12", "denotes", "the", "operator", "of", "permutation", "of", "x1", "and", "x2.", "We", "use", "the", "notation", "D1", "=", "x12\u22021", "and", "D2", "=", "x12\u22022."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED"]}, "predicted": {"google": {"tokens": ["P12denotes,heoperatorofpermutationofx1andx2.WeusethenotationD1=x12\u22021andD2=x92\u22022."], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["P12", "denotes", ",he", "operator", "of", "permutation", "of", "x1", "and", "x2.", "We", "use", "the", "notation", "D1", "=", "x12\u22021", "and", "D2", "=", "x92\u22022."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG"]}, "BS-bid-OCR+google": {"tokens": ["P12", "denotes", "the", "operator", "of", "permutation", "of", "x1", "and", "x2.", "We", "use", "the", "notation", "D1", "=", "x12\u22021", "and", "D2", "=", "x92\u22022."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG"]}}}, {"corrupt": {"tokens": ["PerformanceEvaluation"], "labels": ["WRONG"]}, "correct": {"tokens": ["Performance", "Evaluation"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["PerformanceEvaluation"], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["Performance", "Evaluation"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["Performance", "Evaluation"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["Longcyclesinrandomsubgraphsofgraphsw;thlargenlinim.mdegree"], "labels": ["WRONG"]}, "correct": {"tokens": ["Long", "cycles", "in", "random", "subgraphs", "of", "graphs", "with", "large", "minimum", "degree"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["Longcyclesinrandomsubgraphsofgraphsw;thlargenlinim.mdegree"], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["Long", "cycles", "in", "random", "subgraphs", "of", "graphs", "w;th", "large", "nlinim.m", "degree"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["Long", "cycles", "in", "random", "subgraphs", "of", "graphs", "w;th", "large", "nlinim.m", "degree"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["TheK2,3case"], "labels": ["WRONG"]}, "correct": {"tokens": ["The", "K2,", "3", "case"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["TheK2,3case"], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["The", "K2,", "3", "case"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["The", "K2,", "3", "case"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["ReversalsofthcLSC"], "labels": ["WRONG"]}, "correct": {"tokens": ["Reversals", "of", "the", "LSC"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["ReversalsofthcLSC"], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["Reversals", "of", "thc", "LSC"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["Reversals", "of", "thc", "LSC"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["Forclarity,onlythesimplestvariantoftheRIDCInethod(constructedusingfirsto'deEuleriritegrators,uniformtime-steppilis,seiiall.computationofthesteproutine)hasbenpresented,\\andreleasedasYpartofthebasesoftwareversion.Here,wemakesomeremarksonhowtheb;seversionofthesoftwareeanbemodifisdbytheusertoaccommodateseveralgeneraliz~ttionsdiscussedi.lithissecton;indeed,theauthorswillrelease(whenpossible)modifiedvensionsofth(;softwarewithinthessurcerepositorythatillustratehowtogenerategeneralizedRIDCintegrators."], "labels": ["WRONG"]}, "correct": {"tokens": ["For", "clarity,", "only", "the", "simplest", "variant", "of", "the", "RIDC", "method", "(constructed", "using", "first", "order", "Euler", "integrators,", "uniform", "time-stepping,", "serial", "computation", "of", "the", "step", "routine)", "has", "been", "presented,", "and", "released", "as", "part", "of", "the", "base", "software", "version.", "Here,", "we", "make", "some", "remarks", "on", "how", "the", "base", "version", "of", "the", "software", "can", "be", "modified", "by", "the", "user", "to", "accommodate", "several", "generalizations", "discussed", "in", "this", "secton;", "indeed,", "the", "authors", "will", "release", "(when", "possible)", "modified", "versions", "of", "the", "software", "within", "the", "source", "repository", "that", "illustrate", "how", "to", "generate", "generalized", "RIDC", "integrators."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["Forclarity,onlythesimplestvariantoftheRIDCInethod(constructedusingfirsto'deEuleriritegrators,uniformtime-steppilis,serial.computation", "the", "step", "routine)has", "been", "presented,\\andreleasedasYpartofthebasesoftwareversion.Here,wemakesomeremarksonhowtheb;seversionofthesoftwareeanbemodifisdbytheusertoaccommodateseveralgeneraliz~ttionsdiscussedi.lithissecton;indeed,theauthorswillrelease(when", "possible)modified", "vensionsofth(;softwarewithinthessurcerepositorythatillustratehowtogenerategeneralizedRIDCintegrators."], "labels": ["WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "MIXED", "WRONG", "WRONG", "WRONG"]}, "BS-bid-OCR": {"tokens": ["For", "clarity,", "only", "the", "simplest", "variant", "of", "the", "RIDC", "Inethod", "(constructed", "using", "first", "o'de", "Euler", "iritegrators,", "uniform", "time-steppilis,", "seiiall.", "computation", "of", "the", "step", "routine)", "has", "ben", "presented,", "\\and", "released", "asY", "part", "of", "the", "base", "software", "version.", "Here,", "we", "make", "some", "remarks", "on", "how", "the", "b;se", "version", "of", "the", "software", "ean", "be", "modifisd", "by", "the", "user", "to", "accommodate", "several", "generaliz~ttions", "discussed", "i.li", "this", "secton;", "indeed,", "the", "authors", "will", "release", "(when", "possible)", "modified", "vensions", "of", "th(;", "software", "within", "the", "ssurce", "repository", "that", "illustrate", "how", "to", "generate", "generalized", "RIDC", "integrators."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["For", "clarity,", "only", "the", "simplest", "variant", "of", "the", "RIDC", "Inethod", "(constructed", "using", "first", "ode", "Euler", "integrators,", "uniform", "time-step", "pilis,", "serial.", "computation", "of", "the", "step", "routine)", "has", "been", "presented,", "\\and", "released", "asY", "part", "of", "the", "base", "software", "version.", "Here,", "we", "make", "some", "remarks", "on", "how", "the", "b;se", "version", "of", "the", "software", "can", "be", "modified", "by", "the", "user", "to", "accommodate", "several", "generaliz~ttions", "discussed", "i.li", "this", "section;", "indeed,", "the", "authors", "will", "release", "(when", "possible)", "modified", "versions", "of", "th(;", "software", "within", "the", "source", "repository", "that", "illustrate", "how", "to", "generate", "generalized", "RIDC", "integrators."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "WRONG", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["where"], "labels": ["NONE"]}, "correct": {"tokens": ["where"], "labels": ["NONE"]}, "predicted": {"google": {"tokens": ["where"], "labels": ["NONE"]}, "BS-bid-OCR": {"tokens": ["where"], "labels": ["NONE"]}, "BS-bid-OCR+google": {"tokens": ["where"], "labels": ["NONE"]}}}, {"corrupt": {"tokens": ["where"], "labels": ["NONE"]}, "correct": {"tokens": ["where"], "labels": ["NONE"]}, "predicted": {"google": {"tokens": ["where"], "labels": ["NONE"]}, "BS-bid-OCR": {"tokens": ["where"], "labels": ["NONE"]}, "BS-bid-OCR+google": {"tokens": ["where"], "labels": ["NONE"]}}}, {"corrupt": {"tokens": ["DomainswithNoncompact~utomorphismGroup"], "labels": ["WRONG"]}, "correct": {"tokens": ["Domains", "with", "Noncompact", "Automorphism", "Group"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["Domains", "with", "Non", "compact~automorphism", "Group"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR"]}, "BS-bid-OCR": {"tokens": ["Domains", "with", "Noncompact", "~utomorphism", "Group"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["Domains", "with", "Noncompact", "~automorphism", "Group"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["andforthevacuumenergydenSitygives"], "labels": ["WRONG"]}, "correct": {"tokens": ["and", "for", "the", "vacuum", "energy", "density", "gives"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["andforthevacuumenergydenSitygives"], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["and", "for", "the", "vacuum", "energy", "denSity", "gives"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["and", "for", "the", "vacuum", "energy", "denSity", "gives"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["References"], "labels": ["NONE"]}, "correct": {"tokens": ["References"], "labels": ["NONE"]}, "predicted": {"google": {"tokens": ["References"], "labels": ["NONE"]}, "BS-bid-OCR": {"tokens": ["References"], "labels": ["NONE"]}, "BS-bid-OCR+google": {"tokens": ["References"], "labels": ["NONE"]}}}, {"corrupt": {"tokens": ["Soweget"], "labels": ["WRONG"]}, "correct": {"tokens": ["So", "we", "get"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["Soweget"], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["So", "we", "get"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["So", "we", "get"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["L\\(\u03b1(M))=D\u03b1(L(M))"], "labels": ["WRONG"]}, "correct": {"tokens": ["L(\u03b1(M))", "=", "D\u03b1(L(M))"], "labels": ["MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["L\\(\u03b1(M))=D\u03b1(L(M))"], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["L\\(\u03b1(M))", "=", "D\u03b1(L(M))"], "labels": ["WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["L\\(\u03b1(M))", "=", "D\u03b1(L(M))"], "labels": ["WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["Now,wea~einaposil,iontoprovethcuniquenessoftheweaksolution."], "labels": ["WRONG"]}, "correct": {"tokens": ["Now,", "we", "are", "in", "a", "position", "to", "prove", "the", "uniqueness", "of", "the", "weak", "solution."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["Now,wea~einaposil,iontoprovethcuniquenessoftheweaksolution."], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["Now,", "we", "a~e", "in", "a", "posil,ion", "to", "prove", "thc", "uniqueness", "of", "the", "weak", "solution."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["Now,", "we", "a~e", "in", "a", "fossils", "to", "prove", "the", "uniqueness", "of", "the", "weak", "solution."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["Acknowledgoments.Theatti;horswouldliketothankRuiPachecoforhelpfulconvcrsatiolls.Veryspeci$lthanksareduetoFranBurstallandDavidCalderbank,dwhofirstobsorvedtheparticulargeometricsignificaneeofpovalynomialdependenceonsparsmeterl'orsomefamiliesofparallelsectionsandwhohavehadaecisiveinflueuccontlfeorlginofthispaper."], "labels": ["WRONG"]}, "correct": {"tokens": ["Acknowledgements.", "The", "authors", "would", "like", "to", "thank", "Rui", "Pacheco", "for", "helpful", "conversations.", "Very", "special", "thanks", "are", "due", "to", "Fran", "Burstall", "and", "David", "Calderbank,", "who", "first", "observed", "the", "particular", "geometric", "significance", "of", "polynomial", "dependence", "on", "a", "parameter", "for", "some", "families", "of", "parallel", "sections", "and", "who", "have", "had", "a", "decisive", "influence", "on", "the", "origin", "of", "this", "paper."], "labels": ["MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["Acknowledgoments.Theatti;horswouldliketothankRuiPachecoforhelpfulconvcrsatiolls.Veryspeci$lthanksareduetoFranBurstallandDavidCalderbank,dwhofirstobsorvedtheparticulargeometricsignificaneeofpovalynomialdependenceonsparsmeterl'orsomefamiliesofparallelsectionsandwhohavehadaecisiveinflueuccontlfeorlginofthispaper."], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["Acknowledgoments.", "The", "atti;hors", "would", "like", "to", "thank", "Rui", "Pacheco", "for", "helpful", "convcrsatiolls.", "Very", "speci$l", "thanks", "are", "due", "to", "Fran", "Burstall", "and", "David", "Calderbank,d", "who", "first", "obsorved", "the", "particular", "geometric", "significanee", "of", "povalynomial", "dependence", "on", "sparsmeter", "l'or", "some", "families", "of", "parallel", "sections", "and", "who", "have", "had", "a", "ecisive", "influeucc", "on", "tlfe", "orlgin", "of", "this", "paper."], "labels": ["WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["Acknowledgements.", "The", "atti;hors", "would", "like", "to", "thank", "Rui", "Pacheco", "for", "helpful", "conversations.", "Very", "speci$l", "thanks", "are", "due", "to", "Fran", "Burstall", "and", "David", "Calderbank,who", "first", "observed", "the", "particular", "geometric", "significance", "of", "polynomial", "dependence", "on", "parameter", "l'or", "some", "families", "of", "parallel", "sections", "and", "who", "have", "had", "a", "decisive", "influence", "on", "tlfe", "origin", "of", "this", "paper."], "labels": ["MIXED", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "WRONG", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["anforthefermions:"], "labels": ["WRONG"]}, "correct": {"tokens": ["and", "for", "the", "fermions:"], "labels": ["MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["anfora", "fermions:"], "labels": ["WRONG", "TOKENIZATION_ERROR"]}, "BS-bid-OCR": {"tokens": ["an", "for", "the", "fermions:"], "labels": ["WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["an", "for", "the", "fermions:"], "labels": ["WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["\\Averagingover:Maxwell-Boltzmandistributionin3DCwefind"], "labels": ["WRONG"]}, "correct": {"tokens": ["Averaging", "over", "a", "Maxwell-Boltzmann", "distribution", "in", "3D", "we", "find"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["\\Averaging", "Over:Maxwell-Boltzmann", "distribution", "3D", "Cwe", "find"], "labels": ["WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR"]}, "BS-bid-OCR": {"tokens": ["\\Averaging", "over", ":", "Maxwell-Boltzman", "distribution", "in", "3DC", "we", "find"], "labels": ["WRONG", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["\\Averaging", "over", ":", "Maxwell-Boltzman", "distribution", "in", "3DC", "we", "find"], "labels": ["WRONG", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["Wecanfurtherexpat,d\u03b8-function"], "labels": ["WRONG"]}, "correct": {"tokens": ["We", "can", "further", "expand", "\u03b8-function"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["We", "Can", "Further", "Expat,d\u03b8-function"], "labels": ["TOKENIZATION_ERROR", "WRONG", "WRONG", "WRONG"]}, "BS-bid-OCR": {"tokens": ["We", "can", "further", "expat,d", "\u03b8-function"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["We", "can", "further", "expat,d", "\u03b8-function"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["Onecanse(!agoodagFeementl)etweenth~expermentaldistributlonsandtherticalcalcelations."], "labels": ["WRONG"]}, "correct": {"tokens": ["One", "can", "see", "a", "good", "agreement", "between", "the", "experimental", "distributions", "and", "theoretical", "calculations."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "MIXED", "MIXED", "MIXED", "TOKENIZATION_ERROR", "MIXED", "MIXED"]}, "predicted": {"google": {"tokens": ["Onecanse(!agoodagFeementl)etweenth~expermentaldistributlonsandtherticalcalcelations."], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["One", "can", "se(!", "a", "good", "agFeement", "l)etween", "th~", "expermental", "distributlons", "and", "thertical", "calcelations."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "WRONG", "WRONG", "WRONG", "TOKENIZATION_ERROR", "WRONG", "WRONG"]}, "BS-bid-OCR+google": {"tokens": ["One", "can", "see(!", "a", "good", "agFeement", "l)between", "the~", "experimental", "distributions", "and", "theoretical", "calculations."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "WRONG", "MIXED", "MIXED", "TOKENIZATION_ERROR", "MIXED", "MIXED"]}}}, {"corrupt": {"tokens": ["where"], "labels": ["NONE"]}, "correct": {"tokens": ["where"], "labels": ["NONE"]}, "predicted": {"google": {"tokens": ["where"], "labels": ["NONE"]}, "BS-bid-OCR": {"tokens": ["where"], "labels": ["NONE"]}, "BS-bid-OCR+google": {"tokens": ["where"], "labels": ["NONE"]}}}, {"corrupt": {"tokens": ["Multi-MetricTheory"], "labels": ["WRONG"]}, "correct": {"tokens": ["Multi-Metric", "Theory"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["Multi-MetricTheory"], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["Multi-Metric", "Theory"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["Multi-Metric", "Theory"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["Int?roduction"], "labels": ["WRONG"]}, "correct": {"tokens": ["Introduction"], "labels": ["OCR_ERROR"]}, "predicted": {"google": {"tokens": ["Introduction"], "labels": ["OCR_ERROR"]}, "BS-bid-OCR": {"tokens": ["Int?roduction"], "labels": ["WRONG"]}, "BS-bid-OCR+google": {"tokens": ["Introduction"], "labels": ["OCR_ERROR"]}}}, {"corrupt": {"tokens": ["Ep:y2=x3+18p2x,"], "labels": ["WRONG"]}, "correct": {"tokens": ["Ep:", "y2", "=", "x3", "+", "18p2x,"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["Ep:y2=x3+18p2x,"], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["Ep", ":", "y2", "=", "x3", "+", "18p2x,"], "labels": ["WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["Ep", ":", "y2", "=", "x3", "+", "18p2x,"], "labels": ["WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["Clustringofgalaxieswithdifferentuminsityz=1"], "labels": ["WRONG"]}, "correct": {"tokens": ["Clustering", "of", "galaxies", "with", "different", "luminosity", "at", "z", "=", "1"], "labels": ["MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["Clustringofgalaxieswithdifferentuminsityz=1"], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["Clustring", "of", "galaxies", "with", "different", "uminsity", "z", "=", "1"], "labels": ["WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["Clustering", "of", "galaxies", "with", "different", "uminsity", "z", "=", "1"], "labels": ["MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["Therefore,wefindthatthesmallandlargeislandsareautornaticallydecoupledintodifferentlayers.XealisticcaSesaremorec.omplicated,butthefeatureofth(\"rapidsignchangestillremainsevenluthosecases."], "labels": ["WRONG"]}, "correct": {"tokens": ["Therefore,", "we", "find", "that", "the", "small", "and", "large", "islands", "are", "automatically", "decoupled", "into", "different", "layers.", "Realistic", "cases", "are", "more", "complicated,", "but", "the", "feature", "of", "the", "rapid", "sign", "change", "still", "remains", "even", "in", "those", "cases."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["Therefore,wefindthatthesmallandlargeislandsareautornaticallydecoupledintodifferentlayers.XealisticcaSesaremorec.omplicated,butthefeatureofth(\"rapidsignchangestillremainsevenluthosecases."], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["Therefore,", "we", "find", "that", "the", "small", "and", "large", "islands", "are", "autornatically", "decoupled", "into", "different", "layers.", "Xealistic", "caSes", "are", "more", "c.omplicated,", "but", "the", "feature", "of", "th(\"", "rapid", "sign", "change", "still", "remains", "even", "lu", "those", "cases."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["Therefore,", "we", "find", "that", "the", "small", "and", "large", "islands", "are", "automatically", "decoupled", "into", "different", "layers.", "Realistic", "caSes", "are", "more", "complicated,", "but", "the", "feature", "of", "th(\"", "rapid", "sign", "change''", "still", "remains", "even", "in", "those", "cases."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["Thiscompletestl~eproof."], "labels": ["WRONG"]}, "correct": {"tokens": ["This", "completes", "the", "proof."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["Thiscompletestl~eproof."], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["This", "completes", "tl~e", "proof."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["This", "completes", "tl~e", "proof."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["Ill-Conditioningforsmallt"], "labels": ["WRONG"]}, "correct": {"tokens": ["Ill-Conditioning", "for", "small", "t"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["Ill-Conditioning", "For", "Small"], "labels": ["TOKENIZATION_ERROR", "WRONG", "WRONG"]}, "BS-bid-OCR": {"tokens": ["Ill-Conditioning", "for", "small", "t"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["Ill-Conditioning", "for", "small", "t"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["attd"], "labels": ["WRONG"]}, "correct": {"tokens": ["and"], "labels": ["OCR_ERROR"]}, "predicted": {"google": {"tokens": ["attd"], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["attd"], "labels": ["WRONG"]}, "BS-bid-OCR+google": {"tokens": ["attd"], "labels": ["WRONG"]}}}, {"corrupt": {"tokens": ["AbstractWepre(:ntsomeresultsofanewcalcul~tionoftheO(\u03b1)electroweakradiativecorrectionstoWbosollproductionathadroncolliderswithspecialemphasisonthetrannsversmassdistribution."], "labels": ["WRONG"]}, "correct": {"tokens": ["Abstract", "We", "present", "some", "results", "of", "a", "new", "calculation", "of", "the", "O(\u03b1)", "electroweak", "radiative", "corrections", "to", "W", "boson", "production", "at", "hadron", "colliders", "with", "special", "emphasis", "on", "the", "transverse", "mass", "distribution."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["AbstractWepre(:ntsomeresultsofanewcalcul~tionoftheO(\u03b1)electroweakradiativecorrectionstoWbosollproductionathadroncolliderswithspecialemphasisonthetrannsversmassdistribution."], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["Abstract", "We", "pre(:nt", "some", "results", "of", "a", "new", "calcul~tion", "of", "the", "O(\u03b1)", "electroweak", "radiative", "corrections", "to", "W", "bosoll", "production", "at", "hadron", "colliders", "with", "special", "emphasis", "on", "the", "trannsvers", "mass", "distribution."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["Abstract", "We", "pre(:nt", "some", "results", "of", "a", "new", "calcul~tion", "of", "the", "O(\u03b1)", "electroweak", "radiative", "corrections", "to", "W", "boson", "production", "at", "hadron", "colliders", "with", "special", "emphasis", "on", "the", "transverse", "mass", "distribution."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["HereweproposeageneraliZat:onoftheBindercumulranttthetrappedsystemoftheform"], "labels": ["WRONG"]}, "correct": {"tokens": ["Here", "we", "propose", "a", "generalization", "of", "the", "Binder", "cumulant", "to", "the", "trapped", "system", "of", "the", "form"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["HereweproposeageneraliZat:onoftheBindercumulranttthetrappedsystemoftheform"], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["Here", "we", "propose", "a", "generaliZat:on", "of", "the", "Binder", "cumulrant", "t", "the", "trapped", "system", "of", "the", "form"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["Here", "we", "propose", "a", "generaliZat:on", "of", "the", "Binder", "cumulant", "t", "the", "trapped", "system", "of", "the", "form"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["Now,wehavetuplesofbooleantcrms?thatwecanuseasint)uttothetheorcmpyrover."], "labels": ["WRONG"]}, "correct": {"tokens": ["Now,", "we", "have", "tuples", "of", "boolean", "terms", "that", "we", "can", "use", "as", "input", "to", "the", "theorem", "prover."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED"]}, "predicted": {"google": {"tokens": ["Now,wehavetuplesofbooleantcrms?thatwecanuseasint)uttothetheorcmpyrover."], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["Now,", "we", "have", "tuples", "of", "boolean", "tcrms", "?that", "we", "can", "use", "as", "int)ut", "to", "the", "theorcm", "pyrover."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG"]}, "BS-bid-OCR+google": {"tokens": ["Now,", "do", "we", "have", "tuples", "of", "boolean", "terms", "?that", "we", "can", "use", "as", "an", "int)ut", "to", "the", "theorem", "prover."], "labels": ["TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED"]}}}, {"corrupt": {"tokens": ["Ele(:l,remagne\\ticStructureofHadrons"], "labels": ["WRONG"]}, "correct": {"tokens": ["Electromagnetic", "Structure", "of", "Hadrons"], "labels": ["MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["Ele(:l,remagne\\ticStructureofHadrons"], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["Ele(:l,remagne\\tic", "Structure", "of", "Hadrons"], "labels": ["WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["Ele(:l,remagne\\tic", "Structure", "of", "Hadrons"], "labels": ["WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["Anyprocessofinelasticscatteringrm(thatisthescatteringwit-hnewparticlesproduced)canbech\\aracterizedbythe\\functionP-n,theemultiplictydistributionfunction.ThevalueofPndenotestheprobabil|tytoobservenparticlel;sproduceclinthecoLliion.IticlearthatPnmuStbenmrmalizedtnunity:"], "labels": ["WRONG"]}, "correct": {"tokens": ["Any", "process", "of", "inelastic", "scattering", "(that", "is", "the", "scattering", "with", "new", "particles", "produced)", "can", "be", "characterized", "by", "the", "function", "Pn,", "the", "multiplicity", "distribution", "function.", "The", "value", "of", "Pn", "denotes", "the", "probability", "to", "observe", "n", "particles", "produced", "in", "the", "collision.", "It", "is", "clear", "that", "Pn", "must", "be", "normalized", "to", "unity:"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["Any", "Process", "Of", "Inelastic", "Scattering", "Rm(thatisthescatteringwit-hnewparticlesproduced)canbech\\aracterizedbythe\\functionP-n,theemultiplictydistributionfunction.ThevalueofPndenotestheprobabil|tytoobservenparticlel;sproduceclinthecoLliion.IticlearthatPnmuStbenmrmalizedtnunity:"], "labels": ["TOKENIZATION_ERROR", "WRONG", "WRONG", "WRONG", "WRONG", "WRONG"]}, "BS-bid-OCR": {"tokens": ["Any", "process", "of", "inelastic", "scattering", "rm", "(that", "is", "the", "scattering", "wit-h", "new", "particles", "produced)", "can", "be", "ch\\aracterized", "by", "the\\", "function", "P", "-", "n,", "thee", "multiplicty", "distribution", "function.", "The", "value", "of", "Pn", "denotes", "the", "probabil|ty", "to", "observe", "n", "particlel;s", "producecl", "in", "the", "coLliion.", "It", "i", "clear", "that", "Pn", "muSt", "be", "nmrmalized", "tn", "unity:"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "WRONG", "WRONG", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["Any", "process", "of", "inelastic", "scattering", "rm", "(that", "is", "the", "scattering", "wit-h", "new", "particles", "produced)", "can", "be", "ch\\aracterized", "by", "the\\", "function", "P", "-", "n,", "thee", "multiplicity", "distribution", "function.", "The", "value", "of", "Pn", "denotes", "the", "probabil|try", "to", "observe", "a", "particlel;s", "produced", "in", "the", "coLlision.", "It", "i", "clear", "that", "Pn", "muSt", "be", "normalized", "to", "unity:"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "WRONG", "WRONG", "WRONG", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["Considerg\u2208Gsuchthat"], "labels": ["WRONG"]}, "correct": {"tokens": ["Consider", "g", "\u2208", "G", "such", "that"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["Considerg\u2208Gsuchthat"], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["Consider", "g", "\u2208", "G", "such", "that"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["Consider", "g", "\u2208", "G", "such", "that"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["Here,B>0(:anbechosenfexreelytoobtainthetightestpossibleboundontheprobabilityo2failu\\re.I,'ornotationalconvenience,write"], "labels": ["WRONG"]}, "correct": {"tokens": ["Here,", "B", ">", "0", "can", "be", "chosen", "freely", "to", "obtain", "the", "tightest", "possible", "bound", "on", "the", "probability", "of", "failure.", "For", "notational", "convenience,", "write"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["Here,B>0(:anbechosenfexreelytoobtainthetightestpossibleboundontheprobabilityo2failu\\re.I,'for", "notational", "convenience,write"], "labels": ["WRONG", "TOKENIZATION_ERROR", "WRONG"]}, "BS-bid-OCR": {"tokens": ["Here,", "B", ">", "0", "(:an", "be", "chosen", "fexreely", "to", "obtain", "the", "tightest", "possible", "bound", "on", "the", "probability", "o2", "failu\\re.", "I,'or", "notational", "convenience,", "write"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["Here,", "B", ">", "0", "(:an", "be", "chosen", "freely", "to", "obtain", "the", "tightest", "possible", "bound", "on", "the", "probability", "o2", "failu\\re.", "I,'for", "notational", "convenience,", "write"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["forsomep\u03b1\u2208V,suchthat:"], "labels": ["WRONG"]}, "correct": {"tokens": ["for", "some", "p\u03b1", "\u2208", "V,", "such", "that:"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["forsomep\u03b1\u2208V,such", "that:"], "labels": ["WRONG", "TOKENIZATION_ERROR"]}, "BS-bid-OCR": {"tokens": ["for", "some", "p\u03b1", "\u2208", "V,", "such", "that:"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["for", "some", "p\u03b1", "\u2208", "V,", "such", "that:"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["Themostgeneralsolvabletrialactionisoftheform"], "labels": ["WRONG"]}, "correct": {"tokens": ["The", "most", "general", "solvable", "trial", "action", "is", "of", "the", "form"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["Themostgeneralsolvabletrialactionisoftheform"], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["The", "most", "general", "solvable", "trial", "action", "is", "of", "the", "form"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["The", "most", "general", "solvable", "trial", "action", "is", "of", "the", "form"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["Eothmigrationscenarior,cquirethepresenceofadaitionalcompanion(s1inthesystemm.High-eccentricitylnigrationmechanisnlsrequireamassive,notverydistantperurbertobringthewarmJupiterintoaKozai\\-Lidovcycle,typeIImigrationrequiresmultipleplanetstoclearawideinerholeandprematurelystopthemigrationoftheplanet.KOI-614bisChusaninterestingcandidateforfutureobservationswiththeailnoffindingladditional!ow-mass,short-periodplnetaryeompanionsoramoredistanSandmassivepertnrber."], "labels": ["WRONG"]}, "correct": {"tokens": ["Both", "migration", "scenarios", "require", "the", "presence", "of", "additional", "companion(s)", "in", "the", "system.", "High-eccentricity", "migration", "mechanisms", "require", "a", "massive,", "not", "very", "distant", "perturber", "to", "bring", "the", "warm", "Jupiter", "into", "a", "Kozai-Lidov", "cycle,", "type", "II", "migration", "requires", "multiple", "planets", "to", "clear", "a", "wide", "inner", "hole", "and", "prematurely", "stop", "the", "migration", "of", "the", "planet.", "KOI-614b", "is", "thus", "an", "interesting", "candidate", "for", "future", "observations", "with", "the", "aim", "of", "finding", "additional", "low-mass,", "short-period", "planetary", "companions", "or", "a", "more", "distant", "and", "massive", "perturber."], "labels": ["MIXED", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED"]}, "predicted": {"google": {"tokens": ["Eothmigrationscenarior,cquirethepresenceofadaitionalcompanion(s1inthesystemm.High-eccentricitylnigrationmechanisnlsrequireamassive,notverydistantperurbertobringthewarmJupiterintoaKozai\\-Lidovcycle,typeIImigrationrequiresmultipleplanetstoclearawideinerholeandprematurelystopthemigrationoftheplanet.KOI-614bisChusaninterestingcandidateforfutureobservationswiththeailnoffindingladditional!ow-mass,short-periodplnetaryeompanionsoramoredistanSandmassivepertnrber."], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["Eoth", "migration", "scenario", "r,cquire", "the", "presence", "of", "adaitional", "companion(s1", "in", "the", "systemm.", "High-eccentricity", "lnigration", "mechanisnls", "require", "a", "massive,", "not", "very", "distant", "perurber", "to", "bring", "the", "warm", "Jupiter", "into", "a", "Kozai\\-Lidov", "cycle,", "type", "II", "migration", "requires", "multiple", "planets", "to", "clear", "a", "wide", "iner", "hole", "and", "prematurely", "stop", "the", "migration", "of", "the", "planet.", "KOI-614b", "is", "Chus", "an", "interesting", "candidate", "for", "future", "observations", "with", "the", "ailn", "of", "findingl", "additional", "!ow-mass,", "short-period", "plnetary", "eompanions", "or", "a", "more", "distanS", "and", "massive", "pertnrber."], "labels": ["WRONG", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "MIXED", "WRONG", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG"]}, "BS-bid-OCR+google": {"tokens": ["With", "migration", "scenario", "r,acquire", "the", "presence", "of", "additional", "companion(s1", "in", "the", "system.", "High-eccentricity", "migration", "mechanisms", "require", "a", "massive,", "not", "very", "distant", "perurber", "to", "bring", "the", "warm", "Jupiter", "into", "a", "Kozai\\-Lidov", "cycle,", "type", "II", "migration", "requires", "multiple", "planets", "to", "clear", "a", "wide", "inner", "hole", "and", "prematurely", "stop", "the", "migration", "of", "the", "planet.", "KOI-614b", "is", "Chus", "an", "interesting", "candidate", "for", "future", "observations", "with", "the", "alien", "of", "finding", "additional", "low-mass,", "short-period", "planetary", "companions", "or", "a", "more", "distanT", "and", "massive", "perturber."], "labels": ["WRONG", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED"]}}}, {"corrupt": {"tokens": ["Then,theZi,i=1,...,2karePoisso?nvectorfeeldstransversaltothefoliationFandtheDiracstcnctureisregulartrnsversallycmstant."], "labels": ["WRONG"]}, "correct": {"tokens": ["Then,", "the", "Zi,", "i", "=", "1,", "...,", "2k", "are", "Poisson", "vector", "fields", "transversal", "to", "the", "foliation", "F", "and", "the", "Dirac", "structure", "is", "regular", "transversally", "constant."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED"]}, "predicted": {"google": {"tokens": ["Then,theZi,i=1,...,2karePoisso?nvectorfeeldstransversaltothefoliationFandtheDiracstcnctureisregulartrnsversallycmstant."], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["Then,", "the", "Zi,", "i", "=", "1,", "...,", "2k", "are", "Poisso?n", "vector", "feelds", "transversal", "to", "the", "foliation", "F", "and", "the", "Dirac", "stcncture", "is", "regular", "trnsversally", "cmstant."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG"]}, "BS-bid-OCR+google": {"tokens": ["Then,", "the", "Zi,", "i", "=", "1,", "...,", "2k", "are", "Poisson", "vector", "fields", "transversal", "to", "the", "foliation", "F", "and", "the", "Dirac", "structure", "is", "regular", "transversally", "constant."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED"]}}}, {"corrupt": {"tokens": ["Thechannelenergyranedgesusedfoi'theanalysisare0.15-2keV,0.6-10keV,and1.0-7keVfortheROSATPSPC,ASCRGIS,andASCASIS,respo.ctively.Becauseofthec?librationunceFtaintisrelatetdtotheradiationdametge,wchaveignoredAS',CASISchannelsbelow1keV."], "labels": ["WRONG"]}, "correct": {"tokens": ["The", "channel", "energy", "ranges", "used", "for", "the", "analysis", "are", "0.15-2", "keV,", "0.6-10", "keV,", "and", "1.0-7", "keV", "for", "the", "ROSAT", "PSPC,", "ASCA", "GIS,", "and", "ASCA", "SIS,", "respectively.", "Because", "of", "the", "calibration", "uncertainties", "related", "to", "the", "radiation", "damage,", "we", "have", "ignored", "ASCA", "SIS", "channels", "below", "1", "keV."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["Thechannelenergyranedgesusedfoi'theanalysisare0.15-2keV,0.6-10keV,and1.0-7keVfortheROSATPSPC,ASCARIS,andASCASIS,respectively.Becauseoftasha?librationunceFtaintisrelatetdtotheradiationdametge,wchaveignoredAS',CASISchannelsbelow1keV."], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["The", "channel", "energy", "ranedges", "used", "foi'", "the", "analysis", "are", "0.15-2", "keV,", "0.6-10", "keV,", "and", "1.0-7", "keV", "for", "the", "ROSAT", "PSPC,", "ASCRGIS,", "and", "ASCASIS,", "respo.ctively.", "Because", "of", "the", "c?libration", "unceFtaintis", "relatetd", "to", "the", "radiation", "dametge,", "wc", "have", "ignored", "AS',CASIS", "channels", "below", "1", "keV."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["The", "channel", "energy", "ranges", "used", "for", "the", "analysis", "are", "0.15-2", "keV,", "0.6-10", "keV,", "and", "1.0-7", "keV", "for", "the", "ROSAT", "PSPC,", "ASCARIS,", "and", "ASCASIS,", "respectively.", "Because", "of", "the", "calibration", "unceRtainties", "related", "to", "the", "radiation", "damage,", "we", "have", "ignored", "AS',CASIS", "channels", "below", "1", "keV."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "WRONG", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["Itis~othartosdethatthetruthofl;hestrongopennessconjecturaisequivlenttothefollowingtheorenl:"], "labels": ["WRONG"]}, "correct": {"tokens": ["It", "is", "not", "hard", "to", "see", "that", "the", "truth", "of", "the", "strong", "openness", "conjecture", "is", "equivalent", "to", "the", "following", "theorem:"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED"]}, "predicted": {"google": {"tokens": ["Itis~othartosdethatthetruthofl;hestrongopennessconjecturaisequivlenttothefollowingtheorenl:"], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["It", "is", "~ot", "har", "to", "sde", "that", "the", "truth", "of", "l;he", "strong", "openness", "conjectura", "is", "equivlent", "to", "the", "following", "theorenl:"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG"]}, "BS-bid-OCR+google": {"tokens": ["It", "is", "~other", "to", "see", "that", "the", "truth", "of", "l;he", "strong", "openness", "conjecture", "is", "equivalent", "to", "the", "following", "theorem:"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED"]}}}, {"corrupt": {"tokens": ["TherelationsbetwaenL\u00b1operat(>rsandthegeneratgrsinthequantumenvelopingalgebrasarestud1ed.TheL\u00b1operatrsforUqANandUqG2algehrasareexplicillyexpressedbyChegeneraliorsasexamples."], "labels": ["WRONG"]}, "correct": {"tokens": ["The", "relations", "between", "L", "\u00b1", "operators", "and", "the", "generators", "in", "the", "quantum", "enveloping", "algebras", "are", "studied.", "The", "L", "\u00b1", "operators", "for", "UqAN", "and", "UqG2", "algebras", "are", "explicitly", "expressed", "by", "the", "generators", "as", "examples."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["TherelationsbetwaenL\u00b1operat(>rsandthegeneratgrsinthequantumenvelopingalgebrasarestud1ed.TheL\u00b1operatrsforUqANandUqG2algehrasareexplicillyexpressedbyChegeneraliorsasexamples."], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["The", "relations", "betwaen", "L", "\u00b1", "operat(>rs", "and", "the", "generatgrs", "in", "the", "quantum", "enveloping", "algebras", "are", "stud1ed.", "The", "L", "\u00b1", "operatrs", "for", "UqAN", "and", "UqG2", "algehras", "are", "explicilly", "expressed", "by", "Che", "generaliors", "as", "examples."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["The", "relations", "between", "L", "\u00b1", "operat(>rs", "and", "the", "generators", "in", "the", "quantum", "enveloping", "algebras", "are", "studied.", "The", "L", "\u00b1", "operators", "for", "UqAN", "and", "UqG2", "algebras", "are", "explicitly", "expressed", "by", "Che", "generators", "as", "examples."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["Forrhe\\caseswherethereisonlyoneecayamplitudeA,|\u03bb|equals1,andweh~ve"], "labels": ["WRONG"]}, "correct": {"tokens": ["For", "the", "cases", "where", "there", "is", "only", "one", "decay", "amplitude", "A,", "|\u03bb", "|", "equals", "1,", "and", "we", "have"], "labels": ["TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED"]}, "predicted": {"google": {"tokens": ["Forrhe\\caseswherethereisonlyoneecayamplitudeA,|\u03bb|equals1,andweh~ve"], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["For", "rhe\\", "cases", "where", "there", "is", "only", "one", "ecay", "amplitude", "A,", "|\u03bb", "|", "equals", "1,", "and", "we", "h~ve"], "labels": ["TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG"]}, "BS-bid-OCR+google": {"tokens": ["For", "the\\", "cases", "where", "there", "is", "only", "one", "ecay", "amplitude", "A,", "|\u03bb", "|", "equals", "1,", "and", "we", "h~ve"], "labels": ["TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG"]}}}, {"corrupt": {"tokens": ["Nowconsiderthediagonalelementsofs,tedecoherencefunction,representi,ngtheprobabi~itiesforhistories."], "labels": ["WRONG"]}, "correct": {"tokens": ["Now", "consider", "the", "diagonal", "elements", "of", "the", "decoherence", "function,", "representing", "the", "probabilities", "for", "histories."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["Nowconsiderthediagonalelementsofs,tedecoherencefunction,representi,ngtheprobabi~itiesforhistories."], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["Now", "consider", "the", "diagonal", "elements", "of", "s,", "te", "decoherence", "function,", "representi,ng", "the", "probabi~ities", "for", "histories."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["Now", "consider", "the", "diagonal", "elements", "of", "the", "decoherence", "function,", "representing", "the", "probability~ities", "for", "histories."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["Quantummasterequation"], "labels": ["WRONG"]}, "correct": {"tokens": ["Quantum", "master", "equation"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["Quantum", "Master", "Equation"], "labels": ["TOKENIZATION_ERROR", "WRONG", "WRONG"]}, "BS-bid-OCR": {"tokens": ["Quantum", "master", "equation"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["Quantum", "master", "equation"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["Thepowercase"], "labels": ["WRONG"]}, "correct": {"tokens": ["The", "power", "case"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["The", "Powercase"], "labels": ["TOKENIZATION_ERROR", "WRONG"]}, "BS-bid-OCR": {"tokens": ["The", "power", "case"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["The", "power", "case"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["accordirlgtotheirsixpoeiblepreferenceorders:"], "labels": ["WRONG"]}, "correct": {"tokens": ["according", "to", "their", "six", "possible", "preference", "orders:"], "labels": ["MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["accordirlgtotheirsixpoeiblepreferenceorders:"], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["accordirlg", "to", "their", "six", "poeible", "preference", "orders:"], "labels": ["WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["according", "to", "their", "six", "possible", "preference", "orders:"], "labels": ["MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["Deviationsfrombasicassumpion?s"], "labels": ["WRONG"]}, "correct": {"tokens": ["Deviations", "from", "basic", "assumptions"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED"]}, "predicted": {"google": {"tokens": ["Deviations", "From", "Basic", "Assumptions"], "labels": ["TOKENIZATION_ERROR", "WRONG", "WRONG", "WRONG"]}, "BS-bid-OCR": {"tokens": ["Deviations", "from", "basic", "assumpion?s"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG"]}, "BS-bid-OCR+google": {"tokens": ["Deviations", "from", "basic", "assumptions"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED"]}}}, {"corrupt": {"tokens": ["Th\\eseexaml)lesalsoshowthatoutliers,inthefunctionalsense,arenotsimplythe_resultofmisrecordcddataorextremenoise.Theycorrespondtoindividualsthat,forsomereason,dollotfollowthep:~tternoftbemajorityofthedat,an(1oftendeservetobestdiedmorecarefullyratherthansimplydiscasded.However,theseatypicaicurves~mustbedownweightedattheestimatiostep,orthemayleadtoerroneou\\scenclusionsfortherestofthepopulation."], "labels": ["WRONG"]}, "correct": {"tokens": ["These", "examples", "also", "show", "that", "outliers,", "in", "the", "functional", "sense,", "are", "not", "simply", "the", "result", "of", "misrecorded", "data", "or", "extreme", "noise.", "They", "correspond", "to", "individuals", "that,", "for", "some", "reason,", "do", "not", "follow", "the", "pattern", "of", "the", "majority", "of", "the", "data,", "and", "often", "deserve", "to", "be", "studied", "more", "carefully", "rather", "than", "simply", "discarded.", "However,", "these", "atypical", "curves", "must", "be", "downweighted", "at", "the", "estimation", "step,", "or", "they", "may", "lead", "to", "erroneous", "conclusions", "for", "the", "rest", "of", "the", "population."], "labels": ["MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["Th\\eseexaml)lesalsoshowthatoutliers,inthefunctionalsense,arenotsimplythe_resultofmisrecordcddataorextremenoise.Theycorrespondtoindividualsthat,forsomereason,dollotfollowthep:~tternoftbemajorityofthedat,an(1oftendeservetobestdiedmorecarefullyratherthansimplydiscasded.However,theseatypicaicurves~mustbedownweightedattheestimatiostep,orthemayleadtoerroneou\\scenclusionsfortherestofthepopulation."], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["Th\\ese", "examl)les", "also", "show", "that", "outliers,", "in", "the", "functional", "sense,", "are", "not", "simply", "the", "_result", "of", "misrecordcd", "data", "or", "extreme", "noise.", "They", "correspond", "to", "individuals", "that,", "for", "some", "reason,", "do", "llot", "follow", "the", "p:~ttern", "of", "tbe", "majority", "of", "the", "dat,", "an(1", "often", "deserve", "to", "be", "stdied", "more", "carefully", "rather", "than", "simply", "discasded.", "However,", "these", "a", "typicai", "curves~", "must", "be", "downweighted", "at", "the", "estimatio", "step,", "or", "the", "may", "lead", "to", "erroneou\\s", "cenclusions", "for", "the", "rest", "of", "the", "population."], "labels": ["WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["Th\\ese", "exam)les", "also", "show", "that", "outliers,", "in", "the", "functional", "sense,", "are", "not", "simply", "the", "_result", "of", "misrecorded", "data", "or", "extreme", "noise.", "They", "correspond", "to", "individuals", "that,", "for", "some", "reason,", "do", "not", "follow", "the", "p:~ttern", "of", "the", "majority", "of", "the", "day,", "an(1", "often", "deserve", "to", "be", "studied", "more", "carefully", "rather", "than", "simply", "discarded.", "However,", "these", "typical", "curves~", "must", "be", "down", "weighted", "at", "the", "estimation", "step,", "or", "this", "may", "lead", "to", "erroneou\\s", "conclusions", "for", "the", "rest", "of", "the", "population."], "labels": ["WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["Finally,forfaintobjects(SNRaround1perspectralchannel),elc(:tromagneticinterferencesintheVLTIinterfer?ometricabratorywiththedetectorel\\ectroinicspreventscurrentlytogetunbiasedmeasurements.IdeasareunderstudytocorrectinthedataI)rocssingsidethisleffect,bntahardwarefixshouldbeinvostigatedseriouflysinceitlimitsseriouslytheeffectivelimitinglnagnitudeoftheiostrument."], "labels": ["WRONG"]}, "correct": {"tokens": ["Finally,", "for", "faint", "objects", "(SNR", "around", "1", "per", "spectral", "channel),", "electromagnetic", "interferences", "in", "the", "VLTI", "interferometric", "laboratory", "with", "the", "detector", "electronics", "prevents", "currently", "to", "get", "unbiased", "measurements.", "Ideas", "are", "under", "study", "to", "correct", "in", "the", "data", "processing", "side", "this", "effect,", "but", "a", "hardware", "fix", "should", "be", "investigated", "seriously", "since", "it", "limits", "seriously", "the", "effective", "limiting", "magnitude", "of", "the", "instrument."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED"]}, "predicted": {"google": {"tokens": ["Finally,for", "faint", "objects(SNRaround1perspectralchannel),elc(:tromagneticinterferencesintheVLTIinterfer?ometricabratorywiththedetectorel\\ectroinicspreventscurrentlytogetunbiasedmeasurements.IdeasareunderstudytocorrectinthedataI)rocssingsidethisleffect,bntahardwarefixshouldbeinvostigatedseriouflysinceitlimitsseriouslytheeffectivelimitinglnagnitudeoftheiostrument."], "labels": ["WRONG", "TOKENIZATION_ERROR", "WRONG"]}, "BS-bid-OCR": {"tokens": ["Finally,", "for", "faint", "objects", "(SNR", "around", "1", "per", "spectral", "channel),", "elc(:tromagnetic", "interferences", "in", "the", "VLTI", "interfer?ometric", "abratory", "with", "the", "detector", "el\\ectroinics", "prevents", "currently", "to", "get", "unbiased", "measurements.", "Ideas", "are", "under", "study", "to", "correct", "in", "the", "data", "I)rocssing", "side", "this", "leffect,", "bnt", "a", "hardware", "fix", "should", "be", "invostigated", "serioufly", "since", "it", "limits", "seriously", "the", "effective", "limiting", "lnagnitude", "of", "the", "iostrument."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG"]}, "BS-bid-OCR+google": {"tokens": ["Finally,", "for", "faint", "objects", "(SNR", "around", "1", "per", "spectral", "channel),", "elc(:tromagnetic", "interference", "in", "the", "VLTI", "interferometric", "laboratory", "with", "the", "detector", "el\\ectroinics", "prevents", "currently", "unbiased", "measurements.", "Ideas", "are", "under", "study", "to", "correct", "in", "the", "data", "I)rocking", "side", "this", "effect,", "bnt", "a", "hardware", "fix", "should", "be", "investigated", "seriously", "since", "it", "seriously", "limits", "the", "effective", "limiting", "magnitude", "of", "the", "instrument."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED"]}}}, {"corrupt": {"tokens": ["Symmetrybreakinginnonconservativesystems"], "labels": ["WRONG"]}, "correct": {"tokens": ["Symmetry", "breaking", "in", "non", "conservative", "systems"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["Symmetry", "Breaking", "In", "Nonconservative", "Systems"], "labels": ["TOKENIZATION_ERROR", "WRONG", "WRONG", "WRONG", "WRONG"]}, "BS-bid-OCR": {"tokens": ["Symmetry", "breaking", "in", "nonconservative", "systems"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["Symmetry", "breaking", "in", "nonconservative", "systems"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["http:l6/wwu.youtube.com/watch?v=UftnkLtRWbU"], "labels": ["WRONG"]}, "correct": {"tokens": ["http://www.youtube.com/watch?v=UftnkLtRWbU"], "labels": ["OCR_ERROR"]}, "predicted": {"google": {"tokens": ["http:l6/wwu.youtube.com/watch?v=UftnkLtRWbU"], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["http:l6/wwu.youtube.com/watch?v=UftnkLtRWbU"], "labels": ["WRONG"]}, "BS-bid-OCR+google": {"tokens": ["http:l6/wwu.youtube.com/watch?v=UftnkLtRWbU"], "labels": ["WRONG"]}}}, {"corrupt": {"tokens": ["Notehattherighthandsideisaconstant.Weclaimthat"], "labels": ["WRONG"]}, "correct": {"tokens": ["Note", "that", "the", "right", "hand", "side", "is", "a", "constant.", "We", "claim", "that"], "labels": ["TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["Notehattherighthandsideisaconstant.Weclaimthat"], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["Note", "hat", "the", "right", "hand", "side", "is", "a", "constant.", "We", "claim", "that"], "labels": ["TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["Note", "that", "the", "right", "hand", "side", "is", "a", "constant.", "We", "claim", "that"], "labels": ["TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["ThisworkassupportedbytheAustralianResearchCouncIlCell\\treofExcelle\\ncefgorQuantumAomOptics(GrantNumberCE034817),theRoualSocietyandtheWolfsonfoulldation.TheauthorsthankJ.Corey,P.Drummond,M.Oloenand(L.\\Plimakforhelpfuldiscussions.'l'heaut?hor8aregratefultoDrCGilson,Dept.ofAppliedMaths.,UniversityofGlagowforthefir.tderivationofasolutiontothefactorisationD=BBTfo.anti-symreetridGrassmannmatricesDaudtoarefereefordirectingourattention\\tothelocalityissueandotheraspeotsinvolvedInnumericalcalculations."], "labels": ["WRONG"]}, "correct": {"tokens": ["This", "work", "was", "supported", "by", "the", "Australian", "Research", "Council", "Centre", "of", "Excellence", "for", "Quantum", "Atom", "Optics", "(Grant", "Number", "CE0348178),", "the", "Royal", "Society", "and", "the", "Wolfson", "foundation.", "The", "authors", "thank", "J.", "Corney,", "P.", "Drummond,", "M.", "Olsen", "and", "L.", "Plimak", "for", "helpful", "discussions.", "The", "authors", "are", "grateful", "to", "Dr", "C", "Gilson,", "Dept.", "of", "Applied", "Maths.,", "University", "of", "Glasgow", "for", "the", "first", "derivation", "of", "a", "solution", "to", "the", "factorisation", "D", "=", "BBT", "for", "anti-symmetric", "Grassmann", "matrices", "D", "and", "to", "a", "referee", "for", "directing", "our", "attention", "to", "the", "locality", "issue", "and", "other", "aspects", "involved", "in", "numerical", "calculations."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["ThisworkassupportedbytheAustralianResearchCouncIlCell\\treofExcelle\\ncefgorQuantumAomOptics(GrantNumberCE034817),theRoualSocietyandtheWolfsonfoulldation.TheauthorsthankJ.Corey,P.Drummond,M.Oloenand(L.\\Plimakforhelpfuldiscussions.'l'heaut?hor8aregratefultoDrCGilson,Dept.ofAppliedMaths.,UniversityofGlagowforthefir.tderivationofasolutiontothefactorisationD=BBTfo.anti-symreetridGrassmannmatricesDaudtoarefereefordirectingourattention\\tothelocalityissueandotheraspeotsinvolvedInnumericalcalculations."], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["This", "work", "as", "supported", "by", "the", "Australian", "Research", "CouncIl", "Cell\\tre", "of", "Excelle\\nce", "fgor", "Quantum", "Aom", "Optics", "(Grant", "Number", "CE034817),", "the", "Roual", "Society", "and", "the", "Wolfson", "foulldation.", "The", "authors", "thank", "J.", "Corey,", "P.", "Drummond,", "M.", "Oloen", "and", "(L.\\", "Plimak", "for", "helpful", "discussions.", "'l'he", "aut?hor8", "are", "grateful", "to", "DrC", "Gilson,", "Dept.", "of", "Applied", "Maths.,", "University", "of", "Glagow", "for", "the", "fir.t", "derivation", "of", "a", "solution", "to", "the", "factorisation", "D", "=", "BBT", "fo.", "anti-symreetrid", "Grassmann", "matrices", "D", "aud", "to", "a", "referee", "for", "directing", "our", "attention", "\\to", "the", "locality", "issue", "and", "other", "aspeots", "involved", "In", "numerical", "calculations."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["This", "work", "was", "supported", "by", "the", "Australian", "Research", "CouncIl", "Cell\\tree", "of", "Excelle\\nce", "for", "Quantum", "Atom", "Optics", "(Grant", "Number", "CE034817),", "the", "Royal", "Society", "and", "the", "Wolfson", "foundation.", "The", "authors", "thank", "J.", "Corey,", "P.", "Drummond,", "M.", "Oloen", "and", "(L.\\", "Plimak", "for", "helpful", "discussions.", "'l'he", "aut?hor8", "are", "grateful", "to", "DrC", "Gilson,", "Dept.", "of", "Applied", "Maths.,", "University", "of", "Glasgow", "for", "the", "first", "derivation", "of", "a", "solution", "to", "the", "factorisation", "D", "=", "BBT", "fo.", "anti-symreetrid", "Grassmann", "matrices", "D", "aud", "to", "a", "referee", "for", "directing", "our", "attention", "\\to", "the", "locality", "issue", "and", "other", "aspects", "involved", "In", "numerical", "calculations."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "WRONG", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["Ifn=1,asymetriconS1iscle.arlyconformallyequivalenItotherourldmetric.Forn=2,thieuniformizationtheoremsayst'hatanymetriconS2isconformallyequivalenttotheroundlnetric.Multiplyingthemetri?cbytheconformalfactorwllyieldametricthatisawarpedproductofSnwithSa."], "labels": ["WRONG"]}, "correct": {"tokens": ["If", "n", "=", "1,", "any", "metric", "on", "S1", "is", "clearly", "conformally", "equivalent", "to", "the", "round", "metric.", "For", "n", "=", "2,", "the", "uniformization", "theorem", "says", "that", "any", "metric", "on", "S2", "is", "conformally", "equivalent", "to", "the", "round", "metric.", "Multiplying", "the", "metric", "by", "the", "conformal", "factor", "will", "yield", "a", "metric", "that", "is", "a", "warped", "product", "of", "Sn", "with", "Sm."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED"]}, "predicted": {"google": {"tokens": ["Ifn=1,asymetriconS1iscle.arlyconformallyequivalenItotherourldmetric.Forn=2,thieuniformizationtheoremsayst'hatanymetriconS2isconformallyequivalenttotheroundlnetric.Multiplyingthemetri?cbytheconformalfactorwllyieldametricthatisawarpedproductofSnwithSa."], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["If", "n", "=", "1,", "asy", "metric", "on", "S1", "is", "cle.arly", "conformally", "equivalenI", "to", "the", "rourld", "metric.", "For", "n", "=", "2,", "thie", "uniformization", "theorem", "says", "t'hat", "any", "metric", "on", "S2", "is", "conformally", "equivalent", "to", "the", "round", "lnetric.", "Multiplying", "the", "metri?c", "by", "the", "conformal", "factor", "wll", "yield", "a", "metric", "that", "is", "a", "warped", "product", "of", "Sn", "with", "Sa."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG"]}, "BS-bid-OCR+google": {"tokens": ["If", "n", "=", "1,", "asymmetric", "on", "S1", "is", "clearly", "conformally", "equivalenT", "to", "the", "world", "metric.", "For", "n", "=", "2,", "the", "uniformization", "theorem", "says", "that", "any", "metric", "on", "S2", "is", "conformally", "equivalent", "to", "the", "round", "metric.", "Multiplying", "the", "metric", "by", "the", "conformal", "factor", "will", "yield", "a", "metric", "that", "is", "a", "warped", "product", "of", "Sn", "with", "Sa."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG"]}}}, {"corrupt": {"tokens": ["assmoothmanifolds."], "labels": ["WRONG"]}, "correct": {"tokens": ["as", "smooth", "manifolds."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["as", "smooth", "manifolds."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR": {"tokens": ["as", "smooth", "manifolds."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["as", "smooth", "manifolds."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["xn+1=f(x)"], "labels": ["WRONG"]}, "correct": {"tokens": ["xn", "+", "1", "=", "f(x)"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["xn+1=f(x)"], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["xn", "+", "1", "=", "f(x)"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["xn", "+", "1", "=", "f(x)"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["Aftersomestraightforwavdmanipulationsebtalnthegen~ralformoftheelectricandmgneticfieldstrengths"], "labels": ["WRONG"]}, "correct": {"tokens": ["After", "some", "straightforward", "manipulations", "we", "obtain", "the", "general", "form", "of", "the", "electric", "and", "magnetic", "field", "strengths"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["Aftersomestraightforwavdmanipulationsebtalnthegen~ralformoftheelectricandmgneticfieldstrengths"], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["After", "some", "straightforwavd", "manipulations", "ebtaln", "the", "gen~ral", "form", "of", "the", "electric", "and", "mgnetic", "field", "strengths"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["After", "some", "straightforward", "manipulations", "ebt", "in", "the", "gen~ral", "form", "of", "the", "electric", "and", "magnetic", "field", "strengths"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["validlb,'0e\u2264r\u2264R,,kR?<1."], "labels": ["WRONG"]}, "correct": {"tokens": ["valid", "for", "0", "\u2264", "r", "\u2264", "R,", "kR", "<", "<1."], "labels": ["TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["valid", "lb,'0e\u2264r\u2264R,,kR?<1."], "labels": ["TOKENIZATION_ERROR", "WRONG"]}, "BS-bid-OCR": {"tokens": ["valid", "lb,'", "0e", "\u2264", "r", "\u2264", "R,,", "kR?", "<", "1."], "labels": ["TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "MIXED", "WRONG"]}, "BS-bid-OCR+google": {"tokens": ["valid", "lb,'", "0e", "\u2264", "r", "\u2264", "R,,", "kR?", "<", "1."], "labels": ["TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "MIXED", "WRONG"]}}}, {"corrupt": {"tokens": ["TheexpressionsofthrenormaLizedcouplingsgobeyondl;hcaccuracyoftimusualone-looprelations.Ahectually,theyensurethatachangeinthenormaliiationscaleeanbccompensatedinallformulaebelowbyanappropriatechangeiutilecouplings.Thefo\\]lowingnon-perturbativemass-andself-couplingrenormalizationsaveintroduced:"], "labels": ["WRONG"]}, "correct": {"tokens": ["The", "expressions", "of", "the", "renormalized", "couplings", "go", "beyond", "the", "accuracy", "of", "the", "usual", "one-loop", "relations.", "Actually,", "they", "ensure", "that", "a", "change", "in", "the", "normalization", "scale", "can", "be", "compensated", "in", "all", "formulae", "below", "by", "an", "appropriate", "change", "in", "the", "couplings.", "The", "following", "non-perturbative", "mass-", "and", "self-coupling", "renormalizations", "are", "introduced:"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["TheexpressionsofthrenormaLizedcouplingsgobeyondl;hcaccuracyoftimusualone-looprelations.Ahectually,theyensurethatachangeinthenormaliiationscaleeanbccompensatedinallformulaebelowbyanappropriatechangeiutilecouplings.Thefo\\]lowing", "non-perturbative", "mass-and", "self-coupling", "renormalization", "save", "introduced:"], "labels": ["WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR"]}, "BS-bid-OCR": {"tokens": ["The", "expressions", "of", "th", "renormaLized", "couplings", "go", "beyond", "l;hc", "accuracy", "of", "tim", "usual", "one-loop", "relations.", "Ahectually,", "they", "ensure", "that", "a", "change", "in", "the", "normaliiation", "scale", "ean", "bc", "compensated", "in", "all", "formulae", "below", "by", "an", "appropriate", "change", "iu", "tile", "couplings.", "The", "fo\\]lowing", "non-perturbative", "mass-", "and", "self-coupling", "renormalizations", "ave", "introduced:"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["The", "expressions", "of", "th", "renormaLized", "couplings", "go", "beyond", "l;hc", "accuracy", "of", "usual", "one-loop", "relations.", "Actually,", "they", "ensure", "that", "a", "change", "in", "the", "normalization", "scale", "can", "be", "compensated", "in", "all", "formulae", "below", "by", "an", "appropriate", "change", "in", "tile", "couplings.", "The", "fo\\]lowing", "non-perturbative", "mass-", "and", "self-coupling", "renormalization", "have", "introduced:"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["As~Lnex;tmple,uncertaintyl'elationEq.(4)inthemaintextholbdsbecause"], "labels": ["WRONG"]}, "correct": {"tokens": ["As", "an", "example,", "uncertainty", "relation", "Eq.(4)", "in", "the", "main", "text", "holds", "because"], "labels": ["TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["As~Lex;temple,uncertaintyl'elationEq.(4)inthemaintextholbdsbecause"], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["As", "~Ln", "ex;tmple,", "uncertainty", "l'elation", "Eq.", "(4)", "in", "the", "main", "text", "holbds", "because"], "labels": ["TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "WRONG", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["As", "~Ln", "ex;temple,", "uncertainty", "l'elation", "Eq.", "(4)", "in", "the", "main", "text", "holds", "because"], "labels": ["TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "WRONG", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["un=mn({\u03b7}(n))."], "labels": ["WRONG"]}, "correct": {"tokens": ["un", "=", "mn({\u03b7}(n))."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["un=mn({\u03b7}(n))."], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["un", "=", "mn({\u03b7}(n))."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["un", "=", "mn({\u03b7}(n))."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["Recovfryofthcfreepropagator"], "labels": ["WRONG"]}, "correct": {"tokens": ["Recovery", "of", "the", "free", "propagator"], "labels": ["MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["Recovery", "Of", "Htc", "Free", "Propagator"], "labels": ["MIXED", "WRONG", "WRONG", "WRONG", "WRONG"]}, "BS-bid-OCR": {"tokens": ["Recovfry", "of", "thc", "free", "propagator"], "labels": ["WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["Recovery", "of", "thc", "free", "propagator"], "labels": ["MIXED", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["i.e.weedwithaproductsl;ate,Jwherethephysicalstatesevolvedaccordiagt,otheresiredHamillonianHandtheauxiliarysystemsbackinitsinitialstate."], "labels": ["WRONG"]}, "correct": {"tokens": ["i.e.", "we", "end", "with", "a", "product", "state,", "where", "the", "physical", "state", "has", "evolved", "according", "to", "the", "desired", "Hamiltonian", "H", "and", "the", "auxiliary", "system", "is", "back", "in", "its", "initial", "state."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["i.e.weedwithaproductsl;ate,Jwherethephysicalstatesevolvedaccordiagt,otheresiredHamillonianHandtheauxiliarysystemsbackinitsinitialstate."], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["i.e.", "we", "ed", "with", "a", "product", "sl;ate,", "J", "where", "the", "physical", "states", "evolved", "accordiag", "t,o", "the", "resired", "Hamillonian", "H", "and", "the", "auxiliary", "systems", "back", "in", "its", "initial", "state."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["i.s.", "weed", "with", "a", "product", "slate,", "J", "where", "the", "physical", "states", "evolved", "according", "to", "the", "desired", "Hamiltonian", "H", "and", "the", "auxiliary", "systems", "back", "in", "its", "initial", "state."], "labels": ["WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["Acknowledgements"], "labels": ["NONE"]}, "correct": {"tokens": ["Acknowledgements"], "labels": ["NONE"]}, "predicted": {"google": {"tokens": ["Acknowledgements"], "labels": ["NONE"]}, "BS-bid-OCR": {"tokens": ["Acknowledgements"], "labels": ["NONE"]}, "BS-bid-OCR+google": {"tokens": ["Acknowledgements"], "labels": ["NONE"]}}}, {"corrupt": {"tokens": ["However,heinghigherdimensienal,weexpectitl;obesuppressedatleastbyonel)owerof1/\u039b,henceweshallneglectitinthediscussionthattollews,"], "labels": ["WRONG"]}, "correct": {"tokens": ["However,", "being", "higher", "dimensional,", "we", "expect", "it", "to", "be", "suppressed", "at", "least", "by", "one", "power", "of", "1/\u039b,", "hence", "we", "shall", "neglect", "it", "in", "the", "discussion", "that", "follows."], "labels": ["TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED"]}, "predicted": {"google": {"tokens": ["However,heinghigherdimensienal,weexpectitl;obesuppressedatleastbyonel)owner", "of", "1/\u039b,henceweshallneglectitinthediscussionthattollews,"], "labels": ["WRONG", "TOKENIZATION_ERROR", "WRONG"]}, "BS-bid-OCR": {"tokens": ["However,", "heing", "higher", "dimensienal,", "we", "expect", "it", "l;o", "be", "suppressed", "at", "least", "by", "one", "l)ower", "of", "1/\u039b,", "hence", "we", "shall", "neglect", "it", "in", "the", "discussion", "that", "tollews,"], "labels": ["TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG"]}, "BS-bid-OCR+google": {"tokens": ["However,", "being", "higher", "dimensional,", "we", "expect", "it", "l;o", "be", "suppressed", "at", "least", "by", "one", "l)power", "of", "1/\u039b,", "hence", "we", "shall", "neglect", "it", "in", "the", "discussion", "that", "follows,"], "labels": ["TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG"]}}}, {"corrupt": {"tokens": ["In??conclusion,wesummarizethemainpointsofthisletter."], "labels": ["WRONG"]}, "correct": {"tokens": ["In", "conclusion,", "we", "summarize", "the", "main", "points", "of", "this", "letter."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["In??in", "conclusion,we", "summarize", "the", "main", "points", "of", "this", "letter."], "labels": ["WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR": {"tokens": ["In??", "conclusion,", "we", "summarize", "the", "main", "points", "of", "this", "letter."], "labels": ["WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["In??", "conclusion,", "we", "summarize", "the", "main", "points", "of", "this", "letter."], "labels": ["WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["PHYSICALPARAMETERS"], "labels": ["WRONG"]}, "correct": {"tokens": ["PHYSICAL", "PARAMETERS"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["PHYSICALPARAMETERS"], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["PHYSICAL", "PARAMETERS"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["PHYSICAL", "PARAMETERS"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["Thereexiettw<)non-intersectingciosedarcsI,J\u2282S1.~;uchthat:"], "labels": ["WRONG"]}, "correct": {"tokens": ["There", "exist", "two", "non-intersecting", "closed", "arcs", "I,", "J", "\u2282", "S1", "such", "that:"], "labels": ["TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["Thereexiettw<)non-intersectingciosedarcsI,J\u2282S1.~;uchthat:"], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["There", "exiet", "tw<)", "non-intersecting", "ciosed", "arcs", "I,", "J", "\u2282", "S1", ".~;uch", "that:"], "labels": ["TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["There", "exist", "two<)", "non-intersecting", "closed", "arcs", "I,", "J", "\u2282", "S1", ".~;uch", "that:"], "labels": ["TOKENIZATION_ERROR", "MIXED", "WRONG", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["where"], "labels": ["NONE"]}, "correct": {"tokens": ["where"], "labels": ["NONE"]}, "predicted": {"google": {"tokens": ["where"], "labels": ["NONE"]}, "BS-bid-OCR": {"tokens": ["where"], "labels": ["NONE"]}, "BS-bid-OCR+google": {"tokens": ["where"], "labels": ["NONE"]}}}, {"corrupt": {"tokens": ["Case2."], "labels": ["WRONG"]}, "correct": {"tokens": ["Case", "2."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["Case2."], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["Case", "2."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["Case", "2."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["Inthesubsequentdiscussion,omeefficwientnl&tionwrillprovcuseful.ThisissaummariiedinTable1."], "labels": ["WRONG"]}, "correct": {"tokens": ["In", "the", "subsequent", "discussion,", "some", "efficient", "notation", "will", "prove", "useful.", "This", "is", "summarized", "in", "Table", "1."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "MIXED", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["Inthe", "Subsequent", "Discussion,omeefficwient", "l&tionwrillprovcuseful.ThisissaummariiedinTable1."], "labels": ["WRONG", "WRONG", "WRONG", "WRONG"]}, "BS-bid-OCR": {"tokens": ["In", "the", "subsequent", "discussion,", "ome", "efficwient", "nl&tion", "wrill", "provc", "useful.", "This", "is", "saummariied", "in", "Table", "1."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "WRONG", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["In", "the", "subsequent", "discussion,", "some", "efficient", "nl", "tion", "will", "prove", "useful.", "This", "is", "summarized", "in", "Table", "1."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "WRONG", "WRONG", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["6.Conclusion"], "labels": ["WRONG"]}, "correct": {"tokens": ["6.", "Conclusion"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["6.Conclusion"], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["6.", "Conclusion"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["6.", "Conclusion"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["Thetol:alenergy\\ofanucleusisgivenbyE=Enucl+ECoul+ECM,where=nucl,ECoulandECMar('.thecontributionsfromnuclea\\r,Coiflombandcenter-of-masscorrection,respectively.Tl~nuclearpartoftheenergyforaneffectveinteractionisgivenby,"], "labels": ["WRONG"]}, "correct": {"tokens": ["The", "total", "energy", "of", "a", "nucleus", "is", "given", "by", "E", "=", "Enucl", "+", "ECoul", "+", "ECM,", "where", "Enucl,", "ECoul", "and", "ECM", "are", "the", "contributions", "from", "nuclear,", "Coulomb", "and", "center-of-mass", "correction,", "respectively.", "The", "nuclear", "part", "of", "the", "energy", "for", "an", "effective", "interaction", "is", "given", "by,"], "labels": ["TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["Thetol:alenergy\\ofanucleusisgivenbyE=Enucl+ECoul+ECM,where=nucl,ECoulandECMar('.thecontributionsfromnuclea\\r,Coiflombandcenter-of-masscorrection,respectively.Tl~nuclearpartoftheenergyforaneffectveinteractionisgivenby,"], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["The", "tol:al", "energy", "\\of", "a", "nucleus", "is", "given", "by", "E", "=", "Enucl", "+", "ECoul", "+", "ECM,", "where", "=nucl,", "ECoul", "and", "ECM", "ar('.", "the", "contributions", "from", "nuclea\\r,", "Coiflomb", "and", "center-of-mass", "correction,", "respectively.", "Tl~", "nuclear", "part", "of", "the", "energy", "for", "an", "effectve", "interaction", "is", "given", "by,"], "labels": ["TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["The", "tol:al", "energy", "\\of", "a", "nucleus", "is", "given", "by", "E", "=", "Enucl", "+", "ECoul", "+", "ECM,", "where", "=nucl,", "ECoul", "and", "ECM", "ar('.", "the", "contributions", "from", "nuclea\\r,", "Coulomb", "and", "center-of-mass", "correction,", "respectively.", "Tl~", "nuclear", "part", "of", "the", "energy", "for", "an", "effective", "interaction", "is", "given", "by,"], "labels": ["TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["Oneofthelessonsofstatisticalmechanicsisthatinanextensivesytemofvariables,withsh()rtrangeintractions,atgenericchoiccsofpara.metersthecorrelationsdecyexponentiallv.Thecorrelationle.,gthistypicallynhetmuchgreaterthltherangeof;theinteraction,anditisonly?intheLanguvicinityofcritlcalp\\ointsthatcorrelationsexhibitstructurasofmtlchgreaterscales.Forafieldtheory.basedonlocalinteractionhs~theinteractlonrangehvanishesonthescolproeo~thecontinuumlimit.Hence,inaconstructiveapproximation,forwhlchconvcr~enceisaccomplishedthroughultravioletCutoffs,theundcrLyingystemofthelocalvariablesneedstobeverynearacriticaIpoint.Somefamiliaritywithcriticalphenomenais,thermf()re,essentialnfortheundsrstanndingo\\facontnnuumfieldtheory."], "labels": ["WRONG"]}, "correct": {"tokens": ["One", "of", "the", "lessons", "of", "statistical", "mechanics", "is", "that", "in", "an", "extensive", "system", "of", "variables,", "with", "short", "range", "interactions,", "at", "generic", "choices", "of", "parameters", "the", "correlations", "decay", "exponentially.", "The", "correlation", "length", "is", "typically", "not", "much", "greater", "than", "the", "range", "of", "the", "interaction,", "and", "it", "is", "only", "in", "the", "vicinity", "of", "critical", "points", "that", "correlations", "exhibit", "structures", "of", "much", "greater", "scales.", "For", "a", "field", "theory", "based", "on", "local", "interactions,", "the", "interaction", "range", "vanishes", "on", "the", "scale", "of", "the", "continuum", "limit.", "Hence,", "in", "a", "constructive", "approximation,", "for", "which", "convergence", "is", "accomplished", "through", "ultraviolet", "cutoffs,", "the", "underlying", "system", "of", "the", "local", "variables", "needs", "to", "be", "very", "near", "a", "critical", "point.", "Some", "familiarity", "with", "critical", "phenomena", "is,", "therefore,", "essential", "for", "the", "understanding", "of", "a", "continuum", "field", "theory."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["Oneofthelessonsofstatisticalmechanicsisthatinanextensivesytemofvariables,withsh()rtrangeintractions,atgenericchoiccsofpara.metersthecorrelationsdecyexponentiallv.Thecorrelationle.,gthistypicallynhetmuchgreaterthltherangeof;theinteraction,anditisonly?intheLanguvicinityofcritlcalp\\ointsthatcorrelationsexhibitstructurasofmtlchgreaterscales.Forafieldtheory.basedonlocalinteractionhs~theinteractlonrangehvanishesonthescolproeo~thecontinuumlimit.Hence,inaconstructiveapproximation,forwhlchconvcr~enceisaccomplishedthroughultravioletCutoffs,theundcrLyingystemofthelocalvariablesneedstobeverynearacriticaIpoint.Somefamiliaritywithcriticalphenomenais,thermf()re,essentialnfortheundsrstanndingo\\facontnnuumfieldtheory."], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["One", "of", "the", "lessons", "of", "statistical", "mechanics", "is", "that", "in", "an", "extensive", "sytem", "of", "variables,", "with", "sh()rt", "range", "intractions,", "at", "generic", "choiccs", "of", "para.meters", "the", "correlations", "decy", "exponentiallv.", "The", "correlation", "le.,gth", "is", "typically", "nhet", "much", "greater", "thl", "the", "range", "of", ";the", "interaction,", "and", "it", "is", "only", "?in", "the", "Langu", "vicinity", "of", "critlcal", "p\\oints", "that", "correlations", "exhibit", "structuras", "of", "mtlch", "greater", "scales.", "For", "a", "field", "theory.", "based", "on", "local", "interactionhs~", "the", "interactlon", "range", "h", "vanishes", "on", "the", "scolproe", "o~", "the", "continuum", "limit.", "Hence,", "in", "a", "constructive", "approximation,", "for", "whlch", "convcr~ence", "is", "accomplished", "through", "ultraviolet", "Cutoffs,", "the", "undcrLying", "ystem", "of", "the", "local", "variables", "needs", "to", "be", "very", "near", "a", "criticaI", "point.", "Some", "familiarity", "with", "critical", "phenomena", "is,", "thermf()re,", "essentialn", "for", "the", "undsrstannding", "o\\f", "a", "contnnuum", "field", "theory."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["One", "of", "the", "lessons", "of", "statistical", "mechanics", "is", "that", "in", "an", "extensive", "system", "of", "variables,", "with", "sh()rt", "range", "interactions,", "at", "generic", "choices", "of", "parameters", "the", "correlations", "decay", "exponentially.", "The", "correlation", "le.,gth", "is", "typically", "nhet", "much", "greater", "thl", "the", "range", "of", ";the", "interaction,", "and", "it", "is", "only", "?in", "the", "Langu", "vicinity", "of", "critical", "p\\oints", "that", "correlations", "exhibit", "structures", "of", "mulch", "greater", "scales.", "For", "a", "field", "theory.", "based", "on", "local", "interactions~", "the", "interaction", "range", "h", "vanishes", "on", "the", "sculptor", "of~", "the", "continuum", "limit.", "Hence,", "in", "a", "constructive", "approximation,", "for", "which", "cover~ence", "is", "accomplished", "through", "ultraviolet", "Cutoffs,", "the", "underLying", "system", "of", "the", "local", "variables", "needs", "to", "be", "very", "near", "a", "criticaL", "point.", "Some", "familiarity", "with", "critical", "phenomena", "is,", "thermf()re,", "essential", "for", "the", "understanding", "o\\f", "a", "continuum", "field", "theory."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "WRONG", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["Aglimpselnto4-dlmensionalskeinmodules"], "labels": ["WRONG"]}, "correct": {"tokens": ["A", "glimpse", "into", "4-dimensional", "skein", "modules"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["Aglimpselnto4-dlmensionalskeinmodules"], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["A", "glimpse", "lnto", "4-dlmensional", "skein", "modules"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["A", "glimpse", "into", "4-dimensional", "skein", "modules"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["Emailaddress:morsej@math.drexel.edu"], "labels": ["WRONG"]}, "correct": {"tokens": ["Email", "address:", "morsej@math.drexel.edu"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["Emailaddress:morsej@math.drexel.edu"], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["Email", "address:", "morsej@math.drexel.edu"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["Email", "address:", "morsej@math.drexel.edu"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["Scenario3"], "labels": ["WRONG"]}, "correct": {"tokens": ["Scenario", "3"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["Scenario3"], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["Scenario", "3"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["Scenario", "3"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["JetEff2ciellcyofADAFSurroundi.ugaSpinningBH"], "labels": ["WRONG"]}, "correct": {"tokens": ["Jet", "Efficiency", "of", "ADAF", "Surrounding", "a", "Spinning", "BH"], "labels": ["TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["JetEff2ciellcyofADAFSurroundi.ugaSpinningBH"], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["Jet", "Eff2ciellcy", "of", "ADAF", "Surroundi.ug", "a", "Spinning", "BH"], "labels": ["TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["Jet", "Eff2ciellcy", "of", "ADAF", "Surroundi.ug", "a", "Spinning", "BH"], "labels": ["TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["Atone-piloopl~velthepresenceofthenewquartictermsintheLagrangiandoesnotaf\\[\"cctthepropagatorsandthe1PIfunctionswhichenter?thecomputationofthebeta-functionsfortheYukawacouplingconstant\u03bb.Soweexpecttofindthesame\u03b2\u03bbasintheN=1case.Similarly*,slncethe?ne-loopbetefunctionforthegaugecouplingdependsonlyontheeldcontentofthemodel,wilichiskepttcsameasiN=?4,wereproducetne\u03b2g=0resultofN=4case."], "labels": ["WRONG"]}, "correct": {"tokens": ["At", "one-loop", "level", "the", "presence", "of", "the", "new", "quartic", "terms", "in", "the", "Lagrangian", "does", "not", "affect", "the", "propagators", "and", "the", "1PI", "functions", "which", "enter", "the", "computation", "of", "the", "beta-functions", "for", "the", "Yukawa", "coupling", "constant", "\u03bb.", "So", "we", "expect", "to", "find", "the", "same", "\u03b2\u03bb", "as", "in", "the", "N", "=", "1", "case.", "Similarly,", "since", "the", "one-loop", "beta", "function", "for", "the", "gauge", "coupling", "depends", "only", "on", "the", "field", "content", "of", "the", "model,", "which", "is", "kept", "the", "same", "as", "in", "N", "=", "4,", "we", "reproduce", "the", "\u03b2g", "=", "0", "result", "of", "N", "=", "4", "case."], "labels": ["TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["Atone-piloopl~velthepresenceofthenewquartictermsintheLagrangiandoesnotaf\\[\"cctthepropagatorsandthe1PIfunctionswhichenter?thecomputationofthebeta-functionsfortheYukawacouplingconstant\u03bb.Soweexpecttofindthesame\u03b2\u03bbasintheN=1case.Similarly*,slncethe?ne-loopbetefunctionforthegaugecouplingdependsonlyontheeldcontentofthemodel,wilichiskepttcsameasiN=?4,wereproducetne\u03b2g=0resultofN=4case."], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["At", "one-piloop", "l~vel", "the", "presence", "of", "the", "new", "quartic", "terms", "in", "the", "Lagrangian", "does", "not", "af\\[\"cct", "the", "propagators", "and", "the", "1PI", "functions", "which", "enter", "?the", "computation", "of", "the", "beta-functions", "for", "the", "Yukawa", "coupling", "constant", "\u03bb.", "So", "we", "expect", "to", "find", "the", "same", "\u03b2\u03bb", "as", "in", "the", "N", "=", "1", "case.", "Similarly*,", "slnce", "the", "?ne-loop", "bete", "function", "for", "the", "gauge", "coupling", "depends", "only", "on", "the", "eld", "content", "of", "the", "model,", "wilich", "is", "kept", "tc", "same", "as", "i", "N", "=", "?4,", "we", "reproduce", "tne", "\u03b2g", "=", "0", "result", "of", "N", "=", "4", "case."], "labels": ["TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["At", "one-loop", "l~vel", "the", "presence", "of", "the", "new", "quartic", "terms", "in", "the", "Lagrangian", "does", "not", "af\\[\"cct", "the", "propagators", "and", "the", "1PI", "functions", "which", "enter", "?the", "computation", "of", "the", "beta-functions", "for", "the", "Yukawa", "coupling", "constant", "\u03bb.", "So", "we", "expect", "to", "find", "the", "same", "\u03b2\u03bb", "as", "in", "the", "N", "=", "1", "case.", "Similarly*,", "since", "then", "?the", "one-loop", "beta", "function", "for", "the", "gauge", "coupling", "depends", "only", "on", "the", "eld", "content", "of", "the", "model,", "wilich", "is", "kept", "the", "same", "as", "i", "N", "=", "?4,", "we", "reproduce", "the", "\u03b2g", "=", "0", "result", "of", "N", "=", "4", "case."], "labels": ["TOKENIZATION_ERROR", "MIXED", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "MIXED", "WRONG", "WRONG", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["Inthissubsectioninsteadoffixingthem~ssMwefixthedensity\u03bb>0.LetV(x,y,z;\u03c1)\\be1;hepotential?inducedbythefixedilomogencouscircle,continedinthexy-cpl?ane,centeredattheorigin,witconstantdensity\u03bbandwithradius\u03c1."], "labels": ["WRONG"]}, "correct": {"tokens": ["In", "this", "subsection", "instead", "of", "fixing", "the", "mass", "M", "we", "fix", "the", "density", "\u03bb", ">", "0.", "Let", "V(x,", "y,", "z;", "\u03c1)", "be", "the", "potential", "induced", "by", "the", "fixed", "homogeneous", "circle,", "contained", "in", "the", "xy-plane,", "centered", "at", "the", "origin,", "with", "constant", "density", "\u03bb", "and", "with", "radius", "\u03c1."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["In", "This", "Subsection", "Instead", "Of", "Fixing", "Them~ssMwefixthedensity\u03bb>0.LetV(x,y,z;\u03c1)\\be1;potential?induced", "by", "thefixedilomogencouscircle,continentes-cpl?ane,centeredattheorigin,witconstantdensity\u03bbandwithradius\u03c1."], "labels": ["TOKENIZATION_ERROR", "WRONG", "WRONG", "WRONG", "WRONG", "WRONG", "WRONG", "TOKENIZATION_ERROR", "WRONG"]}, "BS-bid-OCR": {"tokens": ["In", "this", "subsection", "instead", "of", "fixing", "the", "m~ss", "M", "we", "fix", "the", "density", "\u03bb", ">", "0.", "Let", "V(x,", "y,", "z;", "\u03c1)", "\\be", "1;he", "potential", "?induced", "by", "the", "fixed", "ilomogencous", "circle,", "contined", "in", "the", "xy-c", "pl?ane,", "centered", "at", "the", "origin,", "wit", "constant", "density", "\u03bb", "and", "with", "radius", "\u03c1."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["In", "this", "subsection", "instead", "of", "fixing", "the", "m~ss", "M", "we", "fix", "the", "density", "\u03bb", ">", "0.", "Let", "V(x,", "y,", "z;", "\u03c1)", "\\be", "1;the", "potential", "induced", "by", "the", "fixed", "ilomogencous", "circle,", "continued", "in", "the", "xy-c", "plane,", "centered", "at", "the", "origin,", "with", "constant", "density", "\u03bb", "and", "radius", "\u03c1."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["Toescribethecvolutionoftheclassicalfleld\u03c3duringinflationwemustspec?ifythedifferentphasesofinflation.Wethuswritethetotallengthofinflatinas"], "labels": ["WRONG"]}, "correct": {"tokens": ["To", "describe", "the", "evolution", "of", "the", "classical", "field", "\u03c3", "during", "inflation", "we", "must", "specify", "the", "different", "phases", "of", "inflation.", "We", "thus", "write", "the", "total", "length", "of", "inflation", "as"], "labels": ["TOKENIZATION_ERROR", "MIXED", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["Toescribethecvolutionoftheclassicalfleld\u03c3duringinflationwemustspec?ifythedifferentphasesofinflation.Wethuswritethetotallengthofinflatinas"], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["To", "escribe", "the", "cvolution", "of", "the", "classical", "fleld", "\u03c3", "during", "inflation", "we", "must", "spec?ify", "the", "different", "phases", "of", "inflation.", "We", "thus", "write", "the", "total", "length", "of", "inflatin", "as"], "labels": ["TOKENIZATION_ERROR", "WRONG", "MIXED", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["To", "describe", "the", "evolution", "of", "the", "classical", "field", "\u03c3", "during", "inflation", "we", "must", "specify", "the", "different", "phases", "of", "inflation.", "We", "thus", "write", "the", "total", "length", "of", "inflation", "as"], "labels": ["TOKENIZATION_ERROR", "MIXED", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["w,it:"], "labels": ["WRONG"]}, "correct": {"tokens": ["with:"], "labels": ["OCR_ERROR"]}, "predicted": {"google": {"tokens": ["w,it:"], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["w,it:"], "labels": ["WRONG"]}, "BS-bid-OCR+google": {"tokens": ["w,it:"], "labels": ["WRONG"]}}}, {"corrupt": {"tokens": ["IfChasgenuszero,thenCandLhanomoduli,alld?hncethemeasilrejustdescribydcanserVeasameasureonM.ForCofposit,ivegenuswCandLdohavemoduli.Itisnotatallclearwhatsortofmeasur('.shollldbeusedotointegrateoverhosemoduli,soatthemomenttheeisnotalearframdworkforhighergenuScomputationsintwistorspace.Forthisreason,insection3,wilenteverityparityinvarianceofthescatteringauplitndesinaprecisefashin,weconsiderpnlythecontribulionsfromcur~sofgenuszero.However,animporlantt)altofthecalculationcanbecarriedoutforarbitrarygenns,aswwewillnowsee."], "labels": ["WRONG"]}, "correct": {"tokens": ["If", "C", "has", "genus", "zero,", "then", "C", "and", "L", "have", "no", "moduli,", "and", "hence", "the", "measure", "just", "described", "can", "serve", "as", "a", "measure", "on", "M.", "For", "C", "of", "positive", "genus,", "C", "and", "L", "do", "have", "moduli.", "It", "is", "not", "at", "all", "clear", "what", "sort", "of", "measure", "should", "be", "used", "to", "integrate", "over", "those", "moduli,", "so", "at", "the", "moment", "there", "is", "not", "a", "clear", "framework", "for", "higher", "genus", "computations", "in", "twistor", "space.", "For", "this", "reason,", "in", "section", "3,", "when", "we", "verify", "parity", "invariance", "of", "the", "scattering", "amplitudes", "in", "a", "precise", "fashion,", "we", "consider", "only", "the", "contributions", "from", "curves", "of", "genus", "zero.", "However,", "an", "important", "part", "of", "the", "calculation", "can", "be", "carried", "out", "for", "arbitrary", "genus,", "as", "we", "will", "now", "see."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["IfChasgenuszero,thenCandLhanomoduli,alld?hncethemeasilrejustdescribydcanserVeasameasureonM.ForCofposit,ivegenuswCandLdohavemoduli.Itisnotatallclearwhatsortofmeasur('.shollldbeusedotointegrateoverhosemoduli,soatthemomenttheeisnotalearframdworkforhighergenuScomputationsintwistorspace.Forthisreason,insection3,wilenteverityparityinvarianceofthescatteringauplitndesinaprecisefashin,weconsiderpnlythecontribulionsfromcur~sofgenuszero.However,animporlantt)altofthecalculationcanbecarriedoutforarbitrarygenns,aswwewillnowsee."], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["If", "C", "has", "genus", "zero,", "then", "C", "and", "L", "ha", "no", "moduli,", "alld", "?hnce", "the", "measilre", "just", "describyd", "can", "serVe", "as", "a", "measure", "on", "M.", "For", "C", "of", "posit,ive", "genus", "w", "C", "and", "L", "do", "have", "moduli.", "It", "is", "not", "at", "all", "clear", "what", "sort", "of", "measur('.", "shollld", "be", "usedo", "to", "integrate", "over", "hose", "moduli,", "so", "at", "the", "moment", "thee", "is", "not", "a", "lear", "framdwork", "for", "higher", "genuS", "computations", "in", "twistor", "space.", "For", "this", "reason,", "in", "section", "3,", "wilen", "te", "verity", "parity", "invariance", "of", "the", "scattering", "auplitndes", "in", "a", "precise", "fashin,", "we", "consider", "pnly", "the", "contribulions", "from", "cur~s", "of", "genus", "zero.", "However,", "an", "imporlant", "t)alt", "of", "the", "calculation", "can", "be", "carried", "out", "for", "arbitrary", "genns,", "as", "wwe", "will", "now", "see."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["If", "C", "has", "genus", "zero,", "then", "C", "and", "L", "have", "no", "moduli,", "all", "?Hence", "the", "measure", "just", "described", "can", "serVe", "as", "a", "measure", "on", "M.", "For", "C", "of", "positive", "genus", "w", "C", "and", "L", "do", "have", "moduli.", "It", "is", "not", "at", "all", "clear", "what", "sort", "of", "measure('.", "should", "be", "used", "to", "integrate", "over", "those", "moduli,", "so", "at", "the", "moment", "there", "is", "not", "a", "clear", "framework", "for", "higher", "genuS", "computations", "in", "twistor", "space.", "For", "this", "reason,", "in", "section", "3,", "the", "variety", "parity", "invariance", "of", "the", "scattering", "amplitudes", "in", "a", "precise", "fashion,", "we", "consider", "only", "the", "contributions", "from", "cur~s", "of", "genus", "zero.", "However,", "an", "important", "t)alt", "of", "the", "calculation", "can", "be", "carried", "out", "for", "arbitrary", "genns,", "as", "wwe", "will", "now", "see."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["Set\\tingtheambipolardiff,,sionReynoldsnumberKA=1yieldsadiffusionlengthscal\\eof"], "labels": ["WRONG"]}, "correct": {"tokens": ["Setting", "the", "ambipolar", "diffusion", "Reynolds", "number", "RA", "=", "1", "yields", "a", "diffusion", "length", "scale", "of"], "labels": ["MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["Set\\tingtheambipolardiff,,sionReynoldsnumberKA=1yieldsadiffusionlengthscal\\eof"], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["Set\\ting", "the", "ambipolar", "diff,,sion", "Reynolds", "number", "KA", "=", "1", "yields", "a", "diffusion", "length", "scal\\e", "of"], "labels": ["WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["Set\\ting", "the", "ambipolar", "diff,,sion", "Reynolds", "number", "KA", "=", "1", "yields", "a", "diffusion", "length", "scal\\e", "of"], "labels": ["WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["T.heinfinitesimalversionofthisactionleadsutothefoIlbwingpresntationoffeedbackvectorocfields:"], "labels": ["WRONG"]}, "correct": {"tokens": ["The", "infinitesimal", "version", "of", "this", "action", "leads", "us", "to", "the", "following", "presentation", "of", "feedback", "vector", "fields:"], "labels": ["MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["T.heinfinitesimalversionofthisactionleadsutothefoIlbwingpresntationoffeedbackvectorocfields:"], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["T.he", "infinitesimal", "version", "of", "this", "action", "leads", "u", "to", "the", "foIlbwing", "presntation", "of", "feedback", "vector", "oc", "fields:"], "labels": ["WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["The", "infinitesimal", "version", "of", "this", "action", "leads", "u", "to", "the", "foLlowing", "presentation", "of", "feedback", "vector", "oc", "fields:"], "labels": ["MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["and"], "labels": ["NONE"]}, "correct": {"tokens": ["and"], "labels": ["NONE"]}, "predicted": {"google": {"tokens": ["and"], "labels": ["NONE"]}, "BS-bid-OCR": {"tokens": ["and"], "labels": ["NONE"]}, "BS-bid-OCR+google": {"tokens": ["and"], "labels": ["NONE"]}}}, {"corrupt": {"tokens": ["i=2N+3"], "labels": ["WRONG"]}, "correct": {"tokens": ["i", "=", "2N", "+", "3"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["i=2N+3"], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["i", "=", "2N", "+", "3"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["i", "=", "2N", "+", "3"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["Evenreconstruction"], "labels": ["WRONG"]}, "correct": {"tokens": ["Event", "reconstruction"], "labels": ["MIXED", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["Evenreconstruction"], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["Even", "reconstruction"], "labels": ["WRONG", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["Even", "reconstruction"], "labels": ["WRONG", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["SELF-PULSATINGLASERCHA'RACTRISATION"], "labels": ["WRONG"]}, "correct": {"tokens": ["SELF-PULSATING", "LASER", "CHARACTERISATION"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED"]}, "predicted": {"google": {"tokens": ["SELF-PULSATINGLASERCHA'RACTRISATION"], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["SELF-PULSATING", "LASER", "CHA'RACTRISATION"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG"]}, "BS-bid-OCR+google": {"tokens": ["SELF-PULSATING", "LASER", "CHARACTERIZATION"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG"]}}}, {"corrupt": {"tokens": ["Experinlentalobservationofsin&e-electrondamptng"], "labels": ["WRONG"]}, "correct": {"tokens": ["Experimental", "observation", "of", "single-electron", "damping"], "labels": ["MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED"]}, "predicted": {"google": {"tokens": ["Experinlentalobservationofsin&e-electrondamptng"], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["Experinlental", "observation", "of", "sin&e-electron", "damptng"], "labels": ["WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG"]}, "BS-bid-OCR+google": {"tokens": ["Experimental", "observation", "of", "single-electron", "damping"], "labels": ["MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED"]}}}, {"corrupt": {"tokens": ["whichisjstthe-mi-collinearpawtofourLLresultplusa,'unning-couplingNLLcontrihution"], "labels": ["WRONG"]}, "correct": {"tokens": ["which", "is", "just", "the", "anti-collinear", "part", "of", "our", "LL", "result", "plus", "a", "running-coupling", "NLL", "contribution"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED"]}, "predicted": {"google": {"tokens": ["whichisjstthe-mi-collinearpawtofourLLresultplusa,'running-coupling", "contribution"], "labels": ["WRONG", "MIXED"]}, "BS-bid-OCR": {"tokens": ["which", "is", "jst", "the", "-mi-collinear", "pawt", "of", "our", "LL", "result", "plus", "a", ",'unning-coupling", "NLL", "contrihution"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG"]}, "BS-bid-OCR+google": {"tokens": ["which", "is", "just", "the", "-mi-collinear", "pawt", "of", "our", "LL", "result", "plus", "a", ",'running-coupling", "NI", "contribution"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "MIXED"]}}}, {"corrupt": {"tokens": ["Acknow+ledgementso:wetha?kPijushBhatI.acharjee,VivekDatar,ShrihariGop~\\alakrishna,RomeshKaul,KKMondal,VSNarasimham,SandipPakvasaaddRahulSinhafordiscussionandvaluablecomments."], "labels": ["WRONG"]}, "correct": {"tokens": ["Acknowledgements:", "We", "thank", "Pijush", "Bhattacharjee,", "Vivek", "Datar,", "Shrihari", "Gopalakrishna,", "Romesh", "Kaul,", "N", "K", "Mondal,", "V", "S", "Narasimham,", "Sandip", "Pakvasa", "and", "Rahul", "Sinha", "for", "discussions", "and", "valuable", "comments."], "labels": ["MIXED", "MIXED", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["Acknow+ledgementso:wetha?kPijushBhatI.acharjee,VivekDatar,ShrihariGop~\\alakrishna,RomeshKaul,KKMondal,VSNarasimham,SandipPakvasaaddRahulSinhafordiscussionandvaluablecomments."], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["Acknow+ledgementso:", "we", "tha?k", "Pijush", "BhatI.acharjee,", "Vivek", "Datar,", "Shrihari", "Gop~\\alakrishna,", "Romesh", "Kaul,", "KK", "Mondal,", "VS", "Narasimham,", "Sandip", "Pakvasa", "add", "Rahul", "Sinha", "for", "discussion", "and", "valuable", "comments."], "labels": ["WRONG", "WRONG", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["Acknowledgements:", "we", "thank", "Pijush", "BhatI.acharjee,", "Vivek", "Datar,", "Shrihari", "Gop~\\alakrishna,", "Romesh", "Kaul,", "KK", "Mondal,", "VS", "Narasimham,", "Sandip", "Pakvasa", "add", "Rahul", "Sinha", "for", "discussion", "and", "valuable", "comments."], "labels": ["MIXED", "WRONG", "MIXED", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["20<E<60"], "labels": ["WRONG"]}, "correct": {"tokens": ["20", "<", "E", "<", "60"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["20<E<60"], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["20", "<", "E", "<", "60"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["20", "<", "E", "<", "60"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["Torecapitulate,westu<tiedanalyticalLyandnumericallythcdynamicfsoftheapparenl;reflectonPoin<tattheoverdensepla;masurface.Wehaveshownthattheve~ocitv?f?thispointisasmoothfuncti<)noftime.However,thecorresponding\u03b3-f?ctorhasqwasi-singularitiesorspikeswhenthsurfaceverocityapproachesthespeedoflight.Theseultra-re\\]ativisticspikesareresponsibleforthehighharmonicgenerationintheforlmofanattosecondpulsetraitl.Weshowthattheattosecondpulseem.issioncanbeefficienllycontrolledbymanagingtilelaserpolarization.Thisidonebyaddingalowintensitycontrolpulsewithperpendicularpolarlzationandfrequncyslightlydlfferentfromthatofthedrivingpulse.Thisrelativisticplasmacontrolallowstog\\ateasingleattosecondpulseoraprescribedgroupofatt_osecondpulses."], "labels": ["WRONG"]}, "correct": {"tokens": ["To", "recapitulate,", "we", "studied", "analytically", "and", "numerically", "the", "dynamics", "of", "the", "apparent", "reflection", "point", "at", "the", "overdense", "plasma", "surface.", "We", "have", "shown", "that", "the", "velocity", "of", "this", "point", "is", "a", "smooth", "function", "of", "time.", "However,", "the", "corresponding", "\u03b3-factor", "has", "quasi-singularities", "or", "spikes", "when", "the", "surface", "velocity", "approaches", "the", "speed", "of", "light.", "These", "ultra-relativistic", "spikes", "are", "responsible", "for", "the", "high", "harmonic", "generation", "in", "the", "form", "of", "an", "attosecond", "pulse", "train.", "We", "show", "that", "the", "attosecond", "pulse", "emission", "can", "be", "efficiently", "controlled", "by", "managing", "the", "laser", "polarization.", "This", "is", "done", "by", "adding", "a", "low", "intensity", "control", "pulse", "with", "perpendicular", "polarization", "and", "frequency", "slightly", "different", "from", "that", "of", "the", "driving", "pulse.", "This", "relativistic", "plasma", "control", "allows", "to", "gate", "a", "single", "attosecond", "pulse", "or", "a", "prescribed", "group", "of", "attosecond", "pulses."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["Torecapitulate,westu<tiedanalyticalLyandnumericallythcdynamicfsoftheapparenl;reflectonPoin<tattheoverdensepla;masurface.Wehaveshownthattheve~ocitv?f?thispointisasmoothfuncti<)noftime.However,thecorresponding\u03b3-f?ctorhasqwasi-singularitiesorspikeswhenthsurfaceverocityapproachesthespeedoflight.Theseultra-re\\]ativisticspikesareresponsibleforthehighharmonicgenerationintheforlmofanattosecondpulsetraitl.Weshowthattheattosecondpulseem.issioncanbeefficienllycontrolledbymanagingtilelaserpolarization.Thisidonebyaddingalowintensitycontrolpulsewithperpendicularpolarlzationandfrequncyslightlydlfferentfromthatofthedrivingpulse.Thisrelativisticplasmacontrolallowstog\\ateasingleattosecondpulseoraprescribedgroupofatt_osecondpulses."], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["To", "recapitulate,", "we", "stu<tied", "analyticalLy", "and", "numerically", "thc", "dynamicfs", "of", "the", "apparenl;", "reflecton", "Poin<t", "at", "the", "overdense", "pla;ma", "surface.", "We", "have", "shown", "that", "the", "ve~ocitv", "?f?", "this", "point", "is", "a", "smooth", "functi<)n", "of", "time.", "However,", "the", "corresponding", "\u03b3-f?ctor", "has", "qwasi-singularities", "or", "spikes", "when", "th", "surface", "verocity", "approaches", "the", "speed", "of", "light.", "These", "ultra-re\\]ativistic", "spikes", "are", "responsible", "for", "the", "high", "harmonic", "generation", "in", "the", "forlm", "of", "an", "attosecond", "pulse", "traitl.", "We", "show", "that", "the", "attosecond", "pulse", "em.ission", "can", "be", "efficienlly", "controlled", "by", "managing", "tile", "laser", "polarization.", "This", "i", "done", "by", "adding", "a", "low", "intensity", "control", "pulse", "with", "perpendicular", "polarlzation", "and", "frequncy", "slightly", "dlfferent", "from", "that", "of", "the", "driving", "pulse.", "This", "relativistic", "plasma", "control", "allows", "to", "g\\ate", "a", "single", "attosecond", "pulse", "or", "a", "prescribed", "group", "of", "att_osecond", "pulses."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["To", "recapitulate,", "we", "stu<tied", "analyticalLy", "and", "numerically", "the", "dynamics", "of", "the", "apparent;", "reflection", "Poin<t", "at", "the", "overdense", "plasma", "surface.", "We", "have", "shown", "that", "the", "ve~ocitv", "?f?", "this", "point", "is", "a", "smooth", "function<)n", "of", "time.", "However,", "the", "corresponding", "\u03b3-f?ctor", "has", "qwasi-singularities", "or", "spikes", "when", "the", "surface", "velocity", "approaches", "the", "speed", "of", "light.", "These", "ultra-re\\]atavistic", "spikes", "are", "responsible", "for", "the", "high", "harmonic", "generation", "in", "the", "form", "of", "an", "attosecond", "pulse", "traitl.", "We", "show", "that", "the", "attosecond", "pulse", "emission", "can", "be", "efficiently", "controlled", "by", "managing", "tile", "laser", "polarization.", "This", "is", "done", "by", "adding", "a", "low", "intensity", "control", "pulse", "with", "perpendicular", "polarization", "and", "frequency", "slightly", "different", "from", "that", "of", "the", "driving", "pulse.", "This", "relativistic", "plasma", "control", "allows", "to", "g\\ate", "a", "single", "attosecond", "pulse", "or", "a", "prescribed", "group", "of", "att_osecond", "pulses."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "MIXED", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["Misseddetecionandfalsealarmsaretradedofbyanarbitrarychoiceofthresholld,sinanydetectionalgorithm."], "labels": ["WRONG"]}, "correct": {"tokens": ["Missed", "detection", "and", "false", "alarms", "are", "traded", "off", "by", "an", "arbitrary", "choice", "of", "threshold,", "as", "in", "any", "detection", "algorithm."], "labels": ["TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["Misseddetecionandfalsealarmsaretradedofbyanarbitrarychoiceofthresholld,sinanydetectionalgorithm."], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["Missed", "detecion", "and", "false", "alarms", "are", "traded", "of", "by", "an", "arbitrary", "choice", "of", "thresholld,s", "in", "any", "detection", "algorithm."], "labels": ["TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["Missed", "detection", "and", "false", "alarms", "are", "traded", "off", "by", "an", "arbitrary", "choice", "of", "thresholds", "in", "any", "detection", "algorithm."], "labels": ["TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["Atreenodeo\\[anevolutionarynetworkN=~V,E)isanodeofin-degreeatmost1,andahybridnodeisanode0fin-degreestleast2.Atreearc(hybridizationarc)isapathsuchthat~hestartvcrtexisatreenodem(hybrilnode).Asintree,anodev\u2208Visachildofu\u2208Vif(u,v)\u2208E,wealsasayinthisca.seth?tnisa\\parentofv,notethab\\inthisc~aseanodecanilavemorethanoneparent."], "labels": ["WRONG"]}, "correct": {"tokens": ["A", "tree", "node", "of", "an", "evolutionary", "network", "N", "=", "(V,", "E)", "is", "a", "node", "of", "in-degree", "at", "most", "1,", "and", "a", "hybrid", "node", "is", "a", "node", "of", "in-degree", "at", "least", "2.", "A", "tree", "arc", "(hybridization", "arc", ")", "is", "a", "path", "such", "that", "the", "start", "vertex", "is", "a", "tree", "node", "(hybrid", "node).", "As", "in", "tree,", "a", "node", "v", "\u2208", "V", "is", "a", "child", "of", "u", "\u2208", "V", "if", "(u,", "v)", "\u2208", "E,", "we", "also", "say", "in", "this", "case", "that", "u", "is", "a", "parent", "of", "v,", "note", "that", "in", "this", "case", "a", "node", "can", "have", "more", "than", "one", "parent."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["Atreenodeo\\[an", "evolutionary", "network=~V,E)isanodeofin-degreeatmost1,andahybridnodeisanode0fin-degreestleast2.Atreearc(hybridization", "arc)isapathsuchthat~hestartvcrtexisatreenodem(hybrilnode).Asintree,anodev\u2208Visachildofu\u2208Vif(u,v)\u2208E,wealsasayinthisca.seth?tnisa\\parentofv,notethab\\inthisc~aseanodecanilavemorethanoneparent."], "labels": ["WRONG", "TOKENIZATION_ERROR", "WRONG", "WRONG"]}, "BS-bid-OCR": {"tokens": ["A", "tree", "node", "o\\[", "an", "evolutionary", "network", "N", "=", "~V,", "E)", "is", "a", "node", "of", "in-degree", "at", "most", "1,", "and", "a", "hybrid", "node", "is", "a", "node", "0f", "in-degree", "st", "least", "2.", "A", "tree", "arc", "(hybridization", "arc)", "is", "a", "path", "such", "that", "~he", "start", "vcrtex", "is", "a", "tree", "nodem", "(hybril", "node).", "As", "in", "tree,", "a", "node", "v", "\u2208", "V", "is", "a", "child", "of", "u", "\u2208", "V", "if", "(u,", "v)", "\u2208", "E,", "we", "alsa", "say", "in", "this", "ca.se", "th?t", "n", "is", "a\\", "parent", "of", "v,", "note", "thab\\", "in", "this", "c~ase", "a", "node", "can", "ilave", "more", "than", "one", "parent."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["A", "tree", "node", "o\\[", "an", "evolutionary", "network", "N", "=", "~V,", "E)", "is", "a", "node", "of", "in-degree", "at", "most", "1,", "and", "a", "hybrid", "node", "is", "a", "node", "0f", "in-degree", "at", "least", "2.", "A", "tree", "arc", "(hybridization", "arc)", "is", "a", "path", "such", "that", "~he", "start", "vertex", "is", "a", "tree", "node", "(hybril", "node).", "As", "in", "tree,", "a", "node", "v", "\u2208", "V", "is", "a", "child", "of", "u", "\u2208", "V", "if", "(u,", "v)", "\u2208", "E,", "we", "alsa", "say", "in", "this", "ca.se", "th?t", "n", "is", "a\\", "parent", "of", "v,", "note", "tab\\", "in", "this", "c~ase", "a", "node", "can", "have", "more", "than", "one", "parent."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "WRONG", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["Inderivin~thea\\bove,wehaveusedkinematicrelations"], "labels": ["WRONG"]}, "correct": {"tokens": ["In", "deriving", "the", "above,", "we", "have", "used", "kinematic", "relations"], "labels": ["TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["Deriving~thea\\bove,we", "have", "used", "kinematic", "relations"], "labels": ["WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR": {"tokens": ["In", "derivin~", "the", "a\\bove,", "we", "have", "used", "kinematic", "relations"], "labels": ["TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["In", "deriving~", "the", "a\\bove,", "we", "have", "used", "kinematic", "relations"], "labels": ["TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["ThePDPsachievedbydifferentARQareshowninFig.1?.Ingeneral,ahigherEArateisneedeinordertomeetahigherthoughputrequirement4.Also,withalargerK,i.e.,th6maximumnumberoftransmissionattempts,thesystemhansthepotentialtoa\u0002hieveasm~llerPDP,?butthethroughputrequirementbecomuesmoredifficultosatisfy.Besides,whenthethroughputconstraintismet,ARQwitboutfeedbackandARQwithadaptivefeedbackachievethesame?performanceundertt)eoptimalpolicies.ThisisbecauseHeachpacketusesallthetransmjssionattelpts\\toavoidpacketdrop,andtheproposedARQp?otocolreducestoth(~ARQwithoutfeedback.F~omthissetofresults,wecandrawnewdesigni\"nsightsforeommunicationsysgcmswithEHreceivera:"], "labels": ["WRONG"]}, "correct": {"tokens": ["The", "PDPs", "achieved", "by", "different", "ARQs", "are", "shown", "in", "Fig.", "1.", "In", "general,", "a", "higher", "EH", "rate", "is", "needed", "in", "order", "to", "meet", "a", "higher", "throughput", "requirement.", "Also,", "with", "a", "larger", "K,", "i.e.,", "the", "maximum", "number", "of", "transmission", "attempts,", "the", "system", "has", "the", "potential", "to", "achieve", "a", "smaller", "PDP,", "but", "the", "throughput", "requirement", "becomes", "more", "difficult", "to", "satisfy.", "Besides,", "when", "the", "throughput", "constraint", "is", "met,", "ARQ", "without", "feedback", "and", "ARQ", "with", "adaptive", "feedback", "achieve", "the", "same", "performance", "under", "the", "optimal", "policies.", "This", "is", "because", "each", "packet", "uses", "all", "the", "transmission", "attempts", "to", "avoid", "packet", "drop,", "and", "the", "proposed", "ARQ", "protocol", "reduces", "to", "the", "ARQ", "without", "feedback.", "From", "this", "set", "of", "results,", "we", "can", "draw", "new", "design", "insights", "for", "communication", "systems", "with", "EH", "receivers:"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED"]}, "predicted": {"google": {"tokens": ["ThePDPsachievedbydifferentARQareshowninFig.1?.Ingeneral,ahigherEArateisneedeinordertomeetahigherthoughputrequirement4.Also,withalargerK,i.e.,th6maximumnumberoftransmissionattempts,thesystemhansthepotentialtoahieveasm~llerPDP,?butthethroughputrequirementbecomuesmoredifficultosatisfy.Besides,whenthethroughputconstraintismet,ARQwitboutfeedbackandARQwithadaptivefeedbackachievethesame?performanceundertt)eoptimalpolicies.ThisisbecauseHeachpacketusesallthetransmjssionattelpts\\toavoidpacketdrop,andtheproposedARQp?otocolreducestoth(~ARQwithoutfeedback.F~omthissetofresults,wecandrawnewdesigni\"nsightsforeommunicationsysgcmswithEHreceivera:"], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["The", "PDPs", "achieved", "by", "different", "ARQ", "are", "shown", "in", "Fig.", "1?.", "In", "general,", "a", "higher", "EA", "rate", "is", "neede", "in", "order", "to", "meet", "a", "higher", "thoughput", "requirement", "4.", "Also,", "with", "a", "larger", "K,", "i.e.,", "th6", "maximum", "number", "of", "transmission", "attempts,", "the", "system", "hans", "the", "potential", "to", "a\u0002hieve", "a", "sm~ller", "PDP,", "?but", "the", "throughput", "requirement", "becomues", "more", "difficult", "o", "satisfy.", "Besides,", "when", "the", "throughput", "constraint", "is", "met,", "ARQ", "witbout", "feedback", "and", "ARQ", "with", "adaptive", "feedback", "achieve", "the", "same?", "performance", "under", "tt)e", "optimal", "policies.", "This", "is", "because", "Heach", "packet", "uses", "all", "the", "transmjssion", "attelpts", "\\to", "avoid", "packet", "drop,", "and", "the", "proposed", "ARQ", "p?otocol", "reduces", "to", "th(~", "ARQ", "without", "feedback.", "F~om", "this", "set", "of", "results,", "we", "can", "draw", "new", "design", "i\"nsights", "for", "eommunication", "sysgcms", "with", "EH", "receiver", "a:"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "MIXED", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG"]}, "BS-bid-OCR+google": {"tokens": ["The", "PDPs", "achieved", "by", "different", "ARQ", "are", "shown", "in", "Fig.", "1?.", "In", "general,", "a", "higher", "EA", "rate", "is", "needed", "in", "order", "to", "meet", "a", "higher", "throughput", "requirement", "4.", "Also,", "with", "a", "larger", "K,", "i.e.,", "th6", "maximum", "number", "of", "transmission", "attempts,", "the", "system", "has", "the", "potential", "to", "achieve", "a", "sm~ller", "PDF,", "but", "the", "throughput", "requirement", "becomes", "more", "difficult", "to", "satisfy.", "Besides,", "when", "the", "throughput", "constraint", "is", "met,", "ARQ", "without", "feedback", "and", "ARQ", "with", "adaptive", "feedback", "achieve", "the", "same?", "performance", "under", "tt)e", "optimal", "policies.", "This", "is", "because", "Heach", "packet", "uses", "all", "the", "transmission", "attempts", "\\to", "avoid", "packet", "drop,", "and", "the", "proposed", "ARQ", "protocol", "reduces", "to", "th(~", "ARQ", "without", "feedback.", "F~om", "this", "set", "of", "results,", "we", "can", "draw", "new", "design", "i\"insights", "for", "communication", "systems", "with", "EH", "receiver", "a:"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG"]}}}, {"corrupt": {"tokens": ["So,thelinearinfinitelylongcurrent,linearygrowingwithtime,l)roduces>>aroundastationaryelectr%calfieldparalleltoitself,growiagogat'ithmicaltywithadistancefrOmthecurrent."], "labels": ["WRONG"]}, "correct": {"tokens": ["So,", "the", "linear", "infinitely", "long", "current,", "lineary", "growing", "with", "time,", "produces", "around", "a", "stationary", "electrical", "field", "parallel", "to", "itself,", "growing", "logarithmically", "with", "a", "distance", "from", "the", "current."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["So,thelinearinfinitelylongcurrent,linearygrowingwithtime,l)roduces>>aroundastationaryelectr%calfieldparalleltoitself,growiagogat'ithmicaltywithadistancefrOmthecurrent."], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["So,", "the", "linear", "infinitely", "long", "current,", "lineary", "growing", "with", "time,", "l)roduces", ">>around", "a", "stationary", "electr%cal", "field", "parallel", "to", "itself,", "growiag", "ogat'ithmicalty", "with", "a", "distance", "frOm", "the", "current."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["So,", "the", "linear", "infinitely", "long", "current,", "lineary", "growing", "with", "time,", "l)produces", ">>around", "a", "stationary", "electr%cal", "field", "parallel", "to", "itself,", "growiag", "ogat'ithmicalty", "with", "a", "distance", "frOm", "the", "current."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["Thecurrentlyavaitable(2dFGRS,\\SDSS)andnextgen,eration(e.g.BOSSlarge;galaxrredshiftsurpeysincombinatlonwiththeanafyticalformaismpresentedinthispaper,willa?lloatwustoestimatethevaluesoftherelBevantcosmoloqicalparametersus?ingvoidstatistics,providingindependentmeasurement.These,alongwiththeestimationsmadebyothermethodswillcontributetoreducetheiruncertai?nties.Itisalsoworthtomentionthatinafo~thcomingpaperwewillexplorethedependenceoftestatisticsofvoidswith\u03c38and\u0393,usiugthevoidstatisticsfoundinthe2dFGRS(Patirietal.,inprep.).AIlthismakesthestatistsiesofunderenseregionsaverypromisingtoolt-oconstraincosmologynotjustwiththecurrentsurveysbtalsbtoncxtgenerationhighredsh1f;tsurveyrs."], "labels": ["WRONG"]}, "correct": {"tokens": ["The", "currently", "available", "(2dFGRS,", "SDSS)", "and", "next", "generation", "(e.g.", "BOSS)", "large", "galaxy", "redshift", "surveys", "in", "combination", "with", "the", "analytical", "formalism", "presented", "in", "this", "paper,", "will", "allow", "us", "to", "estimate", "the", "values", "of", "the", "relevant", "cosmological", "parameters", "using", "void", "statistics,", "providing", "independent", "measurements.", "These,", "along", "with", "the", "estimations", "made", "by", "other", "methods", "will", "contribute", "to", "reduce", "their", "uncertainties.", "It", "is", "also", "worth", "to", "mention", "that", "in", "a", "forthcoming", "paper", "we", "will", "explore", "the", "dependence", "of", "the", "statistics", "of", "voids", "with", "\u03c38", "and", "\u0393,", "using", "the", "void", "statistics", "found", "in", "the", "2dFGRS", "(Patiri", "et", "al.,", "in", "prep.).", "All", "this", "makes", "the", "statistics", "of", "underdense", "regions", "a", "very", "promising", "tool", "to", "constrain", "cosmology", "not", "just", "with", "the", "current", "surveys", "but", "also", "to", "next", "generation", "high", "redshift", "surveys."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED"]}, "predicted": {"google": {"tokens": ["The", "Currently", "Available(2dFGRS,\\SDSS)and", "next", "generation(e.g.BOSSlarge;galaxrredshiftsurpeysincombinatlonwiththeanafyticalformaismpresentedinthispaper,willa?lloatwustoestimatethevaluesoftherelBevantcosmoloqicalparametersus?ingvoidstatistics,providingindependentmeasurement.These,alongwiththeestimationsmadebyothermethodswillcontributetoreducetheiruncertai?nties.Itisalsoworthtomentionthatinafo~thcomingpaperwewillexplorethedependenceoftestatisticsofvoidswith\u03c38and\u0393,usiugthevoidstatisticsfoundinthe2dFGRS(Parietal.,inprep.).AIlthismakesthestatistsiesofunderenseregionsaverypromisingtoolt-oconstraincosmologynotjustwiththecurrentsurveysbtalsbtoncxtgenerationhighredsh1f;tsurveyrs."], "labels": ["TOKENIZATION_ERROR", "WRONG", "WRONG", "MIXED", "WRONG"]}, "BS-bid-OCR": {"tokens": ["The", "currently", "avaitable", "(2dFGRS,", "\\SDSS)", "and", "next", "gen,eration", "(e.g.", "BOSS", "large;", "galaxr", "redshift", "surpeys", "in", "combinatlon", "with", "the", "anafytical", "formaism", "presented", "in", "this", "paper,", "will", "a?lloatw", "us", "to", "estimate", "the", "values", "of", "the", "relBevant", "cosmoloqical", "parameters", "us?ing", "void", "statistics,", "providing", "independent", "measurement.", "These,", "along", "with", "the", "estimations", "made", "by", "other", "methods", "will", "contribute", "to", "reduce", "their", "uncertai?nties.", "It", "is", "also", "worth", "to", "mention", "that", "in", "a", "fo~thcoming", "paper", "we", "will", "explore", "the", "dependence", "of", "te", "statistics", "of", "voids", "with", "\u03c38", "and", "\u0393,", "usiug", "the", "void", "statistics", "found", "in", "the", "2dFGRS", "(Patiri", "et", "al.,", "in", "prep.).", "AIl", "this", "makes", "the", "statistsies", "of", "underense", "regions", "a", "very", "promising", "tool", "t-o", "constrain", "cosmology", "not", "just", "with", "the", "current", "surveys", "bt", "alsb", "to", "ncxt", "generation", "high", "redsh1f;t", "surveyrs."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "WRONG", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG"]}, "BS-bid-OCR+google": {"tokens": ["The", "currently", "available", "(2dFGRS,", "\\SDSS)", "and", "next", "generation", "(e.g.", "BOSS", "large;", "galaxy", "redshift", "surveys", "in", "combination", "with", "the", "analytical", "formalism", "presented", "in", "this", "paper,", "will", "allow", "us", "to", "estimate", "the", "values", "of", "the", "relevant", "cosmological", "parameters", "using", "void", "statistics,", "providing", "independent", "measurement.", "These,", "along", "with", "the", "estimations", "made", "by", "other", "methods", "will", "contribute", "to", "reducing", "their", "uncertainties.", "It", "is", "also", "worth", "mentioning", "that", "in", "a", "fo~thcoming", "paper", "we", "will", "explore", "the", "dependence", "of", "the", "statistics", "of", "voids", "with", "\u03c38", "and", "\u0393,", "using", "the", "void", "statistics", "found", "in", "the", "2dFGRS", "(Patiri", "et", "al.,", "in", "prep.).", "AIl", "this", "makes", "the", "statistics", "of", "underense", "regions", "a", "very", "promising", "tool", "t-o", "constrain", "cosmology", "not", "just", "with", "the", "current", "surveys", "bt", "alsb", "to", "next", "generation", "high", "redsh1f;t", "surveys."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "WRONG", "WRONG", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "MIXED"]}}}, {"corrupt": {"tokens": ["I)etectionofYarkovskyaccelerationinthecontextofprecoveryobservationsandthlefutureGaiacatalogue"], "labels": ["WRONG"]}, "correct": {"tokens": ["Detection", "of", "Yarkovsky", "acceleration", "in", "the", "context", "of", "precovery", "observations", "and", "the", "future", "Gaia", "catalogue"], "labels": ["MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["I)etectionofYarkovskyaccelerationinthecontextofprecoveryobservationsandthlefutureGaiacatalogue"], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["I)etection", "of", "Yarkovsky", "acceleration", "in", "the", "context", "of", "precovery", "observations", "and", "thle", "future", "Gaia", "catalogue"], "labels": ["WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["I)detection", "of", "Yarkovsky", "acceleration", "in", "the", "context", "of", "recovery", "observations", "and", "the", "future", "Gaia", "catalogue"], "labels": ["WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["~ereB=0.126,andrijisthedislancebetweenparticlesiandj.Thediameter\u03c3isemployeasthelengthurittodisplaythesimulationresultsthroughoutthispaper.AC\u221e-cutofffunction"], "labels": ["WRONG"]}, "correct": {"tokens": ["where", "B", "=", "0.126,", "and", "rij", "is", "the", "distance", "between", "particles", "i", "and", "j.", "The", "diameter", "\u03c3", "is", "employed", "as", "the", "length", "unit", "to", "display", "the", "simulation", "results", "throughout", "this", "paper.", "A", "C\u221e-cutoff", "function"], "labels": ["MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["~ereB=0.126,andrijisthedislancebetweenparticlesiandj.Thediameter\u03c3isemployeasthelengthurittodisplaythesimulationresultsthroughoutthispaper.AC\u221e-cutofffunction"], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["~ere", "B", "=", "0.126,", "and", "rij", "is", "the", "dislance", "between", "particles", "i", "and", "j.", "The", "diameter", "\u03c3", "is", "employe", "as", "the", "length", "urit", "to", "display", "the", "simulation", "results", "throughout", "this", "paper.", "A", "C\u221e-cutoff", "function"], "labels": ["WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["~enB", "=", "0.126,", "and", "rij", "is", "the", "distance", "between", "particles", "i", "and", "j.", "The", "diameter", "\u03c3", "is", "employed", "as", "the", "length", "urit", "to", "display", "the", "simulation", "results", "throughout", "this", "paper.", "A", "C\u221e-cutoff", "function"], "labels": ["WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["weobtain"], "labels": ["WRONG"]}, "correct": {"tokens": ["we", "obtain"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["we", "obtain"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR": {"tokens": ["we", "obtain"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["we", "obtain"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["HexeSdissisanempiricdissit)ativcterm,correspndingtowhite-cappAng."], "labels": ["WRONG"]}, "correct": {"tokens": ["Here", "Sdiss", "is", "an", "empiric", "dissipative", "term,", "corresponding", "to", "white-capping."], "labels": ["MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED"]}, "predicted": {"google": {"tokens": ["HexeSdissisanempiricdissit)ativ", "term,correspndingtowhite-cappAng."], "labels": ["WRONG", "WRONG"]}, "BS-bid-OCR": {"tokens": ["Hexe", "Sdiss", "is", "an", "empiric", "dissit)ativc", "term,", "correspnding", "to", "white-cappAng."], "labels": ["WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG"]}, "BS-bid-OCR+google": {"tokens": ["Hexe", "Sdiss", "is", "an", "empiric", "dissit)ivc", "term,", "corresponding", "to", "white-cappAng."], "labels": ["WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "WRONG"]}}}, {"corrupt": {"tokens": ["Iotheseconditionsiontrappingoleddyingappear.Aswehaveshowntilisstronglyinfluencesthestatistics:oftrajectories.Thedist~ibutinofthetrajectoriesisnotmoreGaussianduetotrappeJdtrajectoriesthaI;formqua?si-coherentstructutes.Atthisstage~hetruppingisweakinthesenseth~tt5hefractionoftrappedtrajectoriesntrismuchsmallerthantheRfractionnfoffre('trajector\\ies."], "labels": ["WRONG"]}, "correct": {"tokens": ["In", "these", "conditions", "ion", "trapping", "or", "eddying", "appears.", "As", "we", "have", "shown", "this", "strongly", "influences", "the", "statistics", "of", "trajectories.", "The", "distribution", "of", "the", "trajectories", "is", "not", "more", "Gaussian", "due", "to", "trapped", "trajectories", "that", "form", "quasi-coherent", "structures.", "At", "this", "stage", "the", "trapping", "is", "weak", "in", "the", "sense", "that", "the", "fraction", "of", "trapped", "trajectories", "ntr", "is", "much", "smaller", "than", "the", "fraction", "nf", "of", "free", "trajectories."], "labels": ["MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED"]}, "predicted": {"google": {"tokens": ["Iotheseconditionsiontrappingoleddyingappear.Aswehaveshowntilisstronglyinfluencesthestatistics:oftrajectories.Thedist~ibutinofthetrajectoriesisnotmoreGaussianduetotrappeJdtrajectoriesthaI;formqua?si-coherentstructutes.Atthisstage~hetruppingisweakinthesenseth~tt5hefractionoftrappedtrajectoriesntrismuchsmallerthantheRfractionnfoffre('trajector\\ies."], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["Io", "these", "conditions", "iontrapping", "oleddying", "appear.", "As", "we", "have", "shown", "tilis", "strongly", "influences", "the", "statistics", ":of", "trajectories.", "The", "dist~ibutin", "of", "the", "trajectories", "is", "not", "more", "Gaussian", "due", "to", "trappeJd", "trajectories", "thaI;", "form", "qua?si-coherent", "structutes.", "At", "this", "stage", "~he", "trupping", "is", "weak", "in", "the", "sense", "th~t", "t5he", "fraction", "of", "trapped", "trajectories", "ntr", "is", "much", "smaller", "than", "the", "R", "fraction", "nfof", "fre('", "trajector\\ies."], "labels": ["WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "WRONG", "WRONG"]}, "BS-bid-OCR+google": {"tokens": ["Io", "these", "conditions", "ion", "trapping", "oled", "dying", "appear.", "As", "we", "have", "shown", "tilis", "strongly", "influences", "the", "statistics", ":of", "trajectories.", "The", "dist~ibutin", "of", "the", "trajectories", "is", "not", "more", "Gaussian", "due", "to", "trapped", "trajectories", "thaI;", "form", "quasi-coherent", "structures.", "At", "this", "stage", "~he", "tripping", "is", "weak", "in", "the", "sense", "th~t", "t5he", "fraction", "of", "trapped", "trajectories", "ntr", "is", "much", "smaller", "than", "the", "R", "fraction", "for", "free('", "trajector\\ies."], "labels": ["WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "WRONG", "WRONG"]}}}, {"corrupt": {"tokens": [","], "labels": ["NONE"]}, "correct": {"tokens": [","], "labels": ["NONE"]}, "predicted": {"google": {"tokens": [","], "labels": ["NONE"]}, "BS-bid-OCR": {"tokens": [","], "labels": ["NONE"]}, "BS-bid-OCR+google": {"tokens": [","], "labels": ["NONE"]}}}, {"corrupt": {"tokens": ["ThepuPposeofthissectienistopl'Ovethetollowingresult:"], "labels": ["WRONG"]}, "correct": {"tokens": ["The", "purpose", "of", "this", "section", "is", "to", "prove", "the", "following", "result", ":"], "labels": ["TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["ThepuPposeofthissectienistopl'Ovethetollowingresult:"], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["The", "puPpose", "of", "this", "sectien", "is", "to", "pl'Ove", "the", "tollowing", "result:"], "labels": ["TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "WRONG"]}, "BS-bid-OCR+google": {"tokens": ["The", "puRpose", "of", "this", "section", "is", "to", "lOve", "the", "following", "result:"], "labels": ["TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "MIXED", "WRONG"]}}}, {"corrupt": {"tokens": ["Weconsiderathcstal)ilityoffilamentarymolecularclaudsagainstaxisymmletricfragmentationintocores.Bysolvingthoelinearize(tuationsofMH.~Dadself-gravity,wedeternlehowpressuretruncationandtheindividualmtoEneticfieldcomponentsaffectthestabilityofiurmadels.Wefindthatpressuretruncationhasastabilizingeffect,whichresultsfr(imthedecreasedmassperunil,lengtholtfiefiL~Lment.Bothfieldcomponentsalsostabilizecleudsagainstgravit~tienalfragmentation.However,wefindthatsuf~icientIystrongtoroidalfieldsm;tytrggerMHD-driveninstabi.llties.WereferthereadertoFiege&Pudritz(1999b),wherewefullyexplorethestabilityofourmodels."], "labels": ["WRONG"]}, "correct": {"tokens": ["We", "consider", "the", "stability", "of", "filamentary", "molecular", "clouds", "against", "axisymmetric", "fragmentation", "into", "cores.", "By", "solving", "the", "linearized", "equations", "of", "MHD", "and", "self-gravity,", "we", "determine", "how", "pressure", "truncation", "and", "the", "individual", "magnetic", "field", "components", "affect", "the", "stability", "of", "our", "models.", "We", "find", "that", "pressure", "truncation", "has", "a", "stabilizing", "effect,", "which", "results", "from", "the", "decreased", "mass", "per", "unit", "length", "of", "the", "filament.", "Both", "field", "components", "also", "stabilize", "clouds", "against", "gravitational", "fragmentation.", "However,", "we", "find", "that", "sufficiently", "strong", "toroidal", "fields", "may", "trigger", "MHD-driven", "instabilities.", "We", "refer", "the", "reader", "to", "Fiege", "&", "Pudritz", "(1999b),", "where", "we", "fully", "explore", "the", "stability", "of", "our", "models."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "MIXED", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["Weconsiderathcstal)ilityoffilamentarymolecularclaudsagainstaxisymmletricfragmentationintocores.Bysolvingthoelinearize(tuationsofMH.~Dadself-gravity,wedeternlehowpressuretruncationandtheindividualmtoEneticfieldcomponentsaffectthestabilityofiurmadels.Wefindthatpressuretruncationhasastabilizingeffect,whichresultsfr(imthedecreasedmassperunil,lengtholtfiefiL~Lment.Bothfieldcomponentsalsostabilizecleudsagainstgravit~tienalfragmentation.However,wefindthatsuf~icientIystrongtoroidalfieldsm;tytrggerMHD-driveninstabi.llties.WereferthereadertoFiege&Pudritz(1999b),where", "we", "fully", "explore", "the", "stability", "of", "our", "models."], "labels": ["WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR": {"tokens": ["We", "considera", "thc", "stal)ility", "of", "filamentary", "molecular", "clauds", "against", "axisymmletric", "fragmentation", "into", "cores.", "By", "solving", "thoe", "linearize", "(tuations", "of", "MH.~D", "ad", "self-gravity,", "we", "deternle", "how", "pressure", "truncation", "and", "the", "individual", "mtoEnetic", "field", "components", "affect", "the", "stability", "of", "iur", "madels.", "We", "find", "that", "pressure", "truncation", "has", "a", "stabilizing", "effect,", "which", "results", "fr(im", "the", "decreased", "mass", "per", "unil,", "length", "ol", "tfie", "fiL~Lment.", "Both", "field", "components", "also", "stabilize", "cleuds", "against", "gravit~tienal", "fragmentation.", "However,", "we", "find", "that", "suf~icientIy", "strong", "toroidal", "fields", "m;ty", "trgger", "MHD-driven", "instabi.llties.", "We", "refer", "the", "reader", "to", "Fiege", "&", "Pudritz", "(1999b),", "where", "we", "fully", "explore", "the", "stability", "of", "our", "models."], "labels": ["TOKENIZATION_ERROR", "WRONG", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "WRONG", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["We", "considera", "thc", "stal)ility", "of", "filamentary", "molecular", "clauds", "against", "axisymmletric", "fragmentation", "into", "cores.", "By", "solving", "the", "linearized", "(situations", "of", "MH.~D", "ad", "self-gravity,", "we", "determine", "how", "pressure", "truncation", "and", "the", "individual", "magnetic", "field", "components", "affect", "the", "stability", "of", "our", "models.", "We", "find", "that", "pressure", "truncation", "has", "a", "stabilizing", "effect,", "which", "results", "from(i'm", "the", "decreased", "mass", "per", "unit,", "length", "ol", "time", "fiL~Lment.", "Both", "field", "components", "also", "stabilize", "clouds", "against", "gravity~tienal", "fragmentation.", "However,", "we", "find", "that", "suf~icientIy", "strong", "toroidal", "fields", "m;ty", "trigger", "MHD-driven", "instabilities.", "We", "refer", "the", "reader", "to", "Fiege", "&", "Pudritz", "(1999b),", "where", "we", "fully", "explore", "the", "stability", "of", "our", "models."], "labels": ["TOKENIZATION_ERROR", "WRONG", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "WRONG", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["WenoticcthatforboundstaI;e(real)solutions,thelastequalionrequil'esthat"], "labels": ["WRONG"]}, "correct": {"tokens": ["We", "notice", "that", "for", "bound", "state", "(real)", "solutions,", "the", "last", "equation", "requires", "that"], "labels": ["TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["WenoticcthatforboundstaI;e(real)solutions,thelastequalionrequil'esthat"], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["We", "noticc", "that", "for", "bound", "staI;e", "(real)", "solutions,", "the", "last", "equalion", "requil'es", "that"], "labels": ["TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["We", "noticed", "that", "for", "bound", "staI;e", "(real)", "solutions,", "the", "last", "equation", "requires", "that"], "labels": ["TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["andthevelocitlas"], "labels": ["WRONG"]}, "correct": {"tokens": ["and", "the", "velocity", "as"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["andthevelocitlas"], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["and", "the", "velocitl", "as"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["and", "the", "velocity", "as"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["Whatis\\obviousfromtheaboveequationisthaaligtftraYonthebraeisdeviatedbyas\\malleramountfflncoinparisonwithitscorrespondingGRdefleetion.Consequently,itturnsoutthatme~suringthedeflectionanglecanserw'asacrucialtcstwh\"ilecomparinebraneworldgravityeffectswiththoseofGj."], "labels": ["WRONG"]}, "correct": {"tokens": ["What", "is", "obvious", "from", "the", "above", "equation", "is", "that", "a", "light", "ray", "on", "the", "brane", "is", "deviated", "by", "a", "smaller", "amount", "in", "comparison", "with", "its", "corresponding", "GR", "deflection.", "Consequently,", "it", "turns", "out", "that", "measuring", "the", "deflection", "angle", "can", "serve", "as", "a", "crucial", "test", "while", "comparing", "braneworld", "gravity", "effects", "with", "those", "of", "GR."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED"]}, "predicted": {"google": {"tokens": ["Whatis\\obviousfromtheaboveequationisthaaligtftraYonthebraeisdeviatedbyas\\malleramountfflncoinparisonwithitscorrespondingGRdefleetion.Consequently,itturnsoutthatme~suringthedeflectionanglecanserw'asacrucialtcstwh\"ilecomparinebraneworldgravityeffectswiththoseofGj."], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["What", "is\\", "obvious", "from", "the", "above", "equation", "is", "tha", "a", "ligtft", "raY", "on", "the", "brae", "is", "deviated", "by", "a", "s\\maller", "amount", "ff", "ln", "coinparison", "with", "its", "corresponding", "GR", "defleetion.", "Consequently,", "it", "turns", "out", "that", "me~suring", "the", "deflection", "angle", "can", "serw'", "as", "a", "crucial", "tcst", "wh\"ile", "comparine", "braneworld", "gravity", "effects", "with", "those", "of", "Gj."], "labels": ["TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG"]}, "BS-bid-OCR+google": {"tokens": ["What", "is\\", "obvious", "from", "the", "above", "equation", "is", "that", "a", "light", "raY", "on", "the", "brae", "is", "deviated", "by", "a", "s\\maller", "amount", "of", "ln", "comparison", "with", "its", "corresponding", "GR", "defleetion.", "Consequently,", "it", "turns", "out", "that", "me~suring", "the", "deflection", "angle", "can", "serve", "as", "a", "crucial", "tcst", "wh\"ile", "comparine", "braneworld", "gravity", "effects", "with", "those", "of", "Gj."], "labels": ["TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "WRONG", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG"]}}}, {"corrupt": {"tokens": ["sothat"], "labels": ["WRONG"]}, "correct": {"tokens": ["so", "that"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["so", "that"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR": {"tokens": ["so", "that"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["so", "that"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["isconcaveonthosetoffutl-rankn\u00d7nmatrices."], "labels": ["WRONG"]}, "correct": {"tokens": ["is", "concave", "on", "the", "set", "of", "full-rank", "n", "\u00d7", "n", "matrices."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["isconcaveonthosetoffutl-rankn\u00d7nmatrices."], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["is", "concave", "on", "tho", "set", "of", "futl-rank", "n", "\u00d7", "n", "matrices."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["is", "concave", "on", "the", "set", "of", "full-rank", "n", "\u00d7", "n", "matrices."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["TheWZcouplingsoftheNS5branecanbefoundasbeforebuconstructingthefullygauge.Jnvri~ntc\\ompletionofthecoupling"], "labels": ["WRONG"]}, "correct": {"tokens": ["The", "WZ", "couplings", "of", "the", "NS5-brane", "can", "be", "found", "as", "before", "by", "constructing", "the", "fully", "gauge", "invariant", "completion", "of", "the", "coupling"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["TheWZcouplingsoftheNS5branecanbefoundasbeforebuconstructingthefullygauge.Jnvri~ntc\\ompletionofthecoupling"], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["The", "WZ", "couplings", "of", "the", "NS5", "brane", "can", "be", "found", "as", "before", "bu", "constructing", "the", "fully", "gauge.", "Jnvri~nt", "c\\ompletion", "of", "the", "coupling"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["The", "WZ", "couplings", "of", "the", "NS5", "brane", "can", "be", "found", "as", "before", "by", "constructing", "the", "fully", "gauge.", "Jnvri~nt", "c\\ompletion", "of", "the", "coupling"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["Couversely,bycuttingthetwoupwardbranchesf.romthe,owestinternalvertex,eaehn-tree\u03c8canbeuniquelyre,presentedasthe^raftigofLwotrees,say;\u03c81\u2208Tpand\u03c82\u2208Tq,wherep+qn.Byitetatjngthegr~ftingoperat5on,onecansilowbyasimple;inductionargume,tthateveryn-t?ree?n\u22652)c?nbeobtinedasaniteratedgraftingofncopiesofthe1-tree."], "labels": ["WRONG"]}, "correct": {"tokens": ["Conversely,", "by", "cutting", "the", "two", "upward", "branches", "from", "the", "lowest", "internal", "vertex,", "each", "n-tree", "\u03c8", "can", "be", "uniquely", "represented", "as", "the", "grafting", "of", "two", "trees,", "say,", "\u03c81", "\u2208", "Tp", "and", "\u03c82", "\u2208", "Tq,", "where", "p", "+", "q", "=", "n.", "By", "iterating", "the", "grafting", "operation,", "one", "can", "show", "by", "a", "simple", "induction", "argument", "that", "every", "n-tree", "(n", "\u2265", "2)", "can", "be", "obtained", "as", "an", "iterated", "grafting", "of", "n", "copies", "of", "the", "1-tree."], "labels": ["MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["Couversely,bycuttingthetwoupwardbranchesf.romthe,owestinternalvertex,eaehn-tree\u03c8canbeuniquelyre,presentedasthe^raftigofLwotrees,say;\u03c81\u2208Tpand\u03c82\u2208Tq,wherep+qn.Byitetatjngthegr~ftingoperat5on,onecansilowbyasimple;inductionargume,tthateveryn-t?ree?n\u22652)c?nbeobtinedasaniteratedgraftingofncopiesofthe1-tree."], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["Couversely,", "by", "cutting", "the", "two", "upward", "branches", "f.rom", "the", ",owest", "internal", "vertex,", "eaeh", "n-tree", "\u03c8", "can", "be", "uniquely", "re,presented", "as", "the", "^raftig", "of", "Lwo", "trees,", "say;", "\u03c81", "\u2208", "Tp", "and", "\u03c82", "\u2208", "Tq,", "where", "p", "+", "qn.", "By", "itetatjng", "the", "gr~fting", "operat5on,", "one", "can", "silow", "by", "a", "simple", ";induction", "argume,t", "that", "every", "n-t?ree", "?n", "\u2265", "2)", "c?n", "be", "obtined", "as", "an", "iterated", "grafting", "of", "n", "copies", "of", "the", "1-tree."], "labels": ["WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["Couversely,", "by", "cutting", "the", "two", "upward", "branches", "from", "the", ",lowest", "internal", "vertex,", "eaeh", "n-tree", "\u03c8", "can", "be", "uniquely", "re,presented", "as", "the", "^raft", "of", "Iwo", "trees,", "say;", "\u03c81", "\u2208", "Tp", "and", "\u03c82", "\u2208", "Tq,", "where", "p", "+", "qn.", "By", "iterating", "the", "gr~fting", "operation,", "one", "can", "silow", "by", "a", "simple", ";induction", "argument", "that", "every", "tree", "?n", "\u2265", "2)", "can", "be", "obtained", "as", "an", "iterated", "grafting", "of", "n", "copies", "of", "the", "1-tree."], "labels": ["WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "WRONG", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["OverviewofHDFS-RAID"], "labels": ["WRONG"]}, "correct": {"tokens": ["Overview", "of", "HDFS-RAID"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["OverviewofHDFS-RAID"], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["Overview", "of", "HDFS-RAID"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["Overview", "of", "HDFS-RAID"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["w\\here\u03bbisanarbitarysuperfield.I'hnsetrasformaxion*scontaintheworld-linediffeomorhismsantilen=8localworld-linesupersymmetry.Ullderl;hesetransformationa,rhecovarianlde\\rivativeDrtranformshomo6eneouJty."], "labels": ["WRONG"]}, "correct": {"tokens": ["where", "\u03bb", "is", "an", "arbitary", "superfield.", "These", "transformations", "contain", "the", "world-line", "diffeomorhisms", "and", "the", "n", "=", "8", "local", "world-line", "supersymmetry.", "Under", "these", "transformations,", "the", "covariant", "derivative", "Dr", "transforms", "homogeneously."], "labels": ["MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "MIXED", "MIXED", "MIXED", "MIXED", "TOKENIZATION_ERROR", "MIXED", "MIXED"]}, "predicted": {"google": {"tokens": ["w\\here\u03bbisanarbitarysuperfield.I", "Hns", "Transformation*scontaintheworld-linediffeomorhismsantilen=8localworld-linesupersymmetry.Ullderl;hesetransformationa,rhecovarianlde\\rivativeDrtranformshomo6eneouJty."], "labels": ["WRONG", "WRONG", "WRONG"]}, "BS-bid-OCR": {"tokens": ["w\\here", "\u03bb", "is", "an", "arbitary", "superfield.", "I'hnse", "trasformaxion*s", "contain", "the", "world-line", "diffeomorhisms", "an", "tile", "n", "=", "8", "local", "world-line", "supersymmetry.", "Ullder", "l;hese", "transformationa,", "rhe", "covarianl", "de\\rivative", "Dr", "tranforms", "homo6eneouJty."], "labels": ["WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "WRONG", "WRONG", "WRONG", "WRONG", "TOKENIZATION_ERROR", "WRONG", "WRONG"]}, "BS-bid-OCR+google": {"tokens": ["w\\here", "\u03bb", "is", "an", "arbitrary", "superfield.", "I'se", "transformation*s", "contain", "the", "world-line", "diffeomorphisms", "and", "tile", "n", "=", "8", "local", "world-line", "supersymmetry.", "Ullder", "l;hese", "transformationa,", "the", "covariant", "de\\rivative", "Dr", "transforms", "homogeneouS."], "labels": ["WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "MIXED", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "WRONG", "MIXED", "MIXED", "WRONG", "TOKENIZATION_ERROR", "MIXED", "WRONG"]}}}, {"corrupt": {"tokens": ["DecomposeU(\u03b1)andi1tsinverseasfollows"], "labels": ["WRONG"]}, "correct": {"tokens": ["Decompose", "U(\u03b1)", "and", "its", "inverse", "as", "follows"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["DecomposeU(\u03b1)andi1tsinverseasfollows"], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["Decompose", "U(\u03b1)", "and", "i1ts", "inverse", "as", "follows"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["Decompose", "U(\u03b1)", "and", "i1ts", "inverse", "as", "follows"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["Indicesonspacetimequantitiesareraisedandloweredwithhe4-metric,gab,and/tsinverscswhilethe3-metri(;hijanditsinveIseareusedtoraiseandlowerindicesonspatialantities."], "labels": ["WRONG"]}, "correct": {"tokens": ["Indices", "on", "spacetime", "quantities", "are", "raised", "and", "lowered", "with", "the", "4-metric,", "gab,", "and", "its", "inverse,", "while", "the", "3-metric", "hij", "and", "its", "inverse", "are", "used", "to", "raise", "and", "lower", "indices", "on", "spatial", "quantities."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED"]}, "predicted": {"google": {"tokens": ["Indicesonspacetimequantitiesareraisedandloweredwithhe4-metric,gab,and/tsinverscswhilethe3-metri(;hijanditsinveIseareusedtoraiseandlowerindicesonspatialantities."], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["Indices", "on", "spacetime", "quantities", "are", "raised", "and", "lowered", "with", "he", "4-metric,", "gab,", "and", "/ts", "inverscs", "while", "the", "3-metri(;", "hij", "and", "its", "inveIse", "are", "used", "to", "raise", "and", "lower", "indices", "on", "spatial", "antities."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG"]}, "BS-bid-OCR+google": {"tokens": ["Indices", "on", "spacetime", "quantities", "are", "raised", "and", "lowered", "with", "the", "4-metric,", "gab,", "and", "/its", "inverses", "while", "the", "3-metri(;", "hij", "and", "its", "inveRse", "are", "used", "to", "raise", "and", "lower", "indices", "on", "spatial", "entities."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG"]}}}, {"corrupt": {"tokens": ["Here,followlngthisexamph:,weapplythesemi-classicalmethodtogheca1\\eoftheNS5-braneandcomparewithourpp-wavc~results."], "labels": ["WRONG"]}, "correct": {"tokens": ["Here,", "following", "this", "example,", "we", "apply", "the", "semi-classical", "method", "to", "the", "case", "of", "the", "NS5-brane", "and", "compare", "with", "our", "pp-wave", "results."], "labels": ["TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["Here,followlngthisexamph:,weapplythesemi-classicalmethodtogheca1\\eoftheNS5-braneandcomparewithourpp-wavc~results."], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["Here,", "followlng", "this", "examph:,", "we", "apply", "the", "semi-classical", "method", "to", "ghe", "ca1\\e", "of", "the", "NS5-brane", "and", "compare", "with", "our", "pp-wavc~", "results."], "labels": ["TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["Here,", "following", "this", "example:,", "we", "apply", "the", "semiclassical", "method", "to", "the", "ca1\\e", "of", "the", "NS5-brane", "and", "compare", "with", "our", "pp-wavc~", "results."], "labels": ["TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["Wehauveinvestigatedthebraihistochroneproblcmforentangledstates.Thisanswersthequestionthatwehaveraisedinthcbeginning,namely,givenanatbitraryproducttateandgeneralnon-loealHamiltonian,whatisthemillimumtimeforcreatingadesiredentangledstate?WehaveshownthOttheminimumtimedepcndsinlverselyonthespeedcftheevolutiono\\[thequantnmsystem.Thisisindependentofthe\\particularentanglementmeasureandholclsevenfOrmultiparticleentangledsystems.Wehaveshownthatforfw'oqubitsthepresenceofinitialentanglementdoeshelpinminintisingthewaitingditime.Icparticular,wenfindthatIwearegithenanoptionofstastingfromaproductstateandanentangledstate,andwantsloreochtheinaximallyentetngledstate,thenitisbettertostartfrmsomealreadynitialental~gledstate.Because,inthelatercasethetimerequiredisless.weilaveshownthatthetimeaverageofentanglementatedependsontheSchmid1,rankandonhefluctuationillthenon-localHamiltonian.Wehavealsoshownthatinat)ilocalrot.~tin.gfram;etheentanglingcapabilityisalsodirectlyrelatettothespeedofheevolquiutionofthentangledstats.Thisshowsthattheentanglingcapabilityofanon-localHamil?toniauisactuallyageometricauantity.Furth(',rmore,whaveprovedacompositionlawforthemnimumtimewhenthesystemevolvesundercomposliteHamiltonians.Wehopethatthesefindingswilll)eofinter.estinunderstandingtheetanglementrateandentanglingcapiibilitiesofnon-localHamiltoniansandin?re;~lexperieenalltual;ions.Infuture,itwillbeinterestiugtoseeifallthesefindingsalsholdforquditsandmultiparticlesystems."], "labels": ["WRONG"]}, "correct": {"tokens": ["We", "have", "investigated", "the", "brachistochrone", "problem", "for", "entangled", "states.", "This", "answers", "the", "question", "that", "we", "have", "raised", "in", "the", "beginning,", "namely,", "given", "an", "arbitrary", "product", "state", "and", "general", "non-local", "Hamiltonian,", "what", "is", "the", "minimum", "time", "for", "creating", "a", "desired", "entangled", "state?", "We", "have", "shown", "that", "the", "minimum", "time", "depends", "inversely", "on", "the", "speed", "of", "the", "evolution", "of", "the", "quantum", "system.", "This", "is", "independent", "of", "the", "particular", "entanglement", "measure", "and", "holds", "even", "for", "multiparticle", "entangled", "systems.", "We", "have", "shown", "that", "for", "two", "qubits", "the", "presence", "of", "initial", "entanglement", "does", "help", "in", "minimising", "the", "waiting", "time.", "In", "particular,", "we", "find", "that", "if", "we", "are", "given", "an", "option", "of", "starting", "from", "a", "product", "state", "and", "an", "entangled", "state,", "and", "wants", "to", "reach", "the", "maximally", "entangled", "state,", "then", "it", "is", "better", "to", "start", "from", "some", "already", "initial", "entangled", "state.", "Because,", "in", "the", "later", "case", "the", "time", "required", "is", "less.", "We", "have", "shown", "that", "the", "time", "average", "of", "entanglement", "rate", "depends", "on", "the", "Schmidt", "rank", "and", "on", "the", "fluctuation", "in", "the", "non-local", "Hamiltonian.", "We", "have", "also", "shown", "that", "in", "a", "bilocal", "rotating", "frame", "the", "entangling", "capability", "is", "also", "directly", "related", "to", "the", "speed", "of", "the", "evolution", "of", "the", "entangled", "states.", "This", "shows", "that", "the", "entangling", "capability", "of", "a", "non-local", "Hamiltonian", "is", "actually", "a", "geometric", "quantity.", "Furthermore,", "we", "have", "proved", "a", "composition", "law", "for", "the", "minimum", "time", "when", "the", "system", "evolves", "under", "composite", "Hamiltonians.", "We", "hope", "that", "these", "findings", "will", "be", "of", "interest", "in", "understanding", "the", "entanglement", "rate", "and", "entangling", "capabilities", "of", "non-local", "Hamiltonians", "and", "in", "real", "experimental", "situations.", "In", "future,", "it", "will", "be", "interesting", "to", "see", "if", "all", "these", "findings", "also", "hold", "for", "qudits", "and", "multiparticle", "systems."], "labels": ["TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["Wehauveinvestigatedthebraihistochroneproblcmforentangledstates.Thisanswersthequestionthatwehaveraisedinthcbeginning,namely,givenanatbitraryproducttateandgeneralnon-loealHamiltonian,whatisthemillimumtimeforcreatingadesiredentangledstate?WehaveshownthOttheminimumtimedepcndsinlverselyonthespeedcftheevolutiono\\[thequantnmsystem.Thisisindependentofthe\\particularentanglementmeasureandholclsevenfOrmultiparticleentangledsystems.Wehaveshownthatforfw'oqubitsthepresenceofinitialentanglementdoeshelpinminintisingthewaitingditime.Icparticular,wenfindthatIwearegithenanoptionofstastingfromaproductstateandanentangledstate,andwantsloreochtheinaximallyentetngledstate,thenitisbettertostartfrmsomealreadynitialental~gledstate.Because,inthelatercasethetimerequiredisless.weilaveshownthatthetimeaverageofentanglementatedependsontheSchmid1,rankandonhefluctuationillthenon-localHamiltonian.Wehavealsoshownthatinat)ilocalrot.~tin.gfram;etheentanglingcapabilityisalsodirectlyrelatettothespeedofheevolquiutionofthentangledstats.Thisshowsthattheentanglingcapabilityofanon-localHamil?toniauisactuallyageometricauantity.Furth(',rmore,whaveprovedacompositionlawforthemnimumtimewhenthesystemevolvesundercomposliteHamiltonians.Wehopethatthesefindingswilll)eofinter.estinunderstandingtheetanglementrateandentanglingcapiibilitiesofnon-localHamiltoniansandin?re;~lexperieenalltual;ions.Infuture,itwillbeinterestiugtoseeifallthesefindingsalsholdforquditsandmultiparticlesystems."], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["We", "hauve", "investigated", "the", "brai", "histochrone", "problcm", "for", "entangled", "states.", "This", "answers", "the", "question", "that", "we", "have", "raised", "in", "thc", "beginning,", "namely,", "given", "an", "atbitrary", "product", "tate", "and", "general", "non-loeal", "Hamiltonian,", "what", "is", "the", "millimum", "time", "for", "creating", "a", "desired", "entangled", "state?", "We", "have", "shown", "thOt", "the", "minimum", "time", "depcnds", "inlversely", "on", "the", "speed", "cf", "the", "evolution", "o\\[", "the", "quantnm", "system.", "This", "is", "independent", "of", "the\\", "particular", "entanglement", "measure", "and", "holcls", "even", "fOr", "multiparticle", "entangled", "systems.", "We", "have", "shown", "that", "for", "fw'o", "qubits", "the", "presence", "of", "initial", "entanglement", "does", "help", "in", "minintising", "the", "waiting", "ditime.", "Ic", "particular,", "we", "nfind", "that", "I", "we", "are", "githen", "an", "option", "of", "stasting", "from", "a", "product", "state", "and", "an", "entangled", "state,", "and", "wants", "lo", "reoch", "the", "inaximally", "entetngled", "state,", "then", "it", "is", "better", "to", "start", "frm", "some", "already", "nitial", "ental~gled", "state.", "Because,", "in", "the", "later", "case", "the", "time", "required", "is", "less.", "we", "ilave", "shown", "that", "the", "time", "average", "of", "entanglement", "ate", "depends", "on", "the", "Schmid1,", "rank", "and", "on", "he", "fluctuation", "ill", "the", "non-local", "Hamiltonian.", "We", "have", "also", "shown", "that", "in", "a", "t)ilocal", "rot.~tin.g", "fram;e", "the", "entangling", "capability", "is", "also", "directly", "relatet", "to", "the", "speed", "of", "he", "evolquiution", "of", "the", "ntangled", "stats.", "This", "shows", "that", "the", "entangling", "capability", "of", "a", "non-local", "Hamil?toniau", "is", "actually", "a", "geometric", "auantity.", "Furth(',rmore,", "w", "have", "proved", "a", "composition", "law", "for", "the", "mnimum", "time", "when", "the", "system", "evolves", "under", "composlite", "Hamiltonians.", "We", "hope", "that", "these", "findings", "will", "l)e", "of", "inter.est", "in", "understanding", "the", "etanglement", "rate", "and", "entangling", "capiibilities", "of", "non-local", "Hamiltonians", "and", "in", "?re;~l", "experieen", "alltual;ions.", "In", "future,", "it", "will", "be", "interestiug", "to", "see", "if", "all", "these", "findings", "als", "hold", "for", "qudits", "and", "multiparticle", "systems."], "labels": ["TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "MIXED", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["We", "have", "investigated", "the", "brain", "cytochrome", "problem", "for", "entangled", "states.", "This", "answers", "the", "question", "that", "we", "have", "raised", "in", "the", "beginning,", "namely,", "given", "an", "arbitrary", "product", "state", "and", "general", "non-local", "Hamiltonian,", "what", "is", "the", "minimum", "time", "for", "creating", "a", "desired", "entangled", "state?", "We", "have", "shown", "thOt", "the", "minimum", "time", "depends", "inversely", "on", "the", "speed", "of", "the", "evolution", "o\\[", "the", "quantum", "system.", "This", "is", "independent", "of", "the\\", "particular", "entanglement", "measure", "and", "holcls", "even", "fOr", "multiparticle", "entangled", "systems.", "We", "have", "shown", "that", "for", "two", "qubits", "the", "presence", "of", "initial", "entanglement", "does", "help", "in", "minimising", "the", "waiting", "time.", "In", "particular,", "we", "find", "that", "if", "we", "are", "githen", "an", "option", "of", "starting", "from", "a", "product", "state", "and", "an", "entangled", "state,", "and", "want", "to", "reoch", "the", "maximally", "entangled", "state,", "then", "it", "is", "better", "to", "start", "from", "some", "already", "initial", "rental~gled", "state.", "Because,", "in", "the", "latter", "case,", "the", "time", "required", "is", "less.", "we", "ilave", "shown", "that", "the", "time", "average", "of", "entanglement", "ate", "depends", "on", "the", "Schmid1,", "rank", "and", "on", "the", "fluctuation", "of", "the", "non-local", "Hamiltonian.", "We", "have", "also", "shown", "that", "in", "a", "t)ilocal", "rot.~tin.g", "fram;e", "the", "entangling", "capability", "is", "also", "directly", "related", "to", "the", "speed", "of", "the", "evolution", "of", "the", "tangled", "stats.", "This", "shows", "that", "the", "entangling", "capability", "of", "a", "non-local", "Hamil?toniau", "is", "actually", "a", "geometric", "quantity.", "Furth(',rmore,", "we", "have", "proved", "a", "composition", "law", "for", "the", "minimum", "time", "when", "the", "system", "evolves", "under", "composite", "Hamiltonians.", "We", "hope", "that", "these", "findings", "will", "l)e", "of", "interest", "in", "understanding", "the", "entanglement", "rate", "and", "entangling", "capabilities", "of", "non-local", "Hamiltonians", "and", "in", "?re;~l", "experience", "actual;ions.", "In", "future,", "it", "will", "be", "interesting", "to", "see", "if", "all", "these", "findings", "als", "hold", "for", "qudits", "and", "multiparticle", "systems."], "labels": ["TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "MIXED", "WRONG", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "MIXED", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "WRONG", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["Reflectionandtransmissionatasurfaae"], "labels": ["WRONG"]}, "correct": {"tokens": ["Reflection", "and", "transmission", "at", "a", "surface"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED"]}, "predicted": {"google": {"tokens": ["Reflectionandtransmissionatasurfaae"], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["Reflection", "and", "transmission", "at", "a", "surfaae"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG"]}, "BS-bid-OCR+google": {"tokens": ["Reflection", "and", "transmission", "at", "a", "surface"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED"]}}}, {"corrupt": {"tokens": ["We~adoptisospineigensatesformesonstatesasfollows:"], "labels": ["WRONG"]}, "correct": {"tokens": ["We", "adopt", "isospin", "eigenstates", "for", "meson", "states", "as", "follows:"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["We~adoptisospineigensatesformesonstates", "as", "follows:"], "labels": ["WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR": {"tokens": ["We~", "adopt", "isospin", "eigensates", "for", "meson", "states", "as", "follows:"], "labels": ["WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["We~", "adopt", "iso", "spin", "eigenstates", "for", "meson", "states", "as", "follows:"], "labels": ["WRONG", "TOKENIZATION_ERROR", "WRONG", "WRONG", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["Sparsesignals:Theargumetscanbeseamtess\\]yextended?teincorporatesparsesignals."], "labels": ["WRONG"]}, "correct": {"tokens": ["Sparse", "signals:", "The", "arguments", "can", "be", "seamlessly", "extended", "to", "incorporate", "sparse", "signals."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["Sparse", "Signals:Theargumetscanbeseamtess\\]y", "extended", "to", "incorporate", "sparse", "signals."], "labels": ["TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR": {"tokens": ["Sparse", "signals:", "The", "argumets", "can", "be", "seamtess\\]y", "extended?", "te", "incorporate", "sparse", "signals."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["Sparse", "signals:", "The", "arguments", "can", "be", "seamless\\]y", "extended?", "te", "incorporate", "sparse", "signals."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["by"], "labels": ["NONE"]}, "correct": {"tokens": ["by"], "labels": ["NONE"]}, "predicted": {"google": {"tokens": ["by"], "labels": ["NONE"]}, "BS-bid-OCR": {"tokens": ["by"], "labels": ["NONE"]}, "BS-bid-OCR+google": {"tokens": ["by"], "labels": ["NONE"]}}}, {"corrupt": {"tokens": ["Webeginwithamultidimensionalfirstordersystemwithforcing:"], "labels": ["WRONG"]}, "correct": {"tokens": ["We", "begin", "with", "a", "multidimensional", "first", "order", "system", "with", "forcing:"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["Webeginwithamultidimensionalfirstordersystemwithforcing:"], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["We", "begin", "with", "a", "multidimensional", "first", "order", "system", "with", "forcing:"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["We", "begin", "with", "a", "multidimensional", "first", "order", "system", "with", "forcing:"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["Gapdec>upling"], "labels": ["WRONG"]}, "correct": {"tokens": ["Gap", "decoupling"], "labels": ["TOKENIZATION_ERROR", "MIXED"]}, "predicted": {"google": {"tokens": ["Gap", "Inc>uplink"], "labels": ["TOKENIZATION_ERROR", "WRONG"]}, "BS-bid-OCR": {"tokens": ["Gap", "dec>upling"], "labels": ["TOKENIZATION_ERROR", "WRONG"]}, "BS-bid-OCR+google": {"tokens": ["Gap", "dec>upling"], "labels": ["TOKENIZATION_ERROR", "WRONG"]}}}, {"corrupt": {"tokens": ["Thimethodtoestimatethecentralblackholemasses?fAGNshasbeendiscussedbysomeauthors(Wang,&\\],u2001;BiendeZhao2003b;Bian&Zhao2005c;$\\hie\\l(Is?otal.2003;Boroson2003\\)."], "labels": ["WRONG"]}, "correct": {"tokens": ["This", "method", "to", "estimate", "the", "central", "black", "hole", "masses", "of", "AGNs", "has", "been", "discussed", "by", "some", "authors", "(Wang", "&", "Lu", "2001;", "Bian", "&", "Zhao", "2003b;", "Bian", "&", "Zhao", "2003c;", "Shields", "et", "al.", "2003;", "Boroson", "2003)."], "labels": ["MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED"]}, "predicted": {"google": {"tokens": ["Thimethodtoestimatethecentralblackholemasses?fAGNshasbeendiscussedbysomeauthors(Wang,&\\],u2001;BiendeZhao2003b;Bian&Zhao2005c;$\\hie\\l(Is?otal.2003;Boroson2003\\)."], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["Thi", "method", "to", "estimate", "the", "central", "black", "hole", "masses", "?f", "AGNs", "has", "been", "discussed", "by", "some", "authors", "(Wang,", "&", "\\],u", "2001;", "Biende", "Zhao", "2003b;", "Bian", "&", "Zhao", "2005c;", "$\\hie\\l(Is", "?ot", "al.", "2003;", "Boroson", "2003\\)."], "labels": ["WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG"]}, "BS-bid-OCR+google": {"tokens": ["Thi", "method", "to", "estimate", "the", "central", "black", "hole", "masses", "?f", "AGNs", "has", "been", "discussed", "by", "some", "authors", "(Wang,", "&", "\\],u", "2001;", "Biende", "Zhao", "2003b;", "Bian", "&", "Zhao", "2005c;", "$\\hie\\l(Is", "?it", "al.", "2003;", "Boroson", "2003\\)."], "labels": ["WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG"]}}}, {"corrupt": {"tokens": ["Thus.thei\\nitialoQisapproximatelygivenby"], "labels": ["WRONG"]}, "correct": {"tokens": ["Thus,", "the", "initial", "Q", "is", "approximately", "given", "by"], "labels": ["MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["Thus.thei\\nitialoQisapproximatelygivenby"], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["Thus.", "the", "i\\nitial", "o", "Q", "is", "approximately", "given", "by"], "labels": ["WRONG", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["Thus.", "the", "i\\nitial", "o", "Q", "is", "approximately", "given", "by"], "labels": ["WRONG", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["Introduction"], "labels": ["NONE"]}, "correct": {"tokens": ["Introduction"], "labels": ["NONE"]}, "predicted": {"google": {"tokens": ["Introduction"], "labels": ["NONE"]}, "BS-bid-OCR": {"tokens": ["Introduction"], "labels": ["NONE"]}, "BS-bid-OCR+google": {"tokens": ["Introduction"], "labels": ["NONE"]}}}, {"corrupt": {"tokens": ["withthesameinitialdataat(0,0),wehaveE(x,t,0)=g~x,t)."], "labels": ["WRONG"]}, "correct": {"tokens": ["with", "the", "same", "initial", "data", "at", "(0,", "0),", "we", "have", "E(x,", "t,", "0)", "=", "g(x,", "t)."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["withthesameinitialdataat(0,0),wehaveE(x,t,0)=g~x,t)."], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["with", "the", "same", "initial", "data", "at", "(0,", "0),", "we", "have", "E(x,", "t,", "0)", "=", "g~x,", "t)."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["with", "the", "same", "initial", "data", "at", "(0,", "0),", "we", "have", "E(x,", "t,", "0)", "=", "g~x,", "t)."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["wheretheGaussianuldth\u03baisthe\\kernelparamet(;r.Tosavethecomputationcost,welimittilenumberofkernelbas(!sto500withrandomlgseletodkeruelcenters."], "labels": ["WRONG"]}, "correct": {"tokens": ["where", "the", "Gaussian", "width", "\u03ba", "is", "the", "kernel", "parameter.", "To", "save", "the", "computation", "cost,", "we", "limit", "the", "number", "of", "kernel", "bases", "to", "500", "with", "randomly", "selected", "kernel", "centers."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "MIXED", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["wheretheGaussianuldth\u03baisthe\\kernel", "parameter(;r.Tosavethecomputationcost,welimittilenumberofkernelbas(!sto500withrandomlgseletodkeruelcenters."], "labels": ["WRONG", "WRONG"]}, "BS-bid-OCR": {"tokens": ["where", "the", "Gaussian", "uldth", "\u03ba", "is", "the\\", "kernel", "paramet(;r.", "To", "save", "the", "computation", "cost,", "we", "limit", "tile", "number", "of", "kernel", "bas(!s", "to", "500", "with", "randomlg", "seletod", "keruel", "centers."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "WRONG", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["where", "the", "Gaussian", "uleth", "\u03ba", "is", "the\\", "kernel", "parameter(;r.", "To", "save", "the", "computation", "cost,", "we", "limit", "the", "tile", "number", "of", "kernel", "bas(!s", "to", "500", "with", "randomly", "selected", "kernel", "centers."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "MIXED", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["andtoblindlyimplem(>nttileBellmeasuementssettingswe(:hoose:"], "labels": ["WRONG"]}, "correct": {"tokens": ["and", "to", "blindly", "implement", "the", "Bell", "measurements", "settings", "we", "choose:"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED"]}, "predicted": {"google": {"tokens": ["andtoblindlyimplem(>nttileBellmeasuementssettingswe(:hoose:"], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["and", "to", "blindly", "implem(>nt", "tile", "Bell", "measuements", "settings", "we", "(:hoose:"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG"]}, "BS-bid-OCR+google": {"tokens": ["and", "to", "blindly", "implem(>nt", "tile", "Bell", "measurements", "settings", "we", "(:hoose:"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG"]}}}, {"corrupt": {"tokens": ["Inthispaper,wconsideradeterministicdifferentialequationofthefollowingtype:"], "labels": ["WRONG"]}, "correct": {"tokens": ["In", "this", "paper,", "we", "consider", "a", "deterministic", "differential", "equation", "of", "the", "following", "type:"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["Inthispaper,wconsideradeterministicdifferentialequationofthefollowingtype:"], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["In", "this", "paper,", "w", "consider", "a", "deterministic", "differential", "equation", "of", "the", "following", "type:"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["In", "this", "paper,", "w", "consider", "a", "deterministic", "differential", "equation", "of", "the", "following", "type:"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["ForaquadraticforminsideBarS,theDeJauuaytessellati(mcontainsSasasimi)lt;x.Foraquad~aticformonafacetofBa.rS,thesimplexS,isapartofarepartltioningt)lolytope,i.e.,aDelaunaypolyopewithn+2vertices."], "labels": ["WRONG"]}, "correct": {"tokens": ["For", "a", "quadratic", "form", "inside", "BarS,", "the", "Delaunay", "tessellation", "contains", "S", "as", "a", "simplex.", "For", "a", "quadratic", "form", "on", "a", "facet", "of", "BarS,", "the", "simplex", "S", "is", "a", "part", "of", "a", "repartitioning", "polytope,", "i.e.,", "a", "Delaunay", "polytope", "with", "n", "+", "2", "vertices."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["ForaquadraticforminsideBarS,theDeJauuaytessellati(mcontainsSasasimi)lt;x.Foraquad~aticformonafacetofBa.rS,thesimplexS,isapartofarepartltioningt)lolytope,i.e.,a", "Delaunay", "polyope", "with+2vertices."], "labels": ["WRONG", "TOKENIZATION_ERROR", "WRONG", "WRONG"]}, "BS-bid-OCR": {"tokens": ["For", "a", "quadratic", "form", "inside", "BarS,", "the", "DeJauuay", "tessellati(m", "contains", "S", "as", "a", "simi)lt;x.", "For", "a", "quad~atic", "form", "on", "a", "facet", "of", "Ba.rS,", "the", "simplex", "S,", "is", "a", "part", "of", "a", "repartltioning", "t)lolytope,", "i.e.,", "a", "Delaunay", "polyope", "with", "n", "+", "2", "vertices."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["For", "a", "quadratic", "form", "inside", "BarS,", "the", "DeLaunay", "tessellation(m", "contains", "S", "as", "a", "simi)lt;x.", "For", "a", "quad~atic", "form", "on", "a", "facet", "of", "Ba.rS,", "the", "simplex", "S,", "is", "a", "part", "of", "a", "repartitioning", "t)lolytop,", "i.e.,", "a", "Delaunay", "polyope", "with", "n", "+", "2", "vertices."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["Othe\\rareasDofcurrentactivityillthefieldofraraKdecaysicudestudiesofraditiveDrocessesrelevanttoChiralPerturbationTheory(CHPT)andsearchesforexoticreactions."], "labels": ["WRONG"]}, "correct": {"tokens": ["Other", "areas", "of", "current", "activity", "in", "the", "field", "of", "rare", "K", "decays", "include", "studies", "of", "radiative", "processes", "relevant", "to", "Chiral", "Perturbation", "Theory", "(CHPT)", "and", "searches", "for", "exotic", "reactions."], "labels": ["MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["Othe\\rareasDofcurrentactivityillthefieldofraraKdecaysicudestudiesofraditiveDrocessesrelevanttoChiralPerturbationTheory(CHPT)andsearchesforexoticreactions."], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["Othe\\r", "areasD", "of", "current", "activity", "ill", "the", "field", "of", "raraK", "decays", "icude", "studies", "of", "raditive", "Drocesses", "relevant", "to", "Chiral", "Perturbation", "Theory", "(CHPT)", "and", "searches", "for", "exotic", "reactions."], "labels": ["WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["Othe\\r", "areasD", "of", "current", "activity", "in", "the", "field", "of", "raraK", "decays", "include", "studies", "of", "radiative", "Processes", "relevant", "to", "Chiral", "Perturbation", "Theory", "(CHPT)", "and", "searches", "for", "exotic", "reactions."], "labels": ["WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["weassumethattheJohnsonnoisevoltagesacrosstheresistors?domi.nateallothersourccsofnoi~eilltileamplifier.WhiteGaussiannoiseineachofthreeresistorswasmodeledbyatrainofrectangulitrpulsesfolowingeachatherwithoutinterruption.Thecurrentamplitud.e,In,of,eitchpulseisrandomwlthzeroaverageandthefollowingvarianee:"], "labels": ["WRONG"]}, "correct": {"tokens": ["We", "assume", "that", "the", "Johnson", "noise", "voltages", "across", "the", "resistors", "dominate", "all", "other", "sources", "of", "noise", "in", "the", "amplifier.", "White", "Gaussian", "noise", "in", "each", "of", "three", "resistors", "was", "modeled", "by", "a", "train", "of", "rectangular", "pulses", "following", "each", "other", "without", "interruption.", "The", "current", "amplitude,", "In,", "of", "each", "pulse", "is", "random", "with", "zero", "average", "and", "the", "following", "variance:"], "labels": ["MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED"]}, "predicted": {"google": {"tokens": ["weassumethattheJohnsonnoisevoltagesacrosstheresistors?domi.nateallothersourccsofnoi~eilltileamplifier.WhiteGaussiannoiseineachofthreeresistorswasmodeledbyatrainofrectangulitrpulsesfolowingeachatherwithoutinterruption.Thecurrentamplitud.e,In,of,eitchpulseisrandomwlthzeroaverageandthefollowingvarianee:"], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["we", "assume", "that", "the", "Johnson", "noise", "voltages", "across", "the", "resistors", "?domi.nate", "all", "other", "sourccs", "of", "noi~e", "ill", "tile", "amplifier.", "White", "Gaussian", "noise", "in", "each", "of", "three", "resistors", "was", "modeled", "by", "a", "train", "of", "rectangulitr", "pulses", "folowing", "each", "ather", "without", "interruption.", "The", "current", "amplitud.e,", "In,", "of,", "eitch", "pulse", "is", "random", "wlth", "zero", "average", "and", "the", "following", "varianee:"], "labels": ["WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG"]}, "BS-bid-OCR+google": {"tokens": ["we", "assume", "that", "the", "Johnson", "noise", "voltages", "across", "the", "resistors", "?dominate", "all", "other", "sources", "of", "noi~e", "i'll", "tile", "amplifiers.", "White", "Gaussian", "noise", "in", "each", "of", "three", "resistors", "was", "modeled", "by", "a", "train", "of", "rectangular", "pulses", "following", "each", "other", "without", "interruption.", "The", "current", "amplitude,", "In,", "of,", "which", "pulse", "is", "random", "with", "zero", "average", "and", "the", "following", "variances:"], "labels": ["WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "WRONG", "WRONG", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG"]}}}, {"corrupt": {"tokens": ["Thustheorthogonalmatrixgivestherealandimaginar:ypart\\softhecomplexvariables.Reciprocaliy,startngwithaN-vectorwithunitperimeterE=2,wewriteboththefixedeperimeterandclosureconstraintsintermscftherealandimaginarypartsoftheco\\]mplexcoordiDates,zi=Ri+iIi:"], "labels": ["WRONG"]}, "correct": {"tokens": ["Thus", "the", "orthogonal", "matrix", "gives", "the", "real", "and", "imaginary", "parts", "of", "the", "complex", "variables.", "Reciprocally,", "starting", "with", "a", "N-vector", "with", "unit", "perimeter", "E", "=", "2,", "we", "write", "both", "the", "fixed", "perimeter", "and", "closure", "constraints", "in", "terms", "of", "the", "real", "and", "imaginary", "parts", "of", "the", "complex", "coordinates,", "zi", "=", "Ri", "+", "iIi:"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["Thustheorthogonalmatrixgivestherealandimaginar:part\\sofa", "complex", "variables.Reciprocality,startswith-vectorwithunitperimeterE=2,wewriteboththefixedeperimeterandclosureconstraintsintermscftherealandimaginarypartsoftheco\\]mplex", "coordiNates,zi=Ri+iIi:"], "labels": ["WRONG", "MIXED", "WRONG", "WRONG"]}, "BS-bid-OCR": {"tokens": ["Thus", "the", "orthogonal", "matrix", "gives", "the", "real", "and", "imaginar:y", "part\\s", "of", "the", "complex", "variables.", "Reciprocaliy,", "startng", "with", "a", "N-vector", "with", "unit", "perimeter", "E", "=", "2,", "we", "write", "both", "the", "fixed", "eperimeter", "and", "closure", "constraints", "in", "terms", "cf", "the", "real", "and", "imaginary", "parts", "of", "the", "co\\]mplex", "coordiDates,", "zi", "=", "Ri", "+", "iIi:"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["Thus", "the", "orthogonal", "matrix", "gives", "the", "real", "and", "imaginar:y", "part\\s", "of", "the", "complex", "variables.", "Reciprocaliy,", "starting", "with", "a", "N-vector", "with", "unit", "perimeter", "E", "=", "2,", "we", "write", "both", "the", "fixed", "perimeter", "and", "closure", "constraints", "in", "terms", "cf", "the", "real", "and", "imaginary", "parts", "of", "the", "co\\]mplex", "coordiNates,", "zi", "=", "Ri", "+", "iIi:"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["Thisexpansionholdswhenever|b/a|<1.Since"], "labels": ["WRONG"]}, "correct": {"tokens": ["This", "expansion", "holds", "whenever", "|b/a", "|", "<1.", "Since"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["This", "Expansion", "Holds", "Whenever|b/a|<1.Since"], "labels": ["TOKENIZATION_ERROR", "WRONG", "WRONG", "WRONG"]}, "BS-bid-OCR": {"tokens": ["This", "expansion", "holds", "whenever", "|b/a", "|", "<1.", "Since"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["This", "expansion", "holds", "whenever", "|b/a", "|", "<1.", "Since"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["Ifc1<\u03b2wecanassumetilatk(c1)=0,an(\\]wecan.makethissumtobc?egativeby\"choosinglargek.Thuswemusthavec1=\u03b2,inwhichcasethesumunderstudyispro\\portionalgo\\"], "labels": ["WRONG"]}, "correct": {"tokens": ["If", "c1", "<", "\u03b2", "we", "can", "assume", "that", "k(c1)", "=", "0,", "and", "we", "can", "make", "this", "sum", "to", "be", "negative", "by", "choosing", "large", "k.", "Thus", "we", "must", "have", "c1", "=", "\u03b2,", "in", "which", "case", "the", "sum", "under", "study", "is", "proportional", "to"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED"]}, "predicted": {"google": {"tokens": ["Ifc1<\u03b2wecanassumetilatk(c1)=0,an(\\]wecan.makethissumtobc?egativeby\"choosing", "large.Thus", "We", "Must", "Have", "1=\u03b2,inwhichcasethesumunderstudyispro\\portionalgo\\"], "labels": ["WRONG", "WRONG", "WRONG", "WRONG", "WRONG", "WRONG"]}, "BS-bid-OCR": {"tokens": ["If", "c1", "<", "\u03b2", "we", "can", "assume", "tilat", "k(c1)", "=", "0,", "an(\\]", "we", "can.", "make", "this", "sum", "to", "bc", "?egative", "by", "\"choosing", "large", "k.", "Thus", "we", "must", "have", "c1", "=", "\u03b2,", "in", "which", "case", "the", "sum", "under", "study", "is", "pro\\portional", "go\\"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG"]}, "BS-bid-OCR+google": {"tokens": ["If", "c1", "<", "\u03b2", "we", "can", "assume", "tilat", "k(c1)", "=", "0,", "an(\\]", "we", "can.", "make", "this", "sum", "to", "be", "negative", "by", "\"choosing", "large", "k.", "Thus", "we", "must", "have", "c1", "=", "\u03b2,", "in", "which", "case", "the", "sum", "under", "study", "is", "pro\\portional", "go\\"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG"]}}}, {"corrupt": {"tokens": ["Numericalexperimens"], "labels": ["WRONG"]}, "correct": {"tokens": ["Numerical", "experiments"], "labels": ["TOKENIZATION_ERROR", "MIXED"]}, "predicted": {"google": {"tokens": ["Numerical", "Experiments"], "labels": ["TOKENIZATION_ERROR", "WRONG"]}, "BS-bid-OCR": {"tokens": ["Numerical", "experimens"], "labels": ["TOKENIZATION_ERROR", "WRONG"]}, "BS-bid-OCR+google": {"tokens": ["Numerical", "experiments"], "labels": ["TOKENIZATION_ERROR", "MIXED"]}}}, {"corrupt": {"tokens": ["Href\u03b1(t,s)isdefinedby"], "labels": ["WRONG"]}, "correct": {"tokens": ["Here", "f\u03b1(t,", "s)", "is", "defined", "by"], "labels": ["MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["Href\u03b1(t,s)isdefinedby"], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["Hre", "f\u03b1(t,", "s)", "is", "defined", "by"], "labels": ["WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["Hre", "f\u03b1(t,", "s)", "is", "defined", "by"], "labels": ["WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["an(tuNisstrongsolutiocnofthed\\iscr\\etellrobleln"], "labels": ["WRONG"]}, "correct": {"tokens": ["and", "uN", "is", "strong", "solution", "of", "the", "discrete", "problem"], "labels": ["MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED"]}, "predicted": {"google": {"tokens": ["an(tuNisstrongsolutiocnofthed\\iscr\\etellrobleln"], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["an(t", "uN", "is", "strong", "solutiocn", "of", "the", "d\\iscr\\ete", "llrobleln"], "labels": ["WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG"]}, "BS-bid-OCR+google": {"tokens": ["an(t", "uN", "is", "strong", "solution", "of", "the", "d\\iscr\\ete", "problem"], "labels": ["WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "MIXED"]}}}, {"corrupt": {"tokens": ["Harmon-icpoteDtialwithvaryingforceconstant"], "labels": ["WRONG"]}, "correct": {"tokens": ["Harmonic", "potential", "with", "varying", "force", "constant"], "labels": ["MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["Harmon-icpoteDtialwithvaryingforceconstant"], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["Harmon-ic", "poteDtial", "with", "varying", "force", "constant"], "labels": ["WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["Harmon-ic", "poteNtial", "with", "varying", "force", "constant"], "labels": ["WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["May1998"], "labels": ["WRONG"]}, "correct": {"tokens": ["May", "1998"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["May1998"], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["May", "1998"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["May", "1998"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["LctIbetheincidencematrixofthegraphX,thatis"], "labels": ["WRONG"]}, "correct": {"tokens": ["Let", "I", "be", "the", "incidence", "matrix", "of", "the", "graph", "X,", "that", "is"], "labels": ["MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["LctIbetheincidencematrixofthegraphX,thatis"], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["Lct", "I", "be", "the", "incidence", "matrix", "of", "the", "graph", "X,", "that", "is"], "labels": ["WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["Lct", "I", "be", "the", "incidence", "matrix", "of", "the", "graph", "X,", "that", "is"], "labels": ["WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["Inturnwepreparethe~xcitedstatedefinedbyactingvariousoperatorsonthegroundstatesuchas"], "labels": ["WRONG"]}, "correct": {"tokens": ["In", "turn", "we", "prepare", "the", "excited", "state", "defined", "by", "acting", "various", "operators", "on", "the", "ground", "state", "such", "as"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["Inturnwepreparethe~xcitedstatedefinedbyactingvariousoperatorsonthegroundstatesuchas"], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["In", "turn", "we", "prepare", "the", "~xcited", "state", "defined", "by", "acting", "various", "operators", "on", "the", "ground", "state", "such", "as"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["In", "turn", "we", "prepare", "the", "~excited", "state", "defined", "by", "acting", "various", "operators", "on", "the", "ground", "state", "such", "as"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["Nowadaystheconceptthatthetidalbrakingeffectoftheearthrotationiscausedbythegravitationalforceofthemoonactingontheviscousoceanicwatersazotradthe\\earthisacceptedingeneral.Withrespecttothedetatlsofthisbrakinsmechanismseveralm\\odelswereproposedandtheor(,ticallyinvestigatedindetail,\\includingnumericalcOmputercalculation.?Wer.efra~.nfromreviewingthhistorlcallyf~rsti(leasandtheafterW~rdsfo!lowIngpublicatonsonthissub~ect,butwer~Lthercitesomepreviouspapers,whe\\retheinterestedrammeadercanfindfurthrinforation:Broche1975,1979,198')aswell?as?roscheandSchuh1998."], "labels": ["WRONG"]}, "correct": {"tokens": ["Nowadays", "the", "concept", "that", "the", "tidal", "braking", "effect", "of", "the", "earth", "rotation", "is", "caused", "by", "the", "gravitational", "force", "of", "the", "moon", "acting", "on", "the", "viscous", "oceanic", "waters", "around", "the", "earth", "is", "accepted", "in", "general.", "With", "respect", "to", "the", "details", "of", "this", "braking", "mechanism", "several", "models", "were", "proposed", "and", "theoretically", "investigated", "in", "detail,", "including", "numerical", "computer", "calculation.", "We", "refrain", "from", "reviewing", "the", "historically", "first", "ideas", "and", "the", "afterwards", "following", "publications", "on", "this", "subject,", "but", "we", "rather", "cite", "some", "previous", "papers,", "where", "the", "interested", "reader", "can", "find", "further", "information:", "Brosche", "1975,", "1979,", "1989", "as", "well", "as", "Brosche", "and", "Schuh", "1998."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["Nowadaystheconceptthatthetidalbrakingeffectoftheearthrotationiscausedbythegravitationalforceofthemoonactingontheviscousoceanicwatersazotradthe\\earthisacceptedingeneral.Withrespecttothedetatlsofthisbrakinsmechanismseveralm\\odelswereproposedandtheor(,typically", "investigated", "in", "detail,\\includingnumericalcOmputercalculation.?Wer.efra~.nfromreviewingthhistorlcallyf~rsti(leasandtheafterW~rdsfo!lowIngpublicatonsonthissub~ect,butwer~Lthercitesomepreviouspapers,whe\\retheinterestedrammeadercanfindfurthrinforation:Broche1975,1979,198')as", "well?as?waschhandSchuh", "1998."], "labels": ["WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR"]}, "BS-bid-OCR": {"tokens": ["Nowadays", "the", "concept", "that", "the", "tidal", "braking", "effect", "of", "the", "earth", "rotation", "is", "caused", "by", "the", "gravitational", "force", "of", "the", "moon", "acting", "on", "the", "viscous", "oceanic", "waters", "azotrad", "the\\", "earth", "is", "accepted", "in", "general.", "With", "respect", "to", "the", "detatls", "of", "this", "brakins", "mechanism", "several", "m\\odels", "were", "proposed", "and", "theor(,tically", "investigated", "in", "detail,\\", "including", "numerical", "cOmputer", "calculation.?", "We", "r.efra~.n", "from", "reviewing", "th", "historlcally", "f~rst", "i(leas", "and", "the", "afterW~rds", "fo!lowIng", "publicatons", "on", "this", "sub~ect,", "but", "we", "r~Lther", "cite", "some", "previous", "papers,", "whe\\re", "the", "interested", "rammeader", "can", "find", "furthr", "inforation:", "Broche", "1975,", "1979,", "198')", "as", "well", "?as", "?rosche", "and", "Schuh", "1998."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["Nowadays", "the", "concept", "that", "the", "tidal", "braking", "effect", "of", "the", "earth", "rotation", "is", "caused", "by", "the", "gravitational", "force", "of", "the", "moon", "acting", "on", "the", "viscous", "oceanic", "waters", "azotrad", "the\\", "earth", "is", "accepted", "in", "general.", "With", "respect", "to", "the", "details", "of", "this", "brackins", "mechanism", "several", "m\\odels", "were", "proposed", "and", "theor(,tically", "investigated", "in", "detail,\\", "including", "numerical", "cOmputer", "calculation.?", "We", "refrain", "from", "reviewing", "the", "historically", "f~rst", "i(leas", "and", "the", "afterW~rds", "followIng", "publications", "on", "this", "sub~ect,", "but", "we", "r~Lther", "cite", "some", "previous", "papers,", "whe\\re", "the", "interested", "reader", "can", "find", "further", "information:", "Broche", "1975,", "1979,", "198')", "as", "well", "?as", "?rosche", "and", "Schuh", "1998."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["The\u03b4V?ischosentobeabout3%ofthevlumeV.TheenergyU(V+\u03b4V)iscalculatedeverytimeaMonteCarlomoweisaccepted."], "labels": ["WRONG"]}, "correct": {"tokens": ["The", "\u03b4V", "is", "chosen", "to", "be", "about", "3%", "of", "the", "volume", "V.", "The", "energy", "U(V", "+", "\u03b4V)", "is", "calculated", "every", "time", "a", "Monte", "Carlo", "move", "is", "accepted."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["The\u03b4V?ischosentobeabout3%of", "the", "lumeN.The", "energy(V+\u03b4V)iscalculatedeverytimeaMonteCarlomoweisaccepted."], "labels": ["WRONG", "TOKENIZATION_ERROR", "WRONG", "WRONG"]}, "BS-bid-OCR": {"tokens": ["The", "\u03b4V?", "is", "chosen", "to", "be", "about", "3%", "of", "the", "vlume", "V.", "The", "energy", "U(V", "+", "\u03b4V)", "is", "calculated", "every", "time", "a", "Monte", "Carlo", "mowe", "is", "accepted."], "labels": ["TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["The", "\u03b4V", "is", "chosen", "to", "be", "about", "3%", "of", "the", "volume", "V.", "The", "energy", "U(V", "+", "\u03b4V)", "is", "calculated", "every", "time", "a", "Monte", "Carlo", "mowe", "is", "accepted."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["ItisworthnotingthattheLegendrtransformthatweinroducedinequations(4)and(5)?invo'lveabinaryopera?tionthatcanbeviewedasagneralizationo,frhePoissonBracket.Indeed,takingintoaccounttilepal'tialderivativeidentities(7),wecanwritetheequation(4)asfollows"], "labels": ["WRONG"]}, "correct": {"tokens": ["It", "is", "worth", "noting", "that", "the", "Legendre", "transforms", "that", "we", "introduced", "in", "equations", "(4)", "and", "(5)", "involve", "a", "binary", "operation", "that", "can", "be", "viewed", "as", "a", "generalization", "of", "the", "Poisson", "Bracket.", "Indeed,", "taking", "into", "account", "the", "partial", "derivative", "identities", "(7),", "we", "can", "write", "the", "equation", "(4)", "as", "follows"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["ItisworthnotingthattheLegendrtransformthatweinroducedinequations(4)and(5)?invo'lveabinaryopera?tionthatcanbeviewedasagneralizationo,frhePoissonBracket.Indeed,takingintoaccounttilepal'tialderivativeidentities(7),we", "can", "write", "the", "equation(4)as", "follows"], "labels": ["WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR"]}, "BS-bid-OCR": {"tokens": ["It", "is", "worth", "noting", "that", "the", "Legendr", "transform", "that", "we", "inroduced", "in", "equations", "(4)", "and", "(5)?", "invo'lve", "a", "binary", "opera?tion", "that", "can", "be", "viewed", "as", "a", "gneralization", "o,f", "rhe", "Poisson", "Bracket.", "Indeed,", "taking", "into", "account", "tile", "pal'tial", "derivative", "identities", "(7),", "we", "can", "write", "the", "equation", "(4)", "as", "follows"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["It", "is", "worth", "noting", "that", "the", "Legendr", "transform", "that", "we", "introduced", "in", "equations", "(4)", "and", "(5)?", "involve", "a", "binary", "operation", "that", "can", "be", "viewed", "as", "a", "generalization", "of", "the", "Poisson", "Bracket.", "Indeed,", "taking", "into", "account", "tile", "partial", "derivative", "identities", "(7),", "we", "can", "write", "the", "equation", "(4)", "as", "follows"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["WecacombinetheaBovethuoremssothatltiseasytoseehowtheyapplytoourproblem."], "labels": ["WRONG"]}, "correct": {"tokens": ["We", "can", "combine", "the", "above", "theorems", "so", "that", "it", "is", "easy", "to", "see", "how", "they", "apply", "to", "our", "problem."], "labels": ["TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["WecacombinetheaBovethuoremssothatltiseasytoseehowtheyapplytoourproblem."], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["We", "ca", "combine", "the", "aBove", "thuorems", "so", "that", "lt", "is", "easy", "to", "see", "how", "they", "apply", "to", "our", "problem."], "labels": ["TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["We", "can", "combine", "the", "aBove", "theorems", "so", "that", "it", "is", "easy", "to", "see", "how", "they", "apply", "to", "our", "problem."], "labels": ["TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["Nora-localvariabIesnelectrodynamics"], "labels": ["WRONG"]}, "correct": {"tokens": ["Non-local", "variables", "in", "electrodynamics"], "labels": ["MIXED", "MIXED", "MIXED", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["Nora-localvariabIes", "electrodynamics"], "labels": ["WRONG", "TOKENIZATION_ERROR"]}, "BS-bid-OCR": {"tokens": ["Nora-local", "variabIes", "n", "electrodynamics"], "labels": ["WRONG", "WRONG", "WRONG", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["Nora-local", "variabLes", "in", "electrodynamics"], "labels": ["WRONG", "WRONG", "MIXED", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["Therequirmentforthemodelapparatus(K,\u03c3,U,B)todescribeameasurementofheobsctvableAisthattheontcomedist~ibu~ionisidenticalw1ththprobabilitydistributionfAin1.hestate\u03c1(t),i.e.,"], "labels": ["WRONG"]}, "correct": {"tokens": ["The", "requirement", "for", "the", "model", "apparatus", "(K,", "\u03c3,", "U,", "B)", "to", "describe", "a", "measurement", "of", "the", "observable", "A", "is", "that", "the", "outcome", "distribution", "is", "identical", "with", "the", "probability", "distribution", "of", "A", "in", "the", "state", "\u03c1(t),", "i.e.,"], "labels": ["TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["Therequirmentforthemodelapparatus(K,\u03c3,U,B)todescribeameasurementofheobsctvableAisthattheontcomedist~ibu~ionisidenticalw1ththprobabilitydistributionfAin1.hestate\u03c1(t),i.e.,"], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["The", "requirment", "for", "the", "model", "apparatus", "(K,", "\u03c3,", "U,", "B)", "to", "describe", "a", "measurement", "of", "he", "obsctvable", "A", "is", "that", "the", "ontcome", "dist~ibu~ion", "is", "identical", "w1th", "th", "probability", "distribution", "f", "A", "in", "1.he", "state", "\u03c1(t),", "i.e.,"], "labels": ["TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["The", "requirement", "for", "the", "model", "apparatus", "(K,", "\u03c3,", "U,", "B)", "to", "describe", "a", "measurement", "of", "the", "observable", "A", "is", "that", "the", "outcome", "dist~ibu~ion", "is", "identical", "w1th", "the", "probability", "distribution", "f", "A", "in", "1.he", "state", "\u03c1(t),", "i.e.,"], "labels": ["TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["evaluatedat\u03b1apt,increasesbyincr?easing(P1,P2)bythesamefactorordecreasingW."], "labels": ["WRONG"]}, "correct": {"tokens": ["evaluated", "at", "\u03b1opt,", "increases", "by", "increasing", "(P1,P2)", "by", "the", "same", "factor", "or", "decreasing", "W."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["evaluatedat\u03b1apt,increases", "by", "increasing(P1,P2)bythesamefactorordecreasingW."], "labels": ["WRONG", "TOKENIZATION_ERROR", "WRONG"]}, "BS-bid-OCR": {"tokens": ["evaluated", "at", "\u03b1apt,", "increases", "by", "incr?easing", "(P1,", "P2)", "by", "the", "same", "factor", "or", "decreasing", "W."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["evaluated", "at", "\u03b1apt,", "increases", "by", "increasing", "(P1,", "P2)", "by", "the", "same", "factor", "or", "decreasing", "W."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["Letusstartwith(i).Thetransfol'matio~Vwith"], "labels": ["WRONG"]}, "correct": {"tokens": ["Let", "us", "start", "with", "(i).", "The", "transformation", "V", "with"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["Letusstartwith(i).The", "Transformation", "With"], "labels": ["WRONG", "WRONG", "WRONG"]}, "BS-bid-OCR": {"tokens": ["Let", "us", "start", "with", "(i).", "The", "transfol'matio~", "V", "with"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["Let", "us", "start", "with", "(i).", "The", "transformation~", "V", "with"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["Rclet'ences"], "labels": ["WRONG"]}, "correct": {"tokens": ["References"], "labels": ["OCR_ERROR"]}, "predicted": {"google": {"tokens": ["Rclet'ences"], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["Rclet'ences"], "labels": ["WRONG"]}, "BS-bid-OCR+google": {"tokens": ["Rclet'ences"], "labels": ["WRONG"]}}}, {"corrupt": {"tokens": ["Fromtheexpresion,theL0regularizedMLEfor\u03b2is"], "labels": ["WRONG"]}, "correct": {"tokens": ["From", "the", "expression,", "the", "L0", "regularized", "MLE", "for", "\u03b2", "is"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["From", "Expresion,theL0regularizedMLEfor\u03b2is"], "labels": ["TOKENIZATION_ERROR", "WRONG"]}, "BS-bid-OCR": {"tokens": ["From", "the", "expresion,", "the", "L0", "regularized", "MLE", "for", "\u03b2", "is"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["From", "the", "expresion,", "the", "L0", "regularized", "MLE", "for", "\u03b2", "is"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["Ratelimi~forphotoassociationofaBhse-Eins(;eincon(\\[ensate"], "labels": ["WRONG"]}, "correct": {"tokens": ["Rate", "limit", "for", "photoassociation", "of", "a", "Bose-Einstein", "condensate"], "labels": ["TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED"]}, "predicted": {"google": {"tokens": ["Ratelimi~forphotoassociationofaBhse-Eins(;rincon(\\[ensate"], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["Rate", "limi~", "for", "photoassociation", "of", "a", "Bhse-Eins(;ein", "con(\\[ensate"], "labels": ["TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG"]}, "BS-bid-OCR+google": {"tokens": ["Rate", "limit~", "for", "photoassociation", "of", "a", "Bhse-Eins(;ein", "con(\\[ensate"], "labels": ["TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG"]}}}, {"corrupt": {"tokens": ["~ivenby"], "labels": ["WRONG"]}, "correct": {"tokens": ["given", "by"], "labels": ["MIXED", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["~ivenby"], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["~iven", "by"], "labels": ["WRONG", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["~iven", "by"], "labels": ["WRONG", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["Asourtoyuniverseexpands,weassumethatthehtwofluidsobeyEinsteinequationsandthereforethe~scaleas"], "labels": ["WRONG"]}, "correct": {"tokens": ["As", "our", "toy", "universe", "expands,", "we", "assume", "that", "the", "two", "fluids", "obey", "Einstein", "equations", "and", "therefore", "they", "scale", "as"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["Asourtoyuniverseexpands,weassumethatthehtwofluidsobeyEinsteinequationsandthereforethe~scaleas"], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["As", "our", "toy", "universe", "expands,", "we", "assume", "that", "theh", "two", "fluids", "obey", "Einstein", "equations", "and", "therefore", "the~", "scale", "as"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["As", "our", "toy", "universe", "expands,", "we", "assume", "that", "the", "two", "fluids", "obey", "Einstein", "equations", "and", "therefore", "the~", "scale", "as"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["and"], "labels": ["NONE"]}, "correct": {"tokens": ["and"], "labels": ["NONE"]}, "predicted": {"google": {"tokens": ["and"], "labels": ["NONE"]}, "BS-bid-OCR": {"tokens": ["and"], "labels": ["NONE"]}, "BS-bid-OCR+google": {"tokens": ["and"], "labels": ["NONE"]}}}, {"corrupt": {"tokens": ["OurworkisanadditiontothevUnel'ylimitedliteramtureonbothpriingwithnegativenetworkexternalitjesanditerativepricLcg.Themodelcapturcsmnyint~restingsettingsinreal-worldmarketing,andisusuallymuchmorechallengingthanthepositiveexerna\\litycounterpart.The4hardllessresultidentifiescumplex\\itystatusolafundamentalpricingproblem..Thealgorithmsachi'evesatislactoryperformancesingeneralandseveralimportantspecial?ettings.?AninTeres.ingdirectionforfuturerese?archistonarrowthelowerandupperboundsontheapproximabilityoftheiterativepricingproblemwithnegtiveexternal?ity.ObtainingmoreaccUrateestimationsortaoptidema!pricingisakeytoreducetheapproxi*mationratios."], "labels": ["WRONG"]}, "correct": {"tokens": ["Our", "work", "is", "an", "addition", "to", "the", "very", "limited", "literature", "on", "both", "pricing", "with", "negative", "network", "externalities", "and", "iterative", "pricing.", "The", "model", "captures", "many", "interesting", "settings", "in", "real-world", "marketing,", "and", "is", "usually", "much", "more", "challenging", "than", "the", "positive", "externality", "counterpart.", "The", "hardness", "result", "identifies", "complexity", "status", "of", "a", "fundamental", "pricing", "problem.", "The", "algorithms", "achieve", "satisfactory", "performances", "in", "general", "and", "several", "important", "special", "settings.", "An", "interesting", "direction", "for", "future", "research", "is", "to", "narrow", "the", "lower", "and", "upper", "bounds", "on", "the", "approximability", "of", "the", "iterative", "pricing", "problem", "with", "negative", "externality.", "Obtaining", "more", "accurate", "estimations", "for", "the", "optimal", "pricing", "is", "a", "key", "to", "reduce", "the", "approximation", "ratios."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["OurworkisanadditiontothevUnel'ylimitedliteramtureonbothpriingwithnegativenetworkexternalitjesanditerativepricLcg.Themodelcapturcsmnyint~restingsettingsinreal-worldmarketing,andisusuallymuchmorechallengingthanthepositiveexerna\\litycounterpart.The4hardllessresultidentifiescumplex\\itystatusolafundamentalpricingproblem..Thealgorithmsachi'evesatislactoryperformancesingeneralandseveralimportantspecial?ettings.?AninTeres.ingdirectionforfuturerese?archistonarrowthelowerandupperboundsontheapproximabilityoftheiterativepricingproblemwithnegtiveexternal?ity.ObtainingmoreaccUrateestimationsortaoptidema!pricingisakeytoreducetheapproxi*mationratios."], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["Our", "work", "is", "an", "addition", "to", "the", "vUnel'y", "limited", "literamture", "on", "both", "priing", "with", "negative", "network", "externalitjes", "and", "iterative", "pricLcg.", "The", "model", "capturcs", "mny", "int~resting", "settings", "in", "real-world", "marketing,", "and", "is", "usually", "much", "more", "challenging", "than", "the", "positive", "exerna\\lity", "counterpart.", "The4", "hardlless", "result", "identifies", "cumplex\\ity", "status", "ol", "a", "fundamental", "pricing", "problem..", "The", "algorithms", "achi'eve", "satislactory", "performances", "in", "general", "and", "several", "important", "special", "?ettings.", "?An", "inTeres.ing", "direction", "for", "future", "rese?arch", "is", "to", "narrow", "the", "lower", "and", "upper", "bounds", "on", "the", "approximability", "of", "the", "iterative", "pricing", "problem", "with", "negtive", "external?ity.", "Obtaining", "more", "accUrate", "estimations", "or", "ta", "optidema!", "pricing", "is", "a", "key", "to", "reduce", "the", "approxi*mation", "ratios."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["Our", "work", "is", "an", "addition", "to", "the", "vUnel'y", "limited", "literature", "on", "both", "pricing", "with", "negative", "network", "externalities", "and", "iterative", "price", "Lcg.", "The", "model", "captures", "many", "int~resting", "settings", "in", "real-world", "marketing,", "and", "is", "usually", "much", "more", "challenging", "than", "the", "positive", "exerna\\lity", "counterpart.", "The4", "hardness", "result", "identifies", "cumplex\\ity", "status", "of", "a", "fundamental", "pricing", "problem..", "The", "algorithms", "achieve", "satisfactory", "performances", "in", "general", "and", "several", "important", "special", "settings.", "An", "inTeres.ing", "direction", "for", "future", "research", "is", "to", "narrow", "the", "lower", "and", "upper", "bounds", "on", "the", "approximability", "of", "the", "iterative", "pricing", "problem", "with", "negative", "externality.", "Obtaining", "more", "accUrate", "estimations", "or", "ta", "optidema!", "pricing", "is", "a", "key", "to", "reduce", "the", "approxi*mation", "ratios."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["Fil,al\\ly,wewillmakeuseof:"], "labels": ["WRONG"]}, "correct": {"tokens": ["Finally,", "we", "will", "make", "use", "of:"], "labels": ["MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["Fil,al\\ly,we", "will", "makeuseof:"], "labels": ["WRONG", "TOKENIZATION_ERROR", "WRONG"]}, "BS-bid-OCR": {"tokens": ["Fil,al\\ly,", "we", "will", "make", "use", "of:"], "labels": ["WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["Fil,al\\ly,", "we", "will", "make", "use", "of:"], "labels": ["WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["whereforBosestatisticsmat,dsinthesummationarearbi.rary,butforFemistatisticsthesummationincludeeonlysuchmandnforwhichm+niseven.Thelatterrestricliontakes~ntoaccunttheconservationofhalf-integerspinsoffer?mion.ThequantityArnndoesnotdp\\evdenthefieldoperators.ThefrmofP\u0302mnhereisthesamesinEq.(12),bul;withexplicibtlyshownvari~ble."], "labels": ["WRONG"]}, "correct": {"tokens": ["where", "for", "Bose", "statistics", "m", "and", "n", "in", "the", "summation", "are", "arbitrary,", "but", "for", "Fermi", "statistics", "the", "summation", "includes", "only", "such", "m", "and", "n", "for", "which", "m", "+", "n", "is", "even.", "The", "latter", "restriction", "takes", "into", "account", "the", "conservation", "of", "half-integer", "spins", "of", "fermions.", "The", "quantity", "Amn", "does", "not", "depend", "on", "the", "field", "operators.", "The", "form", "of", "P\u0302mn", "here", "is", "the", "same", "as", "in", "Eq.", "(12),", "but", "with", "explicitly", "shown", "variables."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED"]}, "predicted": {"google": {"tokens": ["whereforBosestatisticsmat,dsinthesummationarearbi.rary,butforFemistatisticsthesummationincludeeonlysuchmandnforwhichm+niseven.Thelatterrestricliontakes~ntoaccunttheconservationofhalf-integerspinsoffer?mion.ThequantityArnndoesnotdp\\evdenthefieldoperators.ThefrmofP\u0302mnhereisthesamesinEq.(12),bul;withexplicibtlyshownvari~ble."], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["where", "for", "Bose", "statistics", "mat,ds", "in", "the", "summation", "are", "arbi.rary,", "but", "for", "Femi", "statistics", "the", "summation", "includee", "only", "such", "m", "and", "n", "for", "which", "m", "+", "n", "is", "even.", "The", "latter", "restriclion", "takes", "~nto", "accunt", "the", "conservation", "of", "half-integer", "spins", "of", "fer?mion.", "The", "quantity", "Arnn", "does", "not", "dp\\evden", "the", "field", "operators.", "The", "frm", "of", "P\u0302mn", "here", "is", "the", "same", "s", "in", "Eq.", "(12),", "bul;", "with", "explicibtly", "shown", "vari~ble."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG"]}, "BS-bid-OCR+google": {"tokens": ["where", "for", "Bose", "statistics", "mat,ds", "in", "the", "summation", "are", "arbi.rary,", "but", "for", "Femi", "statistics", "the", "summation", "includes", "only", "such", "m", "and", "n", "for", "which", "m", "+", "n", "is", "even.", "The", "latter", "restriction", "takes", "~into", "account", "the", "conservation", "of", "half-integer", "spins", "of", "fermion.", "The", "quantity", "Arnn", "does", "not", "dp\\evden", "the", "field", "operators.", "The", "form", "of", "Pmn", "here", "is", "the", "same", "as", "in", "Eq.", "(12),", "bul;", "with", "explicitly", "shown", "vari~ble."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "WRONG", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "WRONG"]}}}, {"corrupt": {"tokens": ["LetussplitEasfollows"], "labels": ["WRONG"]}, "correct": {"tokens": ["Let", "us", "split", "E", "as", "follows"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["LetussplitEasfollows"], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["Let", "us", "split", "E", "as", "follows"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["Let", "us", "split", "E", "as", "follows"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["Al.lthatremainsistofindasuitablelowerboundforMk."], "labels": ["WRONG"]}, "correct": {"tokens": ["All", "that", "remains", "is", "to", "find", "a", "suitable", "lower", "bound", "for", "Mk."], "labels": ["MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["Al.lthatremainsistofindasuitablelowerboundforMk."], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["Al.l", "that", "remains", "is", "to", "find", "a", "suitable", "lower", "bound", "for", "Mk."], "labels": ["WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["All", "that", "remains", "is", "to", "find", "a", "suitable", "lower", "bound", "for", "Mk."], "labels": ["MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["Accordingly,tilewa~?efunctionfoxtheboudstateforthiscaseis"], "labels": ["WRONG"]}, "correct": {"tokens": ["Accordingly,", "the", "wave", "function", "for", "the", "bound", "state", "for", "this", "case", "is"], "labels": ["TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["Accordingly,tilewa~?efunctionfoxtheboudstateforthiscaseis"], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["Accordingly,", "tile", "wa~?e", "function", "fox", "the", "boud", "state", "for", "this", "case", "is"], "labels": ["TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["Accordingly,", "tile", "wa~?e", "function", "fox", "the", "bound", "state", "for", "this", "case", "is"], "labels": ["TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["Wehav;ointroducedin--thispapertwonotfions:(leftrright)lo~erinvamiance(abbreviatedLI)and(leftorrighl)lowerseinicoetinuity(abbreviatedLSC).Theeeno{,ionsdescr?ibethebehavionrOfi,ntegralfunEtionals?oftheform:"], "labels": ["WRONG"]}, "correct": {"tokens": ["We", "have", "introduced", "in", "this", "paper", "two", "notions:", "(left", "or", "right)", "lower", "invariance", "(abbreviated", "LI)", "and", "(left", "or", "right)", "lower", "semicontinuity", "(abbreviated", "LSC).", "These", "notions", "describe", "the", "behaviour", "of", "integral", "functionals", "of", "the", "form:"], "labels": ["TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "MIXED", "TOKENIZATION_ERROR", "MIXED", "MIXED", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["Wehav;ointroducedin--thispapertwonotfions:(left", "right)lo~invariance(abbreviatedLI)and(leftorright)lowerseinicoetinuity(abbreviatedLSC).Theano{,ionsdescr?ibethebehavionrOfi,ntegralfunEtionals?oftheform:"], "labels": ["WRONG", "WRONG"]}, "BS-bid-OCR": {"tokens": ["We", "hav;o", "introduced", "in", "--this", "paper", "two", "notfions:", "(left", "rright)", "lo~er", "invamiance", "(abbreviated", "LI)", "and", "(left", "or", "righl)", "lower", "seinicoetinuity", "(abbreviated", "LSC).", "Theee", "no{,ions", "descr?ibe", "the", "behavionr", "Of", "i,ntegral", "funEtionals?", "of", "the", "form:"], "labels": ["TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "WRONG", "TOKENIZATION_ERROR", "WRONG", "WRONG", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["We", "have;to", "introduced", "in", "--this", "paper", "two", "notions:", "(left", "right)", "lo~er", "invamiance", "(abbreviated", "LI)", "and", "(left", "or", "right)", "lower", "semicontinuity", "(abbreviated", "LSC).", "Three", "no{,ions", "describe", "the", "behavior", "Of", "integral", "funCtionals?", "of", "the", "form:"], "labels": ["TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "MIXED", "TOKENIZATION_ERROR", "WRONG", "WRONG", "MIXED", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["Inthispaper,wepresentmultiple5tiordalrRK\\Nmethodswithbothrealandcomplexstepsizecoefficients.Weputspecialemphasison.me\\thodswithcoefftcientsthathavesmall,positiverealparts,andpuelglmaginaryleadingerrorterms."], "labels": ["WRONG"]}, "correct": {"tokens": ["In", "this", "paper,", "we", "present", "multiple", "5th", "order", "RKN", "methods", "with", "both", "real", "and", "complex", "step", "size", "coefficients.", "We", "put", "special", "emphasis", "on", "methods", "with", "coefficients", "that", "have", "small,", "positive", "real", "parts,", "and", "purely", "imaginary", "leading", "error", "terms."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["Inthispaper,wepresentmultiple5tiordalrRK\\Nmethodswithbothrealandcomplexstepsizecoefficients.Weputspecialemphasison.me\\thodswithcoefftcientsthathavesmall,positiverealparts,andpuelglmaginaryleadingerrorterms."], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["In", "this", "paper,", "we", "present", "multiple", "5tiordalr", "RK\\N", "methods", "with", "both", "real", "and", "complex", "stepsize", "coefficients.", "We", "put", "special", "emphasis", "on", ".me\\thods", "with", "coefftcients", "that", "have", "small,", "positive", "real", "parts,", "and", "puelg", "lmaginary", "leading", "error", "terms."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["In", "this", "paper,", "we", "present", "multiple", "5tiordalr", "RK\\AND", "methods", "with", "both", "real", "and", "complex", "step", "size", "coefficients.", "We", "put", "special", "emphasis", "on", ".me\\thods", "with", "coefficients", "that", "have", "small,", "positive", "real", "parts,", "and", "purely", "imaginary", "leading", "error", "terms."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["Thispaperhasdescribedtheminimaleffectvefieldtheoyformalismneededmtoexplorethclow-energyimplicationsofa3-blaneuniverse.Itappe\\arsrelativelystraightforwardtogeneralizetilepresentfameworkinseveraldirections,forexample,addingnon-minimalbulkfields,makingt??heformalisrdmsupcrsymnetrlc,(:onsideringlnorecomplicatedpacetimetopologies,orconsideringmorethanonebrane?eml)eddedinthebulkspa~etime."], "labels": ["WRONG"]}, "correct": {"tokens": ["This", "paper", "has", "described", "the", "minimal", "effective", "field", "theory", "formalism", "needed", "to", "explore", "the", "low-energy", "implications", "of", "a", "3-brane", "universe.", "It", "appears", "relatively", "straightforward", "to", "generalize", "the", "present", "framework", "in", "several", "directions,", "for", "example,", "adding", "non-minimal", "bulk", "fields,", "making", "the", "formalism", "supersymmetric,", "considering", "more", "complicated", "spacetime", "topologies,", "or", "considering", "more", "than", "one", "brane", "embedded", "in", "the", "bulk", "spacetime."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "MIXED", "MIXED", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED"]}, "predicted": {"google": {"tokens": ["Thispaperhasdescribedtheminimaleffectvefieldtheoyformalismneededmtoexplorethclow-energyimplicationsofa3-blaneuniverse.Itappe\\arsrelativelystraightforwardtogeneralizetilepresentfameworkinseveraldirections,forexample,addingnon-minimalbulkfields,makingt??heformalisrdmsupcrsymnetrlc,(:considering", "norecomplicatedpacetimetopologies,orconsideringmorethanonebrane?eml)eddedinthebulkspa~etime."], "labels": ["WRONG", "WRONG"]}, "BS-bid-OCR": {"tokens": ["This", "paper", "has", "described", "the", "minimal", "effectve", "field", "theoy", "formalism", "needed", "mto", "explore", "thc", "low-energy", "implications", "of", "a", "3-blane", "universe.", "It", "appe\\ars", "relatively", "straightforward", "to", "generalize", "tile", "present", "famework", "in", "several", "directions,", "for", "example,", "adding", "non-minimal", "bulk", "fields,", "making", "t??he", "formalisrdm", "supcrsymnetrlc,", "(:onsidering", "lnore", "complicated", "pacetime", "topologies,", "or", "considering", "more", "than", "one", "brane", "?eml)edded", "in", "the", "bulk", "spa~etime."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "WRONG", "WRONG", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG"]}, "BS-bid-OCR+google": {"tokens": ["This", "paper", "has", "described", "the", "minimal", "effective", "field", "theory", "formalism", "needed", "to", "explore", "the", "low-energy", "implications", "of", "a", "3-blane", "universe.", "It", "appe\\ars", "relatively", "straightforward", "to", "generalize", "tile", "present", "framework", "in", "several", "directions,", "for", "example,", "adding", "non-minimal", "bulk", "fields,", "making", "the", "formalism", "rdm", "supcr", "symnet", "rlc,", "(:considering", "more", "complicated", "pacetime", "topologies,", "or", "considering", "more", "than", "one", "brane", "?eml)added", "in", "the", "bulk", "spacetime."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "WRONG", "WRONG", "WRONG", "WRONG", "WRONG", "MIXED", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED"]}}}, {"corrupt": {"tokens": ["Concl.usion"], "labels": ["WRONG"]}, "correct": {"tokens": ["Conclusion"], "labels": ["OCR_ERROR"]}, "predicted": {"google": {"tokens": ["Conclusion"], "labels": ["OCR_ERROR"]}, "BS-bid-OCR": {"tokens": ["Concl.usion"], "labels": ["WRONG"]}, "BS-bid-OCR+google": {"tokens": ["Conclusion"], "labels": ["OCR_ERROR"]}}}, {"corrupt": {"tokens": ["N=2SupersymmetricComposi?tAbelianHi~gsmodel"], "labels": ["WRONG"]}, "correct": {"tokens": ["N=2", "Supersymmetric", "Composite", "Abelian", "Higgs", "model"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["N=2SupersymmetricComposi?tAbelianHi~gs", "model"], "labels": ["WRONG", "TOKENIZATION_ERROR"]}, "BS-bid-OCR": {"tokens": ["N", "=", "2", "Supersymmetric", "Composi?t", "Abelian", "Hi~gs", "model"], "labels": ["WRONG", "WRONG", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["N", "=", "2", "Supersymmetric", "Composite", "Abelian", "Hi~gs", "model"], "labels": ["WRONG", "WRONG", "WRONG", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["TheimmedimteobjectiontoGolndeni?stheu-seofirrationalntlmbers?andthe\"possibilityofcomputererrorduetolruncation.Using64bitl'ongand64bitoubleinJavaGoledenfailedatF75,differingby1inthea\\stdi~itfr()mAC,whichfairedatF9?fromoverflow.Notethatadoublehasfewerdigitsthmlalongofthesamecomputerbitsizerepresentation,sopfartofthisfailureisapracticallimitationduetotherepresentationofralsinthecomputer.InTable1,assumingnotruncationerror,thepredictedmaximumwithaneffectivemantisaof53bitsisatn=76,theactualmaximum,includlngtruncationerror,isatn=74.~ssumingadditionalspace,Goldenworkscor,:ectlyfori~nyin."], "labels": ["WRONG"]}, "correct": {"tokens": ["The", "immediate", "objection", "to", "Golden", "is", "the", "use", "of", "irrational", "numbers", "and", "the", "possibility", "of", "computer", "error", "due", "to", "truncation.", "Using", "64", "bit", "long", "and", "64", "bit", "double", "in", "Java,", "Golden", "failed", "at", "F75,", "differing", "by", "1", "in", "the", "last", "digit", "from", "AC,", "which", "failed", "at", "F93", "from", "overflow.", "Note", "that", "a", "double", "has", "fewer", "digits", "than", "a", "long", "of", "the", "same", "computer", "bit", "size", "representation,", "so", "part", "of", "this", "failure", "is", "a", "practical", "limitation", "due", "to", "the", "representation", "of", "reals", "in", "the", "computer.", "In", "Table", "1,", "assuming", "no", "truncation", "error,", "the", "predicted", "maximum", "with", "an", "effective", "mantissa", "of", "53", "bits", "is", "at", "n", "=", "76,", "the", "actual", "maximum,", "including", "truncation", "error,", "is", "at", "n", "=", "74.", "Assuming", "additional", "space,", "Golden", "works", "correctly", "for", "any", "n."], "labels": ["TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["TheimmedimteobjectiontoGolndeni?stheu-seofirrationalntlmbers?andthe\"possibilityofcomputererrorduetolruncation.Using64bitl'ongand64bitoubleinJavaGoledenfailedatF75,differing", "by", "1", "thea\\stdi~itfr()mAC,which", "fareeda", "tF9?fromoverflow.Notethatadoublehasfewerdigitsthmlalongofthesamecomputerbitsizerepresentation,sopfartofthisfailureisapracticallimitationduetotherepresentationofralsinthecomputer.InTable1,assumingnotruncationerror,thepredictedmaximumwithaneffectivemantisaof53bitsisatn=76,getactualmaximum,includl", "truncation", "error,isatn=74.~ssumingadditionalspace,Goldenworkscor,:ectlyfori~nyin."], "labels": ["WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "WRONG", "TOKENIZATION_ERROR", "WRONG"]}, "BS-bid-OCR": {"tokens": ["The", "immedimte", "objection", "to", "Golnden", "i?s", "the", "u-se", "of", "irrational", "ntlmbers?", "and", "the", "\"possibility", "of", "computer", "error", "due", "to", "lruncation.", "Using", "64", "bitl'ong", "and", "64", "bit", "ouble", "in", "Java", "Goleden", "failed", "at", "F75,", "differing", "by", "1", "in", "the", "a\\st", "di~it", "fr()m", "AC,", "which", "faired", "at", "F9?", "from", "overflow.", "Note", "that", "a", "double", "has", "fewer", "digits", "thml", "a", "long", "of", "the", "same", "computer", "bit", "size", "representation,", "so", "pfart", "of", "this", "failure", "is", "a", "practical", "limitation", "due", "to", "the", "representation", "of", "rals", "in", "the", "computer.", "In", "Table", "1,", "assuming", "no", "truncation", "error,", "the", "predicted", "maximum", "with", "an", "effective", "mantisa", "of", "53", "bits", "is", "at", "n", "=", "76,", "the", "actual", "maximum,", "includlng", "truncation", "error,", "is", "at", "n", "=", "74.", "~ssuming", "additional", "space,", "Golden", "works", "cor,:ectly", "for", "i~nyin."], "labels": ["TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG"]}, "BS-bid-OCR+google": {"tokens": ["The", "immediate", "objection", "to", "Golden", "is", "the", "use", "of", "irrational", "numbers?", "and", "the", "\"possibility", "of", "computer", "error", "due", "to", "truncation.", "Using", "64", "bit", "long", "and", "64", "bit", "double", "in", "Java,", "Golden", "failed", "at", "F75,", "differing", "by", "1", "in", "the", "a\\st", "do~it", "for()m", "AC,", "which", "fared", "at", "F9?", "from", "overflow.", "Note", "that", "a", "double", "has", "fewer", "digits", "thml", "a", "long", "of", "the", "same", "computer", "bit", "size", "representation,", "so", "part", "of", "this", "failure", "is", "a", "practical", "limitation", "due", "to", "the", "representation", "of", "rals", "in", "the", "computer.", "In", "Table", "1,", "assuming", "no", "truncation", "error,", "the", "predicted", "maximum", "with", "an", "effective", "mantissa", "of", "53", "bits", "is", "at", "n", "=", "76,", "the", "actual", "maximum,", "including", "truncation", "error,", "is", "at", "n", "=", "74.", "~assuming", "additional", "space,", "Golden", "works", "cor,:ectly", "for", "i~nyin."], "labels": ["TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG"]}}}, {"corrupt": {"tokens": ["Wecanthenwrite"], "labels": ["WRONG"]}, "correct": {"tokens": ["We", "can", "then", "write"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["Wecanthenwrite"], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["We", "can", "then", "write"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["We", "can", "then", "write"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["andtiln"], "labels": ["WRONG"]}, "correct": {"tokens": ["and", "then"], "labels": ["TOKENIZATION_ERROR", "MIXED"]}, "predicted": {"google": {"tokens": ["and", "tin"], "labels": ["TOKENIZATION_ERROR", "WRONG"]}, "BS-bid-OCR": {"tokens": ["and", "tiln"], "labels": ["TOKENIZATION_ERROR", "WRONG"]}, "BS-bid-OCR+google": {"tokens": ["and", "tiln"], "labels": ["TOKENIZATION_ERROR", "WRONG"]}}}, {"corrupt": {"tokens": ["AcknowledgementsWewouldliketothankHideoA0ki~orpointingoutteirproposalinthecontextofopticalndatticesandNigelcCoop(:r,SebastianHuber,LeticiaTarruell,LeiWangandAlessandroZenesiniforinsightf\\uldiscussions.eacknowlegeSNF,NCCR-QSiTand5QMS(IRCadvancedgrant)forfunding."], "labels": ["WRONG"]}, "correct": {"tokens": ["Acknowledgements", "We", "would", "like", "to", "thank", "Hideo", "Aoki", "for", "pointing", "out", "their", "proposal", "in", "the", "context", "of", "optical", "lattices", "and", "Nigel", "Cooper,", "Sebastian", "Huber,", "Leticia", "Tarruell,", "Lei", "Wang", "and", "Alessandro", "Zenesini", "for", "insightful", "discussions.", "We", "acknowledge", "SNF,", "NCCR-QSIT", "and", "SQMS", "(ERC", "advanced", "grant)", "for", "funding."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["AcknowledgementsWewouldliketothankHideoA0ki~orpointingoutteirproposalinthecontextofopticalndatticesandNigelcCoop(:r,SebastianHuber,LeticiaTarruell,LeiWangandAlessandroZenesiniforinsightf\\uldiscussions.eacknowlegeSNF,NCCR-QSiTand5QMS(ERC", "advanced", "grant)for", "funding."], "labels": ["WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR"]}, "BS-bid-OCR": {"tokens": ["Acknowledgements", "We", "would", "like", "to", "thank", "Hideo", "A0ki", "~or", "pointing", "out", "teir", "proposal", "in", "the", "context", "of", "optical", "ndattices", "and", "Nigelc", "Coop(:r,", "Sebastian", "Huber,", "Leticia", "Tarruell,", "Lei", "Wang", "and", "Alessandro", "Zenesini", "for", "insightf\\ul", "discussions.", "e", "acknowlege", "SNF,", "NCCR-QSiT", "and", "5QMS", "(IRC", "advanced", "grant)", "for", "funding."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "WRONG", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["Acknowledgements", "We", "would", "like", "to", "thank", "Hideo", "A0ki", "~or", "pointing", "out", "their", "proposal", "in", "the", "context", "of", "optical", "lattices", "and", "Nigel", "Coop(:r,", "Sebastian", "Huber,", "Leticia", "Tarruell,", "Lei", "Wang", "and", "Alessandro", "Zenesini", "for", "insightf\\ul", "discussions.", "We", "acknowledge", "SNF,", "NCCR-QSiT", "and", "5QMS", "(IRC", "advanced", "grant)", "for", "funding."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["Wehavenowprovethemaintheorem?"], "labels": ["WRONG"]}, "correct": {"tokens": ["We", "have", "now", "proved", "the", "main", "theorem."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED"]}, "predicted": {"google": {"tokens": ["Wehavenowprovethemain", "Theorem?"], "labels": ["WRONG", "WRONG"]}, "BS-bid-OCR": {"tokens": ["We", "have", "now", "prove", "the", "main", "theorem?"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG"]}, "BS-bid-OCR+google": {"tokens": ["We", "have", "now", "proven", "the", "main", "theorem?"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG"]}}}, {"corrupt": {"tokens": ["Thisprocedureispe~fectlyweldefilied,evenwhctnringsemerandleaveth\\roughthesamefacesofthecell(seealsoS.I.).Weemphasisethatthisicetakentobeadefinilionofthreading.Itisnecessarilyastrictlyloc;lmeasure,on-thescaleofthecellv0lume.Ifthecel1volullleisicreasednothrea(lingswilleventuallyberecordedsincerin~sintheell;areunlinkedbyconstructio~."], "labels": ["WRONG"]}, "correct": {"tokens": ["This", "procedure", "is", "perfectly", "well", "defined,", "even", "when", "rings", "enter", "and", "leave", "through", "the", "same", "faces", "of", "the", "cell", "(see", "also", "S.I.).", "We", "emphasise", "that", "this", "is", "taken", "to", "be", "a", "definition", "of", "threading.", "It", "is", "necessarily", "a", "strictly", "local", "measure,", "on", "the", "scale", "of", "the", "cell", "volume.", "If", "the", "cell", "volume", "is", "increased", "no", "threadings", "will", "eventually", "be", "recorded", "since", "rings", "in", "the", "melt", "are", "unlinked", "by", "construction."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED"]}, "predicted": {"google": {"tokens": ["Thisprocedureispe~fectlyweldefilied,evenwhctnringsemerandleaveth\\roughthesamefacesofthecell(see", "also.I.).Weemphasisethatthisicetakentobeadefinilionofthreading.Itisnecessarilyastrictlyloc;lmeasure,on-thescaleofthecellv0lume.Ifthecel1volullleisicreasednothrea(lingswilleventuallyberecordedsincerin~sintheell;areunlinkedbyconstructio~."], "labels": ["WRONG", "WRONG"]}, "BS-bid-OCR": {"tokens": ["This", "procedure", "is", "pe~fectly", "wel", "defilied,", "even", "whctn", "ring", "semer", "and", "leave", "th\\rough", "the", "same", "faces", "of", "the", "cell", "(see", "also", "S.I.).", "We", "emphasise", "that", "this", "ice", "taken", "to", "be", "a", "definilion", "of", "threading.", "It", "is", "necessarily", "a", "strictly", "loc;l", "measure,", "on-", "the", "scale", "of", "the", "cell", "v0lume.", "If", "the", "cel1", "volullle", "is", "icreased", "no", "threa(lings", "will", "eventually", "be", "recorded", "since", "rin~s", "in", "the", "ell;", "are", "unlinked", "by", "constructio~."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "WRONG", "TOKENIZATION_ERROR", "WRONG", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG"]}, "BS-bid-OCR+google": {"tokens": ["This", "procedure", "is", "pe~fectly", "well", "defined,", "even", "when", "ring", "semer", "and", "leave", "th\\rough", "the", "same", "faces", "of", "the", "cell", "(see", "also", "S.I.).", "We", "emphasise", "that", "this", "ice", "is", "taken", "to", "be", "a", "definition", "of", "threading.", "It", "is", "necessarily", "a", "strictly", "loc;l", "measure,", "on-", "the", "scale", "of", "the", "cell", "v0lume.", "If", "the", "cel1", "volume", "is", "increased", "no", "thread(kings", "will", "eventually", "be", "recorded", "since", "rin~s", "in", "the", "ell;", "are", "unlinked", "by", "construction~."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "MIXED", "MIXED", "TOKENIZATION_ERROR", "MIXED", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG"]}}}, {"corrupt": {"tokens": ["Onlythesphericalmorphologicaltypleisstuyiedhere.WeconcludethatmostprobablythereisalarepopulationofsphericalPNs,muchmoretha.nnon-pgshericalPNs,thataretoofainttobedetected.Thisleadstoanewestimaterega:dingthedistributiollofPNprogenitrsanddifferentENmorphologytyt)es(summarizedinsetions1and2).ThenewestimatescomparedwithpreviousonessresummarizedinTable1.."], "labels": ["WRONG"]}, "correct": {"tokens": ["Only", "the", "spherical", "morphological", "type", "is", "studied", "here.", "We", "conclude", "that", "most", "probably", "there", "is", "a", "large", "population", "of", "spherical", "PNs,", "much", "more", "than", "non-spherical", "PNs,", "that", "are", "too", "faint", "to", "be", "detected.", "This", "leads", "to", "a", "new", "estimate", "regarding", "the", "distribution", "of", "PN", "progenitors", "and", "different", "PN", "morphology", "types", "(summarized", "in", "sections", "1", "and", "2).", "The", "new", "estimates", "compared", "with", "previous", "ones", "are", "summarized", "in", "Table", "1."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED"]}, "predicted": {"google": {"tokens": ["Onlythesphericalmorphologicaltypleisstuyiedhere.WeconcludethatmostprobablythereisalarepopulationofsphericalPNs,muchmoretha.nnon-pgshericalPNs,thataretoofainttobedetected.Thisleadstoanewestimaterega:dingthedistributiollofPNprogenitrsanddifferentENmorphologytyt)es(summarized", "insertions", "1and2).ThenewestimatescomparedwithpreviousonessresummarizedinTable1.."], "labels": ["WRONG", "WRONG", "WRONG"]}, "BS-bid-OCR": {"tokens": ["Only", "the", "spherical", "morphological", "typle", "is", "stuyied", "here.", "We", "conclude", "that", "most", "probably", "there", "is", "a", "lare", "population", "of", "spherical", "PNs,", "much", "more", "tha.n", "non-pgsherical", "PNs,", "that", "are", "too", "faint", "to", "be", "detected.", "This", "leads", "to", "a", "new", "estimate", "rega:ding", "the", "distributioll", "of", "PN", "progenitrs", "and", "different", "EN", "morphology", "tyt)es", "(summarized", "in", "setions", "1", "and", "2).", "The", "new", "estimates", "compared", "with", "previous", "ones", "sre", "summarized", "in", "Table", "1.."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG"]}, "BS-bid-OCR+google": {"tokens": ["Only", "the", "spherical", "morphological", "type", "is", "studied", "here.", "We", "conclude", "that", "most", "probably", "there", "is", "a", "large", "population", "of", "spherical", "PNs,", "much", "more", "than", "non-pgsherical", "PNs,", "that", "are", "too", "faint", "to", "be", "detected.", "This", "leads", "to", "a", "new", "estimate", "rega:ding", "the", "distribution", "of", "PN", "progenitors", "and", "different", "EN", "morphology", "tyt)es", "(summarized", "in", "sections", "1", "and", "2).", "The", "new", "estimates", "compared", "with", "previous", "ones", "are", "summarized", "in", "Table", "1.."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG"]}}}, {"corrupt": {"tokens": ["ehere,asusual,tbcactionofJonr-formsIs(lefinedby"], "labels": ["WRONG"]}, "correct": {"tokens": ["where,", "as", "usual,", "the", "action", "of", "J", "on", "r-forms", "is", "defined", "by"], "labels": ["MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["ehere,asusual,tbcactionofJonr-formsIs(lefinedby"], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["ehere,", "as", "usual,", "tbc", "action", "of", "J", "on", "r-forms", "Is", "(lefined", "by"], "labels": ["WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["where,", "as", "usual,", "tbc", "action", "of", "J", "on", "r-forms", "Is", "(defined", "by"], "labels": ["MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["Accordingtomathematicalinduction,thelemmaisprored."], "labels": ["WRONG"]}, "correct": {"tokens": ["According", "to", "mathematical", "induction,", "the", "lemma", "is", "proved."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED"]}, "predicted": {"google": {"tokens": ["According", "To", "Mathematical", "Induction,the", "lemma", "is", "pro", "red."], "labels": ["TOKENIZATION_ERROR", "WRONG", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG"]}, "BS-bid-OCR": {"tokens": ["According", "to", "mathematical", "induction,", "the", "lemma", "is", "prored."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG"]}, "BS-bid-OCR+google": {"tokens": ["According", "to", "mathematical", "induction,", "the", "lemma", "is", "prored."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG"]}}}, {"corrupt": {"tokens": ["Thenashortcalchlationgives"], "labels": ["WRONG"]}, "correct": {"tokens": ["Then", "a", "short", "calculation", "gives"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["Thenashortcalchlationgives"], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["Then", "a", "short", "calchlation", "gives"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["Then", "a", "short", "calculation", "gives"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["GrowtdhandfaI)rication"], "labels": ["WRONG"]}, "correct": {"tokens": ["Growth", "and", "fabrication"], "labels": ["MIXED", "TOKENIZATION_ERROR", "MIXED"]}, "predicted": {"google": {"tokens": ["Growth", "and", "faI)rication"], "labels": ["MIXED", "TOKENIZATION_ERROR", "WRONG"]}, "BS-bid-OCR": {"tokens": ["Growtd", "hand", "faI)rication"], "labels": ["WRONG", "WRONG", "WRONG"]}, "BS-bid-OCR+google": {"tokens": ["Growth", "hand", "faI)rication"], "labels": ["MIXED", "WRONG", "WRONG"]}}}, {"corrupt": {"tokens": ["andweseetilat"], "labels": ["WRONG"]}, "correct": {"tokens": ["and", "we", "see", "that"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED"]}, "predicted": {"google": {"tokens": ["andweseetilat"], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["and", "we", "see", "tilat"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG"]}, "BS-bid-OCR+google": {"tokens": ["and", "we", "see", "tilat"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG"]}}}, {"corrupt": {"tokens": ["(iii)Rni'eali?zethedoublet-tripletsplitting,Yukawacoupling\u03a61H2H\u03032shouldbeforbiddienalthough\u03a61H3H\u03033isallowed.Thisgivestheconditienssuchas"], "labels": ["WRONG"]}, "correct": {"tokens": ["(iii)", "To", "realize", "the", "doublet-triplet", "splitting,", "Yukawa", "coupling", "\u03a61H2H\u03032", "should", "be", "forbidden", "although", "\u03a61H3H\u03033", "is", "allowed.", "This", "gives", "the", "conditions", "such", "as"], "labels": ["TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["(iii)Rni'eali?zethedoublet-tripletsplitting,Yukawacoupling\u03a61H2H\u03032shouldbeforbiddienalthough\u03a61H3H\u03033isallowed.Thisgivestheconditienssuchas"], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["(iii)", "Rn", "i'eali?ze", "the", "doublet-triplet", "splitting,", "Yukawa", "coupling", "\u03a61H2H\u03032", "should", "be", "forbiddien", "although", "\u03a61H3H\u03033", "is", "allowed.", "This", "gives", "the", "conditiens", "such", "as"], "labels": ["TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["(iii)", "Rn", "i'll", "be", "the", "doublet-triplet", "splitting,", "Yukawa", "coupling", "\u03a61H2H\u03032", "should", "be", "forbidden", "although", "\u03a61H3H\u03033", "is", "allowed.", "This", "gives", "the", "conditions", "such", "as"], "labels": ["TOKENIZATION_ERROR", "WRONG", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["TheMarkovopel'atorV\u03a0ismixing(comixing)ifandonlyifthepolymorphism\u03a0ismixing(resp.com~xing)."], "labels": ["WRONG"]}, "correct": {"tokens": ["The", "Markov", "operator", "V\u03a0", "is", "mixing", "(comixing)", "if", "and", "only", "if", "the", "polymorphism", "\u03a0", "is", "mixing", "(resp.", "comixing)."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED"]}, "predicted": {"google": {"tokens": ["TheMarkovopel'atorV\u03a0ismixing(comixing)ifandonlyifthepolymorphism\u03a0ismixing(resp.com~xing)."], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["The", "Markov", "opel'ator", "V\u03a0", "is", "mixing", "(comixing)", "if", "and", "only", "if", "the", "polymorphism", "\u03a0", "is", "mixing", "(resp.", "com~xing)."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG"]}, "BS-bid-OCR+google": {"tokens": ["The", "Markov", "operator", "V\u03a0", "is", "mixing", "(comixing)", "if", "and", "only", "if", "the", "polymorphism", "\u03a0", "is", "mixing", "(resp.", "com~xing)."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG"]}}}, {"corrupt": {"tokens": ["Notethatthelimitofthissumaskgoestotheinfinitysatisfic's"], "labels": ["WRONG"]}, "correct": {"tokens": ["Note", "that", "the", "limit", "of", "this", "sum", "as", "k", "goes", "to", "the", "infinity", "satisfies"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED"]}, "predicted": {"google": {"tokens": ["Notethatthelimitofthissumaskgoestotheinfinitysatisfic's"], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["Note", "that", "the", "limit", "of", "this", "sum", "as", "k", "goes", "to", "the", "infinity", "satisfic's"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG"]}, "BS-bid-OCR+google": {"tokens": ["Note", "that", "the", "limit", "of", "this", "sum", "as", "k", "goes", "to", "the", "infinity", "satisfices"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG"]}}}, {"corrupt": {"tokens": ["wher<'Bdisthesurfacefieldstrengthatthe\\stellarequator.Thisismatchedtoenexteriordipolarfieldalignedwiththestarspinaxis"], "labels": ["WRONG"]}, "correct": {"tokens": ["where", "Bd", "is", "the", "surface", "field", "strength", "at", "the", "stellar", "equator.", "This", "is", "matched", "to", "an", "exterior", "dipolar", "field", "aligned", "with", "the", "star", "spin", "axis"], "labels": ["MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["wher<'Bdisthesurfacefieldstrengthatthe\\stellarequator.Thisismatchedtoenexteriordipolarfieldalignedwiththestarspinaxis"], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["wher<'", "Bd", "is", "the", "surface", "field", "strength", "at", "the\\", "stellar", "equator.", "This", "is", "matched", "to", "en", "exterior", "dipolar", "field", "aligned", "with", "the", "star", "spin", "axis"], "labels": ["WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["where<'", "Bd", "is", "the", "surface", "field", "strength", "at", "the\\", "stellar", "equator.", "This", "is", "matched", "to", "en", "exterior", "dipolar", "field", "aligned", "with", "the", "star", "spin", "axis"], "labels": ["WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["isnaweakfactorizationsystem.TheyargueasfollowS."], "labels": ["WRONG"]}, "correct": {"tokens": ["is", "a", "weak", "factorization", "system.", "They", "argue", "as", "follows."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED"]}, "predicted": {"google": {"tokens": ["isnaweakfactorizationsystem.TheyargueasfollowS."], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["isn", "a", "weak", "factorization", "system.", "They", "argue", "as", "followS."], "labels": ["WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG"]}, "BS-bid-OCR+google": {"tokens": ["is", "a", "weak", "factorization", "system.", "They", "argue", "as", "followS."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG"]}}}, {"corrupt": {"tokens": ["c:INFN-LNS,Cata?nia,Italy"], "labels": ["WRONG"]}, "correct": {"tokens": ["c:", "INFN-LNS,", "Catania,", "Italy"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["c:INFN-LNS,Catania,Italy"], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["c:", "INFN-LNS,", "Cata?nia,", "Italy"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["c:", "INFN-LNS,", "Catania,", "Italy"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["ByClaimD,wemay~isumethatx\u2208C,f6rothewiscT\u2208Tasdexired."], "labels": ["WRONG"]}, "correct": {"tokens": ["By", "Claim", "D,", "we", "may", "assume", "that", "x", "\u2208", "C,", "for", "otherwise", "T", "\u2208", "T", "as", "desired."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED"]}, "predicted": {"google": {"tokens": ["ByClaimD,wemay~isumethatx\u2208C,f6rothewiscT\u2208Tasdexired."], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["By", "Claim", "D,", "we", "may", "~isume", "that", "x", "\u2208", "C,", "f6r", "othewisc", "T", "\u2208", "T", "as", "dexired."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG"]}, "BS-bid-OCR+google": {"tokens": ["By", "Claim", "D,", "we", "may", "~assume", "that", "x", "\u2208", "C,", "f6r", "othewisc", "T", "\u2208", "T", "as", "desired."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED"]}}}, {"corrupt": {"tokens": ["Beoreweare~bletodoso,wemusteliminatethecoefficientcA,whichisnotknowneithearatthipoint.Tothisendfirstnotethat"], "labels": ["WRONG"]}, "correct": {"tokens": ["Before", "we", "are", "able", "to", "do", "so,", "we", "must", "eliminate", "the", "coefficient", "cA,", "which", "is", "not", "known", "either", "at", "this", "point.", "To", "this", "end", "first", "note", "that"], "labels": ["MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["Beoreweare~bletodoso,wemusteliminatethecoefficientcA,whichisnotknowneithearatthipoint.Tothisendfirstnotethat"], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["Beore", "we", "are", "~ble", "to", "do", "so,", "we", "must", "eliminate", "the", "coefficient", "cA,", "which", "is", "not", "known", "eithear", "at", "thi", "point.", "To", "this", "end", "first", "note", "that"], "labels": ["WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["Before", "we", "are", "able", "to", "do", "so,", "we", "must", "eliminate", "the", "coefficient", "cA,", "which", "is", "not", "known", "either", "at", "the", "point.", "To", "this", "end", "first", "note", "that"], "labels": ["MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["gaugeinvarianceguaran=teesgen-ralcoordinatetransibrmatiosonconfigurationswhicharos?olutionsoftheequationsofmotions;thegaugeandcoord\\]natetransformatiousarerelatedby:"], "labels": ["WRONG"]}, "correct": {"tokens": ["gauge", "invariance", "guarantees", "general", "coordinate", "transformations", "on", "configurations", "which", "are", "solutions", "of", "the", "equations", "of", "motions;", "the", "gauge", "and", "coordinate", "transformations", "are", "related", "by:"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["gaugeinvarianceguaran=teesgen-ralcoordinatetransibrmatiosonconfigurationswhicharos?olutionsoftheequationsofmotions;thegaugeandcoord\\]natetransformatiousarerelatedby:"], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["gauge", "invariance", "guaran=tees", "gen-ral", "coordinate", "transibrmatios", "on", "configurations", "which", "aro", "s?olutions", "of", "the", "equations", "of", "motions;", "the", "gauge", "and", "coord\\]nate", "transformatious", "are", "related", "by:"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["gauge", "invariance", "guaran=tees", "gen-ral", "coordinate", "transformations", "on", "configurations", "which", "are", "solutions", "of", "the", "equations", "of", "motions;", "the", "gauge", "and", "coord\\]nate", "transformation", "are", "related", "by:"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["Hartshorne3n\\dSpeiserfirstprovedthisrenltinthec?as,:whereRislocalandcontainsitsrsiduefieldwhichisper\\['ect.LyubeznikappliedhistheoryofF-modulestoobtaintheresutwithoutresttictiononthelocalrin@Rofchar3ctelisti_cp."], "labels": ["WRONG"]}, "correct": {"tokens": ["Hartshorne", "and", "Speiser", "first", "proved", "this", "result", "in", "the", "case", "where", "R", "is", "local", "and", "contains", "its", "residue", "field", "which", "is", "perfect.", "Lyubeznik", "applied", "his", "theory", "of", "F-modules", "to", "obtain", "the", "result", "without", "restriction", "on", "the", "local", "ring", "R", "of", "characteristic", "p."], "labels": ["TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["Hartshorne3n\\dSpeiserfirstprovedthisrenltinthec?as,:whereRislocalandcontainsitsrsiduefieldwhichisper\\['ect.LyubeznikappliedhistheoryofF-modulestoobtaintheresutwithoutresttictiononthelocalrin@Rofchar3ctelisti_cp."], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["Hartshorne", "3n\\d", "Speiser", "first", "proved", "this", "renlt", "in", "the", "c?as,:", "where", "R", "is", "local", "and", "contains", "its", "rsidue", "field", "which", "is", "per\\['ect.", "Lyubeznik", "applied", "his", "theory", "of", "F-modules", "to", "obtain", "the", "resut", "without", "resttiction", "on", "the", "local", "rin@", "R", "of", "char3ctelisti_c", "p."], "labels": ["TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["Hartshorne", "3n\\d", "Speiser", "first", "proved", "this", "result", "in", "the", "c?as,:", "where", "R", "is", "local", "and", "contains", "its", "residue", "field", "which", "is", "per\\['ect.", "Lyubeznik", "applied", "his", "theory", "of", "F-modules", "to", "obtain", "the", "result", "without", "restriction", "on", "the", "local", "rin@", "R", "of", "char3ctelisti_c", "p."], "labels": ["TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["Forsimplicity9iuthisexploratoryresearch,wemaketheapproximationthattheforcepacnstantscout)lingthesubstrateatomsareinsensitivetothechemicalspecies.Tilerefore,varyingtheuperlatticrcompositionisachievedsimplybyalteringthemassmatrixM.Forrealsystems,themassmodulationaccountsforthemajoritof?theeffect,pithcompositionallyvaryinforceconstnntscontributingessentiallynoncwphysics."], "labels": ["WRONG"]}, "correct": {"tokens": ["For", "simplicity", "in", "this", "exploratory", "research,", "we", "make", "the", "approximation", "that", "the", "force", "constants", "coupling", "the", "substrate", "atoms", "are", "insensitive", "to", "the", "chemical", "species.", "Therefore,", "varying", "the", "superlattice", "composition", "is", "achieved", "simply", "by", "altering", "the", "mass", "matrix", "M.", "For", "real", "systems,", "the", "mass", "modulation", "accounts", "for", "the", "majority", "of", "the", "effect,", "with", "compositionally", "varying", "force", "constants", "contributing", "essentially", "no", "new", "physics."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["Forsimplicity9iuthisexploratoryresearch,wemaketheapproximationthattheforcepacnstantscout)lingthesubstrateatomsareinsensitivetothechemicalspecies.Tilerefore,varyingtheuperlatticrcompositionisachievedsimplybyalteringthemassmatrixM.Forrealsystems,themassmodulationaccountsforthemajoritof?theeffect,pithcompositionallyvaryinforceconstnntscontributingessentiallynoncwphysics."], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["For", "simplicity9", "iu", "this", "exploratory", "research,", "we", "make", "the", "approximation", "that", "the", "force", "pa", "cnstants", "cout)ling", "the", "substrate", "atoms", "are", "insensitive", "to", "the", "chemical", "species.", "Tilerefore,", "varying", "the", "uperlatticr", "composition", "is", "achieved", "simply", "by", "altering", "the", "mass", "matrix", "M.", "For", "real", "systems,", "the", "mass", "modulation", "accounts", "for", "the", "majorit", "of?", "the", "effect,", "pith", "compositionally", "varyin", "force", "constnnts", "contributing", "essentially", "no", "ncw", "physics."], "labels": ["TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["For", "simplicity9", "iu", "this", "exploratory", "research,", "we", "make", "the", "approximation", "that", "the", "force", "pay", "constants", "court)ling", "the", "substrate", "atoms", "are", "insensitive", "to", "the", "chemical", "species.", "Therefore,", "varying", "the", "operatic", "composition", "is", "achieved", "simply", "by", "altering", "the", "mass", "matrix", "M.", "For", "real", "systems,", "the", "mass", "modulation", "accounts", "for", "the", "majority", "of?", "the", "effect,", "with", "compositionally", "varying", "force", "constants", "contributing", "essentially", "no", "ncw", "physics."], "labels": ["TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "MIXED", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["andtheplanarRN-AdS4solutioncanl)ewritte"], "labels": ["WRONG"]}, "correct": {"tokens": ["and", "the", "planar", "RN-AdS4", "solution", "can", "be", "written"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED"]}, "predicted": {"google": {"tokens": ["andtheplanarRN-AdS4solutioncanl)ewritte"], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["and", "the", "planar", "RN-AdS4", "solution", "can", "l)e", "writte"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG"]}, "BS-bid-OCR+google": {"tokens": ["and", "the", "planar", "RN-AdS4", "solution", "can", "l)e", "written"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "MIXED"]}}}, {"corrupt": {"tokens": ["C\\onclusions:"], "labels": ["WRONG"]}, "correct": {"tokens": ["Conclusions:"], "labels": ["OCR_ERROR"]}, "predicted": {"google": {"tokens": ["C\\onclusions:"], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["C\\onclusions:"], "labels": ["WRONG"]}, "BS-bid-OCR+google": {"tokens": ["C\\onclusions:"], "labels": ["WRONG"]}}}, {"corrupt": {"tokens": ["Opticalbservations?ofthecompanionh?avereveal(>dservera\\[phenomen;thatoccurasthepulsaremisioninter.actcwichthecompanionsnrface:"], "labels": ["WRONG"]}, "correct": {"tokens": ["Optical", "observations", "of", "the", "companion", "have", "revealed", "several", "phenomena", "that", "occur", "as", "the", "pulsar", "emission", "interacts", "with", "the", "companion", "surface:"], "labels": ["TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED"]}, "predicted": {"google": {"tokens": ["Optical", "Observations?of", "the", "companion?ave", "reveal(>dservera\\[phenomenon;that", "occurasthepulsaremisioninter.act", "wichthecompanionsnrface:"], "labels": ["TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "WRONG", "WRONG", "WRONG"]}, "BS-bid-OCR": {"tokens": ["Optical", "bservations?", "of", "the", "companion", "h?ave", "reveal(>d", "servera\\[", "phenomen;", "that", "occur", "as", "the", "pulsar", "emision", "inter.actc", "wich", "the", "companion", "snrface:"], "labels": ["TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG"]}, "BS-bid-OCR+google": {"tokens": ["Optical", "observations?", "of", "the", "companion", "h?ave", "reveal(>d", "servera\\[", "phenomen;", "that", "occur", "as", "the", "pulsar", "emission", "interact", "with", "the", "companion", "surface:"], "labels": ["TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "WRONG", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED"]}}}, {"corrupt": {"tokens": ["\\Introdoction"], "labels": ["WRONG"]}, "correct": {"tokens": ["Introduction"], "labels": ["OCR_ERROR"]}, "predicted": {"google": {"tokens": ["\\Introduction"], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["\\Introdoction"], "labels": ["WRONG"]}, "BS-bid-OCR+google": {"tokens": ["\\Introduction"], "labels": ["WRONG"]}}}, {"corrupt": {"tokens": ["DevelopinganActionCenceptInventory"], "labels": ["WRONG"]}, "correct": {"tokens": ["Developing", "an", "Action", "Concept", "Inventory"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["Developing", "an", "Action", "Concept", "Inventory"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR"]}, "BS-bid-OCR": {"tokens": ["Developing", "an", "Action", "Cencept", "Inventory"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["Developing", "an", "Action", "Concept", "Inventory"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["Thetwo|ightcenesarethen"], "labels": ["WRONG"]}, "correct": {"tokens": ["The", "two", "lightcones", "are", "then"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["The", "Two|ightcenesarethen"], "labels": ["TOKENIZATION_ERROR", "WRONG"]}, "BS-bid-OCR": {"tokens": ["The", "two", "|ight", "cenes", "are", "then"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["The", "two", "|night", "scenes", "are", "then"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["orequivalenl;ly"], "labels": ["WRONG"]}, "correct": {"tokens": ["or", "equivalently"], "labels": ["TOKENIZATION_ERROR", "MIXED"]}, "predicted": {"google": {"tokens": ["orequivalenl;ly"], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["or", "equivalenl;ly"], "labels": ["TOKENIZATION_ERROR", "WRONG"]}, "BS-bid-OCR+google": {"tokens": ["or", "equivalenl;ly"], "labels": ["TOKENIZATION_ERROR", "WRONG"]}}}, {"corrupt": {"tokens": ["Thengk\u2192p;,Jk\u2192\\]ask\u2192\u221e.Itiswell\\know--nthat"], "labels": ["WRONG"]}, "correct": {"tokens": ["Then", "gk", "\u2192", "g,", "Jk", "\u2192", "J", "as", "k", "\u2192", "\u221e.", "It", "is", "well", "known", "that"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["Thengk\u2192p;,Jk\u2192\\]ask\u2192\u221e.It", "Is", "Well\\know--nthat"], "labels": ["WRONG", "WRONG", "WRONG"]}, "BS-bid-OCR": {"tokens": ["Then", "gk", "\u2192", "p;,", "Jk", "\u2192", "\\]", "as", "k", "\u2192", "\u221e.", "It", "is", "well\\", "know--n", "that"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["Then", "gk", "\u2192", "p;,", "Jk", "\u2192", "\\]", "as", "k", "\u2192", "\u221e.", "It", "is", "well\\", "know--n", "that"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["TheCMDsofbothKDG61andKDG64aree1dentlydotheavilycontaminatedbyforegroundsZars,butaswewillerf{}rmadetai\\]edanalysisofthestarfoxmationhistory,wewillmakeaquantitativeassessmentofthispollukion."], "labels": ["WRONG"]}, "correct": {"tokens": ["The", "CMDs", "of", "both", "KDG", "61", "and", "KDG", "64", "are", "evidently", "not", "heavily", "contaminated", "by", "foreground", "stars,", "but", "as", "we", "will", "perform", "a", "detailed", "analysis", "of", "the", "star", "formation", "history,", "we", "will", "make", "a", "quantitative", "assessment", "of", "this", "pollution."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED"]}, "predicted": {"google": {"tokens": ["TheCMDsofbothKDG61andKDG64aree1dentlydotheavilycontaminatedbyforegroundsZars,butaswewillerf{}rmadetai\\]edanalysisofthestarfoxmationhistory,wewillmakeaquantitativeassessmentofthispollukion."], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["The", "CMDs", "of", "both", "KDG61", "and", "KDG64", "are", "e1dently", "dot", "heavily", "contaminated", "by", "foreground", "sZars,", "but", "as", "we", "will", "erf{}rm", "a", "detai\\]ed", "analysis", "of", "the", "star", "foxmation", "history,", "we", "will", "make", "a", "quantitative", "assessment", "of", "this", "pollukion."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG"]}, "BS-bid-OCR+google": {"tokens": ["The", "CMDs", "of", "both", "KDG61", "and", "KDG64", "are", "e1dently", "dot", "heavily", "contaminated", "by", "foreground", "sTars,", "but", "as", "we", "will", "erf{}rm", "a", "detai\\]ed", "analysis", "of", "the", "star", "formation", "history,", "we", "will", "make", "a", "quantitative", "assessment", "of", "this", "pollution."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED"]}}}, {"corrupt": {"tokens": ["AFourier-Muiai(FM)transformrelatingXa:ndYisanexactequivalenceofcategories"], "labels": ["WRONG"]}, "correct": {"tokens": ["A", "Fourier-Mukai", "(FM)", "transform", "relating", "X", "and", "Y", "is", "an", "exact", "equivalence", "of", "categories"], "labels": ["TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["AFourier-Mukai(FM)transformrelatingXa:ndYisanexactequivalenceofcategories"], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["A", "Fourier-Muiai", "(FM)", "transform", "relating", "X", "a:nd", "Y", "is", "an", "exact", "equivalence", "of", "categories"], "labels": ["TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["A", "Fourier-Muiai", "(FM)", "transform", "relating", "X", "a:nd", "Y", "is", "an", "exact", "equivalence", "of", "categories"], "labels": ["TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["whel'eT\u03b1(x)isanoperator"], "labels": ["WRONG"]}, "correct": {"tokens": ["where", "T\u03b1(x)", "is", "an", "operator"], "labels": ["MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["whel'eT\u03b1(x)isa", "operator"], "labels": ["WRONG", "TOKENIZATION_ERROR"]}, "BS-bid-OCR": {"tokens": ["whel'e", "T\u03b1(x)", "is", "an", "operator"], "labels": ["WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["whale", "T\u03b1(x)", "is", "an", "operator"], "labels": ["WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["Forthe.fi~ebalcase~"], "labels": ["WRONG"]}, "correct": {"tokens": ["For", "the", "fireball", "case,"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED"]}, "predicted": {"google": {"tokens": ["Forthe.fi~ebalcase~"], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["For", "the.", "fi~ebal", "case~"], "labels": ["TOKENIZATION_ERROR", "WRONG", "WRONG", "WRONG"]}, "BS-bid-OCR+google": {"tokens": ["For", "the.", "fi~ebal", "case~"], "labels": ["TOKENIZATION_ERROR", "WRONG", "WRONG", "WRONG"]}}}, {"corrupt": {"tokens": ["Inthsnextsectionsweobtainquantumcorrectionsothecla~;sicalpotent.iol..These(:orrectionscanmodifysignificantlythephysic,oftheproble?mandthephasedagramscs.hrnging,forexample,theorderofthetransitions."], "labels": ["WRONG"]}, "correct": {"tokens": ["In", "the", "next", "sections", "we", "obtain", "quantum", "corrections", "to", "the", "classical", "potential.", "These", "corrections", "can", "modify", "significantly", "the", "physics", "of", "the", "problem", "and", "the", "phase", "diagrams", "changing,", "for", "example,", "the", "order", "of", "the", "transitions."], "labels": ["TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["Inthsnext", "Sections", "We", "Obtain", "Quantum", "Correction", "So", "Thecla~;sicalpotent.iol..These(:orrectionscanmodifysignificantlythephysic,oftheproble?mandthephasedagramscs.hanging,for", "example,the", "order", "of", "transitions."], "labels": ["WRONG", "WRONG", "WRONG", "WRONG", "WRONG", "WRONG", "WRONG", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR": {"tokens": ["In", "ths", "next", "sections", "we", "obtain", "quantum", "corrections", "o", "the", "cla~;sical", "potent.iol..", "These", "(:orrections", "can", "modify", "significantly", "the", "physic,", "of", "the", "proble?m", "and", "the", "phase", "dagrams", "cs.hrnging,", "for", "example,", "the", "order", "of", "the", "transitions."], "labels": ["TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["In", "the", "next", "sections", "we", "obtain", "quantum", "corrections", "to", "the", "cla~;sical", "potent.iol..", "These", "(:corrections", "can", "modify", "significantly", "the", "physics", "of", "the", "problem", "and", "the", "phase", "diagrams", "cs.hanging,", "for", "example,", "the", "order", "of", "the", "transitions."], "labels": ["TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["byvirtueoftheattrac?torequations"], "labels": ["WRONG"]}, "correct": {"tokens": ["by", "virtue", "of", "the", "attractor", "equations"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["byvirtueoftheattrac?torequations"], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["by", "virtue", "of", "the", "attrac?tor", "equations"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["by", "virtue", "of", "the", "attractor", "equations"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["wherethecoefficientsabovearesivnby"], "labels": ["WRONG"]}, "correct": {"tokens": ["where", "the", "coefficients", "above", "are", "given", "by"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["where", "the", "coefficients", "above", "are", "seven", "by"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR"]}, "BS-bid-OCR": {"tokens": ["where", "the", "coefficients", "above", "are", "sivn", "by"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["where", "the", "coefficients", "above", "are", "seven", "by"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["trithepresentwork,wehaveinvestigatedtheimlmctthatthess1)ecificrealizationsofthei~teratingDEscenariohavontherotationcurvesofluminousspiralgalaxies.Morespecifica1ly,wehaverestrictedouranalysistcaparticularclaSso\\[coupldDE--scenarioscharacterize{lbyasteepgrowthintimeoflthein?terctionstrength,p??rametrizedasapositivepowerofthecosmics(:alefacl;or.Suchmodelshavebeenshown,tobe.infullagreementwith\\presentconstraintsonthebackgrounde??volutionoftheUniverse,adthey(lonotfeaturethetypicalearlyDEscalingofothercoupledDE'scenarioslikee.g.\\modelswithaconstantoamoreslowlyeVolvingcouplintfunction.Thebackgroundevolutionofthemod\\elsinvestigatedinthisworkisinfactpracticallyijndistin?guishab!efromthestandard\u039bCDMcqsmology.u~hermore,theimpactofthesealternativecosmologiesonthlestatisti?call)ropertielsoflar'gescalestructuresisconfinedatw',rylowredsilifts,whichln?akesiti)roblematictotestthemdclsvae.g.w,eaklensingmeasurements."], "labels": ["WRONG"]}, "correct": {"tokens": ["In", "the", "present", "work,", "we", "have", "investigated", "the", "impact", "that", "these", "specific", "realizations", "of", "the", "interacting", "DE", "scenario", "have", "on", "the", "rotation", "curves", "of", "luminous", "spiral", "galaxies.", "More", "specifically,", "we", "have", "restricted", "our", "analysis", "to", "a", "particular", "class", "of", "coupled", "DE", "scenarios", "characterized", "by", "a", "steep", "growth", "in", "time", "of", "the", "interaction", "strength,", "parametrized", "as", "a", "positive", "power", "of", "the", "cosmic", "scale", "factor.", "Such", "models", "have", "been", "shown", "to", "be", "in", "full", "agreement", "with", "present", "constraints", "on", "the", "background", "evolution", "of", "the", "Universe,", "as", "they", "do", "not", "feature", "the", "typical", "early", "DE", "scaling", "of", "other", "coupled", "DE", "scenarios", "like", "e.g.", "models", "with", "a", "constant", "or", "a", "more", "slowly", "evolving", "coupling", "function.", "The", "background", "evolution", "of", "the", "models", "investigated", "in", "this", "work", "is", "in", "fact", "practically", "indistinguishable", "from", "the", "standard", "\u039bCDM", "cosmology.", "Furthermore,", "the", "impact", "of", "these", "alternative", "cosmologies", "on", "the", "statistical", "properties", "of", "large", "scale", "structures", "is", "confined", "at", "very", "low", "redshifts,", "which", "makes", "it", "problematic", "to", "test", "the", "models", "via", "e.g.", "weak", "lensing", "measurements."], "labels": ["MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["trithepresentwork,wehaveinvestigatedtheimlmctthatthess1)ecificrealizationsofthei~teratingDEscenariohavontherotationcurvesofluminousspiralgalaxies.Morespecifica1ly,wehaverestrictedouranalysistcaparticularclaSso\\[couplE--scenarios", "characterized{lbyasteepgrowthintimeoflthein?actionstrength,p??rametrizedasa", "positive", "power", "of", "the", "cosmics(:alef", "acl;or.Suchmodelshavebeenshown,tobe.infullagreementwith\\present", "constraint", "sonthebackgrounde??volutionoftheUniverse,adthey(lonotfeaturethetypicalearlyDEscalingofothercoupledDE'scenarioslikee.g.\\modelswithaconstantoamoreslowlyeVolvingcouplintfunction.Thebackgroundevolutionofthemod\\elsinvestigatedinthisworkisinfactpracticallyijndistin?guishab!efromthestandard\u039bCDMcqsmology.u~hermore,theimpactofthesealternativecosmologiesonthlestatisti?call)ropertielsoflar'gescalestructuresisconfinedatw',rylowredsilifts,whichln?akesiti)roblematictotestthemdclsvae.g.w,eaklensingmeasurements."], "labels": ["WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "WRONG", "WRONG"]}, "BS-bid-OCR": {"tokens": ["tri", "the", "present", "work,", "we", "have", "investigated", "the", "imlmct", "that", "the", "ss1)ecific", "realizations", "of", "the", "i~terating", "DE", "scenario", "hav", "on", "the", "rotation", "curves", "of", "luminous", "spiral", "galaxies.", "More", "specifica1ly,", "we", "have", "restricted", "our", "analysis", "tc", "a", "particular", "claSs", "o\\[", "coupld", "DE--scenarios", "characterize{l", "by", "a", "steep", "growth", "in", "time", "of", "lthe", "in?terction", "strength,", "p??rametrized", "as", "a", "positive", "power", "of", "the", "cosmic", "s(:ale", "facl;or.", "Such", "models", "have", "been", "shown,", "to", "be.", "in", "full", "agreement", "with\\", "present", "constraints", "on", "the", "background", "e??volution", "of", "the", "Universe,", "ad", "they", "(lo", "not", "feature", "the", "typical", "early", "DE", "scaling", "of", "other", "coupled", "DE'scenarios", "like", "e.g.\\", "models", "with", "a", "constant", "oa", "more", "slowly", "eVolving", "couplint", "function.", "The", "background", "evolution", "of", "the", "mod\\els", "investigated", "in", "this", "work", "is", "in", "fact", "practically", "ijndistin?guishab!e", "from", "the", "standard", "\u039bCDM", "cqsmology.", "u~hermore,", "the", "impact", "of", "these", "alternative", "cosmologies", "on", "thle", "statisti?cal", "l)ropertiels", "of", "lar'ge", "scale", "structures", "is", "confined", "at", "w',ry", "low", "redsilifts,", "which", "ln?akes", "it", "i)roblematic", "to", "test", "the", "mdcls", "va", "e.g.", "w,eak", "lensing", "measurements."], "labels": ["WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "WRONG", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["In", "the", "present", "work,", "we", "have", "investigated", "the", "impact", "that", "the", "ss1)specific", "realizations", "of", "the", "i~terating", "DE", "scenario", "have", "on", "the", "rotation", "curves", "of", "luminous", "spiral", "galaxies.", "More", "specifically,", "we", "have", "restricted", "our", "analysis", "to", "a", "particular", "claSs", "o\\[", "couple", "DE--scenarios", "characterize{l", "by", "a", "steep", "growth", "in", "time", "of", "the", "interaction", "strength,", "parametrized", "as", "a", "positive", "power", "of", "the", "cosmic", "s(:ale", "facl;or.", "Such", "models", "have", "been", "shown,", "to", "be.", "in", "full", "agreement", "with\\", "present", "constraints", "on", "the", "background", "evolution", "of", "the", "Universe,", "and", "they", "(lo", "not", "feature", "the", "typical", "early", "DEscaling", "of", "other", "coupled", "Scenarios", "like", "e.g.\\", "models", "with", "a", "constant", "oa", "more", "slowly", "eVolving", "coupling", "function.", "The", "background", "evolution", "of", "the", "mod\\els", "investigated", "in", "this", "work", "is", "in", "fact", "practically", "ijndistin?guishab!e", "from", "the", "standard", "\u039bCDM", "cosmology.", "u~hermore,", "the", "impact", "of", "these", "alternative", "cosmologies", "on", "the", "statistical", "l)properties", "of", "large", "scale", "structures", "is", "confined", "at", "w',ry", "low", "redshifts,", "which", "lane?takes", "it", "i)problematic", "to", "test", "the", "models", "vs", "e.g.", "w,eak", "lensing", "measurements."], "labels": ["MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "WRONG", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "WRONG", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["Weeouldhaveextendedthissymmetrybreakingpatterntothecasewherewehavetwosetsofvctorxepresentations,\u03c6a1and\u03c6a2.TheinvariantspinconnectioncandependonthelenghofeachLorentzvectorantheanglebetweenthem,|\u03c6a1|,|\u03c6a2|,and|\u03c6a1\u03c6a2|.Thesolutionsfortheminimummustbeobtainedf,omtheconditipnsimposedontheethreequantities.Wecnchoose\u03c6a1withonl\\ythelastcomponntnon-zeroand\u03c6a2wiIhthelasttwocomponentsnoii-zeroinordertosatisfytheseconditions.TheLorentzSO(3,1)symmetrvisthenbrokendowntoO(2)(orU(1))symmetry44."], "labels": ["WRONG"]}, "correct": {"tokens": ["We", "could", "have", "extended", "this", "symmetry", "breaking", "pattern", "to", "the", "case", "where", "we", "have", "two", "sets", "of", "vector", "representations,", "\u03c6a1", "and", "\u03c6a2.", "The", "invariant", "spin", "connection", "can", "depend", "on", "the", "length", "of", "each", "Lorentz", "vector", "and", "the", "angle", "between", "them,", "|\u03c6a1", "|", ",", "|\u03c6a2", "|,", "and", "|\u03c6a1\u03c6a2", "|.", "The", "solutions", "for", "the", "minimum", "must", "be", "obtained", "from", "the", "conditions", "imposed", "on", "these", "three", "quantities.", "We", "can", "choose", "\u03c6a1", "with", "only", "the", "last", "component", "non-zero", "and", "\u03c6a2", "with", "the", "last", "two", "components", "non-zero", "in", "order", "to", "satisfy", "these", "conditions.", "The", "Lorentz", "SO(3,", "1)", "symmetry", "is", "then", "broken", "down", "to", "O(2)", "(or", "U(1))", "symmetry44."], "labels": ["TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["Weeouldhaveextendedthissymmetrybreakingpatterntothecasewherewehavetwosetsofvctorxepresentations,\u03c6a1and\u03c6a2.TheinvariantspinconnectioncandependonthelenghofeachLorentzvectorantheanglebetweenthem,|\u03c6a1|,|\u03c6a2|,and|\u03c6a1\u03c6a2|.Thesolutionsfortheminimummustbeobtainedf,omtheconditipnsimposedontheethreequantities.Wecnchoose\u03c6a1withonl\\ythelastcomponntnon-zeroand\u03c6a2wiIhthelasttwocomponentsnoii-zeroinordertosatisfytheseconditions.TheLorentzSO(3,1)symmetrvisthenbrokendowntoO(2)(orU(1))symmetry44."], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["We", "eould", "have", "extended", "this", "symmetry", "breaking", "pattern", "to", "the", "case", "where", "we", "have", "two", "sets", "of", "vctor", "xepresentations,", "\u03c6a1", "and", "\u03c6a2.", "The", "invariant", "spin", "connection", "can", "depend", "on", "the", "lengh", "of", "each", "Lorentz", "vector", "an", "the", "angle", "between", "them,", "|\u03c6a1", "|,", "|\u03c6a2", "|,", "and", "|\u03c6a1\u03c6a2", "|.", "The", "solutions", "for", "the", "minimum", "must", "be", "obtained", "f,om", "the", "conditipns", "imposed", "on", "thee", "three", "quantities.", "We", "cn", "choose", "\u03c6a1", "with", "onl\\y", "the", "last", "componnt", "non-zero", "and", "\u03c6a2", "wiIh", "the", "last", "two", "components", "noii-zero", "in", "order", "to", "satisfy", "these", "conditions.", "The", "Lorentz", "SO(3,", "1)", "symmetrv", "is", "then", "broken", "down", "to", "O(2)", "(or", "U(1))", "symmetry", "44."], "labels": ["TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG"]}, "BS-bid-OCR+google": {"tokens": ["We", "would", "have", "extended", "this", "symmetry", "breaking", "pattern", "to", "the", "case", "where", "we", "have", "two", "sets", "of", "vector", "representations,", "\u03c6a1", "and", "\u03c6a2.", "The", "invariant", "spin", "connection", "can", "depend", "on", "the", "length", "of", "each", "Lorentz", "vector", "an", "the", "angle", "between", "them,", "|\u03c6a1", "|,", "|\u03c6a2", "|,", "and", "|\u03c6a1\u03c6a2", "|.", "The", "solutions", "for", "the", "minimum", "must", "be", "obtained", "from", "the", "conditions", "imposed", "on", "these", "three", "quantities.", "We", "can", "choose", "\u03c6a1", "with", "onl\\y", "the", "last", "component", "non-zero", "and", "\u03c6a2", "wiTh", "the", "last", "two", "components", "noii-zero", "in", "order", "to", "satisfy", "these", "conditions.", "The", "Lorentz", "SO(3,", "1)", "symmetry", "is", "then", "broken", "down", "to", "O(2)", "(or", "U(1))", "symmetry", "44."], "labels": ["TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG"]}}}, {"corrupt": {"tokens": ["Thisworkwassuppot'tedinpartbytheRFRRgrants08-02-00648-aand10-02-0143s-a.Aniceworkoftheaccel\\eratorgroupoftheLPIsynchrotronanditsleaderG.GSubbotinishighlyappreciaced."], "labels": ["WRONG"]}, "correct": {"tokens": ["This", "work", "was", "supported", "in", "part", "by", "the", "RFBR", "grants", "08-02-00648-a", "and", "10-02-01433-a.", "A", "nice", "work", "of", "the", "accelerator", "group", "of", "the", "LPI", "synchrotron", "and", "its", "leader", "G.G.", "Subbotin", "is", "highly", "appreciated."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED"]}, "predicted": {"google": {"tokens": ["Thisworkwassuppot'tedinpartbytheRFRRgrants08-02-00648-aand10-02-0143s-a.Aniceworkoftheaccel\\eratorgroupoftheLPIsynchrotronanditsleaderG.GSubbotinishighlyappreciaced."], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["This", "work", "was", "suppot'ted", "in", "part", "by", "the", "RFRR", "grants", "08-02-00648-a", "and", "10-02-0143s-a.", "A", "nice", "work", "of", "the", "accel\\erator", "group", "of", "the", "LPI", "synchrotron", "and", "its", "leader", "G.", "G", "Subbotin", "is", "highly", "appreciaced."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG"]}, "BS-bid-OCR+google": {"tokens": ["This", "work", "was", "supported", "in", "part", "by", "the", "RFRR", "grants", "08-02-00648-a", "and", "10-02-0143s-a.", "A", "nice", "work", "of", "the", "accel\\erator", "group", "of", "the", "LPI", "synchrotron", "and", "its", "leader", "G.", "G", "Subbotin", "is", "highly", "appreciated."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED"]}}}, {"corrupt": {"tokens": ["STATiSTICALMECHANICSOFINTERACT.INGPIBERBUNDLESRenaudToussaintDepartmentofPhysics,UniversiryofOslo,P,O.Box1048Blindern,N-0316Oslo,Norway."], "labels": ["WRONG"]}, "correct": {"tokens": ["STATISTICAL", "MECHANICS", "OF", "INTERACTING", "FIBER", "BUNDLES", "Renaud", "Toussaint", "Department", "of", "Physics,", "University", "of", "Oslo,", "P.O.Box", "1048", "Blindern,", "N-0316", "Oslo,", "Norway."], "labels": ["MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["STATiSTICALMECHANICSOFINTERACT.INGPIBERBUNDLESRenaudToussaintDepartmentofPhysics,University", "of", "Oslo,P,O.Box1048Blindern,N-0316Oslo,Norway."], "labels": ["WRONG", "TOKENIZATION_ERROR", "WRONG"]}, "BS-bid-OCR": {"tokens": ["STATiSTICAL", "MECHANICS", "OF", "INTERACT.ING", "PIBER", "BUNDLES", "Renaud", "Toussaint", "Department", "of", "Physics,", "Universiry", "of", "Oslo,", "P,O.", "Box", "1048", "Blindern,", "N-0316", "Oslo,", "Norway."], "labels": ["WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["STATiSTICAL", "MECHANICS", "OF", "INTERACT.ING", "PIBER", "BUNDLES", "Renaud", "Toussaint", "Department", "of", "Physics,", "University", "of", "Oslo,", "P,O.", "Box", "1048", "Blindern,", "N-0316", "Oslo,", "Norway."], "labels": ["WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["AssumeB={(,\u03b8):a\u2208A,\u03b8\u2208\u0398()},and\u039e:B\u2192Uia/~arametrjc?randomfunction,whereAandU~refinitesets.Defin('."], "labels": ["WRONG"]}, "correct": {"tokens": ["Assume", "B", "=", "{(a,", "\u03b8):", "a", "\u2208", "A,", "\u03b8", "\u2208", "\u0398(a)},", "and", "\u039e:", "B", "\u2192", "U", "is", "a", "parametric", "random", "function,", "where", "A", "and", "U", "are", "finite", "sets.", "Define"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED"]}, "predicted": {"google": {"tokens": ["AssumeB={(,\u03b8):a\u2208A,\u03b8\u2208\u0398()},and\u039e:B\u2192Uia/~parametric?random", "function,whereAandU~refinitesets.Define('."], "labels": ["WRONG", "WRONG"]}, "BS-bid-OCR": {"tokens": ["Assume", "B", "=", "{(,", "\u03b8):", "a", "\u2208", "A,", "\u03b8", "\u2208", "\u0398()},", "and", "\u039e:", "B", "\u2192", "U", "i", "a", "/~arametrjc?", "random", "function,", "where", "A", "and", "U", "~re", "finite", "sets.", "Defin('."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG"]}, "BS-bid-OCR+google": {"tokens": ["Assume", "B", "=", "{(,", "\u03b8):", "a", "\u2208", "A,", "\u03b8", "\u2208", "\u0398()},", "and", "\u039e:", "B", "\u2192", "U", "is", "/~parametric?", "random", "function,", "where", "A", "and", "U", "~re", "finite", "sets.", "Define('."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG"]}}}, {"corrupt": {"tokens": ["Since"], "labels": ["NONE"]}, "correct": {"tokens": ["Since"], "labels": ["NONE"]}, "predicted": {"google": {"tokens": ["Since"], "labels": ["NONE"]}, "BS-bid-OCR": {"tokens": ["Since"], "labels": ["NONE"]}, "BS-bid-OCR+google": {"tokens": ["Since"], "labels": ["NONE"]}}}, {"corrupt": {"tokens": ["WeilankProf.S.N.Di\\mova(UniversityofSofia),Prof.I.V.Puzynin(JINR,Dubna)andProfI.V.Barashenkov(UniversityofCapeTown)fortheirusefulMremarks."], "labels": ["WRONG"]}, "correct": {"tokens": ["We", "thank", "Prof.", "S.N.", "Dimova", "(University", "of", "Sofia),", "Prof.", "I.V.", "Puzynin", "(JINR,", "Dubna)", "and", "Prof.", "I.V.", "Barashenkov", "(University", "of", "Cape", "Town)", "for", "their", "useful", "remarks."], "labels": ["TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["WeilankProf.S.N.Di\\mova(UniversityofSofia),Prof.I.V.Puzynina(JINR,Dubna)andProfI.V.Barashenkov(UniversityofCapeTown)for", "their", "useful", "remarks."], "labels": ["WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR": {"tokens": ["We", "ilank", "Prof.", "S.", "N.", "Di\\mova", "(University", "of", "Sofia),", "Prof.", "I.V.", "Puzynin", "(JINR,", "Dubna)", "and", "Prof", "I.V.", "Barashenkov", "(University", "of", "Cape", "Town)", "for", "their", "useful", "Mremarks."], "labels": ["TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG"]}, "BS-bid-OCR+google": {"tokens": ["We", "ilank", "Prof.", "S.", "N.", "Di\\mova", "(University", "of", "Sofia),", "Prof.", "I.V.", "Puzynina", "(JINR,", "Dubna)", "and", "Prof", "I.V.", "Barashenkov", "(University", "of", "Cape", "Town)", "for", "their", "useful", "Remarks."], "labels": ["TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG"]}}}, {"corrupt": {"tokens": ["whichispositvefor\u03c3<0andhenceNMGgravitonsgetatimedelay.ThencausalityudunitarityinNMGarec0mpa.tib\\]e."], "labels": ["WRONG"]}, "correct": {"tokens": ["which", "is", "positive", "for", "\u03c3", "<", "0", "and", "hence", "NMG", "gravitons", "get", "a", "time", "delay.", "Then", "causality", "and", "unitarity", "in", "NMG", "are", "compatible."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED"]}, "predicted": {"google": {"tokens": ["whichispositvefor\u03c3<0andhenceNMGgravitonsgetatimedelay.ThencausalityudunitarityinNMGarec0mpa.tib\\]e."], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["which", "is", "positve", "for", "\u03c3", "<", "0", "and", "hence", "NMG", "gravitons", "get", "a", "time", "delay.", "Then", "causality", "ud", "unitarity", "in", "NMG", "are", "c0mpa.tib\\]e."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG"]}, "BS-bid-OCR+google": {"tokens": ["which", "is", "positive", "for", "\u03c3", "<", "0", "and", "hence", "NMG", "gravitons", "get", "a", "time", "delay.", "Then", "causality", "and", "unitarity", "in", "NMG", "are", "c0mpa.tib\\]e."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG"]}}}, {"corrupt": {"tokens": ["Itisalsoanunsolvedproblemtodetermiuenecessaryand??sufficientconditionsforalatticepolytpePtosatisfytheequation"], "labels": ["WRONG"]}, "correct": {"tokens": ["It", "is", "also", "an", "unsolved", "problem", "to", "determine", "necessary", "and", "sufficient", "conditions", "for", "a", "lattice", "polytope", "P", "to", "satisfy", "the", "equation"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["Itisalsoanunsolvedproblemtodetermiuenecessaryand??sufficientconditionsforalatticepolytpePtosatisfytheequation"], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["It", "is", "also", "an", "unsolved", "problem", "to", "determiue", "necessary", "and", "??sufficient", "conditions", "for", "a", "lattice", "polytpeP", "to", "satisfy", "the", "equation"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["It", "is", "also", "an", "unsolved", "problem", "to", "determine", "necessary", "and", "??sufficient", "conditions", "for", "a", "lattice", "polytope", "to", "satisfy", "the", "equation"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["TransmissionofInformationa.nd,HerdBehavior:anApplicationtoFinancialMarkets"], "labels": ["WRONG"]}, "correct": {"tokens": ["Transmission", "of", "Information", "and", "Herd", "Behavior:", "an", "Application", "to", "Financial", "Markets"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["Transmission", "Information", "and,HerdBehavior:anApplicationtoFinancialMarkets"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG"]}, "BS-bid-OCR": {"tokens": ["Transmission", "of", "Information", "a.nd,", "Herd", "Behavior:", "an", "Application", "to", "Financial", "Markets"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["Transmission", "of", "Information", "and,", "Herd", "Behavior:", "an", "Application", "to", "Financial", "Markets"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["Asymmetric~cut"], "labels": ["WRONG"]}, "correct": {"tokens": ["Asymmetric-cut"], "labels": ["OCR_ERROR"]}, "predicted": {"google": {"tokens": ["Asymmetric~cut"], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["Asymmetric~", "cut"], "labels": ["WRONG", "WRONG"]}, "BS-bid-OCR+google": {"tokens": ["Asymmetric~", "cut"], "labels": ["WRONG", "WRONG"]}}}, {"corrupt": {"tokens": ["forn>1."], "labels": ["WRONG"]}, "correct": {"tokens": ["for", "n", ">", "1."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["form>1."], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["for", "n", ">", "1."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["for", "n", ">", "1."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["where"], "labels": ["NONE"]}, "correct": {"tokens": ["where"], "labels": ["NONE"]}, "predicted": {"google": {"tokens": ["where"], "labels": ["NONE"]}, "BS-bid-OCR": {"tokens": ["where"], "labels": ["NONE"]}, "BS-bid-OCR+google": {"tokens": ["where"], "labels": ["NONE"]}}}, {"corrupt": {"tokens": ["LCSpoint"], "labels": ["WRONG"]}, "correct": {"tokens": ["LCS", "point"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["LCSpoint"], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["LCS", "point"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["LCS", "point"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["WethankO.?Ahar(}nY,T,Banks,M.Berkooz,M.Dine,K.Xntriligator,D.Morri\\so~n,S.Shenker~P.Townsend,C.Vafaa\\ndE.Wittl;enfordiscussions.ThisworkwassupportedinpartbyDOEgrantDE-FG02-9ti6ER40559."], "labels": ["WRONG"]}, "correct": {"tokens": ["We", "thank", "O.", "Aharony,", "T.", "Banks,", "M.", "Berkooz,", "M.", "Dine,", "K.", "Intriligator,", "D.", "Morrison,", "S.", "Shenker,", "P.", "Townsend,", "C.", "Vafa", "and", "E.", "Witten", "for", "discussions.", "This", "work", "was", "supported", "in", "part", "by", "DOE", "grant", "DE-FG02-96ER40559."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED"]}, "predicted": {"google": {"tokens": ["WethankO.?Ahar(}nY,T,Banks,M.Berkooz,M.Dine,K.Intriligator,D.Morri\\so~n,S.Shenker~P.Townsend,C.Vafaa\\ndE.Wittl;enfordiscussions.ThisworkwassupportedinpartbyDOEgrantDE-FG02-9ti6ER40559."], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["We", "thank", "O.", "?Ahar(}nY,", "T,", "Banks,", "M.", "Berkooz,", "M.", "Dine,", "K.", "Xntriligator,", "D.", "Morri\\so~n,", "S.", "Shenker~", "P.", "Townsend,", "C.", "Vafa", "a\\nd", "E.", "Wittl;en", "for", "discussions.", "This", "work", "was", "supported", "in", "part", "by", "DOE", "grant", "DE-FG02-9ti6ER40559."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG"]}, "BS-bid-OCR+google": {"tokens": ["We", "thank", "O.", "?Ahar(}nY,", "T,", "Banks,", "M.", "Berkooz,", "M.", "Dine,", "K.", "Xntriligator,", "D.", "Morri\\so~n,", "S.", "Shenker~", "P.", "Townsend,", "C.", "Vafa", "a\\nd", "E.", "Wittl;en", "for", "discussions.", "This", "work", "was", "supported", "in", "part", "by", "the", "DOE", "grant", "DE-FG02-9ti6ER40559."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG"]}}}, {"corrupt": {"tokens": ["Re1ationtohon-geomQtry"], "labels": ["WRONG"]}, "correct": {"tokens": ["Relation", "to", "non-geometry"], "labels": ["MIXED", "TOKENIZATION_ERROR", "MIXED"]}, "predicted": {"google": {"tokens": ["Re1", "Ationtohon-geomEtry"], "labels": ["WRONG", "WRONG"]}, "BS-bid-OCR": {"tokens": ["Re1ation", "to", "hon-geomQtry"], "labels": ["WRONG", "TOKENIZATION_ERROR", "WRONG"]}, "BS-bid-OCR+google": {"tokens": ["Relation", "to", "hon-geomEtry"], "labels": ["MIXED", "TOKENIZATION_ERROR", "WRONG"]}}}, {"corrupt": {"tokens": ["(evenifYisnotadivisorwithnormalcrossin~8),becausethedirectimng~byX\u2192ptisdefinedbyusingthedeRhamcomplex."], "labels": ["WRONG"]}, "correct": {"tokens": ["(even", "if", "Y", "is", "not", "a", "divisor", "with", "normal", "crossings),", "because", "the", "direct", "image", "by", "X", "\u2192", "pt", "is", "defined", "by", "using", "the", "de", "Rham", "complex."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["(evenifYisnotadivisorwithnormalcrossin~8),becausethedirectimng~byX\u2192ptisdefinedbyusingthedeRhamcomplex."], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["(even", "if", "Y", "is", "not", "a", "divisor", "with", "normal", "crossin~8),", "because", "the", "direct", "imng~", "by", "X", "\u2192", "pt", "is", "defined", "by", "using", "the", "de", "Rham", "complex."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["(even", "if", "Y", "is", "not", "a", "divisor", "with", "normal", "crossing~8),", "because", "the", "direct", "imng~", "by", "X", "\u2192", "pt", "is", "defined", "by", "using", "the", "de", "Rham", "complex."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["Withtheaboveassumptioll,teequationsofmotion()fYang?Midllsfieldcanbereducedto"], "labels": ["WRONG"]}, "correct": {"tokens": ["With", "the", "above", "assumption,", "the", "equations", "of", "motion", "of", "Yang-Mills", "field", "can", "be", "reduced", "to"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["With", "The", "Above", "Assumption", "All,the", "equations", "of", "motion()fYang?Midllsfieldcanbereducedto"], "labels": ["TOKENIZATION_ERROR", "WRONG", "WRONG", "WRONG", "WRONG", "TOKENIZATION_ERROR", "MIXED", "WRONG"]}, "BS-bid-OCR": {"tokens": ["With", "the", "above", "assumptioll,", "te", "equations", "of", "motion", "()f", "Yang?Midlls", "field", "can", "be", "reduced", "to"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["With", "the", "above", "assumption,", "the", "equations", "of", "motion", "()f", "Yang?Mills", "field", "can", "be", "reduced", "to"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["Wea?reglatefultoDGTIC-UNAMand~oI^-UNlMforallowingustousetheinrNE.SandATOC~TLClusterswhereallthesimulationswereperformed.Thtsoftwnr,,usedinthisworkwasinpartdevelopedbytheDOENNSA-ASCOASCRFlashCenteral,theUniversityofChicago.ThisworkwassupportedinpartbyCONACyPgra-tsCB-2009-1No.132400?,CB-20O8-1No.1O1958,project1285S6-FanProdproject1655S4.AlsowassupportedbyPAPITprojec,l;IN106~12.AlsowethanktoDanyPageandWilliamLeeforus~fuldiscussions.ThisworkwassupportedbyLucBinettescholarshipandtheprojectsIG100414faodConacyt101958."], "labels": ["WRONG"]}, "correct": {"tokens": ["We", "are", "grateful", "to", "DGTIC-UNAM", "and", "to", "IA-UNAM", "for", "allowing", "us", "to", "use", "their", "NES", "and", "ATOCATL", "Clusters", "where", "all", "the", "simulations", "were", "performed.", "The", "software", "used", "in", "this", "work", "was", "in", "part", "developed", "by", "the", "DOE", "NNSA-ASC", "OASCR", "Flash", "Center", "at", "the", "University", "of", "Chicago.", "This", "work", "was", "supported", "in", "part", "by", "CONACyT", "grants", "CB-2009-1", "No.", "132400,", "CB-2008-1", "No.", "101958,", "project", "128556-F", "and", "project", "165584.", "Also", "was", "supported", "by", "PAPIIT", "project", "IN106212.", "Also", "we", "thank", "to", "Dany", "Page", "and", "William", "Lee", "for", "useful", "discussions.", "This", "work", "was", "supported", "by", "Luc", "Binette", "scholarship", "and", "the", "projects", "IG100414", "and", "Conacyt", "101958."], "labels": ["TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["Wea?reglatefultoDGTIC-UNAMand~oI^-UNlMforallowingustousetheinrNE.SandATOC~TLClusterswhereallthesimulationswereperformed.Thtsoftwnr,,usedinthisworkwasinpartdevelopedbytheDOENNSA-ASCOASCRFlashCenteral,theUniversityofChicago.ThisworkwassupportedinpartbyCONACyPgra-tsCB-2009-1No.132400?,CB-20O8-1No.1O1958,project1285S6-FanProdproject1655S4.AlsowassupportedbyPAPITprojec,l;IN106~12.AlsowethanktoDanyPageandWilliamLeeforus~fuldiscussions.ThisworkwassupportedbyLucBinettescholarshipandtheprojectsIG100414faodConacyt101958."], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["We", "a?re", "glateful", "to", "DGTIC-UNAM", "and", "~oI^-UNlM", "for", "allowing", "us", "to", "use", "theinr", "NE.S", "and", "ATOC~TL", "Clusters", "where", "all", "the", "simulations", "were", "performed.", "Tht", "softwnr,,", "used", "in", "this", "work", "was", "in", "part", "developed", "by", "the", "DOE", "NNSA-ASCO", "ASCR", "Flash", "Center", "al,", "the", "University", "of", "Chicago.", "This", "work", "was", "supported", "in", "part", "by", "CONACyP", "gra-ts", "CB-2009-1", "No.", "132400?,", "CB-20O8-1", "No.", "1O1958,", "project", "1285S6-FanProd", "project", "1655S4.", "Also", "was", "supported", "by", "PAPIT", "projec,l;", "IN", "106~12.", "Also", "we", "thank", "to", "Dany", "Page", "and", "William", "Lee", "for", "us~ful", "discussions.", "This", "work", "was", "supported", "by", "Luc", "Binette", "scholarship", "and", "the", "projects", "IG100414", "faod", "Conacyt", "101958."], "labels": ["TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["We", "are", "grateful", "to", "DGTIC-UNAM", "and", "~oI^-UNlM", "for", "allowing", "us", "to", "use", "theinr", "NE.S", "and", "ATOC~TL", "Clusters", "where", "all", "the", "simulations", "were", "performed.", "That", "softener,,", "used", "in", "this", "work", "was", "in", "part", "developed", "by", "the", "DOE", "NNSA-ASCO", "ASCR", "Flash", "Center", "al,", "the", "University", "of", "Chicago.", "This", "work", "was", "supported", "in", "part", "by", "CONACyT", "gra-ts", "CB-2009-1", "No.", "132400?,", "CB-20O8-1", "No.", "1O1958,", "project", "1285S6-FanProd", "project", "1655S4.", "Also", "was", "supported", "by", "the", "PAPIT", "project,l;", "IN", "106~12.", "Also", "we", "thank", "to", "Dany", "Page", "and", "William", "Lee", "for", "us~ful", "discussions.", "This", "work", "was", "supported", "by", "Luc", "Binette", "scholarship", "and", "the", "projects", "IG100414", "faod", "Conacyt", "101958."], "labels": ["TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "WRONG", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["WedefinethecorrcspondinggeneratoroftileelectromagneticgaugegroupU(1)em~susualby"], "labels": ["WRONG"]}, "correct": {"tokens": ["We", "define", "the", "corresponding", "generator", "of", "the", "electromagnetic", "gauge", "group", "U(1)em", "as", "usual", "by"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["WedefinethecorrcspondinggeneratoroftileelectromagneticgaugegroupU(1)em~susualby"], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["We", "define", "the", "corrcsponding", "generator", "of", "tile", "electromagnetic", "gauge", "group", "U(1)em", "~s", "usual", "by"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["We", "define", "the", "corresponding", "generator", "of", "tile", "electromagnetic", "gauge", "group", "U(1)em", "~s", "usual", "by"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["Thisresultsinanequationfor\u03b3eoftheform"], "labels": ["WRONG"]}, "correct": {"tokens": ["This", "results", "in", "an", "equation", "for", "\u03b3e", "of", "the", "form"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["Thisresultsinanequationfor\u03b3eoftheform"], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["This", "results", "in", "an", "equation", "for", "\u03b3e", "of", "the", "form"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["This", "results", "in", "an", "equation", "for", "\u03b3e", "of", "the", "form"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["BECinidenticalbosonpairsareoftenstudiedbythctwo-particlecorrelationunctCon"], "labels": ["WRONG"]}, "correct": {"tokens": ["BEC", "in", "identical", "boson", "pairs", "are", "often", "studied", "by", "the", "two-particle", "correlation", "function"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED"]}, "predicted": {"google": {"tokens": ["BECinidenticalbosonpairsareoftenstudiedbythctwo-particlecorrelationunctCon"], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["BEC", "in", "identical", "boson", "pairs", "are", "often", "studied", "by", "thc", "two-particle", "correlation", "unctCon"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG"]}, "BS-bid-OCR+google": {"tokens": ["BEC", "in", "identical", "boson", "pairs", "are", "often", "studied", "by", "thc", "two-particle", "correlation", "unctCon"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG"]}}}, {"corrupt": {"tokens": ["sothat,Obviouly,thepair(q,q)isan,ontthercoupleofmomentawhosedistributionisstationaty.Oviocusly,varlablesq=apandQ=aParenotindep6ndntones,sincetheysharelhesamerandomfaCtora(unlessaislmostsu,elyaconstant,whichreducstotheGallssiancas)."], "labels": ["WRONG"]}, "correct": {"tokens": ["so", "that,", "obviously,", "the", "pair", "(q,", "Q)", "is", "another", "couple", "of", "momenta", "whose", "distribution", "is", "stationary.", "Obviously,", "variables", "q", "=", "ap", "and", "Q", "=", "aP", "are", "not", "independent", "ones,", "since", "they", "share", "the", "same", "random", "factor", "a", "(unless", "a", "is", "almost", "surely", "a", "constant,", "which", "reduces", "to", "the", "Gaussian", "case)."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED"]}, "predicted": {"google": {"tokens": ["so", "that,Obviously,thepair(q,q)isan,ontthercoupleofmomentawhosedistributionisstationaty.Oviocusly,varlablesq=apandQ=aParenotindep6ndntones,sincetheysharelhesamerandomfaCtora(unlessaislmostsu,elyaconstant,whichreducstotheGallssiancas)."], "labels": ["TOKENIZATION_ERROR", "WRONG"]}, "BS-bid-OCR": {"tokens": ["so", "that,", "Obviouly,", "the", "pair", "(q,", "q)", "is", "an,", "ontther", "couple", "of", "momenta", "whose", "distribution", "is", "stationaty.", "Oviocusly,", "varlables", "q", "=", "ap", "and", "Q", "=", "aP", "are", "not", "indep6ndnt", "ones,", "since", "they", "share", "lhe", "same", "random", "faCtor", "a", "(unless", "a", "is", "lmost", "su,ely", "a", "constant,", "which", "reducs", "to", "the", "Gallssian", "cas)."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG"]}, "BS-bid-OCR+google": {"tokens": ["so", "Obviously,", "the", "pair", "(q,", "q)", "is", "another", "couple", "of", "moments", "whose", "distribution", "is", "stationary.", "Obviously,", "variables", "q", "=", "ap", "and", "Q", "=", "aP", "are", "not", "independent", "ones,", "since", "they", "share", "the", "same", "random", "faCtor", "a", "(unless", "a", "is", "almost", "surely", "a", "constant,", "which", "reduces", "to", "the", "Gaussian", "case)."], "labels": ["TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED"]}}}, {"corrupt": {"tokens": [".Conclusionanddiscusslous"], "labels": ["WRONG"]}, "correct": {"tokens": ["4.", "Conclusion", "and", "discussions"], "labels": ["MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED"]}, "predicted": {"google": {"tokens": [".Conclusions", "And", "Discuss", "Lotus"], "labels": ["WRONG", "WRONG", "WRONG", "WRONG"]}, "BS-bid-OCR": {"tokens": [".Conclusion", "and", "discusslous"], "labels": ["WRONG", "TOKENIZATION_ERROR", "WRONG"]}, "BS-bid-OCR+google": {"tokens": [".Conclusion", "and", "discussion"], "labels": ["WRONG", "TOKENIZATION_ERROR", "WRONG"]}}}, {"corrupt": {"tokens": ["{i)Al;almosteverypointinthedomain,DFinducesaLiea|gebrahomomol'phismfromthetangentspaceofthedomailltothetanargentspaceof'tleimage.."], "labels": ["WRONG"]}, "correct": {"tokens": ["(i)", "At", "almost", "every", "point", "in", "the", "domain,", "DF", "induces", "a", "Lie", "algebra", "homomorphism", "from", "the", "tangent", "space", "of", "the", "domain", "to", "the", "tangent", "space", "of", "the", "image."], "labels": ["MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED"]}, "predicted": {"google": {"tokens": ["{i)Al;almosteverypointinthedomain,DFinducesaLiea|gebrahomomol'phismfromthetangentspaceofthedomailltothetanargentspaceof'tleimage.."], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["{i)", "Al;", "almost", "every", "point", "in", "the", "domain,", "DF", "induces", "a", "Lie", "a|gebra", "homomol'phism", "from", "the", "tangent", "space", "of", "the", "domaill", "to", "the", "tanargent", "space", "of'", "tle", "image.."], "labels": ["WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "WRONG", "WRONG"]}, "BS-bid-OCR+google": {"tokens": ["{i)", "Al;", "almost", "every", "point", "in", "the", "domain,", "DF", "induces", "a", "Lie", "a|gebra", "homomorphism", "from", "the", "tangent", "space", "of", "the", "domaill", "to", "the", "tangent", "space", "of'", "tle", "image.."], "labels": ["WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "WRONG", "WRONG", "WRONG"]}}}, {"corrupt": {"tokens": ["weobaintbefollowingspectrum"], "labels": ["WRONG"]}, "correct": {"tokens": ["we", "obtain", "the", "following", "spectrum"], "labels": ["TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["weobaintbefollowingspectrum"], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["we", "obain", "tbe", "following", "spectrum"], "labels": ["TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["we", "obtain", "the", "following", "spectrum"], "labels": ["TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["TheauthorwouldlisketothankDanaFiefordiscussionsoffiberbundlewithex;ternalspace-timetranslation&roup.TheworkwassuppotedinpartbyJngShinR('.searchundendProf.LengMemorialFundoftheUMassDartmouthFoundatton."], "labels": ["WRONG"]}, "correct": {"tokens": ["The", "author", "would", "like", "to", "thank", "Dana", "Fine", "for", "discussions", "of", "fiber", "bundle", "with", "external", "space-time", "translation", "group.", "The", "work", "was", "supported", "in", "part", "by", "Jing", "Shin", "Research", "Fund", "and", "Prof.", "Leung", "Memorial", "Fund", "of", "the", "UMass", "Dartmouth", "Foundation."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "MIXED", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED"]}, "predicted": {"google": {"tokens": ["TheauthorwouldlisketothankDanaFiefordiscussionsoffiberbundlewithex;ternalspace-timetranslation&roup.TheworkwassuppotedinpartbyJngShinR('.searchundendProf.Leng", "Memorial", "Fund", "theUMassDartmouthFoundatton."], "labels": ["WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG"]}, "BS-bid-OCR": {"tokens": ["The", "author", "would", "liske", "to", "thank", "Dana", "Fie", "for", "discussions", "of", "fiber", "bundle", "with", "ex;ternal", "space-time", "translation", "&roup.", "The", "work", "was", "suppoted", "in", "part", "by", "Jng", "Shin", "R('.search", "und", "end", "Prof.", "Leng", "Memorial", "Fund", "of", "the", "UMass", "Dartmouth", "Foundatton."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "WRONG", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG"]}, "BS-bid-OCR+google": {"tokens": ["The", "author", "would", "liske", "to", "thank", "Dana", "Fie", "for", "discussions", "of", "fiber", "bundle", "with", "ex;ternal", "space-time", "translation", "group.", "The", "work", "was", "supported", "in", "part", "by", "Jung", "Shin", "R('.search", "und", "end", "Prof.", "Leng", "Memorial", "Fund", "of", "the", "UMass", "Dartmouth", "Foundation."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "WRONG", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED"]}}}, {"corrupt": {"tokens": ["wheremisthemaximalinvariantmeasureforfonJ(f)."], "labels": ["WRONG"]}, "correct": {"tokens": ["where", "m", "is", "the", "maximal", "invariant", "measure", "for", "f", "on", "J(f)."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["wheremisthemaximalinvariantmeasureforfonJ(f)."], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["where", "m", "is", "the", "maximal", "invariant", "measure", "for", "f", "on", "J(f)."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["where", "m", "is", "the", "maximal", "invariant", "measure", "for", "f", "on", "J(f)."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["OrbitingObservers"], "labels": ["WRONG"]}, "correct": {"tokens": ["Orbiting", "Observers"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["OrbitingObservers"], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["Orbiting", "Observers"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["Orbiting", "Observers"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["Commentsonthecondensationtemperaturointheilftera\\ctingcase"], "labels": ["WRONG"]}, "correct": {"tokens": ["Comments", "on", "the", "condensation", "temperature", "in", "the", "interacting", "case"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["Commentsonthecondensationtemperaturointheilftera\\ctingcase"], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["Comments", "on", "the", "condensation", "temperaturo", "in", "the", "ilftera\\cting", "case"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["Comments", "on", "the", "condensation", "temperature", "in", "the", "ilftera\\cting", "case"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["Letusdescribetheshememathematicallyandfollowupwithasimpleexaple.AlongsymmetrylinesandplancsintheBrillouinsone,teereexistsymmetryoperationsf'oreachkthatformagroup.?oreachsuchmpgrnuplheirre{luciblope.epresentations\u0393pcanbefound,andcanbeusedtoblock-diagonalizethesecularequation,"], "labels": ["WRONG"]}, "correct": {"tokens": ["Let", "us", "describe", "the", "scheme", "mathematically", "and", "follow", "up", "with", "a", "simple", "example.", "Along", "symmetry", "lines", "and", "planes", "in", "the", "Brillouin", "zone,", "there", "exist", "symmetry", "operations", "for", "each", "k", "that", "form", "a", "group.", "For", "each", "such", "group", "the", "irreducible", "representations", "\u0393p", "can", "be", "found,", "and", "can", "be", "used", "to", "block-diagonalize", "the", "secular", "equation,"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["Letusdescribetheshememathematicallyandfollowupwithasimpleexaple.AlongsymmetrylinesandplancsintheBrillouinsone,teereexistsymmetryoperationsf'oreachkthatformagroup.?oreachsuchmpgrnuplheirre{luciblope.epresentations\u0393pcanbefound,and", "canbeusedtoblock-diagonalize", "the", "secular", "equation,"], "labels": ["WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR": {"tokens": ["Let", "us", "describe", "the", "sheme", "mathematically", "and", "follow", "up", "with", "a", "simple", "exaple.", "Along", "symmetry", "lines", "and", "plancs", "in", "the", "Brillouin", "sone,", "teere", "exist", "symmetry", "operations", "f'or", "each", "k", "that", "form", "a", "group.", "?or", "each", "such", "mp", "grnup", "lhe", "irre{luciblope", ".epresentations", "\u0393p", "can", "be", "found,", "and", "can", "be", "used", "to", "block-diagonalize", "the", "secular", "equation,"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "WRONG", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["Let", "us", "describe", "the", "scheme", "mathematically", "and", "follow", "up", "with", "a", "simple", "example.", "Along", "symmetry", "lines", "and", "planes", "in", "the", "Brillouin", "zone,", "there", "exist", "symmetry", "operations", "for", "each", "k", "that", "form", "a", "group.", "?or", "each", "such", "mp", "group", "the", "irre{luciblope", ".epresentations", "\u0393p", "can", "be", "found,", "and", "can", "be", "used", "to", "block-diagonalize", "the", "secular", "equation,"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "MIXED", "MIXED", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["Theplotofl)oweragainstTypeIerrorrateIssometimesknolnastheReceirOperatingChal'acteristic,orROC,thenamearisingfromitsorigininradai:.Itisusedagooddealinmedicine(e.g.zweiq&Campbell1993).Ausefulquantitycouldbetheintegralunder\\theROCcurve,EnownastheA_UC(AreaUndertheCurve).Inourapplication,itisnotdlifficulrtoshowthattheAUCisthe\\probabilitythatthecvidenceratio,assumingH1,xceedstheevidenceratio,asumin6H0.Thiscon6ensestheROCintasinglenllmber,whichforourexamplessquiteclosetounity.Thismayb('a\\usefulcoInpressi()ninsbmecases,butjtdoeslosethepossibi?lityof~scribingweighttbtheegreebywhichtheevidenceratioexceede?achuther."], "labels": ["WRONG"]}, "correct": {"tokens": ["The", "plot", "of", "power", "against", "Type", "I", "error", "rate", "is", "sometimes", "known", "as", "the", "Receiver", "Operating", "Characteristic,", "or", "ROC,", "the", "name", "arising", "from", "its", "origin", "in", "radar.", "It", "is", "used", "a", "good", "deal", "in", "medicine", "(e.g.", "Zweig", "&", "Campbell", "1993).", "A", "useful", "quantity", "could", "be", "the", "integral", "under", "the", "ROC", "curve,", "known", "as", "the", "AUC", "(Area", "Under", "the", "Curve).", "In", "our", "application,", "it", "is", "not", "difficult", "to", "show", "that", "the", "AUC", "is", "the", "probability", "that", "the", "evidence", "ratio,", "assuming", "H1,", "exceeds", "the", "evidence", "ratio,", "assuming", "H0.", "This", "condenses", "the", "ROC", "into", "a", "single", "number,", "which", "for", "our", "examples", "is", "quite", "close", "to", "unity.", "This", "may", "be", "a", "useful", "compression", "in", "some", "cases,", "but", "it", "does", "lose", "the", "possibility", "of", "ascribing", "weight", "to", "the", "degree", "by", "which", "the", "evidence", "ratios", "exceed", "each", "other."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "MIXED"]}, "predicted": {"google": {"tokens": ["Theplotofl)oweragainstTypeIerrorrateIssometimesknolnastheReceirOperatingChal'acteristic,orROC,thenamearisingfromitsorigininradai:.Itisusedagooddealinmedicine(e.g.zweig", "&", "Campbell", "1993).Ausefulquantitycouldbetheintegralunder\\theROCcurve,EnownastheA_UC(AreaUndertheCurve).Inourapplication,itisnotdlifficulrtoshowthattheAUCisthe\\probabilitythatthecvidenceratio,assumingH1,xceedstheevidenceratio,asumin6H0.Thiscon6ensestheROCintasinglenllmber,whichforourexamplessquiteclosetounity.Thismayb('a\\useful", "coMpressi()ninsbmecases,butjtdoeslosethepossibi?lityof~scribingweighttbtheegreebywhichtheevidenceratioexceede?achuther."], "labels": ["WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG"]}, "BS-bid-OCR": {"tokens": ["The", "plot", "of", "l)ower", "against", "Type", "I", "error", "rate", "Is", "sometimes", "knoln", "as", "the", "Receir", "Operating", "Chal'acteristic,", "or", "ROC,", "the", "name", "arising", "from", "its", "origin", "in", "radai:.", "It", "is", "used", "a", "good", "deal", "in", "medicine", "(e.g.", "zweiq", "&", "Campbell", "1993).", "A", "useful", "quantity", "could", "be", "the", "integral", "under\\", "the", "ROC", "curve,", "Enown", "as", "the", "A_UC", "(Area", "Under", "the", "Curve).", "In", "our", "application,", "it", "is", "not", "dlifficulr", "to", "show", "that", "the", "AUC", "is", "the\\", "probability", "that", "the", "cvidence", "ratio,", "assuming", "H1,", "xceeds", "the", "evidence", "ratio,", "asumin6", "H0.", "This", "con6enses", "the", "ROC", "inta", "single", "nllmber,", "which", "for", "our", "examples", "s", "quite", "close", "to", "unity.", "This", "may", "b('", "a\\", "useful", "coInpressi()n", "in", "sbme", "cases,", "but", "jt", "does", "lose", "the", "possibi?lity", "of", "~scribing", "weight", "tb", "the", "egree", "by", "which", "the", "evidence", "ratio", "exceede?", "ach", "uther."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "WRONG", "WRONG"]}, "BS-bid-OCR+google": {"tokens": ["The", "plot", "of", "l)power", "against", "Type", "I", "error", "rate", "Is", "sometimes", "known", "as", "the", "Receiver", "Operating", "Characteristic,", "or", "ROC,", "the", "name", "arising", "from", "its", "origin", "in", "radai:.", "It", "is", "used", "a", "good", "deal", "in", "medicine", "(e.g.", "Zweig", "&", "Campbell", "1993).", "A", "useful", "quantity", "could", "be", "the", "integral", "under\\", "the", "ROC", "curve,", "Known", "as", "the", "A_UC", "(Area", "Under", "the", "Curve).", "In", "our", "application,", "it", "is", "not", "difficult", "to", "show", "that", "the", "AUC", "is", "the\\", "probability", "that", "the", "evidence", "ratio,", "assuming", "H1,", "xceeds", "the", "evidence", "ratio,", "assuming", "H0.", "This", "consensus", "the", "ROC", "into", "a", "single", "number,", "which", "for", "our", "examples", "is", "quite", "close", "to", "unity.", "This", "may", "be('", "a\\", "useful", "coMpressi()n", "in", "sbme", "cases,", "but", "it", "does", "lose", "the", "possibility", "of", "~scribing", "weight", "to", "the", "degree", "by", "which", "the", "evidence", "ratio", "exceeds", "each", "other."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "MIXED", "MIXED"]}}}, {"corrupt": {"tokens": ["Atone-looporderthefermioniccontributiont.otiheenergycanbeewrittenas"], "labels": ["WRONG"]}, "correct": {"tokens": ["At", "one-loop", "order", "the", "fermionic", "contribution", "to", "the", "energy", "can", "be", "rewritten", "as"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["Stone-loop", "order", "Thefermioniccontributiont.otiheenergycanbeewrittenas"], "labels": ["WRONG", "TOKENIZATION_ERROR", "WRONG"]}, "BS-bid-OCR": {"tokens": ["At", "one-loop", "order", "the", "fermionic", "contribution", "t.o", "tihe", "energy", "can", "be", "ewritten", "as"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["At", "one-loop", "order", "the", "fermionic", "contribution", "t.o", "the", "energy", "can", "be", "rewritten", "as"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["Hence,forLBOgravity,theGNEC,GECat~GSECarerespccively"], "labels": ["WRONG"]}, "correct": {"tokens": ["Hence,", "for", "LBD", "gravity,", "the", "GNEC,", "GWEC", "and", "GSEC", "are", "respectively"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED"]}, "predicted": {"google": {"tokens": ["Hence,forLBOgravity,theGNEC,GECat~GSECarerespcc", "lively"], "labels": ["WRONG", "WRONG"]}, "BS-bid-OCR": {"tokens": ["Hence,", "for", "LBO", "gravity,", "the", "GNEC,", "GEC", "at~", "GSEC", "are", "respccively"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG"]}, "BS-bid-OCR+google": {"tokens": ["Hence,", "for", "LBO", "gravity,", "the", "GNEC,", "GEC", "at~", "GSEC", "are", "respectively"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED"]}}}, {"corrupt": {"tokens": ["Assnimmedlateconsequenceoftheaboveresult,webarvethefollowingcorollary:"], "labels": ["WRONG"]}, "correct": {"tokens": ["As", "an", "immediate", "consequence", "of", "the", "above", "result,", "we", "have", "the", "following", "corollary:"], "labels": ["TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["Assnimmedlateconsequenceoftheaboveresult,webarvethefollowingcorollary:"], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["As", "sn", "immedlate", "consequence", "of", "the", "above", "result,", "we", "barve", "the", "following", "corollary:"], "labels": ["TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["As", "an", "immediate", "consequence", "of", "the", "above", "result,", "we", "barve", "the", "following", "corollary:"], "labels": ["TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["Thedcrivedmeanrelationsbet\\weenthetwosystmsareaslollow:"], "labels": ["WRONG"]}, "correct": {"tokens": ["The", "derived", "mean", "relations", "between", "the", "two", "systems", "are", "as", "follow:"], "labels": ["TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED"]}, "predicted": {"google": {"tokens": ["Thedcrivedmeanrelationsbet\\weenthetwosystmsareaslollow:"], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["The", "dcrived", "mean", "relations", "bet\\ween", "the", "two", "systms", "are", "as", "lollow:"], "labels": ["TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG"]}, "BS-bid-OCR+google": {"tokens": ["The", "derived", "mean", "relations", "bet\\ween", "the", "two", "systems", "are", "as", "follow:"], "labels": ["TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED"]}}}, {"corrupt": {"tokens": ["Disentanglingthe(1ielectricpropertiesofpristinegraphite?fromtheeffectsOfsize,shapesor.ientation,agglomerationandaggregationrequiresinvcrtingthemathematicaloperattonsofRouleauandMnartin,whichi8obviouslyaverytrickybusiness.DerivatiOnfrotmrefletancemeasurements,asinthepresentwork,appearstobeanappealingaltern?ative."], "labels": ["WRONG"]}, "correct": {"tokens": ["Disentangling", "the", "dielectric", "properties", "of", "pristine", "graphite", "from", "the", "effects", "of", "size,", "shape,", "orientation,", "agglomeration", "and", "aggregation", "requires", "inverting", "the", "mathematical", "operations", "of", "Rouleau", "and", "Martin,", "which", "is", "obviously", "a", "very", "tricky", "business.", "Derivation", "from", "reflectance", "measurements,", "as", "in", "the", "present", "work,", "appears", "to", "be", "an", "appealing", "alternative."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED"]}, "predicted": {"google": {"tokens": ["Disentangling", "The(1ielectricpropertiesofpristinegraphite?fromtheeffectsOfsize,shapesor.ientation,agglomerationandaggregationrequiresinvcrtingthemathematicaloperattonsofRouleauandMnartin,whichi8obviouslyaverytrickybusiness.DerivatiOnfrotmrefletancemeasurements,asinthepresentwork,appearstobeanappealingaltern?ative."], "labels": ["TOKENIZATION_ERROR", "WRONG"]}, "BS-bid-OCR": {"tokens": ["Disentangling", "the", "(1ielectric", "properties", "of", "pristine", "graphite?", "from", "the", "effects", "Of", "size,", "shapes", "or.ientation,", "agglomeration", "and", "aggregation", "requires", "invcrting", "the", "mathematical", "operattons", "of", "Rouleau", "and", "Mnartin,", "which", "i8", "obviously", "a", "very", "tricky", "business.", "DerivatiOn", "frotm", "refletance", "measurements,", "as", "in", "the", "present", "work,", "appears", "to", "be", "an", "appealing", "altern?ative."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG"]}, "BS-bid-OCR+google": {"tokens": ["Disentangling", "the", "(1ielectric", "properties", "of", "pristine", "graphite?", "From", "the", "effects", "Of", "size,", "shape", "orientation,", "agglomeration", "and", "aggregation", "requires", "inverting", "the", "mathematical", "operations", "of", "Rouleau", "and", "Martin,", "which", "i8", "obviously", "a", "very", "tricky", "business.", "DerivatiOn", "from", "reflectance", "measurements,", "as", "in", "the", "present", "work,", "appears", "to", "be", "an", "appealing", "alternative."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED"]}}}, {"corrupt": {"tokens": ["asdthefollowingbounds"], "labels": ["WRONG"]}, "correct": {"tokens": ["and", "the", "following", "bounds"], "labels": ["MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["asdthefollowingbounds"], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["asd", "the", "following", "bounds"], "labels": ["WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["asd", "the", "following", "bounds"], "labels": ["WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["wIththeotalm~mssM=m1+m2."], "labels": ["WRONG"]}, "correct": {"tokens": ["with", "the", "total", "mass", "M", "=", "m1", "+", "m2."], "labels": ["MIXED", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["wIththeotalm~mssM=m1+m2."], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["wIth", "the", "otal", "m~mss", "M", "=", "m1", "+", "m2."], "labels": ["WRONG", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["wIth", "the", "total", "m~mss", "M", "=", "m1", "+", "m2."], "labels": ["WRONG", "TOKENIZATION_ERROR", "MIXED", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["NaandSabundances"], "labels": ["WRONG"]}, "correct": {"tokens": ["Na", "and", "S", "abundances"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["And", "Abundances"], "labels": ["WRONG", "WRONG"]}, "BS-bid-OCR": {"tokens": ["Na", "and", "S", "abundances"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["Na", "and", "S", "abundances"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["VerifyingthetheOreticilcalc.u?lat{ons"], "labels": ["WRONG"]}, "correct": {"tokens": ["Verifying", "the", "theoretical", "calculations"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED"]}, "predicted": {"google": {"tokens": ["Verifying", "the", "theOretical", "calc.u?later{ons"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG"]}, "BS-bid-OCR": {"tokens": ["Verifying", "the", "theOreticil", "calc.u?lat{ons"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG"]}, "BS-bid-OCR+google": {"tokens": ["Verifying", "the", "theOretical", "calcu?lat{ons"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG"]}}}, {"corrupt": {"tokens": ["Nextweinvestigatethemonomi;alrelations."], "labels": ["WRONG"]}, "correct": {"tokens": ["Next", "we", "investigate", "the", "monomial", "relations."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["Next", "We", "Investigate", "Their", "Omi;al", "relations."], "labels": ["TOKENIZATION_ERROR", "WRONG", "WRONG", "WRONG", "WRONG", "TOKENIZATION_ERROR"]}, "BS-bid-OCR": {"tokens": ["Next", "we", "investigate", "the", "monomi;al", "relations."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["Next", "we", "investigate", "the", "monomi;al", "relations."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["sinceth?eheartofthispathingproblemisthelackofturninfo1\"mationoneapproiachitotreatthisasaclassificatIonproblem.Here,weexainel;\\hespeedtracestoxtractfeatures:stop,rightturn,leftturn,oorstraightroad.Ifclassificatienwolildworkwell,wecanassignprobabilitiestodifferentclmLcesantgachintersectionandeventuallyflndthehighestprobabilitypath.However,roadconditionsanddrivinghabit~areverydiverse.Withourdatasetwewereunabletoclassifturnfeatureswitilhighenoughaccuracytobuildcorectpahs.Thesheervolumenofpathstoexploremeantthatunlessthecorrectvathwase'\\xtremelydiffrentfromalloftheincorrectpaths,thealgorithmwouldfihdsomeincorrectpathshatlookedjustasgood,orbetter~thanthecorrectpai;h."], "labels": ["WRONG"]}, "correct": {"tokens": ["Since", "the", "heart", "of", "this", "pathing", "problem", "is", "the", "lack", "of", "turn", "information", "one", "approach", "is", "to", "treat", "this", "as", "a", "classification", "problem.", "Here,", "we", "examine", "the", "speed", "traces", "to", "extract", "features:", "stop,", "right", "turn,", "left", "turn,", "or", "straight", "road.", "If", "classification", "would", "work", "well,", "we", "can", "assign", "probabilities", "to", "different", "choices", "at", "each", "intersection", "and", "eventually", "find", "the", "highest", "probability", "path.", "However,", "road", "conditions", "and", "driving", "habits", "are", "very", "diverse.", "With", "our", "data", "set", "we", "were", "unable", "to", "classify", "turn", "features", "with", "high", "enough", "accuracy", "to", "build", "correct", "paths.", "The", "sheer", "volume", "of", "paths", "to", "explore", "meant", "that", "unless", "the", "correct", "path", "was", "extremely", "different", "from", "all", "of", "the", "incorrect", "paths,", "the", "algorithm", "would", "find", "some", "incorrect", "paths", "that", "looked", "just", "as", "good,", "or", "better,", "than", "the", "correct", "path."], "labels": ["MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED"]}, "predicted": {"google": {"tokens": ["since", "the", "heart", "thispathingproblemisthelackofturninfo1\"mationoneapproiachitotreatthisasaclassificatIonproblem.Here,weexainel;\\hespeedtracestoxtractfeatures:stop,rightturn,leftturn,oorstraightroad.Ifclassificatienwolildworkwell,wecanassignprobabilitiestodifferentclmLcesantgachintersectionandeventuallyflndthehighestprobabilitypath.However,roadconditionsanddrivinghabit~areverydiverse.Withourdatasetwewereunabletoclassifturnfeatureswitilhighenoughaccuracytobuildcorectpahs.Thesheervolumenofpathstoexploremeantthatunlessthecorrectvathwase'\\xtremelydiffrentfromalloftheincorrectpaths,thealgorithmwouldfihdsomeincorrectpathshatlookedjustasgood,orbetter~thanthecorrectpai;h."], "labels": ["WRONG", "MIXED", "TOKENIZATION_ERROR", "WRONG"]}, "BS-bid-OCR": {"tokens": ["since", "th?e", "heart", "of", "this", "pathing", "problem", "is", "the", "lack", "of", "turn", "info1\"mation", "one", "approiachi", "to", "treat", "this", "as", "a", "classificatIon", "problem.", "Here,", "we", "exaine", "l;\\he", "speed", "traces", "to", "xtract", "features:", "stop,", "right", "turn,", "left", "turn,", "oor", "straight", "road.", "If", "classificatien", "wolild", "work", "well,", "we", "can", "assign", "probabilities", "to", "different", "clmLces", "ant", "gach", "intersection", "and", "eventually", "flnd", "the", "highest", "probability", "path.", "However,", "road", "conditions", "and", "driving", "habit~", "are", "very", "diverse.", "With", "our", "dataset", "we", "were", "unable", "to", "classif", "turn", "features", "witil", "high", "enough", "accuracy", "to", "build", "corect", "pahs.", "The", "sheer", "volumen", "of", "paths", "to", "explore", "meant", "that", "unless", "the", "correct", "vath", "was", "e'\\xtremely", "diffrent", "from", "all", "of", "the", "incorrect", "paths,", "the", "algorithm", "would", "fihd", "some", "incorrect", "paths", "hat", "looked", "just", "as", "good,", "or", "better", "~than", "the", "correct", "pai;h."], "labels": ["WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG"]}, "BS-bid-OCR+google": {"tokens": ["Since", "the", "heart", "of", "this", "pathing", "problem", "is", "the", "lack", "of", "turn", "info1,", "one", "approach", "to", "treat", "this", "as", "a", "classificatIon", "problem.", "Here,", "we", "examine", "l;\\he", "speed", "traces", "to", "extract", "features:", "stop,", "right", "turn,", "left", "turn,", "oor", "straight", "road.", "If", "classification", "would", "work", "well,", "we", "can", "assign", "probabilities", "to", "different", "climAtes", "at", "each", "intersection", "and", "eventually", "find", "the", "highest", "probability", "path.", "However,", "road", "conditions", "and", "driving", "habit~", "are", "very", "diverse.", "With", "our", "dataset", "we", "were", "unable", "to", "classify", "turn", "features", "witil", "high", "enough", "accuracy", "to", "build", "correct", "paths.", "The", "sheer", "volume", "of", "paths", "to", "explore", "meant", "that", "unless", "the", "correct", "vath", "was", "e'\\xtremely", "different", "from", "all", "of", "the", "incorrect", "paths,", "the", "algorithm", "would", "find", "some", "incorrect", "paths", "that", "looked", "just", "as", "good,", "or", "better", "~than", "the", "correct", "pai;h."], "labels": ["MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG"]}}}, {"corrupt": {"tokens": ["for"], "labels": ["NONE"]}, "correct": {"tokens": ["for"], "labels": ["NONE"]}, "predicted": {"google": {"tokens": ["for"], "labels": ["NONE"]}, "BS-bid-OCR": {"tokens": ["for"], "labels": ["NONE"]}, "BS-bid-OCR+google": {"tokens": ["for"], "labels": ["NONE"]}}}, {"corrupt": {"tokens": ["TheLeviForm"], "labels": ["WRONG"]}, "correct": {"tokens": ["The", "Levi", "Form"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["TheLeviForm"], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["The", "Levi", "Form"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["The", "Levi", "Form"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["reminiscesetoftheEO$ofnoninteractingquans."], "labels": ["WRONG"]}, "correct": {"tokens": ["reminiscent", "of", "the", "EOS", "of", "noninteracting", "quarks."], "labels": ["MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED"]}, "predicted": {"google": {"tokens": ["reminisce", "tafheEM$of", "noninteracting", "quans."], "labels": ["WRONG", "WRONG", "TOKENIZATION_ERROR", "WRONG"]}, "BS-bid-OCR": {"tokens": ["reminisceset", "of", "the", "EO$", "of", "noninteracting", "quans."], "labels": ["WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG"]}, "BS-bid-OCR+google": {"tokens": ["reminiscent", "of", "the", "EO$", "of", "noninteracting", "quans."], "labels": ["MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG"]}}}, {"corrupt": {"tokens": ["WeexPloredantennaseleclionasapracticalwayi)fachieving'thefulldiversityorerofthenonregeneratI?veIMOrelaychannel.ItwasshowntoachievethisdiversitywitilasmallSNRpenaltyrelativetoGrassmanniancodebeoks."], "labels": ["WRONG"]}, "correct": {"tokens": ["We", "explored", "antenna", "selection", "as", "a", "practical", "way", "of", "achieving", "the", "full", "diversity", "order", "of", "the", "nonregenerative", "MIMO", "relay", "channel.", "It", "was", "shown", "to", "achieve", "this", "diversity", "with", "a", "small", "SNR", "penalty", "relative", "to", "Grassmannian", "codebooks."], "labels": ["TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED"]}, "predicted": {"google": {"tokens": ["WeexPloredantennaseleclionasapracticalwayi)fachieving'thefulldiversityorerofthenonregeneratI?veIMOrelaychannel.ItwasshowntoachievethisdiversitywitilasmallSNRpenaltyrelativetoGrassmanniancodebeoks."], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["We", "exPlored", "antenna", "seleclion", "as", "a", "practical", "way", "i)f", "achieving", "'the", "full", "diversity", "orer", "of", "the", "nonregeneratI?ve", "IMO", "relay", "channel.", "It", "was", "shown", "to", "achieve", "this", "diversity", "witil", "a", "small", "SNR", "penalty", "relative", "to", "Grassmannian", "codebeoks."], "labels": ["TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG"]}, "BS-bid-OCR+google": {"tokens": ["We", "exPlored", "antenna", "selection", "as", "a", "practical", "way", "i)f", "achieving", "'the", "full", "diversity", "order", "of", "the", "non", "regenerative", "MIMO", "relay", "channel.", "It", "was", "shown", "to", "achieve", "this", "diversity", "within", "a", "small", "SNR", "penalty", "relative", "to", "Grassmannian", "codebooks."], "labels": ["TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED"]}}}, {"corrupt": {"tokens": ["itrangesfromavalueof\u03ba=0forasymmetricpulseto\u03ba=1foranasymmetricpulsewitharapidriseandslowdecay."], "labels": ["WRONG"]}, "correct": {"tokens": ["it", "ranges", "from", "a", "value", "of", "\u03ba", "=", "0", "for", "a", "symmetric", "pulse", "to", "\u03ba", "=", "1", "for", "an", "asymmetric", "pulse", "with", "a", "rapid", "rise", "and", "slow", "decay."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["itrangesfromavalueof\u03ba=0forasymmetricpulseto\u03ba=1foranasymmetricpulsewitharapidriseandslowdecay."], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["it", "ranges", "from", "a", "value", "of", "\u03ba", "=", "0", "for", "a", "symmetric", "pulse", "to", "\u03ba", "=", "1", "for", "an", "asymmetric", "pulse", "with", "a", "rapid", "rise", "and", "slow", "decay."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["it", "ranges", "from", "a", "value", "of", "\u03ba", "=", "0", "for", "a", "symmetric", "pulse", "to", "\u03ba", "=", "1", "for", "an", "asymmetric", "pulse", "with", "a", "rapid", "rise", "and", "slow", "decay."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["Intheremainder,wealwaysr?efertosomearbitrarynodeinthenetwo~kand{ilusmakenodistinctionbeteennodes.Thisisbecausethealgorithmsthatweexamine,considereachnodeindependentlyoftheothers.Consequently,thefollowingsectionanalysestheexpect\\edlossforasingienodeoficunknowntype."], "labels": ["WRONG"]}, "correct": {"tokens": ["In", "the", "remainder,", "we", "always", "refer", "to", "some", "arbitrary", "node", "in", "the", "network", "and", "thus", "make", "no", "distinction", "between", "nodes.", "This", "is", "because", "the", "algorithms", "that", "we", "examine,", "consider", "each", "node", "independently", "of", "the", "others.", "Consequently,", "the", "following", "section", "analyses", "the", "expected", "loss", "for", "a", "single", "node", "of", "unknown", "type."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["Intheremainder,wealwaysr?efertosomearbitrarynodeinthenetwo~kand{ilusmakenodistinctionbeteennodes.Thisisbecausethealgorithmsthatweexamine,considereachnode", "independently", "of", "the", "others.Consequently,the", "followingsectionanalysestheexpect\\edlossforasingienodeoficun", "knowntype."], "labels": ["WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "WRONG"]}, "BS-bid-OCR": {"tokens": ["In", "the", "remainder,", "we", "always", "r?efer", "to", "some", "arbitrary", "node", "in", "the", "netwo~k", "and", "{ilus", "make", "no", "distinction", "beteen", "nodes.", "This", "is", "because", "the", "algorithms", "that", "we", "examine,", "consider", "each", "node", "independently", "of", "the", "others.", "Consequently,", "the", "following", "section", "analyses", "the", "expect\\ed", "loss", "for", "a", "singie", "node", "ofic", "unknown", "type."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["In", "the", "remainder,", "we", "always", "refer", "to", "some", "arbitrary", "node", "in", "the", "netwo~k", "and", "{ilus", "makes", "no", "distinction", "between", "nodes.", "This", "is", "because", "the", "algorithms", "that", "we", "examine,", "consider", "each", "node", "independently", "of", "the", "others.", "Consequently,", "the", "following", "section", "analyses", "the", "expect\\ed", "loss", "for", "a", "single", "node", "of", "unknown", "type."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["proving"], "labels": ["NONE"]}, "correct": {"tokens": ["proving"], "labels": ["NONE"]}, "predicted": {"google": {"tokens": ["proving"], "labels": ["NONE"]}, "BS-bid-OCR": {"tokens": ["proving"], "labels": ["NONE"]}, "BS-bid-OCR+google": {"tokens": ["proving"], "labels": ["NONE"]}}}, {"corrupt": {"tokens": ["Densityandpressuredistributi(m"], "labels": ["WRONG"]}, "correct": {"tokens": ["Density", "and", "pressure", "distribution"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED"]}, "predicted": {"google": {"tokens": ["Density", "And", "Pressure", "Distribution(m"], "labels": ["TOKENIZATION_ERROR", "WRONG", "WRONG", "WRONG"]}, "BS-bid-OCR": {"tokens": ["Density", "and", "pressure", "distributi(m"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG"]}, "BS-bid-OCR+google": {"tokens": ["Density", "and", "pressure", "distribution(m"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG"]}}}, {"corrupt": {"tokens": ["Gonsidertheycasewlerefisaquasi-periodicfunction.Wehavethefollowingresultonthenon-existenceofk-quasi-periodicsolutions."], "labels": ["WRONG"]}, "correct": {"tokens": ["Consider", "the", "case", "where", "f", "is", "a", "quasi-periodic", "function.", "We", "have", "the", "following", "result", "on", "the", "non-existence", "of", "k-quasi-periodic", "solutions."], "labels": ["MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["Gonsidertheycasewlerefisaquasi-periodic", "function.Wehavethefollowingresultonthenon-existence", "k-quasi-periodic", "solutions."], "labels": ["WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR": {"tokens": ["Gonsider", "they", "case", "wlere", "f", "is", "a", "quasi-periodic", "function.", "We", "have", "the", "following", "result", "on", "the", "non-existence", "of", "k-quasi-periodic", "solutions."], "labels": ["WRONG", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["Consider", "the", "case", "where", "f", "is", "a", "quasi-periodic", "function.", "We", "have", "the", "following", "result", "on", "the", "non-existence", "of", "k-quasi-periodic", "solutions."], "labels": ["MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["Theappearancecf?rings,ringiensesandlensesisnctverysensitivetogalaxylnminosity.However,hwhllelumpingtogethertheouerlense\\s(L)an.dringlenses(RL)theyapp(',&rmoref~requentlyamongthefaintergalaxics(32\u00b15%vs*19\u00b14%intstwogala?yluminesit?bins,respectively;Table3n,)l.Also,theinerrings(r,rs)appearmorefrequentlyamongthefaintergalaxies(20\u00b14%vs.3\u00b12%,inthetwobins,respectivcly).\u0002hetendenciesaresimilarifonlythebarredgalaxiesareconsi(h;red('Pable6)."], "labels": ["WRONG"]}, "correct": {"tokens": ["The", "appearance", "of", "rings,", "ringlenses", "and", "lenses", "is", "not", "very", "sensitive", "to", "galaxy", "luminosity.", "However,", "while", "lumping", "together", "the", "outer", "lenses", "(L)", "and", "ringlenses", "(RL)", "they", "appear", "more", "frequently", "among", "the", "fainter", "galaxies", "(32\u00b15%", "vs.", "19\u00b14%", "in", "the", "two", "galaxy", "luminosity", "bins,", "respectively;", "Table", "3,", ").", "Also,", "the", "inner", "rings", "(r,rs)", "appear", "more", "frequently", "among", "the", "fainter", "galaxies", "(20\u00b14%", "vs.", "3\u00b12%,", "in", "the", "two", "bins,", "respectively).", "The", "tendencies", "are", "similar", "if", "only", "the", "barred", "galaxies", "are", "considered", "(Table", "6)."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["Theappearancecf?rings,ringiensesandlensesisnctverysensitivetogalaxylnminosity.However,hwhllelumpingtogethertheouerlense\\s(L)an.dringlenses(RL)theyapp(',&rmoref~requentlyamongthefaintergalaxics(32\u00b15%vs*19\u00b14%intstwogala?yluminesit?bins,respectively;Table3n,)l.Also,theinerrings(r,rs)appear", "more", "frequently", "among", "the", "fainter", "galaxies(20\u00b14%vs.3\u00b12%,inthetwo", "bins,respectively).hetendenciesaresimilarifonlythebarredgalaxiesareconsi(h;red('Pable6)."], "labels": ["WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG"]}, "BS-bid-OCR": {"tokens": ["The", "appearance", "cf", "?rings,", "ring", "ienses", "and", "lenses", "is", "nct", "very", "sensitive", "to", "galaxy", "lnminosity.", "However,h", "whlle", "lumping", "together", "the", "ouer", "lense\\s", "(L)", "an.d", "ring", "lenses", "(RL)", "they", "app(',&r", "more", "f~requently", "among", "the", "fainter", "galaxics", "(32", "\u00b1", "5%", "vs*", "19", "\u00b1", "4%", "in", "ts", "two", "gala?y", "luminesit?", "bins,", "respectively;", "Table", "3n,)l.", "Also,", "the", "iner", "rings", "(r,", "rs)", "appear", "more", "frequently", "among", "the", "fainter", "galaxies", "(20\u00b14%", "vs.", "3", "\u00b1", "2%,", "in", "the", "two", "bins,", "respectivcly).", "\u0002he", "tendencies", "are", "similar", "if", "only", "the", "barred", "galaxies", "are", "consi(h;red", "('Pable", "6)."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "WRONG", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "WRONG", "WRONG", "WRONG", "WRONG", "WRONG", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["The", "appearance", "of", "rings,", "ring", "lenses", "and", "lenses", "is", "nct", "very", "sensitive", "to", "galaxy", "luminosity.", "However,h", "while", "lumping", "together", "the", "outer", "lense\\s", "(L)", "an.d", "ring", "lenses", "(RL)", "they", "app(',h&r", "more", "f~requently", "among", "the", "fainter", "galaxies", "(32", "\u00b1", "5%", "vs*", "19", "\u00b1", "4%", "in", "its", "two", "galaxy", "luminosities?", "bins,", "respectively;", "Table", "3n,)l.", "Also,", "the", "inner", "rings", "(r,", "rs)", "appear", "more", "frequently", "among", "the", "fainter", "galaxies", "(20\u00b14%", "vs.", "3", "\u00b1", "2%,", "in", "the", "two", "bins,", "respectively).", "he", "tendencies", "are", "similar", "if", "only", "the", "barred", "galaxies", "are", "consi(h;red", "('Pable", "6)."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "WRONG", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "WRONG", "TOKENIZATION_ERROR", "WRONG", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "WRONG", "WRONG", "WRONG", "WRONG", "WRONG", "WRONG", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "MIXED", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["A8anexample,wehave"], "labels": ["WRONG"]}, "correct": {"tokens": ["As", "an", "example,", "we", "have"], "labels": ["MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["A8ani", "Example,we", "have"], "labels": ["WRONG", "WRONG", "TOKENIZATION_ERROR"]}, "BS-bid-OCR": {"tokens": ["A8", "an", "example,", "we", "have"], "labels": ["WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["A8", "an", "example,", "we", "have"], "labels": ["WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["Atthiteperatureboththepressure"], "labels": ["WRONG"]}, "correct": {"tokens": ["At", "this", "temperature", "both", "the", "pressure"], "labels": ["TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["Atthiteperatureboththepressure"], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["At", "thi", "teperature", "both", "the", "pressure"], "labels": ["TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["At", "the", "temperature", "both", "the", "pressure"], "labels": ["TOKENIZATION_ERROR", "WRONG", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["whichfollowsfromtimphysicalmeaningofPn,asaprobabil~ty.Thesolution,withtilesetwocol,ditions,willgi?veusthesumofenhtnceddiagrams.;"], "labels": ["WRONG"]}, "correct": {"tokens": ["which", "follows", "from", "the", "physical", "meaning", "of", "Pn", "as", "a", "probability.", "The", "solution,", "with", "these", "two", "conditions,", "will", "give", "us", "the", "sum", "of", "enhanced", "diagrams."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["whichfollowsfromtimphysicalmeaningofPn,asaprobabil~ty.Thesolution,withtilesetwocol,ditions,willgi?veusthesumofenhtnceddiagrams.;"], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["which", "follows", "from", "tim", "physical", "meaning", "of", "Pn,", "as", "a", "probabil~ty.", "The", "solution,", "with", "tilese", "two", "col,ditions,", "will", "gi?ve", "us", "the", "sum", "of", "enhtnced", "diagrams.;"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG"]}, "BS-bid-OCR+google": {"tokens": ["which", "follows", "from", "the", "physical", "meaning", "of", "Pn,", "as", "a", "probability.", "The", "solution,", "with", "tiles", "two", "col,ditions,", "will", "give", "us", "the", "sum", "of", "enhanced", "diagrams.;"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "WRONG"]}}}, {"corrupt": {"tokens": ["Theoretiealbackground"], "labels": ["WRONG"]}, "correct": {"tokens": ["Theoretical", "background"], "labels": ["MIXED", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["Theoretical", "Background"], "labels": ["MIXED", "WRONG"]}, "BS-bid-OCR": {"tokens": ["Theoretieal", "background"], "labels": ["WRONG", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["Theoretical", "background"], "labels": ["MIXED", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["Followingthesamemanipulationsasfordescent=based\u03c3,weobtainthecorrespondingoperatorsshowninthetablcbelow,"], "labels": ["WRONG"]}, "correct": {"tokens": ["Following", "the", "same", "manipulations", "as", "for", "descent=based", "\u03c3,", "we", "obtain", "the", "corresponding", "operators", "shown", "in", "the", "table", "below."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED"]}, "predicted": {"google": {"tokens": ["Following", "The", "Same", "Manipulations", "Asfordescent=based\u03c3,weobtainthecorrespondingoperatorsshowninthetablcbelow,"], "labels": ["TOKENIZATION_ERROR", "WRONG", "WRONG", "WRONG", "WRONG"]}, "BS-bid-OCR": {"tokens": ["Following", "the", "same", "manipulations", "as", "for", "descent=based", "\u03c3,", "we", "obtain", "the", "corresponding", "operators", "shown", "in", "the", "tablc", "below,"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG"]}, "BS-bid-OCR+google": {"tokens": ["Following", "the", "same", "manipulations", "as", "for", "descent=based", "\u03c3,", "we", "obtain", "the", "corresponding", "operators", "shown", "in", "the", "table", "below,"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "WRONG"]}}}, {"corrupt": {"tokens": ["andthepart,itionfunctio~tbecomes"], "labels": ["WRONG"]}, "correct": {"tokens": ["and", "the", "partition", "function", "becomes"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["andthepart,itionfunctio~tbecomes"], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["and", "the", "part,ition", "functio~t", "becomes"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["and", "the", "partition", "function~t", "becomes"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "WRONG", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["Furthermore,bydefinition,wehavc"], "labels": ["WRONG"]}, "correct": {"tokens": ["Furthermore,", "by", "definition,", "we", "have"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED"]}, "predicted": {"google": {"tokens": ["Furthermore,definition,hvac"], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["Furthermore,", "by", "definition,", "we", "havc"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG"]}, "BS-bid-OCR+google": {"tokens": ["Furthermore,", "by", "definition,", "we", "hvac"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG"]}}}, {"corrupt": {"tokens": ["WZWmodelsa?smutualsuperPoisson-LieT-dllalsigmamodels"], "labels": ["WRONG"]}, "correct": {"tokens": ["WZW", "models", "as", "mutual", "super", "Poisson-Lie", "T-dual", "sigma", "models"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["WZW", "models?mutual", "super", "Poisson-LieT-dll", "sigma", "models"], "labels": ["TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR": {"tokens": ["WZW", "models", "a?s", "mutual", "super", "Poisson-Lie", "T-dllal", "sigma", "models"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["WZW", "models", "a?s", "mutual", "super", "Poisson-Lie", "TO-dellal", "sigma", "models"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["modelCoDES-GroupsXXX.tar."], "labels": ["WRONG"]}, "correct": {"tokens": ["model", "CoDECS-Groups", "XXX.tar", "."], "labels": ["TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["modelCoDES-GroupsXXX.tar."], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["model", "CoDES-Groups", "XXX.tar."], "labels": ["TOKENIZATION_ERROR", "WRONG", "WRONG"]}, "BS-bid-OCR+google": {"tokens": ["model", "CoDES-Groups", "XXX.tar."], "labels": ["TOKENIZATION_ERROR", "WRONG", "WRONG"]}}}, {"corrupt": {"tokens": ["(ii)\u03c0iisagenerically\\[iaite-to-one."], "labels": ["WRONG"]}, "correct": {"tokens": ["(ii)", "\u03c0i", "is", "a", "generically", "finite-to-one."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED"]}, "predicted": {"google": {"tokens": ["(ii)\u03c0iisagenerically\\[iaite-to-one."], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["(ii)", "\u03c0i", "is", "a", "generically", "\\[iaite-to-one."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG"]}, "BS-bid-OCR+google": {"tokens": ["(ii)", "\u03c0i", "is", "generically", "\\[iaite-to-one."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG"]}}}, {"corrupt": {"tokens": ["SincePyisspe,cial,SerredualityOimpliesthat"], "labels": ["WRONG"]}, "correct": {"tokens": ["Since", "Py", "is", "special,", "Serre", "duality", "implies", "that"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["SincePyisspe,cial,SerredualityOimpliesthat"], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["Since", "Py", "is", "spe,cial,", "Serre", "dualityO", "implies", "that"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["Since", "Py", "is", "special,", "Serre", "dualityO", "implies", "that"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["Nctethat\u03c4kd<0."], "labels": ["WRONG"]}, "correct": {"tokens": ["Note", "that", "\u03c4kd", "<", "0."], "labels": ["MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["Nctethat\u03c4kd<0."], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["Ncte", "that", "\u03c4kd", "<", "0."], "labels": ["WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["Ncte", "that", "\u03c4kd", "<", "0."], "labels": ["WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["Inthefollowingsubsectionsu,wewillcxplorehowwelltheLHCandILCmayadvanceStages2and3."], "labels": ["WRONG"]}, "correct": {"tokens": ["In", "the", "following", "subsections,", "we", "will", "explore", "how", "well", "the", "LHC", "and", "ILC", "may", "advance", "Stages", "2", "and", "3."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["Inthefollowingsubsectionsu,wewillcxplorehowwelltheLHCandILCmayadvanceStages2and3."], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["In", "the", "following", "subsectionsu,", "we", "will", "cxplore", "how", "well", "the", "LHC", "and", "ILC", "may", "advance", "Stages", "2", "and", "3."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["In", "the", "following", "subsections,", "we", "will", "explore", "how", "well", "the", "LHC", "and", "ILC", "may", "advance", "Stages", "2", "and", "3."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["ADAGlnodelencodescOndltionalindepen\\dencerel~tionshipsviatheuotionof(l-separation.SeveralDAGscouldencodethexamesetofconditionalindepedplencerelatiohips.ThesKeDAGsformanequivalencecluss,enSistingofDAGswiththesameskeletonandv-structures.Acompletepartiallydirectedacyclicgraph(CPDAG)uniquelydescribessuchanequivalenLeclass.Intf~ct,directededgesintheCPDAGarecommontoallDAGsintheequivalenceclass.UndtrectedegesintheCPDA(;correspondtoedgesthat,~redirectedonwayinsomeDAGsandanotherwayinotherDAGsoftieequvaienceclass.TheabsenceofedgesintheCPDALmeansthatallDlAGmemberinth'eequivalenceelasshave?ocorrespondingedge.Ifallthecondimetionalindependenc\u0002relationshiosofadistributlonPandnoaddition\\alconditionatindependencer(:lations,canbeinferrc.dfromtheraph?,wesaythalthedistributlonPisfaithfultotheDACG.Moreprecisely,ifPisfaithfultotheDAGG:foranytripleofdisjointsetsA,BandSinV,"], "labels": ["WRONG"]}, "correct": {"tokens": ["A", "DAG", "model", "encodes", "conditional", "independence", "relationships", "via", "the", "notion", "of", "d-separation.", "Several", "DAGs", "could", "encode", "the", "same", "set", "of", "conditional", "independence", "relationships.", "These", "DAGs", "form", "an", "equivalence", "class,", "consisting", "of", "DAGs", "with", "the", "same", "skeleton", "and", "v-structures.", "A", "complete", "partially", "directed", "acyclic", "graph", "(CPDAG)", "uniquely", "describes", "such", "an", "equivalence", "class.", "In", "fact,", "directed", "edges", "in", "the", "CPDAG", "are", "common", "to", "all", "DAGs", "in", "the", "equivalence", "class.", "Undirected", "edges", "in", "the", "CPDAG", "correspond", "to", "edges", "that", "are", "directed", "one", "way", "in", "some", "DAGs", "and", "another", "way", "in", "other", "DAGs", "of", "the", "equivalence", "class.", "The", "absence", "of", "edges", "in", "the", "CPDAG", "means", "that", "all", "DAG", "members", "in", "the", "equivalence", "class", "have", "no", "corresponding", "edge.", "If", "all", "the", "conditional", "independence", "relationships", "of", "a", "distribution", "P", "and", "no", "additional", "conditional", "independence", "relations,", "can", "be", "inferred", "from", "the", "graph,", "we", "say", "that", "the", "distribution", "P", "is", "faithful", "to", "the", "DAG", "G.", "More", "precisely,", "if", "P", "is", "faithful", "to", "the", "DAG", "G:", "for", "any", "triple", "of", "disjoint", "sets", "A,", "B", "and", "S", "in", "V,"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["ADAGlnodelencodescOndltionalindepen\\dencerel~tionshipsviatheuotionof(l-separation.SeveralDAGscouldencodethexamesetofconditionalindepedplencerelatiohips.ThesKeDAGsformanequivalencecluss,enSistingofDAGswiththesameskeletonandv-structures.Acompletepartiallydirectedacyclicgraph(CPDAG)uniquelydescribessuchanequivalenLeclass.Intf~ct,directededgesintheCPDAGarecommontoallDAGsintheequivalenceclass.UndtrectedegesintheCPDA(;correspond", "to", "edges", "that,~redirectedonwayinsomeDAGsandanotherwayinotherDAGsoftieequvaienceclass.TheabsenceofedgesintheCPDALmeansthatallDlAGmemberinth'eequivalenceelasshave?ocorrespondingedge.IfallthecondimetionalindependencrelationshiosofadistributlonPandnoaddition\\alconditionatindependencer(:lations,canbeinferrc.dfromtheraph?,wesaythalthedistributlonPisfaithfultotheDACG.Moreprecisely,ifPisfaithfultotheDAGG:foranytripleofdisjointsetsA,BandSinV,"], "labels": ["WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG"]}, "BS-bid-OCR": {"tokens": ["A", "DAG", "lnodel", "encodes", "cOndltional", "indepen\\dence", "rel~tionships", "via", "the", "uotion", "of", "(l-separation.", "Several", "DAGs", "could", "encode", "the", "xame", "set", "of", "conditional", "indepedplence", "relatiohips.", "ThesKe", "DAGs", "form", "an", "equivalence", "cluss,", "enSisting", "of", "DAGs", "with", "the", "same", "skeleton", "and", "v-structures.", "A", "complete", "partially", "directed", "acyclic", "graph", "(CPDAG)", "uniquely", "describes", "such", "an", "equivalenLe", "class.", "In", "tf~ct,", "directed", "edges", "in", "the", "CPDAG", "are", "common", "to", "all", "DAGs", "in", "the", "equivalence", "class.", "Undtrected", "eges", "in", "the", "CPDA(;", "correspond", "to", "edges", "that", ",~re", "directed", "on", "way", "in", "some", "DAGs", "and", "another", "way", "in", "other", "DAGs", "of", "tie", "equvaience", "class.", "The", "absence", "of", "edges", "in", "the", "CPDAL", "means", "that", "all", "DlAG", "member", "in", "th'e", "equivalence", "elass", "have", "?o", "corresponding", "edge.", "If", "all", "the", "condimetional", "independenc\u0002", "relationshios", "of", "a", "distributlon", "P", "and", "no", "addition\\al", "conditionat", "independence", "r(:lations,", "can", "be", "inferrc.d", "from", "the", "raph?,", "we", "say", "thal", "the", "distributlon", "P", "is", "faithful", "to", "the", "DACG.", "More", "precisely,", "if", "P", "is", "faithful", "to", "the", "DAGG:", "for", "any", "triple", "of", "disjoint", "sets", "A,", "B", "and", "S", "in", "V,"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["A", "DAG", "model", "encodes", "cOnditional", "indepen\\dence", "rel~tionships", "via", "the", "notion", "of", "(l-separation.", "Several", "DAGs", "could", "encode", "the", "same", "set", "of", "conditional", "independence", "relationships.", "These", "DAGs", "form", "an", "equivalence", "class,", "enSisting", "of", "DAGs", "with", "the", "same", "skeleton", "and", "v-structures.", "A", "complete", "partially", "directed", "acyclic", "graph", "(CPDAG)", "uniquely", "describes", "such", "an", "equivalenCe", "class.", "In", "tf~ct,", "directed", "edges", "in", "the", "CPDAG", "are", "common", "to", "all", "DAGs", "in", "the", "equivalence", "class.", "Undirected", "eyes", "in", "the", "CPDA(;", "correspond", "to", "edges", "that", ",~redirected", "one", "way", "in", "some", "DAGs", "and", "another", "way", "in", "other", "DAGs", "of", "tie", "equivalence", "class.", "The", "absence", "of", "edges", "in", "the", "CAUDAL", "means", "that", "all", "DlAG", "members", "in", "the", "equivalence", "class", "have", "?o", "corresponding", "edge.", "If", "all", "the", "conditional", "independence", "relationships", "of", "a", "distribution", "P", "and", "no", "addition\\al", "conditional", "independence", "r(:lations,", "can", "be", "inferred", "from", "the", "raph?,", "we", "say", "that", "the", "distribution", "P", "is", "faithful", "to", "the", "DACG.", "More", "precisely,", "if", "P", "is", "faithful", "to", "the", "DAGG:", "for", "any", "triple", "of", "disjoint", "sets", "A,", "B", "and", "S", "in", "V,"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "WRONG", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "MIXED", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["Dipati,mentodiMatematicaedApplicazioni,UniversitadiPalermo,I-90123PaIcrmo,,ItalyE-mailaddres:trapani@unipa.it"], "labels": ["WRONG"]}, "correct": {"tokens": ["Dipartimento", "di", "Matematica", "ed", "Applicazioni,", "Universita", "di", "Palermo,", "I-90123", "Palermo,", "Italy", "E-mail", "address:", "trapani@unipa.it"], "labels": ["MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["Dipati,mentodiMatematicaedApplicazioni,UniversitadiPalermo,I-90123PaIcrmo,,ItalyE-mailaddres:trapani@unipa.it"], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["Dipati,mento", "di", "Matematica", "ed", "Applicazioni,", "Universita", "di", "Palermo,", "I-90123", "PaIcrmo,,", "Italy", "E-mail", "addres:", "trapani@unipa.it"], "labels": ["WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["Dipartimento", "di", "Matematica", "ed", "Applicazioni,", "Universit\u00e0", "di", "Palermo,", "I-90123", "PaLermo,,", "Italy", "E-mail", "address:", "trapani@unipa.it"], "labels": ["MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["Introductionandmainres?lt"], "labels": ["WRONG"]}, "correct": {"tokens": ["Introduction", "and", "main", "result"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED"]}, "predicted": {"google": {"tokens": ["Introduction", "And", "Main", "Res?lt"], "labels": ["TOKENIZATION_ERROR", "WRONG", "WRONG", "WRONG"]}, "BS-bid-OCR": {"tokens": ["Introduction", "and", "main", "res?lt"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG"]}, "BS-bid-OCR+google": {"tokens": ["Introduction", "and", "main", "res?lt"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG"]}}}, {"corrupt": {"tokens": ["Intheliteraturetherehavebeensomeattemptstousefinitenonabeleangroupstodescribethefamilyrepetitionstructure.Usually,representatinsareconsideredtomodelthegellerations,andacomplicatedHigssectorisconstructedtoacplcounctfo,theobservedmassdifferencebetweentilefermions.Inmyopiuion,thisdoesnotreall7so\\lvethemassproblembutjustshiftsittoanotherlevel.Itwouldbemuchmoredesirabletounderstandthefermronmassesdynamically,inthemodelathand,forexample,byunderstandingthedifferencebetweenthebi,ndinflsofpreons1,2,3and4."], "labels": ["WRONG"]}, "correct": {"tokens": ["In", "the", "literature", "there", "have", "been", "some", "attempts", "to", "use", "finite", "nonabelean", "groups", "to", "describe", "the", "family", "repetition", "structure.", "Usually,", "representations", "are", "considered", "to", "model", "the", "generations,", "and", "a", "complicated", "Higgs", "sector", "is", "constructed", "to", "account", "for", "the", "observed", "mass", "differences", "between", "the", "fermions.", "In", "my", "opinion,", "this", "does", "not", "really", "solve", "the", "mass", "problem", "but", "just", "shifts", "it", "to", "another", "level.", "It", "would", "be", "much", "more", "desirable", "to", "understand", "the", "fermion", "masses", "dynamically,", "in", "the", "model", "at", "hand,", "for", "example,", "by", "understanding", "the", "differences", "between", "the", "bindings", "of", "preons", "1,", "2,", "3", "and", "4."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["Intheliteraturetherehavebeensomeattemptstousefinitenonabeleangroupstodescribethefamilyrepetitionstructure.Usually,representatinsareconsideredtomodelthegellerations,andacomplicatedHigssectorisconstructedtoacplcounctfo,theobservedmassdifferencebetweentilefermions.Inmyopiuion,thisdoesnotreall7so\\lvethemassproblembutjustshiftsittoanotherlevel.Itwouldbemuchmoredesirabletounderstandthefermronmassesdynamically,inthemodelathand,forexample,byunderstandingthedifferencebetweenthebi,ndinflsofpreons1,2,3and4."], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["In", "the", "literature", "there", "have", "been", "some", "attempts", "to", "use", "finite", "nonabelean", "groups", "to", "describe", "the", "family", "repetition", "structure.", "Usually,", "representatins", "are", "considered", "to", "model", "the", "gellerations,", "and", "a", "complicated", "Higs", "sector", "is", "constructed", "to", "acplcounct", "fo,", "the", "observed", "mass", "difference", "between", "tile", "fermions.", "In", "my", "opiuion,", "this", "does", "not", "reall7", "so\\lve", "the", "mass", "problem", "but", "just", "shifts", "it", "to", "another", "level.", "It", "would", "be", "much", "more", "desirable", "to", "understand", "the", "fermron", "masses", "dynamically,", "in", "the", "model", "at", "hand,", "for", "example,", "by", "understanding", "the", "difference", "between", "the", "bi,ndinfls", "of", "preons", "1,", "2,", "3", "and", "4."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["In", "the", "literature", "there", "have", "been", "some", "attempts", "to", "use", "finite", "nonabelian", "groups", "to", "describe", "the", "family", "repetition", "structure.", "Usually,", "representations", "are", "considered", "to", "model", "the", "generations,", "and", "a", "complicated", "Higgs", "sector", "is", "constructed", "to", "account", "fo,", "the", "observed", "mass", "difference", "between", "tile", "fermions.", "In", "my", "opinion,", "this", "doesn't", "really", "so\\lve", "the", "mass", "problem", "but", "just", "shifts", "it", "to", "another", "level.", "It", "would", "be", "much", "more", "desirable", "to", "understand", "the", "fermion", "masses", "dynamically,", "in", "the", "model", "at", "hand,", "for", "example,", "by", "understanding", "the", "difference", "between", "the", "bi,ndinfls", "of", "preons", "1,", "2,", "3", "and", "4."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "WRONG", "MIXED", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["References"], "labels": ["NONE"]}, "correct": {"tokens": ["References"], "labels": ["NONE"]}, "predicted": {"google": {"tokens": ["References"], "labels": ["NONE"]}, "BS-bid-OCR": {"tokens": ["References"], "labels": ["NONE"]}, "BS-bid-OCR+google": {"tokens": ["References"], "labels": ["NONE"]}}}, {"corrupt": {"tokens": ["Inthelimitconsidered,welhusobtain:"], "labels": ["WRONG"]}, "correct": {"tokens": ["In", "the", "limit", "considered,", "we", "thus", "obtain:"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["Inthe", "Limit", "Considered,welhusobtain:"], "labels": ["WRONG", "WRONG", "WRONG"]}, "BS-bid-OCR": {"tokens": ["In", "the", "limit", "considered,", "we", "lhus", "obtain:"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["In", "the", "limit", "considered,", "we", "lhus", "obtain:"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["Togofuith8er,i{;isusefultomakein(11)thechang('.ofvariable"], "labels": ["WRONG"]}, "correct": {"tokens": ["To", "go", "further,", "it", "is", "useful", "to", "make", "in", "(11)", "the", "change", "of", "variable"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["Together,i{;isusefultomakein(11)thechang('.of", "variable"], "labels": ["WRONG", "TOKENIZATION_ERROR"]}, "BS-bid-OCR": {"tokens": ["To", "go", "fuith8er,", "i{;", "is", "useful", "to", "make", "in", "(11)", "the", "chang('.", "of", "variable"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["To", "go", "further,", "i{;", "is", "useful", "to", "make", "in", "(11)", "the", "chang('.", "of", "variable"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["Althouzhlherehasbeensomeprogressonthea\\bovementionedpoi;entialsysemarchitecturesanadvancedtechniquesforfrOnthaulconstainedsC-RANs,therearestillman2challengesahead,iucludingE-RANswithSDN,C-RANswithNFV,partiallycentralIzedC-RANs,standardsdevelopment,jeldtrials,etc.SillceTheC-RANstanardsdevelopmentsin3GPParestillnotopenandthecorespond\\[ngfieldtralsfor5Gsystemsarefarintilefuture,thissectionwilldiscusstheaforementioncdfirtthreechallenges."], "labels": ["WRONG"]}, "correct": {"tokens": ["Although", "there", "has", "been", "some", "progress", "on", "the", "above", "mentioned", "potential", "system", "architectures", "and", "advanced", "techniques", "for", "fronthaul", "constrained", "C-RANs,", "there", "are", "still", "many", "challenges", "ahead,", "including", "C-RANs", "with", "SDN,", "C-RANs", "with", "NFV,", "partially", "centralized", "C-RANs,", "standards", "development,", "field", "trials,", "etc.", "Since", "the", "C-RAN", "standards", "developments", "in", "3GPP", "are", "still", "not", "open,", "and", "the", "corresponding", "field", "trials", "for", "5G", "systems", "are", "far", "in", "the", "future,", "this", "section", "will", "discuss", "the", "aforementioned", "first", "three", "challenges."], "labels": ["MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["Althouzhlherehasbeensomeprogressonthea\\bovementionedpoi;entialsysemarchitecturesanadvancedtechniquesforfrOnthaulconstainedsC-RANs,therearestillman2challengesahead,iucludingE-RANswithSDN,C-RANswithNFV,partiallycentralIzedC-RANs,standardsdevelopment,jeldtrials,etc.SillceTheC-RANstanardsdevelopmentsin3GPParestillnotopenandthecorespond\\[ngfieldtralsfor5Gsystemsarefarintilefuture,thissectionwilldiscusstheaforementioncdfirtthreechallenges."], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["Althouzh", "lhere", "has", "been", "some", "progress", "on", "the", "a\\bove", "mentioned", "poi;ential", "sysem", "architectures", "an", "advanced", "techniques", "for", "frOnthaul", "constained", "sC-RANs,", "there", "are", "still", "man2", "challenges", "ahead,", "iucluding", "E-RANs", "with", "SDN,", "C-RANs", "with", "NFV,", "partially", "centralIzed", "C-RANs,", "standards", "development,", "jeld", "trials,", "etc.", "Sillce", "The", "C-RAN", "stanards", "developments", "in", "3GPP", "are", "still", "not", "open", "and", "the", "corespond\\[ng", "field", "trals", "for", "5G", "systems", "are", "far", "in", "tile", "future,", "this", "section", "will", "discuss", "the", "aforementioncd", "firt", "three", "challenges."], "labels": ["WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["Although", "there", "has", "been", "some", "progress", "on", "the", "a\\bove", "mentioned", "poi;entail", "system", "architectures", "an", "advanced", "techniques", "for", "frOnthaul", "constrained", "sC-RANs,", "there", "are", "still", "man2", "challenges", "ahead,", "including", "E-RANs", "with", "SDN,", "C-RANs", "with", "NFV,", "partially", "centralIzed", "C-RANs,", "standards", "development,", "jeld", "trials,", "etc.", "Since", "The", "C-RAN", "standards", "developments", "in", "3GPP", "are", "still", "not", "open", "and", "the", "correspond\\[ng", "field", "trials", "for", "5G", "systems", "are", "far", "in", "the", "future,", "this", "section", "will", "discuss", "the", "aforementioned", "first", "three", "challenges."], "labels": ["MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "MIXED", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "MIXED", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "WRONG", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["Introducton"], "labels": ["WRONG"]}, "correct": {"tokens": ["Introduction"], "labels": ["OCR_ERROR"]}, "predicted": {"google": {"tokens": ["Introduction"], "labels": ["OCR_ERROR"]}, "BS-bid-OCR": {"tokens": ["Introducton"], "labels": ["WRONG"]}, "BS-bid-OCR+google": {"tokens": ["Introduction"], "labels": ["OCR_ERROR"]}}}, {"corrupt": {"tokens": ["Generalconclusions"], "labels": ["WRONG"]}, "correct": {"tokens": ["General", "conclusions"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["General", "Conclusions"], "labels": ["TOKENIZATION_ERROR", "WRONG"]}, "BS-bid-OCR": {"tokens": ["General", "conclusions"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["General", "conclusions"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["DuetotheintermittntandslioraicnatureofF~H,thereceptionpolicies\\sh(,u)dbecarefublydet;iqnedinordertomaxidemizethesystemperformance.Inthissection,athroughputconstrainedPDPminimiza\\tionproblemwillbeformulated,anditoptimalso.1utionw1llbedevelopedinSectionIV."], "labels": ["WRONG"]}, "correct": {"tokens": ["Due", "to", "the", "intermittent", "and", "sporadic", "nature", "of", "EH,", "the", "reception", "policies", "should", "be", "carefully", "designed", "in", "order", "to", "maximize", "the", "system", "performance.", "In", "this", "section,", "a", "throughput", "constrained", "PDP", "minimization", "problem", "will", "be", "formulated,", "and", "its", "optimal", "solution", "will", "be", "developed", "in", "Section", "IV."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["DuetotheintermittntandslioraicnatureofF~H,thereceptionpolicies\\sh(,u)dbecarefublydet;iqnedinordertomaxidemizethesystemperformance.Inthissection,athroughputconstrainedPDPminimiza\\tionproblemwillbeformulated,anditoptimalso.1utionw1llbedevelopedinSectionIV."], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["Due", "to", "the", "intermittnt", "and", "slioraic", "nature", "of", "F~H,", "the", "reception", "policies\\", "sh(,u)d", "be", "carefubly", "det;iqned", "in", "order", "to", "maxidemize", "the", "system", "performance.", "In", "this", "section,", "a", "throughput", "constrained", "PDP", "minimiza\\tion", "problem", "will", "be", "formulated,", "and", "it", "optimal", "so.1ution", "w1ll", "be", "developed", "in", "Section", "IV."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["Due", "to", "the", "intermittent", "and", "slioraic", "nature", "of", "F~H,", "the", "reception", "policies\\", "sh(,u)d", "be", "carefully", "get;owned", "in", "order", "to", "maximize", "the", "system", "performance.", "In", "this", "section,", "a", "throughput", "constrained", "PDP", "minimiza\\tion", "problem", "will", "be", "formulated,", "and", "it", "optimal", "so.1ution", "w1ll", "be", "developed", "in", "Section", "IV."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "MIXED", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["Somecrnucialfacts"], "labels": ["WRONG"]}, "correct": {"tokens": ["Some", "crucial", "facts"], "labels": ["TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["Some", "Crucial", "Facts"], "labels": ["TOKENIZATION_ERROR", "WRONG", "WRONG"]}, "BS-bid-OCR": {"tokens": ["Some", "crnucial", "facts"], "labels": ["TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["Some", "crucial", "facts"], "labels": ["TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["ThenoiseofoutptutfieldoperatorscaI~becalulated,e.g.thereflectedone,"], "labels": ["WRONG"]}, "correct": {"tokens": ["The", "noise", "of", "output", "field", "operators", "can", "be", "calculated,", "e.g.", "the", "reflected", "one,"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["ThenoiseofoutptutfieldoperatorscaI~becalulated,e.g.thereflectedone,"], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["The", "noise", "of", "outptut", "field", "operators", "caI~", "be", "calulated,", "e.g.", "the", "reflected", "one,"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["The", "noise", "of", "input", "field", "operators", "caI~", "be", "calculated,", "e.g.", "the", "reflected", "one,"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["ItisinstructivetolookatthewayaneigenfunctionataQivenparalletervalue(\u03b1.\u03b2)isturneditothesecond-nexthigherstateaftertherotationaround,tilesingularity.InFig.IV,aneXampleofsuchwave-functionmorphologyisdisplayeo.\\ODeessentialfeatnreinthenodechangewhichoccursatthecrossingof\u03b2=0line.Onthisline,thesystemisseparatedintothenon\"-c\\omunicat~ngtwosubsystemsa;tx=0becauseoftheinfi?nitevalueof\u03b4.Thereasonofnodalchangeisthattheapproachto\u03b2=0linefromthe\u03b2~>0sideand\u03b2<0sidearephysicallydistilctbecausetheyeachc\\orre-po,(lto\u03b4\u00b1\u221eaitd\u03b4=\u2213\u221erespectively.(Tbecompositesignsareforthecaseof\u03b1\u03b30>1and\u03b1\u03b30<1repectively,in,turn.)Yet~st\u03b2=0linc,twoc\\asesgetconnectedsmoot\"hly."], "labels": ["WRONG"]}, "correct": {"tokens": ["It", "is", "instructive", "to", "look", "at", "the", "way", "an", "eigenfunction", "at", "a", "given", "parameter", "value", "(\u03b1,", "\u03b2)", "is", "turned", "into", "the", "second-next", "higher", "state", "after", "the", "rotation", "around", "the", "singularity.", "In", "Fig.", "IV,", "an", "example", "of", "such", "wave-function", "morphology", "is", "displayed.", "One", "essential", "feature", "is", "the", "node", "change", "which", "occurs", "at", "the", "crossing", "of", "\u03b2", "=", "0", "line.", "On", "this", "line,", "the", "system", "is", "separated", "into", "the", "non-communicating", "two", "subsystems", "at", "x", "=", "0", "because", "of", "the", "infinite", "value", "of", "\u03b4.", "The", "reason", "of", "nodal", "change", "is", "that", "the", "approach", "to", "\u03b2", "=", "0", "line", "from", "the", "\u03b2", ">", "0", "side", "and", "\u03b2", "<", "0", "side", "are", "physically", "distinct", "because", "they", "each", "correspond", "to", "\u03b4", "=", "\u00b1\u221e", "and", "\u03b4", "=", "\u2213\u221e", "respectively.", "(The", "composite", "signs", "are", "for", "the", "case", "of", "\u03b1\u03b30", ">", "1", "and", "\u03b1\u03b30", "<", "1", "respectively,", "in", "turn.)", "Yet,", "at", "\u03b2", "=", "0", "line,", "two", "cases", "get", "connected", "smoothly."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED"]}, "predicted": {"google": {"tokens": ["ItisinstructivetolookatthewayaneigenfunctionataQivenparalletervalue(\u03b1.\u03b2)isturneditothesecond-nexthigherstateaftertherotationaround,tilesingularity.InFig.IV,aneXampleofsuchwave-functionmorphologyisdisplayeo.\\ODeessentialfeatnreinthenodechangewhichoccursatthecrossingof\u03b2=0line.Onthisline,thesystemisseparatedintothenon\"-c\\omunicat~ngtwosubsystemsa;tx=0becauseoftheinfi?nitevalueof\u03b4.Thereasonofnodalchangeisthattheapproachto\u03b2=0linefromthe\u03b2~>0sideand\u03b2<0sidearephysicallydistilctbecausetheyeachc\\orre-po,(lto\u03b4\u00b1\u221eaitd\u03b4=\u2213\u221erespectively.(Tbecompositesignsareforthecaseof\u03b1\u03b30>1and\u03b1\u03b30<1repectively,in,turn.)Yet~st\u03b2=0linc,twoc\\asesgetconnectedsmoot\"hly."], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["It", "is", "instructive", "to", "look", "at", "the", "way", "an", "eigenfunction", "at", "a", "Qiven", "paralleter", "value", "(\u03b1.", "\u03b2)", "is", "turned", "ito", "the", "second-next", "higher", "state", "after", "the", "rotation", "around", ",tile", "singularity.", "In", "Fig.", "IV,", "an", "eXample", "of", "such", "wave-function", "morphology", "is", "displayeo.", "\\ODe", "essential", "featnre", "in", "the", "node", "change", "which", "occurs", "at", "the", "crossing", "of", "\u03b2", "=", "0", "line.", "On", "this", "line,", "the", "system", "is", "separated", "into", "the", "non\"-c\\omunicat~ng", "two", "subsystems", "a;t", "x", "=", "0", "because", "of", "the", "infi?nite", "value", "of", "\u03b4.", "The", "reason", "of", "nodal", "change", "is", "that", "the", "approach", "to", "\u03b2", "=", "0", "line", "from", "the", "\u03b2", "~", ">", "0", "side", "and", "\u03b2", "<", "0", "side", "are", "physically", "distilct", "because", "they", "each", "c\\orre-po,(l", "to", "\u03b4", "\u00b1", "\u221e", "aitd", "\u03b4", "=", "\u2213\u221e", "respectively.", "(Tbe", "composite", "signs", "are", "for", "the", "case", "of", "\u03b1\u03b30", ">", "1", "and", "\u03b1\u03b30", "<", "1", "repectively,", "in", ",turn.)", "Yet~st", "\u03b2", "=", "0", "linc,", "two", "c\\ases", "get", "connected", "smoot\"hly."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG"]}, "BS-bid-OCR+google": {"tokens": ["It", "is", "instructive", "to", "look", "at", "the", "way", "an", "eigenfunction", "at", "a", "Given", "parameter", "value", "(\u03b1.", "\u03b2)", "is", "turned", "into", "the", "second-next", "higher", "state", "after", "the", "rotation", "around", ",tile", "singularity.", "In", "Fig.", "IV,", "an", "eXample", "of", "such", "wave-function", "morphology", "is", "displayed.", "\\ODe", "essential", "feature", "in", "the", "node", "change", "which", "occurs", "at", "the", "crossing", "of", "\u03b2", "=", "0", "line.", "On", "this", "line,", "the", "system", "is", "separated", "into", "the", "non\"-c\\omunicat~ng", "two", "subsystems", "a;t", "x", "=", "0", "because", "of", "the", "infinite", "value", "of", "\u03b4.", "The", "reason", "of", "nodal", "change", "is", "that", "the", "approach", "to", "\u03b2", "=", "0", "line", "from", "the", "\u03b2", "~", ">", "0", "side", "and", "\u03b2", "<", "0", "side", "are", "physically", "distinct", "because", "they", "each", "c\\orre-por,(l", "to", "\u03b4", "\u00b1", "\u221e", "aitd", "\u03b4", "=", "\u2213\u221e", "respectively.", "(The", "composite", "signs", "are", "for", "the", "case", "of", "\u03b1\u03b30", ">", "1", "and", "\u03b1\u03b30", "<", "1", "respectively,", "in", "turn.)", "Yet~st", "\u03b2", "=", "0", "linc,", "two", "c\\ases", "get", "connected", "smoot\"hly."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "MIXED", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "WRONG", "TOKENIZATION_ERROR", "MIXED", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG"]}}}, {"corrupt": {"tokens": ["Elemeiitaryobservations"], "labels": ["WRONG"]}, "correct": {"tokens": ["Elementary", "observations"], "labels": ["MIXED", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["Elementary", "Observations"], "labels": ["MIXED", "WRONG"]}, "BS-bid-OCR": {"tokens": ["Elemeiitary", "observations"], "labels": ["WRONG", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["Elementary", "observations"], "labels": ["MIXED", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["~cknowledgements"], "labels": ["WRONG"]}, "correct": {"tokens": ["Acknowledgements"], "labels": ["OCR_ERROR"]}, "predicted": {"google": {"tokens": ["~acknowledgements"], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["~cknowledgements"], "labels": ["WRONG"]}, "BS-bid-OCR+google": {"tokens": ["~acknowledgements"], "labels": ["WRONG"]}}}, {"corrupt": {"tokens": ["with"], "labels": ["NONE"]}, "correct": {"tokens": ["with"], "labels": ["NONE"]}, "predicted": {"google": {"tokens": ["with"], "labels": ["NONE"]}, "BS-bid-OCR": {"tokens": ["with"], "labels": ["NONE"]}, "BS-bid-OCR+google": {"tokens": ["with"], "labels": ["NONE"]}}}, {"corrupt": {"tokens": ["theforegoingsecond-orderequationsinvectorformread"], "labels": ["WRONG"]}, "correct": {"tokens": ["the", "foregoing", "second-order", "equations", "in", "vector", "form", "read"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["the", "foregoing", "second-order", "equations", "in", "vector", "form", "read"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR": {"tokens": ["the", "foregoing", "second-order", "equations", "in", "vector", "form", "read"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["the", "foregoing", "second-order", "equations", "in", "vector", "form", "read"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["Suchsegregationoficesislndicatedl/ysolidCOobservationstowardsasam?pleoflow-massorprotstarsshowingevide?ncethat60%to90%ofsolidCOisintheformofpureCO-ic(T\\[elen8etal.1991,Buogertetal.20029Pontopiddmanetal.2003).Likewise,observationsofsolidCO2alsoprovideevidenceforseparateicecompnentsalogthesamelineofsight,although,inthiscase,thisisgenerallyattributedtothesegregationofmi?edH2O/CH3OH/CO2icesu1)onwarmupbyanewlyfcrmedstar?Ehrenfreundetal.1998;1999;Gerakines,Moore&Hudson2000Boogertetalt2000)."], "labels": ["WRONG"]}, "correct": {"tokens": ["Such", "segregation", "of", "ices", "is", "indicated", "by", "solid", "CO", "observations", "towards", "a", "sample", "of", "low-mass", "protostars", "showing", "evidence", "that", "60", "%", "to", "90", "%", "of", "solid", "CO", "is", "in", "the", "form", "of", "pure", "CO-ice", "(Tielens", "et", "al.", "1991,", "Boogert", "et", "al.", "2002,", "Pontopiddan", "et", "al.", "2003).", "Likewise,", "observations", "of", "solid", "CO2", "also", "provide", "evidence", "for", "separate", "ice", "components", "along", "the", "same", "line", "of", "sight,", "although,", "in", "this", "case,", "this", "is", "generally", "attributed", "to", "the", "segregation", "of", "mixed", "H2O", "/", "CH3OH", "/", "CO2", "ices", "upon", "warm", "up", "by", "a", "newly", "formed", "star", "(Ehrenfreund", "et", "al.", "1998;", "1999;", "Gerakines,", "Moore", "&", "Hudson", "2000;", "Boogert", "et", "al.", "2000)."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["Suchsegregationoficesislndicatedl/ysolidCOobservationstowardsasam?pleoflow-massorprotstarsshowingevide?ncethat60%to90%ofsolidCOisintheformofpureCO-ic(T\\[elen8etal.1991,Buogertetal.20029Pontopiddmanetal.2003).Likewise,observationsofsolidCO2alsoprovideevidenceforseparateicecompnentsalogthesamelineofsight,although,inthiscase,thisisgenerallyattributedtothesegregationofmi?edH2O/CH3OH/CO2", "ice", "su1)onwarmupbyanewly", "fc", "medstar?Ehrenfreundetal.1998;1999;Gerakines,Moore&Hudson2000Boogertetalt2000)."], "labels": ["WRONG", "TOKENIZATION_ERROR", "WRONG", "WRONG", "WRONG"]}, "BS-bid-OCR": {"tokens": ["Such", "segregation", "ofices", "is", "lndicated", "l/y", "solid", "CO", "observations", "towards", "a", "sam?ple", "of", "low-mass", "or", "prot", "stars", "showing", "evide?nce", "that", "60%", "to", "90%", "of", "solid", "CO", "is", "in", "the", "form", "of", "pure", "CO-ic", "(T\\[elen8", "et", "al.", "1991,", "Buogert", "et", "al.", "20029", "Pontopiddman", "et", "al.", "2003).", "Likewise,", "observations", "of", "solid", "CO2", "also", "provide", "evidence", "for", "separate", "ice", "compnents", "alog", "the", "same", "line", "of", "sight,", "although,", "in", "this", "case,", "this", "is", "generally", "attributed", "to", "the", "segregation", "of", "mi?ed", "H2O/CH3OH/CO2", "ices", "u1)on", "warm", "up", "by", "a", "newly", "fcrmed", "star", "?Ehrenfreund", "et", "al.", "1998;", "1999;", "Gerakines,", "Moore", "&", "Hudson", "2000", "Boogert", "et", "alt", "2000)."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["Such", "segregation", "offices", "is", "indicated", "l/y", "solid", "CO", "observations", "towards", "a", "sample", "of", "low-mass", "or", "prot", "stars", "showing", "evidence", "that", "60%", "to", "90%", "of", "solid", "CO", "is", "in", "the", "form", "of", "pure", "COmic", "(T\\[elen8", "et", "al.", "1991,", "Buogert", "et", "al.", "20029", "Pontopiddman", "et", "al.", "2003).", "Likewise,", "observations", "of", "solid", "CO2", "also", "provide", "evidence", "for", "separate", "ice", "components", "along", "the", "same", "line", "of", "sight,", "although,", "in", "this", "case,", "this", "is", "generally", "attributed", "to", "the", "segregation", "of", "mi?ed", "H2O/CH3OH/CO2", "ices", "u1)on", "warm", "up", "by", "a", "newly", "formed", "star", "?Ehrenfreund", "et", "al.", "1998;", "1999;", "Gerakines,", "Moore", "&", "Hudson", "2000", "Boogert", "et", "al", "2000)."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "MIXED", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "WRONG", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["weaklyconvergetozero(amesN\u2192\u221e)withtheexponentialrate(se(Brodsky,Darkhovs\\ky(2000))."], "labels": ["WRONG"]}, "correct": {"tokens": ["weakly", "converge", "to", "zero", "(as", "N", "\u2192", "\u221e)", "with", "the", "exponential", "rate", "(see", "Brodsky,", "Darkhovsky", "(2000))."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["weakly", "converges", "to", "zero(amesN\u2192\u221e)with", "the", "exponential", "rate(se(Brodsky,Darkhovs\\ky(2000))."], "labels": ["TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG"]}, "BS-bid-OCR": {"tokens": ["weakly", "converge", "to", "zero", "(ames", "N", "\u2192", "\u221e)", "with", "the", "exponential", "rate", "(se(", "Brodsky,", "Darkhovs\\ky", "(2000))."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["weakly", "converge", "to", "zero", "(ames", "N", "\u2192", "\u221e)", "with", "the", "exponential", "rate", "(se(", "Brodsky,", "Darkhovs\\ky", "(2000))."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["\u03c1(x+y)(t)>\u03b1>\u03c1(x)(t)?+\u03c1y)(t)."], "labels": ["WRONG"]}, "correct": {"tokens": ["\u03c1(x", "+", "y)(t)", ">", "\u03b1", ">", "\u03c1(x)(t)", "+", "\u03c1(y)(t)."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED"]}, "predicted": {"google": {"tokens": ["\u03c1(x+y)(t)>\u03b1>\u03c1(x)(t)?+\u03c1y)(t)."], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["\u03c1(x", "+", "y)(t)", ">", "\u03b1", ">", "\u03c1(x)(t)", "?+", "\u03c1y)(t)."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG"]}, "BS-bid-OCR+google": {"tokens": ["\u03c1(x", "+", "y)(t)", ">", "\u03b1", ">", "\u03c1(x)(t)", "?+", "\u03c1y)(t)."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG"]}}}, {"corrupt": {"tokens": ["AOlser/ookattileInterstellarAceretionHypothesis:Metals"], "labels": ["WRONG"]}, "correct": {"tokens": ["A", "Closer", "Look", "at", "the", "Interstellar", "Accretion", "Hypothesis:", "Metals"], "labels": ["TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["AOlser/ookattileInterstellarAceretionHypothesis:Metals"], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["A", "Olser", "/ook", "at", "tile", "Interstellar", "Aceretion", "Hypothesis:", "Metals"], "labels": ["TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["A", "Closer", "/look", "at", "tile", "Interstellar", "Accretion", "Hypothesis:", "Metals"], "labels": ["TOKENIZATION_ERROR", "MIXED", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["Acknowledgement"], "labels": ["NONE"]}, "correct": {"tokens": ["Acknowledgement"], "labels": ["NONE"]}, "predicted": {"google": {"tokens": ["Acknowledgement"], "labels": ["NONE"]}, "BS-bid-OCR": {"tokens": ["Acknowledgement"], "labels": ["NONE"]}, "BS-bid-OCR+google": {"tokens": ["Acknowledgement"], "labels": ["NONE"]}}}, {"corrupt": {"tokens": [";tnd\u03b4(\u03b8?isthebeamingpara,meter,"], "labels": ["WRONG"]}, "correct": {"tokens": ["and", "\u03b4(\u03b8)", "is", "the", "beaming", "parameter,"], "labels": ["MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED"]}, "predicted": {"google": {"tokens": [";tnd\u03b4(\u03b8?is", "the", "beaming", "parameter,"], "labels": ["WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED"]}, "BS-bid-OCR": {"tokens": [";tnd", "\u03b4(\u03b8?", "is", "the", "beaming", "para,meter,"], "labels": ["WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG"]}, "BS-bid-OCR+google": {"tokens": [";tnd", "\u03b4(\u03b8?", "is", "the", "beaming", "para,meter,"], "labels": ["WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG"]}}}, {"corrupt": {"tokens": ["FromAnalyticaltoFastFourierTransform(FFT?"], "labels": ["WRONG"]}, "correct": {"tokens": ["From", "Analytical", "to", "Fast", "Fourier", "Transform", "(FFT)"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED"]}, "predicted": {"google": {"tokens": ["FromAnalyticaltoFastFourierTransform(FFT?"], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["From", "Analytical", "to", "Fast", "Fourier", "Transform", "(FFT?"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG"]}, "BS-bid-OCR+google": {"tokens": ["From", "Analytical", "to", "Fast", "Fourier", "Transform", "(FFT?"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG"]}}}, {"corrupt": {"tokens": ["MW=(,6,98,12,13,10,11,15,14,17,16)."], "labels": ["WRONG"]}, "correct": {"tokens": ["MW", "=", "(7,", "6,", "9,", "8,", "12,", "13,", "10,", "11,", "15,", "14,", "17,", "16)."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["MW=(,6,98,12,13,10,11,15,14,17,16)."], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["MW", "=", "(,6,", "98,", "12,", "13,", "10,", "11,", "15,", "14,", "17,", "16)."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["MW", "=", "(,6,", "98,", "12,", "13,", "10,", "11,", "15,", "14,", "17,", "16)."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["Wenowdefineth{;cfollowindjmensionlcssquantities,"], "labels": ["WRONG"]}, "correct": {"tokens": ["We", "now", "define", "the", "following", "dimensionless", "quantities,"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "MIXED", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["Wenowdefineth{;cfollowindjmensionlcssquantities,"], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["We", "now", "define", "th{;c", "followin", "djmensionlcss", "quantities,"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "WRONG", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["We", "now", "define", "th{;c", "following", "dimensions", "css", "quantities,"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "MIXED", "WRONG", "WRONG", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["Thisconcludesthedescriptio~lofthealKorithnItremainstoprovathat"], "labels": ["WRONG"]}, "correct": {"tokens": ["This", "concludes", "the", "description", "of", "the", "algorithm.", "It", "remains", "to", "prove", "that"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["Thisconcludesthedescriptio~lofthealKorithnItremainstoprovathat"], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["This", "concludes", "the", "descriptio~l", "of", "the", "alKorithn", "It", "remains", "to", "prova", "that"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["This", "concludes", "the", "descriptio~l", "of", "the", "alGorithm", "It", "remains", "to", "prove", "that"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["ExperimentalSetup"], "labels": ["WRONG"]}, "correct": {"tokens": ["Experimental", "Setup"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["ExperimentalSetup"], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["Experimental", "Setup"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["Experimental", "Setup"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["WenouturntoaformaldescriptionofthelanguageofdefeasiblologicanndtheinferencerulescftheaefeasiblelogicDL."], "labels": ["WRONG"]}, "correct": {"tokens": ["We", "now", "turn", "to", "a", "formal", "description", "of", "the", "language", "of", "defeasible", "logic", "and", "the", "inference", "rules", "of", "the", "defeasible", "logic", "DL."], "labels": ["TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["WenouturntoaformaldescriptionofthelanguageofdefeasiblologicanndtheinferencerulescftheaefeasiblelogicDL."], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["We", "nou", "turn", "to", "a", "formal", "description", "of", "the", "language", "of", "defeasiblo", "logic", "annd", "the", "inference", "rules", "cf", "the", "aefeasible", "logic", "DL."], "labels": ["TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["We", "now", "turn", "to", "a", "formal", "description", "of", "the", "language", "of", "defeasible", "logic", "and", "the", "inference", "rules", "of", "the", "defeasible", "logic", "DL."], "labels": ["TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["Inthisletterwehaveex\\amedtheconsequencesoffeedbackfromanearlyepisodeofSNxplosioninproto-gaaxies.AnextensionofthemechanismproposedbyDekel&Silk(1986),tohiglaervelocitydispersionhalosyieldsamodulationofthebaryonfactionavailsblefordiskformationthatdependsonthed\\epth~ftllepotentialwell.Thisfeedbackapplieltosimi)leuprescriptionsfordishkformation/mp\\[iesthattheeithertheze\\ro-pointofthe~ully-Fishetorthemass-to-lightr:ltioisweaklydepe?dentonthev('locitydispersionoftnhehalo.Theimplicationsofthissceno.riofortheMilkyWaydiskar(;tilatapproXimately10%oftheoriginalggasthatfellinwasexpelledpriortodiskassembly,ahigh-redshiftofformationwhichisingoodagreementwiththeaqesoftheoldestthickdiskstarsisinferredforaveragetohi~hvaluesofthespinparameteroftheMilkWayhalowithalocalbaryonfractionthatr;rogesfrmomtheuniversalvalueof5%toavalueof20%whichiswhtisinferredfromX.raystudiesoftheIntra-cluaI;ermediuminclustersofgalaxies."], "labels": ["WRONG"]}, "correct": {"tokens": ["In", "this", "letter", "we", "have", "examined", "the", "consequences", "of", "feedback", "from", "an", "early", "episode", "of", "SN", "explosions", "in", "proto-galaxies.", "An", "extension", "of", "the", "mechanism", "proposed", "by", "Dekel", "&", "Silk", "(1986),", "to", "higher", "velocity", "dispersion", "halos", "yields", "a", "modulation", "of", "the", "baryon", "fraction", "available", "for", "disk", "formation", "that", "depends", "on", "the", "depth", "of", "the", "potential", "well.", "This", "feedback", "applied", "to", "simple", "prescriptions", "for", "disk", "formation", "implies", "that", "the", "either", "the", "zero-point", "of", "the", "Tully-Fisher", "or", "the", "mass-to-", "light", "ratio", "is", "weakly", "dependent", "on", "the", "velocity", "dispersion", "of", "the", "halo.", "The", "implications", "of", "this", "scenario", "for", "the", "Milky", "Way", "disk", "are", "that", "approximately", "10%", "of", "the", "original", "gas", "that", "fell", "in", "was", "expelled", "prior", "to", "disk", "assembly,", "a", "high-redshift", "of", "formation", "which", "is", "in", "good", "agreement", "with", "the", "ages", "of", "the", "oldest", "thick", "disk", "stars", "is", "inferred", "for", "average", "to", "high", "values", "of", "the", "spin", "parameter", "of", "the", "Milky", "Way", "halo", "with", "a", "local", "baryon", "fraction", "that", "ranges", "from", "the", "universal", "value", "of", "5%", "to", "a", "value", "of", "20%", "which", "is", "what", "is", "inferred", "from", "X-ray", "studies", "of", "the", "Intra-cluster", "medium", "in", "clusters", "of", "galaxies."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["Inthisletterwehaveex\\amedtheconsequencesoffeedbackfromanearlyepisodeofSNxplosioninproto-gaaxies.AnextensionofthemechanismproposedbyDekel&Silk(1986),tohiglaervelocitydispersionhalosyieldsamodulationofthebaryonfactionavailsblefordiskformationthatdependsonthed\\epth~ftllepotentialwell.Thisfeedbackapplieltosimi)leuprescriptionsfordishkformation/mp\\[iesthattheeithertheze\\ro-pointofthe~ully-Fishetorthemass-to-lightr:ltioisweaklydepe?dentonthev('locitydispersionoftnhehalo.Theimplicationsofthissceno.riofortheMilkyWaydiskar(;tilatapproXimately10%oftheoriginalggasthatfellinwasexpelledpriortodiskassembly,ahigh-redshiftofformationwhichisingoodagreementwiththeaqesoftheoldestthickdiskstarsisinferredforaveragetohi~hvaluesofthespinparameteroftheMilkWayhalowithalocalbaryonfractionthatr;rogesfrmomtheuniversalvalueof5%toavalueof20%whichiswhtisinferredfromX.raystudiesoftheIntra-cluaI;ermediuminclustersofgalaxies."], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["In", "this", "letter", "we", "have", "ex\\amed", "the", "consequences", "of", "feedback", "from", "an", "early", "episode", "of", "SN", "xplosion", "in", "proto-gaaxies.", "An", "extension", "of", "the", "mechanism", "proposed", "by", "Dekel", "&", "Silk", "(1986),", "to", "higlaer", "velocity", "dispersion", "halos", "yields", "a", "modulation", "of", "the", "baryon", "faction", "availsble", "for", "disk", "formation", "that", "depends", "on", "the", "d\\epth", "~f", "tlle", "potential", "well.", "This", "feedback", "appliel", "to", "simi)leu", "prescriptions", "for", "dishk", "formation", "/mp\\[ies", "that", "the", "either", "the", "ze\\ro-point", "of", "the", "~ully-Fishet", "or", "the", "mass-to-light", "r:ltio", "is", "weakly", "depe?dent", "on", "the", "v('locity", "dispersion", "of", "tnhe", "halo.", "The", "implications", "of", "this", "sceno.rio", "for", "the", "Milky", "Way", "disk", "ar(;", "tilat", "approXimately", "10%", "of", "the", "original", "g", "gas", "that", "fell", "in", "was", "expelled", "prior", "to", "disk", "assembly,", "a", "high-redshift", "of", "formation", "which", "is", "in", "good", "agreement", "with", "the", "aqes", "of", "the", "oldest", "thick", "disk", "stars", "is", "inferred", "for", "average", "to", "hi~h", "values", "of", "the", "spin", "parameter", "of", "the", "Milk", "Way", "halo", "with", "a", "local", "baryon", "fraction", "that", "r;roges", "frmom", "the", "universal", "value", "of", "5%", "to", "a", "value", "of", "20%", "which", "is", "wht", "is", "inferred", "from", "X.ray", "studies", "of", "the", "Intra-cluaI;er", "medium", "in", "clusters", "of", "galaxies."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "WRONG", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["In", "this", "letter", "we", "have", "ex\\amed", "the", "consequences", "of", "feedback", "from", "an", "early", "episode", "of", "SN", "explosion", "in", "proto-galaxies.", "An", "extension", "of", "the", "mechanism", "proposed", "by", "Dekel", "&", "Silk", "(1986),", "to", "higher", "velocity", "dispersion", "halos", "yields", "a", "modulation", "of", "the", "baryon", "fraction", "available", "for", "disk", "formation", "that", "depends", "on", "the", "d\\epth", "~of", "the", "potential", "well.", "This", "feedback", "applied", "to", "simi)leu", "prescriptions", "for", "disk", "formation", "/mp\\[ies", "that", "the", "either", "the", "ze\\ro-point", "of", "the", "~tully-Fisher", "or", "the", "mass-to-light", "r:ltio", "is", "weakly", "depe?dent", "on", "the", "v('velocity", "dispersion", "of", "the", "halo.", "The", "implications", "of", "this", "sceno.rio", "for", "the", "Milky", "Way", "disk", "ar(;", "tilat", "approXimately", "10%", "of", "the", "original", "g", "gas", "that", "fell", "in", "was", "expelled", "prior", "to", "disk", "assembly,", "a", "high-redshift", "of", "formation", "which", "is", "in", "good", "agreement", "with", "the", "ages", "of", "the", "oldest", "thick", "disk", "stars", "is", "inferred", "for", "average", "to", "hi~h", "values", "of", "the", "spin", "parameter", "of", "the", "Milky", "Way", "halo", "with", "a", "local", "baryon", "fraction", "that", "r;rogers", "from", "the", "universal", "value", "of", "5%", "to", "a", "value", "of", "20%", "which", "is", "what", "is", "inferred", "from", "X.ray", "studies", "of", "the", "Intra-cluaI;er", "medium", "in", "clusters", "of", "galaxies."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["T\\hefirstsolutionprocedureisalsequentialone,whereone7firstcomputesgridvaluesofthe('ostfunctiortandthencarryouttheop\\timizationprocedurebyemployingtheapproximatevaluesinterpolate<tfromthegrId.Itisimportanttonotethatallthegridvaluesprovidethedesignoscontrolvariablesalongwitnahthecorrespondingmecilanicalstatevariablesof\\displacementsandrotatinswhigchmutsal1sfytheweakformofequilibriumequation.Inothertoensurethisrequirement,foranygrid~value?ofdesignorcontrolvariablesonealsohastssolveassociatednonlinearprobleininstructur~flmechanics."], "labels": ["WRONG"]}, "correct": {"tokens": ["The", "first", "solution", "procedure", "is", "a", "sequential", "one,", "where", "one", "first", "computes", "grid", "values", "of", "the", "cost", "function", "and", "then", "carry", "out", "the", "optimization", "procedure", "by", "employing", "the", "approximate", "values", "interpolated", "from", "the", "grid.", "It", "is", "important", "to", "note", "that", "all", "the", "grid", "values", "provide", "the", "design", "or", "control", "variables", "along", "with", "the", "corresponding", "mechanical", "state", "variables", "of", "displacements", "and", "rotations", "which", "must", "satisfy", "the", "weak", "form", "of", "equilibrium", "equation.", "In", "other", "to", "ensure", "this", "requirement,", "for", "any", "grid", "value", "of", "design", "or", "control", "variables", "one", "also", "has", "to", "solve", "associated", "nonlinear", "problem", "in", "structural", "mechanics."], "labels": ["MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["T\\hefirstsolutionprocedureisalsequentialone,whereone7firstcomputesgridvaluesofthe('ostfunctiortandthencarryouttheop\\timizationprocedurebyemployingtheapproximatevaluesinterpolate<tfromthegrId.Itisimportanttonotethatallthegridvaluesprovidethedesignoscontrolvariablesalongwitnahthecorrespondingmecilanicalstatevariablesof\\displacementsandrotatinswhigchmutsal1sfytheweakformofequilibriumequation.Inothertoensurethisrequirement,foranygrid~value?ofdesignorcontrolvariablesonealsohastssolveassociatednonlinearprobleininstructur~flmechanics."], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["T\\he", "first", "solution", "procedure", "is", "a", "lsequential", "one,", "where", "one7", "first", "computes", "grid", "values", "of", "the", "('ost", "functiort", "and", "then", "carry", "out", "the", "op\\timization", "procedure", "by", "employing", "the", "approximate", "values", "interpolate<t", "from", "the", "grId.", "It", "is", "important", "to", "note", "that", "all", "the", "grid", "values", "provide", "the", "design", "os", "control", "variables", "along", "witnah", "the", "corresponding", "mecilanical", "state", "variables", "of\\", "displacements", "and", "rotatins", "whigch", "mut", "sal1sfy", "the", "weak", "form", "of", "equilibrium", "equation.", "In", "other", "to", "ensure", "this", "requirement,", "for", "any", "grid", "~value?", "of", "design", "or", "control", "variables", "one", "also", "has", "ts", "solve", "associated", "nonlinear", "problein", "in", "structur~fl", "mechanics."], "labels": ["WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["T\\he", "first", "solution", "procedure", "is", "a", "sequential", "one,", "where", "one7", "first", "computes", "grid", "values", "of", "the", "('cost", "function", "and", "then", "carry", "out", "the", "op\\timization", "procedure", "by", "employing", "the", "approximate", "values", "interpolate<t", "from", "the", "grId.", "It", "is", "important", "to", "note", "that", "all", "the", "grid", "values", "provide", "the", "design", "of", "control", "variables", "along", "with", "the", "corresponding", "mechanical", "state", "variables", "of\\", "displacements", "and", "rotations", "which", "must", "sal1sfy", "the", "weak", "form", "of", "equilibrium", "equation.", "In", "other", "to", "ensure", "this", "requirement,", "for", "any", "grid", "~value?", "of", "design", "or", "control", "variables", "one", "also", "has", "to", "solve", "associated", "nonlinear", "problems", "in", "structural~fl", "mechanics."], "labels": ["WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "MIXED", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["MBH=f2v4/G2\u03c0mpN."], "labels": ["WRONG"]}, "correct": {"tokens": ["MBH", "=", "f2v4/G2\u03c0mpN."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["MBH=f2v4/G2\u03c0mpN."], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["MBH", "=", "f2v4/G2\u03c0mpN."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["MBH", "=", "f2v4/G2\u03c0mpN."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["Sincethisisnowonlyalocalproblemwedropthesiteindex?ndget(als0droppingtheconstantterms):"], "labels": ["WRONG"]}, "correct": {"tokens": ["Since", "this", "is", "now", "only", "a", "local", "problem", "we", "drop", "the", "site", "index", "and", "get", "(also", "dropping", "the", "constant", "terms):"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["Sincethisisnowonlyalocalproblemwedropthesiteindex?ndget(als0", "dropping", "the", "constant", "terms):"], "labels": ["WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR": {"tokens": ["Since", "this", "is", "now", "only", "a", "local", "problem", "we", "drop", "the", "site", "index", "?nd", "get", "(als0", "dropping", "the", "constant", "terms):"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["Since", "this", "is", "now", "only", "a", "local", "problem", "we", "drop", "the", "site", "index", "?nd", "get", "(als0", "dropping", "the", "constant", "terms):"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["an?d"], "labels": ["WRONG"]}, "correct": {"tokens": ["and"], "labels": ["OCR_ERROR"]}, "predicted": {"google": {"tokens": ["an?d"], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["an?d"], "labels": ["WRONG"]}, "BS-bid-OCR+google": {"tokens": ["an?d"], "labels": ["WRONG"]}}}, {"corrupt": {"tokens": ["Sincineconnectionstoeachofthencighborsofth?etargetoccursindependerttlywithmrobabilityp,the1)robabilityQ(a|k)tha\\taadditionallinksaremadetotheneighbor?s?ofatargetofdegreekis"], "labels": ["WRONG"]}, "correct": {"tokens": ["Since", "connections", "to", "each", "of", "the", "neighbors", "of", "the", "target", "occurs", "independently", "with", "probability", "p,", "the", "probability", "Q(a", "|", "k)", "that", "a", "additional", "links", "are", "made", "to", "the", "neighbors", "of", "a", "target", "of", "degree", "k", "is"], "labels": ["MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["Sincineconnectionstoeachofthencighborsofth?etargetoccursindependerttlywithmrobabilityp,the1)probability(a|k)tha\\ta", "additionallinksaremadetothe", "neighbors?s?ofatargetofdegreekis"], "labels": ["WRONG", "WRONG", "WRONG"]}, "BS-bid-OCR": {"tokens": ["Sincine", "connections", "to", "each", "of", "the", "ncighbors", "of", "th?e", "target", "occurs", "independerttly", "with", "mrobability", "p,", "the", "1)robability", "Q(a", "|", "k)", "tha\\t", "aadditional", "links", "are", "made", "to", "the", "neighbor?s?", "of", "a", "target", "of", "degree", "k", "is"], "labels": ["WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["Sincine", "connections", "to", "each", "of", "the", "neighbors", "of", "the", "target", "occurs", "independently", "with", "probability", "p,", "the", "1)probability", "Q(a", "|", "k)", "tha\\t", "additional", "links", "are", "made", "to", "the", "neighbor?s?", "of", "a", "target", "of", "degree", "k", "is"], "labels": ["WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["We\\nowwanttopi'\\ovethefollowingresult,"], "labels": ["WRONG"]}, "correct": {"tokens": ["We", "now", "want", "to", "prove", "the", "following", "result,"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["We\\now", "want", "to", "pi'\\over", "the", "following", "result,"], "labels": ["WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR": {"tokens": ["We\\", "now", "want", "to", "pi'\\ove", "the", "following", "result,"], "labels": ["WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["We\\", "now", "want", "to", "pi'\\ove", "the", "following", "result,"], "labels": ["WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["Thisasumptionimpliesthefollownggeometricconsi(lerations."], "labels": ["WRONG"]}, "correct": {"tokens": ["This", "assumption", "implies", "the", "following", "geometric", "considerations."], "labels": ["TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED"]}, "predicted": {"google": {"tokens": ["Thisasumptionimpliesthefollownggeometricconsi(lerations."], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["This", "asumption", "implies", "the", "followng", "geometric", "consi(lerations."], "labels": ["TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG"]}, "BS-bid-OCR+google": {"tokens": ["This", "assumption", "implies", "the", "following", "geometric", "consi(lerations."], "labels": ["TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "WRONG"]}}}, {"corrupt": {"tokens": ["Acknowledgements:WewuldliketonthankSheIdon(;aldstein,MichaelKiessiag,SteveLyle,a_ndHerbertSpohnforstimulaingdiscussions."], "labels": ["WRONG"]}, "correct": {"tokens": ["Acknowledgements:", "We", "would", "like", "to", "thank", "Sheldon", "Goldstein,", "Michael", "Kiessling,", "Steve", "Lyle,", "and", "Herbert", "Spohn", "for", "stimulating", "discussions."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["Acknowledgements:WewuldliketonthankSheIdon(;aldstein,MichaelKiessiag,SteveLyle,a_ndHerbertSpohnforstimulaingdiscussions."], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["Acknowledgements:", "We", "wuld", "like", "to", "nthank", "SheIdon", "(;aldstein,", "Michael", "Kiessiag,", "Steve", "Lyle,", "a_nd", "Herbert", "Spohn", "for", "stimulaing", "discussions."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["Acknowledgements:", "We", "would", "like", "to", "thank", "SheLdon", "(;aldstein,", "Michael", "Kiessiag,", "Steve", "Lyle,", "a_nd", "Herbert", "Spohn", "for", "stimulating", "discussions."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["Introduction"], "labels": ["NONE"]}, "correct": {"tokens": ["Introduction"], "labels": ["NONE"]}, "predicted": {"google": {"tokens": ["Introduction"], "labels": ["NONE"]}, "BS-bid-OCR": {"tokens": ["Introduction"], "labels": ["NONE"]}, "BS-bid-OCR+google": {"tokens": ["Introduction"], "labels": ["NONE"]}}}, {"corrupt": {"tokens": ["A?cknowledgements"], "labels": ["WRONG"]}, "correct": {"tokens": ["Acknowledgements"], "labels": ["OCR_ERROR"]}, "predicted": {"google": {"tokens": ["Acknowledgements"], "labels": ["OCR_ERROR"]}, "BS-bid-OCR": {"tokens": ["A?cknowledgements"], "labels": ["WRONG"]}, "BS-bid-OCR+google": {"tokens": ["Acknowledgements"], "labels": ["OCR_ERROR"]}}}, {"corrupt": {"tokens": ["Outlook"], "labels": ["NONE"]}, "correct": {"tokens": ["Outlook"], "labels": ["NONE"]}, "predicted": {"google": {"tokens": ["Outlook"], "labels": ["NONE"]}, "BS-bid-OCR": {"tokens": ["Outlook"], "labels": ["NONE"]}, "BS-bid-OCR+google": {"tokens": ["Outlook"], "labels": ["NONE"]}}}, {"corrupt": {"tokens": ["Itisthusjustaswellthattheonlycandidatesecanseeforquntitiethatmightbecalculablewitharbitraryprecisionarethemeta-gbservables,whichextendbeyondanyonehorizon.Sincethehorizonvolume(afterahmitednumberofinflationarye-foldings)doesnotcontainalivingebserveranyway,anyp...reciselycalculablequantitiesastociatedwiththeinterJorofahoriz?onwouldbewasted."], "labels": ["WRONG"]}, "correct": {"tokens": ["It", "is", "thus", "just", "as", "well", "that", "the", "only", "candidates", "we", "can", "see", "for", "quantities", "that", "might", "be", "calculable", "with", "arbitrary", "precision", "are", "the", "meta-observables,", "which", "extend", "beyond", "any", "one", "horizon.", "Since", "the", "horizon", "volume", "(after", "a", "limited", "number", "of", "inflationary", "e-foldings)", "does", "not", "contain", "a", "living", "observer", "anyway,", "any", "precisely", "calculable", "quantities", "associated", "with", "the", "interior", "of", "a", "horizon", "would", "be", "wasted."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["Itisthusjustaswellthattheonlycandidatesecanseeforquntitiethatmightbecalculablewitharbitraryprecisionarethemeta-gbservables,whichextendbeyondanyonehorizon.Sincethehorizonvolume(afterahmitednumberofinflationarye-foldings)doesnotcontainalivingebserveranyway,anyp...reciselycalculablequantitiesastociatedwiththeinterJorofahoriz?onwouldbewasted."], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["It", "is", "thus", "just", "as", "well", "that", "the", "only", "candidatese", "can", "see", "for", "quntitie", "that", "might", "be", "calculable", "with", "arbitrary", "precision", "are", "the", "meta-gbservables,", "which", "extend", "beyond", "any", "one", "horizon.", "Since", "the", "horizon", "volume", "(after", "a", "hmited", "number", "of", "inflationary", "e-foldings)", "does", "not", "contain", "a", "living", "ebserver", "anyway,", "any", "p...recisely", "calculable", "quantities", "astociated", "with", "the", "interJor", "of", "a", "horiz?on", "would", "be", "wasted."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["It", "is", "this", "just", "as", "well", "that", "the", "only", "candidates", "can", "see", "for", "quantities", "that", "might", "be", "calculable", "with", "arbitrary", "precision", "are", "the", "meta-gbservables,", "which", "extend", "beyond", "any", "one", "horizon.", "Since", "the", "horizon", "volume", "(after", "a", "limited", "number", "of", "inflationary", "e-foldings)", "does", "not", "contain", "a", "living", "observer", "anyway,", "any", "p...recisely", "calculable", "quantities", "associated", "with", "the", "interJor", "of", "a", "horizon", "would", "be", "wasted."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["TheViolotionoftheEquivalencePrincipleinECSKTheories"], "labels": ["WRONG"]}, "correct": {"tokens": ["The", "Violation", "of", "the", "Equivalence", "Principle", "in", "ECSK", "Theories"], "labels": ["TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["TheViolotionoftheEquivalencePrincipleinECSKTheories"], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["The", "Violotion", "of", "the", "Equivalence", "Principle", "in", "ECSK", "Theories"], "labels": ["TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["The", "Violation", "of", "the", "Equivalence", "Principle", "in", "ECSK", "Theories"], "labels": ["TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["Tlfisexpressiocisfurthersimplifiedbydefining"], "labels": ["WRONG"]}, "correct": {"tokens": ["This", "expression", "is", "further", "simplified", "by", "defining"], "labels": ["MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["Tlf", "Is", "Expressi\u00f3", "Is", "Further", "Simplified", "By", "Defining"], "labels": ["WRONG", "WRONG", "WRONG", "WRONG", "WRONG", "WRONG", "WRONG", "WRONG"]}, "BS-bid-OCR": {"tokens": ["Tlfis", "expressioc", "is", "further", "simplified", "by", "defining"], "labels": ["WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["This", "expression", "is", "further", "simplified", "by", "defining"], "labels": ["MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["Orthosymplecticsupergroups"], "labels": ["WRONG"]}, "correct": {"tokens": ["Orthosymplectic", "supergroups"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["Orthosymplectic", "Supergroups"], "labels": ["TOKENIZATION_ERROR", "WRONG"]}, "BS-bid-OCR": {"tokens": ["Orthosymplectic", "supergroups"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["Orthosymplectic", "supergroups"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["vherecisthespcedoflIghtinvacuum,\u03bb0isthewavelengthofthezero-velocitycomponent,\\andvisthevelocityofthecomponentthattasDopplershiftedfrom\u03bb0to\u03bb.Wecategorizedtheabsorptionfeatu\\[esexhibitedinourspectraintothreeclassesofstructurncsasfollows(seeFig.1forraphicexamples):"], "labels": ["WRONG"]}, "correct": {"tokens": ["where", "c", "is", "the", "speed", "of", "light", "in", "vacuum,", "\u03bb0", "is", "the", "wavelength", "of", "the", "zero-velocity", "component,", "and", "v", "is", "the", "velocity", "of", "the", "component", "that", "was", "Doppler", "shifted", "from", "\u03bb0", "to", "\u03bb.", "We", "categorized", "the", "absorption", "features", "exhibited", "in", "our", "spectra", "into", "three", "classes", "of", "structures", "as", "follows", "(see", "Fig.", "1", "for", "graphic", "examples):"], "labels": ["MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["vherecisthespcedoflIghtinvacuum,\u03bb0isthewavelengthofthezero-velocitycomponent,\\andvisthevelocityofthecomponentthattasDopplershiftedfrom\u03bb0to\u03bb.Wecategorizedtheabsorptionfeatu\\[esexhibitedinourspectraintothreeclassesofstructurncsasfollows(seeFig.1forraphicexamples):"], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["vhere", "c", "is", "the", "spced", "of", "lIght", "in", "vacuum,", "\u03bb0", "is", "the", "wavelength", "of", "the", "zero-velocity", "component,\\", "and", "v", "is", "the", "velocity", "of", "the", "component", "that", "tas", "Doppler", "shifted", "from", "\u03bb0", "to", "\u03bb.", "We", "categorized", "the", "absorption", "featu\\[es", "exhibited", "in", "our", "spectra", "into", "three", "classes", "of", "structurncs", "as", "follows", "(see", "Fig.", "1", "for", "raphic", "examples):"], "labels": ["WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["where", "c", "is", "the", "speed", "of", "lIght", "in", "vacuum,", "\u03bb0", "is", "the", "wavelength", "of", "the", "zero-velocity", "component,\\", "and", "v", "is", "the", "velocity", "of", "the", "component", "that", "has", "Doppler", "shifted", "from", "\u03bb0", "to", "\u03bb.", "We", "categorized", "the", "absorption", "featu\\[es", "exhibited", "in", "our", "spectra", "into", "three", "classes", "of", "structures", "as", "follows", "(see", "Fig.", "1", "for", "graphic", "examples):"], "labels": ["MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["whichshowthatasuf\\[icientnumberofsextetfleldsmayguarant(~esg4runiiingalm(}stident--icalwiththatufgL,K.Thetringmodelweareproposingint.henextsecti6onhasexactly_onemirrorpa\\ixandfoursextetfields,whereas~ddilionalexoticstat(:smayalsocontributeto?thebctafunctionsiftheyremaIninthelightspectrum."], "labels": ["WRONG"]}, "correct": {"tokens": ["which", "show", "that", "a", "sufficient", "number", "of", "sextet", "fields", "may", "guarantee", "a", "g4", "running", "almost", "identical", "with", "that", "of", "gL,", "R.", "The", "string", "model", "we", "are", "proposing", "in", "the", "next", "section", "has", "exactly", "one", "mirror", "pair", "and", "four", "sextet", "fields,", "whereas", "additional", "exotic", "states", "may", "also", "contribute", "to", "the", "beta", "functions", "if", "they", "remain", "in", "the", "light", "spectrum."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "MIXED", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["whichshowthatasuf\\[icientnumberofsextetfleldsmayguarant(~esg4runiiingalm(}stident--icalwiththatufgL,K.Thetringmodelweareproposingint.henextsecti6onhasexactly_onemirrorpa\\ixandfoursextetfields,whereas~ddilionalexoticstat(:smayalsocontributeto?thebctafunctionsiftheyremaIninthelightspectrum."], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["which", "show", "that", "a", "suf\\[icient", "number", "of", "sextet", "flelds", "may", "guarant(~es", "g4", "runiiing", "alm(}st", "ident--ical", "with", "that", "uf", "gL,", "K.", "The", "tring", "model", "we", "are", "proposing", "in", "t.he", "next", "secti6on", "has", "exactly", "_one", "mirror", "pa\\ix", "and", "four", "sextet", "fields,", "whereas", "~ddilional", "exotic", "stat(:s", "may", "also", "contribute", "to?", "the", "bcta", "functions", "if", "they", "remaIn", "in", "the", "light", "spectrum."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["which", "show", "that", "a", "suf\\[icient", "number", "of", "sextet", "fields", "may", "guarantee(~es", "g4", "running", "alm(}st", "ident--ical", "with", "that", "of", "gL,", "K.", "The", "tring", "model", "we", "are", "proposing", "in", "the", "next", "section", "has", "exactly", "_one", "mirror", "pa\\ix", "and", "four", "sextet", "fields,", "whereas", "~additional", "exotic", "stat(:s", "may", "also", "contribute", "to?", "the", "bcta", "functions", "if", "they", "remaIn", "in", "the", "light", "spectrum."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "MIXED", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["IntegrableBoundaryC<)nitionsforGNandnl\u03c3Models"], "labels": ["WRONG"]}, "correct": {"tokens": ["Integrable", "Boundary", "Conditions", "for", "GN", "and", "nl\u03c3", "Models"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["IntegrableBoundaryC<)nitionsforGNandnl\u03c3Models"], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["Integrable", "Boundary", "C<)nitions", "for", "GN", "and", "nl\u03c3", "Models"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["Integrable", "Boundary", "C<)nitions", "for", "GN", "and", "nl\u03c3", "Models"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["IntersectionsandjOinsoffreegroups"], "labels": ["WRONG"]}, "correct": {"tokens": ["Intersections", "and", "joins", "of", "free", "groups"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["IntersectionsandjOinsoffreegroups"], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["Intersections", "and", "jOins", "of", "free", "groups"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["Intersections", "and", "jOins", "of", "free", "groups"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["Weshallnowverifythat\u03c6(x,z)isasolutionofthesystem\u2202x\u03c6=U\u03c6fromthecondition"], "labels": ["WRONG"]}, "correct": {"tokens": ["We", "shall", "now", "verify", "that", "\u03c6(x,", "z)", "is", "a", "solution", "of", "the", "system", "\u2202x\u03c6", "=", "U\u03c6", "from", "the", "condition"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["Weshallnowverifythat\u03c6(x,z)isa", "solution", "of", "the", "system\u2202x\u03c6=U\u03c6fromthecondition"], "labels": ["WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG"]}, "BS-bid-OCR": {"tokens": ["We", "shall", "now", "verify", "that", "\u03c6(x,", "z)", "is", "a", "solution", "of", "the", "system", "\u2202x\u03c6", "=", "U\u03c6", "from", "the", "condition"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["We", "shall", "now", "verify", "that", "\u03c6(x,", "z)", "is", "a", "solution", "of", "the", "system", "\u2202x\u03c6", "=", "U\u03c6", "from", "the", "condition"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["Thedirectsumandsupertensrproductareunchangedfromth(~irordinaryversionnptotheapplicaionoftheignruleinthecominutativelyisomorphism,"], "labels": ["WRONG"]}, "correct": {"tokens": ["The", "direct", "sum", "and", "super", "tensor", "product", "are", "unchanged", "from", "their", "ordinary", "versions", "up", "to", "the", "application", "of", "the", "sign", "rule", "in", "the", "commutatively", "isomorphism,"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["Thedirectsumandsupertensrproductar", "Unchanged", "Forth(~irordinaryversionnptotheapplicaionoftheignruleinthecominutativelyisomorphism,"], "labels": ["WRONG", "WRONG", "WRONG"]}, "BS-bid-OCR": {"tokens": ["The", "direct", "sum", "and", "supertensr", "product", "are", "unchanged", "from", "th(~ir", "ordinary", "version", "np", "to", "the", "applicaion", "of", "the", "ign", "rule", "in", "the", "cominutatively", "isomorphism,"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["The", "direct", "sum", "and", "supertensr", "product", "are", "unchanged", "from", "th(~ir", "ordinary", "version", "np", "to", "the", "application", "of", "the", "sign", "rule", "in", "the", "cominutatively", "isomorphism,"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["Theintemalsolutionsmstbematchedwiththee?ternal\\ones~ttheboundaryolheflui(l,\u03be=\u03beb,byequatingthecorrespondin9value?solthe1unctions\u03c6,\u03a3,\u03bdandtheirderivatives.TheboundaCyofthefluid\u03bebisdefinedbyp(\u03beb)=O.Knowledgeoftheasymptoticsolutionsinturnallowsnctodet~rmineth(;valueoftheintegrationconstatll\u03bdcatthecenter,proceedingfromtherequirementofasymptoticflatnessoftheexternalsoutions."], "labels": ["WRONG"]}, "correct": {"tokens": ["The", "internal", "solutions", "must", "be", "matched", "with", "the", "external", "ones", "at", "the", "boundary", "of", "the", "fluid,", "\u03be", "=", "\u03beb,", "by", "equating", "the", "corresponding", "values", "of", "the", "functions", "\u03c6,", "\u03a3,", "\u03bd", "and", "their", "derivatives.", "The", "boundary", "of", "the", "fluid", "\u03beb", "is", "defined", "by", "p(\u03beb)", "=", "0.", "Knowledge", "of", "the", "asymptotic", "solutions", "in", "turn", "allows", "one", "to", "determine", "the", "value", "of", "the", "integration", "constant", "\u03bdc", "at", "the", "center,", "proceeding", "from", "the", "requirement", "of", "asymptotic", "flatness", "of", "the", "external", "solutions."], "labels": ["TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED"]}, "predicted": {"google": {"tokens": ["Theintemalsolutionsmstbematchedwith", "The?eternal\\ones~the", "boundaryolheflui(l,\u03be=\u03beb,byequatingthecorrespondin9value?solthe1unctions\u03c6,\u03a3,\u03bdandtheirderivatives.TheboundaCyofthefluid\u03bebisdefinedbyp(\u03beb)=O.Knowledgeoftheasymptoticsolutionsinturnallowsnctodet~rmineth(;valueoftheintegrationconstatll\u03bdcatthecenter,proceedingfromtherequirementofasymptoticflatnessoftheexternalsoutions."], "labels": ["WRONG", "WRONG", "WRONG"]}, "BS-bid-OCR": {"tokens": ["The", "intemal", "solutions", "mst", "be", "matched", "with", "the", "e?ternal\\", "ones", "~t", "the", "boundary", "ol", "he", "flui(l,", "\u03be", "=", "\u03beb,", "by", "equating", "the", "correspondin9", "value?s", "ol", "the", "1unctions", "\u03c6,", "\u03a3,", "\u03bd", "and", "their", "derivatives.", "The", "boundaCy", "of", "the", "fluid", "\u03beb", "is", "defined", "by", "p(\u03beb)", "=", "O.", "Knowledge", "of", "the", "asymptotic", "solutions", "in", "turn", "allows", "nc", "to", "det~rmine", "th(;", "value", "of", "the", "integration", "constatll", "\u03bdc", "at", "the", "center,", "proceeding", "from", "the", "requirement", "of", "asymptotic", "flatness", "of", "the", "external", "soutions."], "labels": ["TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG"]}, "BS-bid-OCR+google": {"tokens": ["The", "internal", "solutions", "must", "be", "matched", "with", "the", "eternal\\", "ones", "~t", "the", "boundary", "ol", "he", "fluid(l,", "\u03be", "=", "\u03beb,", "by", "equating", "the", "corresponding", "value?s", "ol", "the", "1unctions", "\u03c6,", "\u03a3,", "\u03bd", "and", "their", "derivatives.", "The", "boundaRy", "of", "the", "fluid", "\u03beb", "is", "defined", "by", "p(\u03beb)", "=", "O.", "Knowledge", "of", "the", "asymptotic", "solutions", "in", "turn", "allows", "nc", "to", "det~rmine", "th(;", "value", "of", "the", "integration", "constant", "\u03bdc", "at", "the", "center,", "proceeding", "from", "the", "requirement", "of", "asymptotic", "flatness", "of", "the", "external", "solutions."], "labels": ["TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "WRONG", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED"]}}}, {"corrupt": {"tokens": ["weobtain"], "labels": ["WRONG"]}, "correct": {"tokens": ["we", "obtain"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["we", "obtain"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR": {"tokens": ["we", "obtain"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["we", "obtain"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["Figure1.Theschematicissllowntoiml)elementthenon-derermiisticquantumlog~coperation,whichhasbeenexplainedinthcpaper."], "labels": ["WRONG"]}, "correct": {"tokens": ["Figure1", ".", "The", "schematic", "is", "shown", "to", "implement", "the", "non-deterministic", "quantum", "logic", "operation,", "which", "has", "been", "explained", "in", "the", "paper."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["Figure", "1.The", "Schematic", "Issllowntoiml)element", "thenon-derermiisticquantumlog~corporation,whichhasbeenexplainedinth", "paper."], "labels": ["WRONG", "WRONG", "WRONG", "WRONG", "WRONG", "TOKENIZATION_ERROR"]}, "BS-bid-OCR": {"tokens": ["Figure", "1.", "The", "schematic", "is", "sllown", "to", "iml)element", "the", "non-derermiistic", "quantum", "log~c", "operation,", "which", "has", "been", "explained", "in", "thc", "paper."], "labels": ["WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["Figure", "1.", "The", "schematic", "is", "shown", "to", "iml)element", "the", "non-deterministic", "quantum", "log~c", "operation,", "which", "has", "been", "explained", "in", "thc", "paper."], "labels": ["WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["Compu\\tingthen\\ormaltbrm;softhesecompositi{}nswIthrespecttoG1gives"], "labels": ["WRONG"]}, "correct": {"tokens": ["Computing", "the", "normal", "forms", "of", "these", "compositions", "with", "respect", "to", "G1", "gives"], "labels": ["MIXED", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["Compu\\tingthen\\ormaltbrm;softhesecompositi{}nswIt", "respect", "G1", "gives"], "labels": ["WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR": {"tokens": ["Compu\\ting", "the", "n\\ormal", "tbrm;s", "of", "these", "compositi{}ns", "wIth", "respect", "to", "G1", "gives"], "labels": ["WRONG", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["Compu\\ting", "the", "n\\ormal", "tbrm;s", "of", "these", "compositi{}ns", "wIth", "respect", "to", "G1", "gives"], "labels": ["WRONG", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["Acompletediscussioneservestobecarriedoutinanotherwork."], "labels": ["WRONG"]}, "correct": {"tokens": ["A", "complete", "discussion", "deserves", "to", "be", "carried", "out", "in", "another", "work."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["Acompletediscussioneservestobecarriedoutinanotherwork."], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["A", "complete", "discussion", "eserves", "to", "be", "carried", "out", "in", "another", "work."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["A", "complete", "discussion", "deserves", "to", "be", "carried", "out", "in", "another", "work."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["BytheBekenstein-Hawkingrelatsio,thisleadstotheconclusionthatHawkingtcmperatureindS-epacetimeinviewofinertialobstrversindeSitterinvaria~tspecialrelativityshuldbezero.Thisisconsistentwiththepreviousresultfromtheargumenotoftheperiodicityintheimagin\\artime."], "labels": ["WRONG"]}, "correct": {"tokens": ["By", "the", "Bekenstein-Hawking", "relation,", "this", "leads", "to", "the", "conclusion", "that", "Hawking", "temperature", "in", "dS-spacetime", "in", "view", "of", "inertial", "observers", "in", "de", "Sitter", "invariant", "special", "relativity", "should", "be", "zero.", "This", "is", "consistent", "with", "the", "previous", "result", "from", "the", "argument", "of", "the", "periodicity", "in", "the", "imaginary", "time."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["BytheBekenstein-Hawkingrelatsio,thisleadstotheconclusionthatHawkingtcmperatureindS-epacetimeinviewofinertialobstrversindeSitterinvaria~tspecialrelativityshuldbezero.Thisisconsistentwiththepreviousresultfromtheargumenotoftheperiodicityintheimagin\\artime."], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["By", "the", "Bekenstein-Hawking", "relatsio,", "this", "leads", "to", "the", "conclusion", "that", "Hawking", "tcmperature", "in", "dS-epacetime", "in", "view", "of", "inertial", "obstrvers", "in", "de", "Sitter", "invaria~t", "special", "relativity", "shuld", "be", "zero.", "This", "is", "consistent", "with", "the", "previous", "result", "from", "the", "argumenot", "of", "the", "periodicity", "in", "the", "imagin\\ar", "time."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["By", "the", "Bekenstein-Hawking", "relation,", "this", "leads", "to", "the", "conclusion", "that", "Hawking", "temperature", "in", "dS-spacetime", "in", "view", "of", "inertial", "observers", "in", "de", "Sitter", "invaria~t", "special", "relativity", "should", "be", "zero.", "This", "is", "consistent", "with", "the", "previous", "result", "from", "the", "argument", "of", "the", "periodicity", "in", "the", "imagin\\ar", "time."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["Inthissectionuediscusshowtheparametersofrrmodelcanbealsoconstrainedbythengulardiameterdistance\\DAasnleasuredus'theSunyaev-Zeldovnicieffect(SttZE?)andthethermalbremsstrnahlung(X.raybri.ghtncssd~ta)forgalax`yclusters.Actuallyinahomogenousandisotropiccosmologicalmo(leltheangulardiameterrdistancecanbeeasilyrelatdtothecoordinate~distanceleadingto"], "labels": ["WRONG"]}, "correct": {"tokens": ["In", "this", "section", "we", "discuss", "how", "the", "parameters", "of", "our", "model", "can", "be", "also", "constrained", "by", "the", "angular", "diameter", "distance", "DA", "as", "measured", "using", "the", "Sunyaev-Zeldovich", "effect", "(SZE)", "and", "the", "thermal", "bremsstrahlung", "(X-ray", "brightness", "data)", "for", "galaxy", "clusters.", "Actually", "in", "a", "homogenous", "and", "isotropic", "cosmological", "model", "the", "angular", "diameter", "distance", "can", "be", "easily", "related", "to", "the", "coordinate", "distance", "leading", "to"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "MIXED", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["Inthissectionuediscusshowtheparametersofrrmodelcanbealsoconstrainedbythengulardiameterdistance\\DAasnleasuredus'theSunyaev-Zeldovnicieffect(SiZE?)and", "the", "thermal", "bremsstrahlung(X.ray", "brightness~ta)for", "galaxy`clusters.Actually", "Na", "Homogeneous", "And", "Isotropic", "Cosmological", "Mo(leltheangulardiameterrdistancecanbeeasilyrelatdtothecoordinate~distanceleadingto"], "labels": ["WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "WRONG", "WRONG", "WRONG", "WRONG", "WRONG", "WRONG", "WRONG"]}, "BS-bid-OCR": {"tokens": ["In", "this", "section", "ue", "discuss", "how", "the", "parameters", "of", "rr", "model", "can", "be", "also", "constrained", "by", "the", "ngular", "diameter", "distance\\", "DA", "as", "nleasured", "us'", "the", "Sunyaev-Zeldovnici", "effect", "(SttZE?)", "and", "the", "thermal", "bremsstrnahlung", "(X.ray", "bri.ghtncss", "d~ta)", "for", "galax`y", "clusters.", "Actually", "in", "a", "homogenous", "and", "isotropic", "cosmological", "mo(lel", "the", "angular", "diameterr", "distance", "can", "be", "easily", "relatd", "to", "the", "coordinate~", "distance", "leading", "to"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "WRONG", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["In", "this", "section", "we", "discuss", "how", "the", "parameters", "of", "the", "rr", "model", "can", "be", "also", "constrained", "by", "the", "angular", "diameter", "distance\\", "DA", "as", "demonstrated", "by", "the", "Sunyaev-Zel'dovich", "effect", "(SiZE?)", "and", "the", "thermal", "bremsstrahlung", "(X.ray", "brightness", "d~ta)", "for", "galaxy", "clusters.", "Actually", "in", "a", "homogenous", "and", "isotropic", "cosmological", "mo(lel", "the", "angular", "diameter", "distance", "can", "be", "easily", "related", "to", "the", "coordinate~", "distance", "leading", "to"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "WRONG", "MIXED", "WRONG", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["whereU(p\u0303)isdefincas"], "labels": ["WRONG"]}, "correct": {"tokens": ["where", "U(p\u0303)", "is", "defined", "as"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["whereU(p\u0303)isdefincas"], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["where", "U(p\u0303)", "is", "definc", "as"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["where", "U(p\u0303)", "is", "defined", "as"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["Lel.\\uspresentheansatzforth?emctricoffive-dimensionalplanarAdSblackholes,whichwewillbeusingth\\roughoutthepaper:"], "labels": ["WRONG"]}, "correct": {"tokens": ["Let", "us", "present", "the", "ansatz", "for", "the", "metric", "of", "five-dimensional", "planar", "AdS", "black", "holes,", "which", "we", "will", "be", "using", "throughout", "the", "paper:"], "labels": ["MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["Lel.\\uspresentheansatzforth?emctricoffive-dimensionalplanarAdSblackholes,whichwewillbeusingth\\roughoutthepaper:"], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["Lel.\\", "us", "present", "he", "ansatz", "for", "th?e", "mctric", "of", "five-dimensional", "planar", "AdS", "black", "holes,", "which", "we", "will", "be", "using", "th\\roughout", "the", "paper:"], "labels": ["WRONG", "TOKENIZATION_ERROR", "MIXED", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["Let.\\", "us", "present", "he", "ansatz", "for", "the", "matrix", "of", "five-dimensional", "planar", "AdS", "black", "holes,", "which", "we", "will", "be", "using", "th\\roughout", "the", "paper:"], "labels": ["WRONG", "TOKENIZATION_ERROR", "MIXED", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["IHTRODUCTION"], "labels": ["WRONG"]}, "correct": {"tokens": ["INTRODUCTION"], "labels": ["OCR_ERROR"]}, "predicted": {"google": {"tokens": ["INTRODUCTION"], "labels": ["OCR_ERROR"]}, "BS-bid-OCR": {"tokens": ["IHTRODUCTION"], "labels": ["WRONG"]}, "BS-bid-OCR+google": {"tokens": ["INTRODUCTION"], "labels": ["OCR_ERROR"]}}}, {"corrupt": {"tokens": ["Behavloroftilefieldwithdistance"], "labels": ["WRONG"]}, "correct": {"tokens": ["Behavior", "of", "the", "field", "with", "distance"], "labels": ["MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["Behavloroftilefieldwithdistance"], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["Behavlor", "of", "tile", "field", "with", "distance"], "labels": ["WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["Behavior", "of", "tile", "field", "with", "distance"], "labels": ["MIXED", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["and"], "labels": ["NONE"]}, "correct": {"tokens": ["and"], "labels": ["NONE"]}, "predicted": {"google": {"tokens": ["and"], "labels": ["NONE"]}, "BS-bid-OCR": {"tokens": ["and"], "labels": ["NONE"]}, "BS-bid-OCR+google": {"tokens": ["and"], "labels": ["NONE"]}}}, {"corrupt": {"tokens": ["IamindebedtoProfessorFranoBuccellaformanyenlighteningdiscussion~."], "labels": ["WRONG"]}, "correct": {"tokens": ["I", "am", "indebted", "to", "Professor", "Franco", "Buccella", "for", "many", "enlightening", "discussions."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED"]}, "predicted": {"google": {"tokens": ["IamindebedtoProfessorFranoBuccellaformanyenlighteningdiscussion~."], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["I", "am", "indebed", "to", "Professor", "Frano", "Buccella", "for", "many", "enlightening", "discussion~."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG"]}, "BS-bid-OCR+google": {"tokens": ["I", "am", "indebted", "to", "Professor", "Frano", "Buccella", "for", "many", "enlightening", "discussions~."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG"]}}}, {"corrupt": {"tokens": ["FinallywewrtetheHamiltonianforGeneral\\Refativitypartoftheaction"], "labels": ["WRONG"]}, "correct": {"tokens": ["Finally", "we", "write", "the", "Hamiltonian", "for", "General", "Relativity", "part", "of", "the", "action"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["FinallywewrtetheHamiltonianforGeneral\\Refativitypartoftheaction"], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["Finally", "we", "wrte", "the", "Hamiltonian", "for", "General", "\\Refativity", "part", "of", "the", "action"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["Finally", "we", "write", "the", "Hamiltonian", "for", "General", "\\Relativity", "part", "of", "the", "action"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["Weconstructwaveetsusingtranslationsanxldilationof\u03a8k:o"], "labels": ["WRONG"]}, "correct": {"tokens": ["We", "construct", "wavelets", "using", "translations", "and", "dilations", "of", "\u03a8k:"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["Weconstructwaveetsusingtranslationsanxldilationof\u03a8k:o"], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["We", "construct", "waveets", "using", "translations", "anxl", "dilation", "of", "\u03a8k:o"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "WRONG"]}, "BS-bid-OCR+google": {"tokens": ["We", "construct", "waveets", "using", "translations", "and", "dilation", "of", "\u03a8k:o"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "WRONG", "TOKENIZATION_ERROR", "WRONG"]}}}, {"corrupt": {"tokens": ["Theideabehindtheseserieaofopenevaluetionshasbeentoattractteamstoworkonaproblembyprovidingthemwithreal(orrealistic)trainingandtestdata,aswellasobjectiveev?aluat1onmetrics.Thesedatasetsareoft'cnilardtoobtain,andthe<>penevaluaCionmakesitmucheasierforgroupstobuildsystemsandcompar\\eperformanceonacommonproblem.Ifmanyteamsare1nvolved,heresultsareameasureofthestate-of-the-artforthatfask.naddition,whentheteamsshareinformc~tionabouttheira1pproachesandtheevaluationsarerepeaedovertilne,l;hcntheresearchcommunitycandemonstratemeasurableforwai'dl)rogressinafield."], "labels": ["WRONG"]}, "correct": {"tokens": ["The", "idea", "behind", "these", "series", "of", "open", "evaluations", "has", "been", "to", "attract", "teams", "to", "work", "on", "a", "problem", "by", "providing", "them", "with", "real", "(or", "realistic)", "training", "and", "test", "data,", "as", "well", "as", "objective", "evaluation", "metrics.", "These", "data", "sets", "are", "often", "hard", "to", "obtain,", "and", "the", "open", "evaluation", "makes", "it", "much", "easier", "for", "groups", "to", "build", "systems", "and", "compare", "performance", "on", "a", "common", "problem.", "If", "many", "teams", "are", "involved,", "the", "results", "are", "a", "measure", "of", "the", "state-of-the-art", "for", "that", "task.", "In", "addition,", "when", "the", "teams", "share", "information", "about", "their", "approaches", "and", "the", "evaluations", "are", "repeated", "over", "time,", "then", "the", "research", "community", "can", "demonstrate", "measurable", "forward", "progress", "in", "a", "field."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["Theideabehindtheseserieaofopenevaluetionshasbeentoattractteamstoworkonaproblembyprovidingthemwithreal(or", "realistic)training", "and", "test", "data,as", "well", "as", "objective", "ev?aluat1onmetrics.Thesedatasetsareoft'cnilardtoobtain,andthe<>penevaluaCionmakesitmucheasierforgroupstobuildsystemsandcompar\\eperformanceonacommonproblem.Ifmanyteamsare1nvolved,heresultsareameasureofthestate-of-the-artforthatfask.naddition,whentheteamsshareinformc~tionabouttheira1pproachesandtheevaluationsarerepeaedovertilne,l;hcntheresearchcommunitycandemonstratemeasurableforwai'dl)rogressinafield."], "labels": ["WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG"]}, "BS-bid-OCR": {"tokens": ["The", "idea", "behind", "these", "seriea", "of", "open", "evaluetions", "has", "been", "to", "attract", "teams", "to", "work", "on", "a", "problem", "by", "providing", "them", "with", "real", "(or", "realistic)", "training", "and", "test", "data,", "as", "well", "as", "objective", "ev?aluat1on", "metrics.", "These", "datasets", "are", "oft'cn", "ilard", "to", "obtain,", "and", "the", "<>pen", "evaluaCion", "makes", "it", "much", "easier", "for", "groups", "to", "build", "systems", "and", "compar\\e", "performance", "on", "a", "common", "problem.", "If", "many", "teams", "are", "1nvolved,", "he", "results", "are", "a", "measure", "of", "the", "state-of-the-art", "for", "that", "fask.", "n", "addition,", "when", "the", "teams", "share", "informc~tion", "about", "their", "a1pproaches", "and", "the", "evaluations", "are", "repeaed", "over", "tilne,", "l;hcn", "the", "research", "community", "can", "demonstrate", "measurable", "forwai'd", "l)rogress", "in", "a", "field."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["The", "idea", "behind", "these", "series", "of", "open", "evaluations", "has", "been", "to", "attract", "teams", "to", "work", "on", "a", "problem", "by", "providing", "them", "with", "real", "(or", "realistic)", "training", "and", "test", "data,", "as", "well", "as", "objective", "evaluation", "metrics.", "These", "datasets", "are", "often", "hard", "to", "obtain,", "and", "the", "<>pen", "evaluaCion", "makes", "it", "much", "easier", "for", "groups", "to", "build", "systems", "and", "compar\\e", "performance", "on", "a", "common", "problem.", "If", "many", "teams", "are", "1nvolved,", "the", "results", "are", "a", "measure", "of", "the", "state-of-the-art", "for", "that", "fask.", "in", "addition,", "when", "the", "teams", "share", "informc~tion", "about", "their", "approaches", "and", "the", "evaluations", "are", "repeated", "over", "tile,", "l;hcn", "the", "research", "community", "can", "demonstrate", "measurable", "forwai'd", "l)progress", "in", "a", "field."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["wher"], "labels": ["WRONG"]}, "correct": {"tokens": ["where"], "labels": ["OCR_ERROR"]}, "predicted": {"google": {"tokens": ["where"], "labels": ["OCR_ERROR"]}, "BS-bid-OCR": {"tokens": ["wher"], "labels": ["WRONG"]}, "BS-bid-OCR+google": {"tokens": ["where"], "labels": ["OCR_ERROR"]}}}, {"corrupt": {"tokens": ["where"], "labels": ["NONE"]}, "correct": {"tokens": ["where"], "labels": ["NONE"]}, "predicted": {"google": {"tokens": ["where"], "labels": ["NONE"]}, "BS-bid-OCR": {"tokens": ["where"], "labels": ["NONE"]}, "BS-bid-OCR+google": {"tokens": ["where"], "labels": ["NONE"]}}}, {"corrupt": {"tokens": ["Sinceweconsideracyl?inderwithconstantradius(alongtheaxisinthez-direction),thelasttern\\]dropoffamlwegetthefollowingsolution(wexlemandthal,boththepotentialanditsderivativebecontinuousthronghout)"], "labels": ["WRONG"]}, "correct": {"tokens": ["Since", "we", "consider", "a", "cylinder", "with", "constant", "radius", "(along", "the", "axis", "in", "the", "z-direction),", "the", "last", "term", "drops", "off", "and", "we", "get", "the", "following", "solution", "(we", "demand", "that", "both", "the", "potential", "and", "its", "derivative", "be", "continuous", "throughout)"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED"]}, "predicted": {"google": {"tokens": ["Sinceweconsideracyl?inderwithconstantradius(along", "the", "axis", "the", "z-direction),thelasttern\\]drop", "off", "aml", "we", "get", "the", "following", "solution(wexlemandthal,boththepotentialanditsderivativebecontinuousthronghout)"], "labels": ["WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG"]}, "BS-bid-OCR": {"tokens": ["Since", "we", "consider", "a", "cyl?inder", "with", "constant", "radius", "(along", "the", "axis", "in", "the", "z-direction),", "the", "last", "tern\\]", "drop", "off", "aml", "we", "get", "the", "following", "solution", "(we", "xlemand", "thal,", "both", "the", "potential", "and", "its", "derivative", "be", "continuous", "thronghout)"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG"]}, "BS-bid-OCR+google": {"tokens": ["Since", "we", "consider", "a", "cylinder", "with", "constant", "radius", "(along", "the", "axis", "in", "the", "z-direction),", "the", "last", "tern\\]", "drop", "off", "aml", "we", "get", "the", "following", "solution", "(we", "demand", "that,", "both", "the", "potential", "and", "its", "derivative", "be", "continuous", "throughout)"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED"]}}}, {"corrupt": {"tokens": ["Wetherefomobtain"], "labels": ["WRONG"]}, "correct": {"tokens": ["We", "therefore", "obtain"], "labels": ["TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["Wetherefomobtain"], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["We", "therefom", "obtain"], "labels": ["TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["We", "therefore", "obtain"], "labels": ["TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["Insummary,wehavedemonstrated3vldentbias-currentependenceofthespinaccumulationinasemiconductingSichannelat25KbymeasuringtheHanle-effectsignals.WeilaveobsemvedthattheelectrIcalcetectabilityoftheHanle-effectsignalsattheforw\\ard-biasedcentactiShigherthanthatatthereverse-biasedcontact.Thisworkindicatespossribleevidenclforthedeteclionofspin-polar~zedelectronscreatednointhelocalizedstatehinthevicinityoftheinerfacebutinaSichannel."], "labels": ["WRONG"]}, "correct": {"tokens": ["In", "summary,", "we", "have", "demonstrated", "evident", "bias-current", "dependence", "of", "the", "spin", "accumulation", "in", "a", "semiconducting", "Si", "channel", "at", "25", "K", "by", "measuring", "the", "Hanle-effect", "signals.", "We", "have", "observed", "that", "the", "electrical", "detectability", "of", "the", "Hanle-effect", "signals", "at", "the", "forward-biased", "contact", "is", "higher", "than", "that", "at", "the", "reverse-biased", "contact.", "This", "work", "indicates", "possible", "evidence", "for", "the", "detection", "of", "spin-polarized", "electrons", "created", "not", "in", "the", "localized", "state", "in", "the", "vicinity", "of", "the", "interface", "but", "in", "a", "Si", "channel."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["Insummary,wehavedemonstrated3vldentbias-currentependenceofthespinaccumulationinasemiconductingSichannelat25KbymeasuringtheHanle-effectsignals.WeilaveobsemvedthattheelectrIcalcetectabilityoftheHanle-effectsignalsattheforw\\ard-biasedcentactiShigherthanthatatthereverse-biasedcontact.Thisworkindicatespossribleevidenclforthedeteclionofspin-polar~zedelectronscreatednointhelocalizedstatehinthevicinityoftheinerfacebutinaSichannel."], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["In", "summary,", "we", "have", "demonstrated", "3vldent", "bias-current", "ependence", "of", "the", "spin", "accumulation", "in", "a", "semiconducting", "Si", "channel", "at", "25", "K", "by", "measuring", "the", "Hanle-effect", "signals.", "We", "ilave", "obsemved", "that", "the", "electrIcal", "cetectability", "of", "the", "Hanle-effect", "signals", "at", "the", "forw\\ard-biased", "centact", "iS", "higher", "than", "that", "at", "the", "reverse-biased", "contact.", "This", "work", "indicates", "possrible", "evidencl", "for", "the", "deteclion", "of", "spin-polar~zed", "electrons", "created", "noin", "the", "localized", "stateh", "in", "the", "vicinity", "of", "the", "inerface", "but", "in", "a", "Si", "channel."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["In", "summary,", "we", "have", "demonstrated", "3vldent", "bias-current", "dependence", "of", "the", "spin", "accumulation", "in", "a", "semiconducting", "Si", "channel", "at", "25", "K", "by", "measuring", "the", "Hanle-effect", "signals.", "We", "observed", "that", "the", "electrIcal", "detectability", "of", "the", "Hanle-effect", "signals", "at", "the", "forw\\ard-biased", "contact", "iS", "higher", "than", "that", "at", "the", "reverse-biased", "contact.", "This", "work", "indicates", "possible", "evidence", "for", "the", "detection", "of", "spin-polar~zed", "electrons", "created", "in", "the", "localized", "states", "in", "the", "vicinity", "of", "the", "interface", "but", "in", "a", "Si", "channel."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "MIXED", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["everyelementafMristhesumaofofasymmetriandanantisymmetricelement."], "labels": ["WRONG"]}, "correct": {"tokens": ["every", "element", "of", "Mr", "is", "the", "sum", "of", "of", "a", "symmetric", "and", "an", "antisymmetric", "element."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["everyelementafMristhesumaofofasymmetriandanantisymmetricelement."], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["every", "element", "af", "Mr", "is", "the", "sumaof", "of", "a", "symmetri", "and", "an", "antisymmetric", "element."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["every", "element", "of", "Mr", "is", "the", "sum", "of", "a", "symmetric", "and", "an", "antisymmetric", "element."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["Firstopecationanddri#tfieldperformanceofalargeareadoublephasekArElectronMultiplierTimeProj~ctionChamaberwithanimmersedGrin?~.chrhigh-voltagemultipller"], "labels": ["WRONG"]}, "correct": {"tokens": ["First", "operation", "and", "drift", "field", "performance", "of", "a", "large", "area", "double", "phase", "LAr", "Electron", "Multiplier", "Time", "Projection", "Chamber", "with", "an", "immersed", "Greinacher", "high-voltage", "multiplier"], "labels": ["TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED"]}, "predicted": {"google": {"tokens": ["Firstopecationanddri#tfieldperformanceofalargeareadoublephasekArElectronMultiplierTimeProj~ctionChamaberwithanimmersedGrin?~.chrhigh-voltagemultipller"], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["First", "opecation", "and", "dri#t", "field", "performance", "of", "a", "large", "area", "double", "phase", "kAr", "Electron", "Multiplier", "Time", "Proj~ction", "Chamaber", "with", "an", "immersed", "Grin?~.chr", "high-voltage", "multipller"], "labels": ["TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG"]}, "BS-bid-OCR+google": {"tokens": ["First", "operation", "and", "dri#t", "field", "performance", "of", "a", "large", "area", "double", "phase", "kAr", "Electron", "Multiplier", "Time", "Proj~ction", "Chamber", "with", "an", "immersed", "Grin?~.chr", "high-voltage", "multiplier"], "labels": ["TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "MIXED"]}}}, {"corrupt": {"tokens": ["where"], "labels": ["NONE"]}, "correct": {"tokens": ["where"], "labels": ["NONE"]}, "predicted": {"google": {"tokens": ["where"], "labels": ["NONE"]}, "BS-bid-OCR": {"tokens": ["where"], "labels": ["NONE"]}, "BS-bid-OCR+google": {"tokens": ["where"], "labels": ["NONE"]}}}, {"corrupt": {"tokens": ["Thequmtity\u03c0\u03b1\u03b2?islthedeviaticnof/,'hepressuretenshisorfromitsequilibriumpartPeqduetotheFermi?surfacedeformatiott"], "labels": ["WRONG"]}, "correct": {"tokens": ["The", "quantity", "\u03c0\u03b1\u03b2", "is", "the", "deviation", "of", "the", "pressure", "tensor", "from", "its", "equilibrium", "part", "Peq", "due", "to", "the", "Fermi-surface", "deformation"], "labels": ["TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED"]}, "predicted": {"google": {"tokens": ["The", "Quantity", "\u03a0\u03b1\u03b2?is", "the", "deviation/,'hepressuretenshisorfromitsequilibriumpartPeqduetotheFermi?surfacedeformatiott"], "labels": ["TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "WRONG"]}, "BS-bid-OCR": {"tokens": ["The", "qumtity", "\u03c0\u03b1\u03b2?", "is", "lthe", "deviaticn", "of", "/,'he", "pressure", "tenshisor", "from", "its", "equilibrium", "part", "Peq", "due", "to", "the", "Fermi", "?surface", "deformatiott"], "labels": ["TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "WRONG"]}, "BS-bid-OCR+google": {"tokens": ["The", "quantity", "\u03c0\u03b1\u03b2?", "is", "the", "deviation", "of", "/,'he", "pressure", "tenshisor", "from", "its", "equilibrium", "part", "Peq", "due", "to", "the", "Fermi", "?surface", "deformation"], "labels": ["TOKENIZATION_ERROR", "MIXED", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "MIXED"]}}}, {"corrupt": {"tokens": ["Tal)leIV"], "labels": ["WRONG"]}, "correct": {"tokens": ["Table", "IV"], "labels": ["MIXED", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["Tal)leIV"], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["Tal)le", "IV"], "labels": ["WRONG", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["Tal)le", "IV"], "labels": ["WRONG", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["Wehaveprodedthefollowingtheorem:"], "labels": ["WRONG"]}, "correct": {"tokens": ["We", "have", "proved", "the", "following", "theorem:"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["We", "Have", "Produced", "The", "Following", "Theorem:"], "labels": ["TOKENIZATION_ERROR", "WRONG", "WRONG", "WRONG", "WRONG", "WRONG"]}, "BS-bid-OCR": {"tokens": ["We", "have", "proded", "the", "following", "theorem:"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["We", "have", "provided", "the", "following", "theorem:"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["Appendix"], "labels": ["NONE"]}, "correct": {"tokens": ["Appendix"], "labels": ["NONE"]}, "predicted": {"google": {"tokens": ["Appendix"], "labels": ["NONE"]}, "BS-bid-OCR": {"tokens": ["Appendix"], "labels": ["NONE"]}, "BS-bid-OCR+google": {"tokens": ["Appendix"], "labels": ["NONE"]}}}, {"corrupt": {"tokens": ["Inthculet-Su,u~agneticnetworks;cavities;treimportantlocatiouswherethemagneticfieldsaresufficien?ttyincli\\nedduetotheirwellevolvedhofizontalcomponents.Theyareformedoverthegranularcell-sinformofthefIeld-freeregionsd\\uetl)thetransportofplasmaattheiYboundariesandoverlaidbybipolarmagnoticcanopies.Theverticalmagnetlcfields,however,resid\u0002mostlyinthecoreofsuchmagnetienel.workstl\"(Schrijverc-Title,2003;Centenoetal.,2007).Sucgrammhmagneticcavity-canopysystemsarethoughttobeiealreso?atorsofthevariousMHDwavesthatcanbetrappedinfilecav\\ity,aswellcanalsoleakinformofthemagnetoacoustic-graVitywaveupwardthroughthecoreofsuchmagneticelworks.ItishoughtthatthefiPeld-frcec.avityregionsunderlyingthebipolarcanopycantrapchehigh-frequencyacousticoscillations,andthelow-frequencycomponentsmayleakint()thehigheratmosphereinformofiliagnetoacoustic-gravity?waves(Kuridzeetal.,2008;Sr/vasSavaetal.,20O8;Srivastava,2010).Therfore,suchmagneticstructuresinthelowersoaratmospherearetheregionsthatmayplayanimportantrole5nthewa-vefiltering(e.g.NTcIntosh&Judge,2001;Krijgereta.,2001;McAteeretal.,2002;Vecchioetal.,2007,2009jSrivastava,2010,andreferencestherein)."], "labels": ["WRONG"]}, "correct": {"tokens": ["In", "the", "quiet-Sun", "magnetic", "networks,", "cavities", "are", "important", "locations", "where", "the", "magnetic", "fields", "are", "sufficiently", "inclined", "due", "to", "their", "well", "evolved", "horizontal", "components.", "They", "are", "formed", "over", "the", "granular", "cells", "in", "form", "of", "the", "field-free", "regions", "due", "to", "the", "transport", "of", "plasma", "at", "their", "boundaries", "and", "overlaid", "by", "bipolar", "magnetic", "canopies.", "The", "vertical", "magnetic", "fields,", "however,", "reside", "mostly", "in", "the", "core", "of", "such", "magnetic", "networks", "(Schrijver", "&", "Title,", "2003;", "Centeno", "et", "al.,", "2007).", "Such", "magnetic", "cavity-canopy", "systems", "are", "thought", "to", "be", "ideal", "resonators", "of", "the", "various", "MHD", "waves", "that", "can", "be", "trapped", "in", "the", "cavity,", "as", "well", "can", "also", "leak", "in", "form", "of", "the", "magnetoacoustic-gravity", "waves", "upward", "through", "the", "core", "of", "such", "magnetic", "networks.", "It", "is", "thought", "that", "the", "field-free", "cavity", "regions", "underlying", "the", "bipolar", "canopy", "can", "trap", "the", "high-frequency", "acoustic", "oscillations,", "and", "the", "low-frequency", "components", "may", "leak", "into", "the", "higher", "atmosphere", "in", "form", "of", "magnetoacoustic-gravity", "waves", "(Kuridze", "et", "al.,", "2008;", "Srivastava", "et", "al.,", "2008;", "Srivastava,", "2010).", "Therefore,", "such", "magnetic", "structures", "in", "the", "lower", "solar", "atmosphere", "are", "the", "regions", "that", "may", "play", "an", "important", "role", "in", "the", "wave", "filtering", "(e.g.", "McIntosh", "&", "Judge,", "2001;", "Krijger", "et", "al.,", "2001;", "McAteer", "et", "al.,", "2002;", "Vecchio", "et", "al.,", "2007,", "2009;", "Srivastava,", "2010,", "and", "references", "therein)."], "labels": ["TOKENIZATION_ERROR", "MIXED", "MIXED", "MIXED", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["Inthculet-Su,u~agneticnetworks;cavities;treimportantlocatiouswherethemagneticfieldsaresufficien?ttyincli\\nedduetotheirwellevolvedhofizontalcomponents.Theyareformedoverthegranularcell-sinformofthefIeld-freeregionsd\\uetl)thetransportofplasmaattheiYboundariesandoverlaidbybipolarmagnoticcanopies.Theverticalmagnetlcfields,however,residmostlyinthecoreofsuchmagnetienel.workstl\"(Schrijvers-Title,2003;Centenoetal.,2007).Sucgrammhmagneticcavity-canopysystemsarethoughttobeiealreso?atorsofthevariousMHDwavesthatcanbetrappedinfilecav\\ity,aswellcanalsoleakinformofthemagnetoacoustic-graVitywaveupwardthroughthecoreofsuchmagneticelworks.ItishoughtthatthefiPeld-frcec.avityregionsunderlyingthebipolarcanopycantrapchehigh-frequencyacousticoscillations,andthelow-frequencycomponentsmayleakint()thehigheratmosphereinformofiliagneto", "acoustic-gravity?waves(Kuridzeetal.,2008;Sr/vasSavaetal.,20O8;Srivastava,2010).Therfore,suchmagneticstructuresinthelowersoaratmospherearetheregionsthatmayplayanimportantrole5nthewa-vefiltering(e.g.NTcIntosh&Judge,2001;Krijgereta.,2001;McAteeretal.,2002;Vecchio", "Metal.,2007,2009jSrivastava,2010,and", "references", "therein)."], "labels": ["WRONG", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR": {"tokens": ["In", "thc", "ulet-Su,u", "~agnetic", "networks;", "cavities", ";tre", "important", "locatious", "where", "the", "magnetic", "fields", "are", "sufficien?tty", "incli\\ned", "due", "to", "their", "well", "evolved", "hofizontal", "components.", "They", "are", "formed", "over", "the", "granular", "cell-s", "in", "form", "of", "the", "fIeld-free", "regions", "d\\ue", "tl)", "the", "transport", "of", "plasma", "at", "theiY", "boundaries", "and", "overlaid", "by", "bipolar", "magnotic", "canopies.", "The", "vertical", "magnetlc", "fields,", "however,", "resid\u0002", "mostly", "in", "the", "core", "of", "such", "magnetie", "nel.workstl\"", "(Schrijverc-Title,", "2003;", "Centeno", "et", "al.,", "2007).", "Sucgrammh", "magnetic", "cavity-canopy", "systems", "are", "thought", "to", "be", "ieal", "reso?ators", "of", "the", "various", "MHD", "waves", "that", "can", "be", "trapped", "in", "file", "cav\\ity,", "as", "well", "can", "also", "leak", "in", "form", "of", "the", "magnetoacoustic-graVity", "wave", "upward", "through", "the", "core", "of", "such", "magnetic", "elworks.", "It", "is", "hought", "that", "the", "fiPeld-frce", "c.avity", "regions", "underlying", "the", "bipolar", "canopy", "can", "trap", "che", "high-frequency", "acoustic", "oscillations,", "and", "the", "low-frequency", "components", "may", "leak", "int()", "the", "higher", "atmosphere", "in", "form", "of", "iliagneto", "acoustic-gravity", "?waves", "(Kuridze", "et", "al.,", "2008;", "Sr/vasSava", "et", "al.,", "20O8;", "Srivastava,", "2010).", "Therfore,", "such", "magnetic", "structures", "in", "the", "lower", "soar", "atmosphere", "are", "the", "regions", "that", "may", "play", "an", "important", "role", "5n", "the", "wa-ve", "filtering", "(e.g.", "NTcIntosh", "&", "Judge,", "2001;", "Krijger", "et", "a.,", "2001;", "McAteer", "et", "al.,", "2002;", "Vecchio", "et", "al.,", "2007,", "2009j", "Srivastava,", "2010,", "and", "references", "therein)."], "labels": ["TOKENIZATION_ERROR", "WRONG", "WRONG", "WRONG", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["In", "thc", "ulet-Su,u", "~magnetic", "networks;", "cavities", ";tre", "important", "locations", "where", "the", "magnetic", "fields", "are", "sufficient", "ty", "incli\\ned", "due", "to", "their", "well", "evolved", "horizontal", "components.", "They", "are", "formed", "over", "the", "granular", "cell-s", "in", "form", "of", "the", "fIeld-free", "regions", "d\\ue", "tl)", "the", "transport", "of", "plasma", "at", "theiR", "boundaries", "and", "overlaid", "by", "bipolar", "magnetic", "canopies.", "The", "vertical", "magnetic", "fields,", "however,", "reside", "mostly", "in", "the", "core", "of", "such", "magnetie", "nel.works\"", "(Schrijvers-Title,", "2003;", "Centeno", "et", "al.,", "2007).", "Sub", "Grammh", "magnetic", "cavity-canopy", "systems", "are", "thought", "to", "be", "ideal", "resonators", "of", "the", "various", "MHD", "waves", "that", "can", "be", "trapped", "in", "file", "cav\\ity,", "as", "well", "can", "also", "leak", "in", "form", "of", "the", "magnetoacoustic-graVity", "wave", "upward", "through", "the", "core", "of", "such", "magnetic", "elworks.", "It", "is", "thought", "that", "the", "field-force", "cavity", "regions", "underlying", "the", "bipolar", "canopy", "can", "trap", "che", "high-frequency", "acoustic", "oscillations,", "and", "the", "low-frequency", "components", "may", "leak", "int()", "the", "higher", "atmosphere", "in", "form", "of", "iliagneto", "acoustic-gravity", "?waves", "(Kuridze", "et", "al.,", "2008;", "Sr/vasSava", "et", "al.,", "20O8;", "Srivastava,", "2010).", "Therefore,", "such", "magnetic", "structures", "in", "the", "lower", "soar", "atmosphere", "are", "the", "regions", "that", "may", "play", "an", "important", "role", "5n", "the", "wa-ve", "filtering", "(e.g.", "McIntosh", "&", "Judge,", "2001;", "Krijger", "et", "a.,", "2001;", "McAteer", "et", "al.,", "2002;", "Vecchio", "et", "al.,", "2007,", "2009j", "Srivastava,", "2010,", "and", "references", "therein)."], "labels": ["TOKENIZATION_ERROR", "WRONG", "WRONG", "WRONG", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["Inthatcase,assumingthattheparitionfunctions"], "labels": ["WRONG"]}, "correct": {"tokens": ["In", "that", "case,", "assuming", "that", "the", "partition", "functions"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["In", "That", "Case,assuming", "that", "the", "partition", "functions"], "labels": ["TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR"]}, "BS-bid-OCR": {"tokens": ["In", "that", "case,", "assuming", "that", "the", "parition", "functions"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["In", "that", "case,", "assuming", "that", "the", "partition", "functions"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["Weendow|Y|witiralocallyEuclideanmetricasfollows:"], "labels": ["WRONG"]}, "correct": {"tokens": ["We", "endow", "|Y", "|", "with", "a", "locally", "Euclidean", "metric", "as", "follows:"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["We", "Endow|Y|wi", "tira", "locally", "Euclidean", "m\u00e9tricas", "follows:"], "labels": ["TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR"]}, "BS-bid-OCR": {"tokens": ["We", "endow", "|Y", "|", "witir", "a", "locally", "Euclidean", "metric", "as", "follows:"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["We", "endow", "|Y", "|", "witir", "a", "locally", "Euclidean", "metric", "as", "follows:"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["Superconductivityandstoichiometry"], "labels": ["WRONG"]}, "correct": {"tokens": ["Superconductivity", "and", "stoichiometry"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["Superconductivity", "And", "Stoichiometry"], "labels": ["TOKENIZATION_ERROR", "WRONG", "WRONG"]}, "BS-bid-OCR": {"tokens": ["Superconductivity", "and", "stoichiometry"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["Superconductivity", "and", "stoichiometry"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["Acknowledgements"], "labels": ["NONE"]}, "correct": {"tokens": ["Acknowledgements"], "labels": ["NONE"]}, "predicted": {"google": {"tokens": ["Acknowledgements"], "labels": ["NONE"]}, "BS-bid-OCR": {"tokens": ["Acknowledgements"], "labels": ["NONE"]}, "BS-bid-OCR+google": {"tokens": ["Acknowledgements"], "labels": ["NONE"]}}}, {"corrupt": {"tokens": ["Majoran~NeutrinosroductiontNLCinanEffectiveApproach"], "labels": ["WRONG"]}, "correct": {"tokens": ["Majorana", "Neutrinos", "Production", "at", "NLC", "in", "an", "Effective", "Approach"], "labels": ["MIXED", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["Majorana~Neutrinos", "roductiont", "NLC", "in", "an", "Effective", "Approach"], "labels": ["WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR": {"tokens": ["Majoran~", "Neutrinos", "roduction", "t", "NLC", "in", "an", "Effective", "Approach"], "labels": ["WRONG", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["Majorana~", "Neutrinos", "production", "t", "NLC", "in", "an", "Effective", "Approach"], "labels": ["WRONG", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["onMforu\u2208V.Thenl'oru\u2208Vandw\u2208M,"], "labels": ["WRONG"]}, "correct": {"tokens": ["on", "M", "for", "u", "\u2208", "V.", "Then", "for", "u", "\u2208", "V", "and", "w", "\u2208", "M,"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["onMforu\u2208V.Thenl'oru\u2208Vandw\u2208M,"], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["on", "M", "for", "u", "\u2208", "V.", "Then", "l'or", "u", "\u2208", "V", "and", "w", "\u2208", "M,"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["on", "M", "for", "u", "\u2208", "V.", "Then", "l'or", "u", "\u2208", "V", "and", "w", "\u2208", "M,"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["Thegenera1structureofaQCDcrosssectionhlNLOistgehefollowing"], "labels": ["WRONG"]}, "correct": {"tokens": ["The", "general", "structure", "of", "a", "QCD", "cross", "section", "in", "NLO", "is", "the", "following"], "labels": ["TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["Thegenera1structureofaQCDcrosssectionhlNLOistgehefollowing"], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["The", "genera1", "structure", "of", "a", "QCD", "cross", "section", "hl", "NLO", "is", "tgehe", "following"], "labels": ["TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["The", "general", "structure", "of", "a", "QCD", "cross", "section", "hl", "NLO", "is", "the", "following"], "labels": ["TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["Wefirs,te1,urntoapointbrieflymenttonede~/rlierinthepaperaboutadifferenceintheUPBconstructionhichappearswhenorthogonalUPBsrereplacebbygeneralizedUPs.In|;heformercasethePPTpropertyfollowsdirectlyfrom,theprojectioformof\u03c1,sincetilis-impliesalso\u03c1PtobepoportionaltoaprojOctlon,andthel'eforetobepositive.WiththeuseofageneralizedUPB,wehtivenoproofforthistobethecase.Clearlyl,heUPBconstructiontwillbesimplerifweonlyhavetotakeintoaccountcondt\\ionstahatapplyto\u03c1andnottoboth\u03c1and\u03c1P,sndforthortreasonweshallexaminethispoimabitfHrther."], "labels": ["WRONG"]}, "correct": {"tokens": ["We", "first", "return", "to", "a", "point", "briefly", "mentioned", "earlier", "in", "the", "paper", "about", "a", "difference", "in", "the", "UPB", "construction", "which", "appears", "when", "orthogonal", "UPBs", "are", "replaced", "by", "generalized", "UPBs.", "In", "the", "former", "case", "the", "PPT", "property", "follows", "directly", "from", "the", "projection", "form", "of", "\u03c1,", "since", "this", "implies", "also", "\u03c1P", "to", "be", "proportional", "to", "a", "projection,", "and", "therefore", "to", "be", "positive.", "With", "the", "use", "of", "a", "generalized", "UPB,", "we", "have", "no", "proof", "for", "this", "to", "be", "the", "case.", "Clearly", "the", "UPB", "construction", "will", "be", "simpler", "if", "we", "only", "have", "to", "take", "into", "account", "conditions", "that", "apply", "to", "\u03c1", "and", "not", "to", "both", "\u03c1", "and", "\u03c1P,", "and", "for", "that", "reason", "we", "shall", "examine", "this", "point", "a", "bit", "further."], "labels": ["TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED"]}, "predicted": {"google": {"tokens": ["Wefirs,te1,urntoapointbrieflymenttonede~/rlierinthepaperaboutadifferenceintheUPBconstructionhichappearswhenorthogonalUPBsrereplacebbygeneralizedUPs.In|;heformercasethePPTpropertyfollowsdirectlyfrom,theprojectioformof\u03c1,sincetilis-impliesalso\u03c1PtobepoportionaltoaprojOctlon,andthel'eforetobepositive.WiththeuseofageneralizedUPB,wehtivenoproofforthistobethecase.Clearlyl,heUPBconstructiontwillbesimplerifweonlyhavetotakeintoaccountcondt\\ionstahatapplyto\u03c1andnottoboth\u03c1and\u03c1P,sndforthortreasonweshallexaminethispoimabitfHrther."], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["We", "firs,t", "e1,urn", "to", "a", "point", "briefly", "menttoned", "e~/rlier", "in", "the", "paper", "about", "a", "difference", "in", "the", "UPB", "construction", "hich", "appears", "when", "orthogonal", "UPBs", "re", "replaceb", "by", "generalized", "UPs.", "In", "|;he", "former", "case", "the", "PPT", "property", "follows", "directly", "from", ",the", "projectio", "form", "of", "\u03c1,", "since", "tilis-", "implies", "also", "\u03c1P", "to", "be", "poportional", "to", "a", "projOctlon,", "and", "thel'efore", "to", "be", "positive.", "With", "the", "use", "of", "a", "generalized", "UPB,", "we", "htive", "no", "proof", "for", "this", "to", "be", "the", "case.", "Clearly", "l,he", "UPB", "constructiont", "will", "be", "simpler", "if", "we", "only", "have", "to", "take", "into", "account", "condt\\ions", "tahat", "apply", "to", "\u03c1", "and", "not", "to", "both", "\u03c1", "and", "\u03c1P,", "snd", "for", "thort", "reason", "we", "shall", "examine", "this", "poim", "a", "bit", "fHrther."], "labels": ["TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG"]}, "BS-bid-OCR+google": {"tokens": ["We", "first", "e1,urn", "to", "a", "point", "briefly", "mentioned", "e~/earlier", "in", "the", "paper", "about", "a", "difference", "in", "the", "UPB", "construction", "which", "appears", "when", "orthogonal", "UPBs", "are", "replaced", "by", "generalized", "UPs.", "In", "|;he", "former", "case", "the", "PPT", "property", "follows", "directly", "from", ",the", "projection", "form", "of", "\u03c1,", "since", "tilis-", "implies", "also", "\u03c1P", "to", "be", "proportional", "to", "a", "projEction,", "and", "therefore", "to", "be", "positive.", "With", "the", "use", "of", "a", "generalized", "UPB,", "we", "have", "no", "proof", "for", "this", "to", "be", "the", "case.", "Clearly", "l,he", "UPB", "construction", "will", "be", "simpler", "if", "we", "only", "have", "to", "take", "into", "account", "condt\\ions", "that", "apply", "to", "\u03c1", "and", "not", "to", "both", "\u03c1", "and", "\u03c1P,", "and", "for", "that", "reason", "we", "shall", "examine", "this", "poem", "a", "bit", "fUrther."], "labels": ["TOKENIZATION_ERROR", "MIXED", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG"]}}}, {"corrupt": {"tokens": ["Toreason~boutconvergenceofprobabilisticprocesses,wcwillusetheto\\talvariationdist~nceondistri1)utions(alsoknownasstatist~caldistangece)."], "labels": ["WRONG"]}, "correct": {"tokens": ["To", "reason", "about", "convergence", "of", "probabilistic", "processes,", "we", "will", "use", "the", "total", "variation", "distance", "on", "distributions", "(also", "known", "as", "statistical", "distance)."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED"]}, "predicted": {"google": {"tokens": ["Toreason~boutconvergenceofprobabilisticprocesses,wcwillusetheto\\talvariationdist~nceondistri1)utions(also", "known", "as", "statist~caldistangece)."], "labels": ["WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG"]}, "BS-bid-OCR": {"tokens": ["To", "reason", "~bout", "convergence", "of", "probabilistic", "processes,", "wc", "will", "use", "the", "to\\tal", "variation", "dist~nce", "on", "distri1)utions", "(also", "known", "as", "statist~cal", "distangece)."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG"]}, "BS-bid-OCR+google": {"tokens": ["To", "reason", "~about", "convergence", "of", "probabilistic", "processes,", "wc", "will", "use", "the", "to\\tal", "variation", "dist~nce", "on", "distri1)utions", "(also", "known", "as", "statist~cal", "distance)."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "MIXED"]}}}, {"corrupt": {"tokens": ["andhencepositivechiraliyzeromodesaresqual'e-integrablesolutlonsof"], "labels": ["WRONG"]}, "correct": {"tokens": ["and", "hence", "positive", "chirality", "zero", "modes", "are", "square-integrable", "solutions", "of"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["andhencepositivechiraliyzeromodesaresqual'e-integrablesolutlonsof"], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["and", "hence", "positive", "chiraliy", "zero", "modes", "are", "squal'e-integrable", "solutlons", "of"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["and", "hence", "positive", "chirality", "zero", "modes", "are", "square-integrable", "solutions", "of"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["with"], "labels": ["NONE"]}, "correct": {"tokens": ["with"], "labels": ["NONE"]}, "predicted": {"google": {"tokens": ["with"], "labels": ["NONE"]}, "BS-bid-OCR": {"tokens": ["with"], "labels": ["NONE"]}, "BS-bid-OCR+google": {"tokens": ["with"], "labels": ["NONE"]}}}, {"corrupt": {"tokens": ["Thesecalulationsdemollstratethatluminosityandtemperatreolprotostarsnotonlydependonmassanda\\ge,butlsoontheaccretionrateinthemainaccretionphas(~.Tilerefore,thepositionofaprotostarontheHRdiagramssensitivetothelustercnv\\ironme,ut,becausestochasticcoreinteractionandcompettionsronglyinfIuencethemassaccretionCrate:PMSLracksarenotunique,andmass(orsimilarllage)ofindividualpcotstarsfromusingtheHRdiagramcanorilybedeterminedinastetisticalsense."], "labels": ["WRONG"]}, "correct": {"tokens": ["These", "calculations", "demonstrate", "that", "luminosity", "and", "temperature", "of", "protostars", "not", "only", "depend", "on", "mass", "and", "age,", "but", "also", "on", "the", "accretion", "rate", "in", "the", "main", "accretion", "phase.", "Therefore,", "the", "position", "of", "a", "protostar", "on", "the", "HR", "diagram", "is", "sensitive", "to", "the", "cluster", "environment,", "because", "stochastic", "core", "interaction", "and", "competition", "strongly", "influence", "the", "mass", "accretion", "rate:", "PMS", "tracks", "are", "not", "unique,", "and", "mass", "(or", "similarly", "age)", "of", "individual", "protostars", "from", "using", "the", "HR", "diagram", "can", "only", "be", "determined", "in", "a", "statistical", "sense."], "labels": ["TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["Thesecalulationsdemollstratethatluminosityandtemperatreolprotostarsnotonlydependonmassanda\\ge,butlsoontheaccretionrateinthemainaccretionphas(~.Tilerefore,thepositionofaprotostarontheHRdiagramssensitivetothelustercnv\\ironme,ut,becausestochasticcoreinteractionandcompettionsronglyinfIuencethemassaccretionCrate:PMSLracksarenotunique,andmass(or", "similar", "age)ofindividualpcotstarsfromusingtheHRdiagramcanorilybedeterminedinastetisticalsense."], "labels": ["WRONG", "WRONG", "WRONG"]}, "BS-bid-OCR": {"tokens": ["These", "calulations", "demollstrate", "that", "luminosity", "and", "temperatre", "ol", "protostars", "not", "only", "depend", "on", "mass", "and", "a\\ge,", "but", "lso", "on", "the", "accretion", "rate", "in", "the", "main", "accretion", "phas(~.", "Tilerefore,", "the", "position", "of", "a", "protostar", "on", "the", "HR", "diagram", "s", "sensitive", "to", "the", "luster", "cnv\\ironme,ut,", "because", "stochastic", "core", "interaction", "and", "compettion", "srongly", "infIuence", "the", "mass", "accretionC", "rate:", "PMS", "Lracks", "are", "not", "unique,", "and", "mass", "(or", "similar", "llage)", "of", "individual", "pcot", "stars", "from", "using", "the", "HR", "diagram", "can", "orily", "be", "determined", "in", "a", "stetistical", "sense."], "labels": ["TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["These", "calculations", "demonstrate", "that", "luminosity", "and", "temperature", "ol", "protostars", "not", "only", "depend", "on", "mass", "and", "a\\ge,", "but", "also", "on", "the", "accretion", "rate", "in", "the", "main", "accretion", "phase(~.", "Therefore,", "the", "position", "of", "a", "protostar", "on", "the", "HR", "diagram", "s", "sensitive", "to", "the", "luster", "cnv\\ironme,ut,", "because", "stochastic", "core", "interaction", "and", "competition", "strongly", "infLuence", "the", "mass", "accretionC", "rate:", "PMS", "Tracks", "are", "not", "unique,", "and", "mass", "(or", "similar", "llage)", "of", "individual", "pcot", "stars", "from", "using", "the", "HR", "diagram", "can", "only", "be", "determined", "in", "a", "statistical", "sense."], "labels": ["TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["Nonmi,nimaltorsioll-mattercoupliugextensionoff(T)gravity"], "labels": ["WRONG"]}, "correct": {"tokens": ["Nonminimal", "torsion-matter", "coupling", "extension", "of", "f(T)", "gravity"], "labels": ["MIXED", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["Nonmi,nimaltorsioll-mattercoupliugextensionoff(T)gravity"], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["Nonmi,nimal", "torsioll-matter", "coupliug", "extension", "of", "f(T)", "gravity"], "labels": ["WRONG", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["Non", "Minimal", "torsion-matter", "coupling", "extension", "of", "f(T)", "gravity"], "labels": ["WRONG", "WRONG", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["Whenfittingasimp.lemodified'bJ??ck-hodymodetothedata,wemustkeepinmindthatthereisal)artialdegeneracybetween\u03b2andTdand,moreimportantly,aperfectdegeneracybetweenTdandz.ThepatakoftheSEmDisdeterminedbythe\u03bd/Tdtermintheexponential,sothata?measuremntotth(~co1oursaloneeonstrainnonlyt}leratio(1+z)/Td.HoweveP,assumingreas\\onablepriorsonthefreeparametersoftheSEDmodel(inourcase,\u03b2andTd)itisstillpossi\\bletoestimateaquglitativeredshiftdistributionfoxoursampleefsources.Alternatively,ifsecueredshiftsareknownfromopticalcross-identifications,wecand.terminethedusttemperatu\\res."], "labels": ["WRONG"]}, "correct": {"tokens": ["When", "fitting", "a", "simple", "modified", "black-body", "model", "to", "the", "data,", "we", "must", "keep", "in", "mind", "that", "there", "is", "a", "partial", "degeneracy", "between", "\u03b2", "and", "Td", "and,", "more", "importantly,", "a", "perfect", "degeneracy", "between", "Td", "and", "z.", "The", "peak", "of", "the", "SED", "is", "determined", "by", "the", "\u03bd/Td", "term", "in", "the", "exponential,", "so", "that", "a", "measurement", "of", "the", "colours", "alone", "constrains", "only", "the", "ratio", "(1", "+", "z)/Td.", "However,", "assuming", "reasonable", "priors", "on", "the", "free", "parameters", "of", "the", "SED", "model", "(in", "our", "case,", "\u03b2", "and", "Td)", "it", "is", "still", "possible", "to", "estimate", "a", "qualitative", "redshift", "distribution", "for", "our", "sample", "of", "sources.", "Alternatively,", "if", "secure", "redshifts", "are", "known", "from", "optical", "cross-identifications,", "we", "can", "determine", "the", "dust", "temperatures."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "MIXED", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED"]}, "predicted": {"google": {"tokens": ["Whenfittingasimp.lemodified'bJ??ck-hodymodetothedata,wemustkeepinmindthatthereisal)artialdegeneracybetween\u03b2andTdand,more", "importantly,aperfectdegeneracybetweenTdandz.ThepatakoftheSEmDisdeterminedbythe\u03bd/Tdterminthe", "Exponential,sonata?measurements(~co1oursaloneeonstrainnonlyt}leratio(1+z)/Td.HoweveP,assumingreas\\onablepriorsonthefreeparametersoftheSEDmodel(inourcase,\u03b2andTd)itisstillpossi\\bletoestimateaquglitativeredshiftdistributionfoxoursampleefsources.Alternatively,ifsecueredshiftsareknownfromopticalcross-identifications,wecand.terminethedusttemperatu\\res."], "labels": ["WRONG", "WRONG", "WRONG"]}, "BS-bid-OCR": {"tokens": ["When", "fitting", "a", "simp.le", "modified", "'bJ??ck-hody", "mode", "to", "the", "data,", "we", "must", "keep", "in", "mind", "that", "there", "is", "a", "l)artial", "degeneracy", "between", "\u03b2", "and", "Td", "and,", "more", "importantly,", "a", "perfect", "degeneracy", "between", "Td", "and", "z.", "The", "patak", "of", "the", "SEmD", "is", "determined", "by", "the", "\u03bd/Td", "term", "in", "the", "exponential,", "so", "that", "a?", "measuremnt", "ot", "th(~", "co1ours", "alone", "eonstrainn", "only", "t}le", "ratio", "(1", "+", "z)/Td.", "HoweveP,", "assuming", "reas\\onable", "priors", "on", "the", "free", "parameters", "of", "the", "SED", "model", "(in", "our", "case,", "\u03b2", "and", "Td)", "it", "is", "still", "possi\\ble", "to", "estimate", "a", "quglitative", "redshift", "distribution", "fox", "our", "sample", "ef", "sources.", "Alternatively,", "if", "secue", "redshifts", "are", "known", "from", "optical", "cross-identifications,", "we", "can", "d.termine", "the", "dust", "temperatu\\res."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "WRONG", "WRONG", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG"]}, "BS-bid-OCR+google": {"tokens": ["When", "fitting", "a", "simple", "modified", "'bJ??ck-hody", "mode", "to", "the", "data,", "we", "must", "keep", "in", "mind", "that", "there", "is", "a", "l)partial", "degeneracy", "between", "\u03b2", "and", "Td", "and,", "more", "importantly,", "a", "perfect", "degeneracy", "between", "Td", "and", "z.", "The", "patak", "of", "the", "SEmD", "is", "determined", "by", "the", "\u03bd/Td", "term", "in", "the", "exponential,", "so", "that", "a?", "measurement", "ot", "th(~", "colours", "alone", "constraint", "only", "t}le", "ratio", "(1", "+", "z)/Td.", "HoweveR,", "assuming", "reas\\onable", "priors", "on", "the", "free", "parameters", "of", "the", "SED", "model", "(in", "our", "case,", "\u03b2", "and", "Td)", "it", "is", "still", "possi\\ble", "to", "estimate", "a", "qualitative", "redshift", "distribution", "for", "our", "sample", "of", "sources.", "Alternatively,", "if", "secure", "redshifts", "are", "known", "from", "optical", "cross-identifications,", "we", "can", "determine", "the", "dust", "temperatu\\res."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "MIXED", "WRONG", "WRONG", "MIXED", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG"]}}}, {"corrupt": {"tokens": ["ACK~OWLEDGEMENTS"], "labels": ["WRONG"]}, "correct": {"tokens": ["ACKNOWLEDGEMENTS"], "labels": ["OCR_ERROR"]}, "predicted": {"google": {"tokens": ["ACKNOWLEDGEMENTS"], "labels": ["OCR_ERROR"]}, "BS-bid-OCR": {"tokens": ["ACK~OWLEDGEMENTS"], "labels": ["WRONG"]}, "BS-bid-OCR+google": {"tokens": ["ACK~OWLEDGEMENTS"], "labels": ["WRONG"]}}}, {"corrupt": {"tokens": ["Ma\\n~-potcntialvertexpart"], "labels": ["WRONG"]}, "correct": {"tokens": ["Many-potential", "vertex", "part"], "labels": ["MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["Ma\\n~-potcntialvertexpart"], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["Ma\\n~-potcntial", "vertex", "part"], "labels": ["WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["Ma\\n~-potential", "vertex", "part"], "labels": ["WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["Infactour,mainproofholdsevenforaslightlymorerelaxedsmoothnesspropertythatwillproveus?efu\\]inauctionsettings.Ourmailltheoremworksforthefollowingnotionmfsmoothnes\\sundertheconditiondmtth~utilitiesofplayersatequili1)rimaTenon-negqtive."], "labels": ["WRONG"]}, "correct": {"tokens": ["In", "fact", "our", "main", "proof", "holds", "even", "for", "a", "slightly", "more", "relaxed", "smoothness", "property", "that", "will", "prove", "useful", "in", "auction", "settings.", "Our", "main", "theorem", "works", "for", "the", "following", "notion", "of", "smoothness", "under", "the", "condition", "that", "the", "utilities", "of", "players", "at", "equilibrium", "are", "non-negative."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "MIXED"]}, "predicted": {"google": {"tokens": ["Infactour,mainproofholdsevenforaslightlymorerelaxedsmoothnesspropertythatwillproveus?efu\\]inauctionsettings.Ourmailltheoremworksforthefollowingnotionmfsmoothnes\\sundertheconditiondmtth~utilitiesofplayersatequili1)rimaTenon-negative."], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["In", "fact", "our,", "main", "proof", "holds", "even", "for", "a", "slightly", "more", "relaxed", "smoothness", "property", "that", "will", "prove", "us?efu\\]", "in", "auction", "settings.", "Our", "maill", "theorem", "works", "for", "the", "following", "notion", "mf", "smoothnes\\s", "under", "the", "condition", "dmt", "th~", "utilities", "of", "players", "at", "equili1)rim", "aTe", "non-negqtive."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "WRONG"]}, "BS-bid-OCR+google": {"tokens": ["In", "fact", "our,", "main", "proof", "holds", "even", "for", "a", "slightly", "more", "relaxed", "smoothness", "property", "that", "will", "prove", "us?efu\\]", "in", "auction", "settings.", "Our", "main", "theorem", "works", "for", "the", "following", "notion", "of", "smoothnes\\s", "under", "the", "condition", "dmt", "th~", "utilities", "of", "players", "at", "equili1)rim", "aTe", "non-negative."], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "MIXED"]}}}, {"corrupt": {"tokens": ["Nowweusecoordiuatemtodiscussthetaagentiralsmoothability.F?orf\u2208Sd,oneuritesitas"], "labels": ["WRONG"]}, "correct": {"tokens": ["Now", "we", "use", "coordinates", "to", "discuss", "the", "tangential", "smoothability.", "For", "f", "\u2208", "Sd,", "one", "writes", "it", "as"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["Nowweusecoordiuatemtodiscussthetaagentiralsmoothability.F?orf\u2208Sd,oneuritesitas"], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["Now", "we", "use", "coordiuate", "m", "to", "discuss", "the", "taagentiral", "smoothability.", "F?or", "f", "\u2208", "Sd,", "one", "urites", "it", "as"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["Now", "we", "use", "coordinate", "m", "to", "discuss", "the", "tangential", "soothability.", "F?or", "f", "\u2208", "Sd,", "one", "urites", "it", "as"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["Tr(ABn)=2."], "labels": ["WRONG"]}, "correct": {"tokens": ["Tr(AlBn)", "=", "2."], "labels": ["MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["Tr(ABn)=2."], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["Tr(ABn)", "=", "2."], "labels": ["WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["Tr(ABn)", "=", "2."], "labels": ["WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["Thediamodworldsheetisnowgivenby"], "labels": ["WRONG"]}, "correct": {"tokens": ["The", "diamond", "worldsheet", "is", "now", "given", "by"], "labels": ["TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["Thediamodworldsheetisnowgivenby"], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["The", "diamod", "worldsheet", "is", "now", "given", "by"], "labels": ["TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["The", "diamond", "worldsheet", "is", "now", "given", "by"], "labels": ["TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["Finally,wealsoneedtoset"], "labels": ["WRONG"]}, "correct": {"tokens": ["Finally,", "we", "also", "need", "to", "set"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["Finally,we", "also", "need", "to", "set"], "labels": ["WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR": {"tokens": ["Finally,", "we", "also", "need", "to", "set"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["Finally,", "we", "also", "need", "to", "set"], "labels": ["TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["~nalyticalSolutionsexistfornr=0,1,and5.Thdana?lyticalsolutionforn=0is"], "labels": ["WRONG"]}, "correct": {"tokens": ["Analytical", "solutions", "exist", "for", "n", "=", "0,", "1,", "and", "5.", "The", "analytical", "solution", "for", "n", "=", "0", "is"], "labels": ["MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["~analytical", "Solutions", "exist", "for", "n=0,1,and", "5.Th", "Dana?lytical", "solution", "for", "n=0is"], "labels": ["WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG"]}, "BS-bid-OCR": {"tokens": ["~nalytical", "Solutions", "exist", "for", "nr", "=", "0,", "1,", "and", "5.", "Thd", "ana?lytical", "solution", "for", "n", "=", "0", "is"], "labels": ["WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["~analytical", "Solutions", "exist", "for", "nr", "=", "0,", "1,", "and", "5.", "The", "analytical", "solution", "for", "n", "=", "0", "is"], "labels": ["WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}}}, {"corrupt": {"tokens": ["nhallcedconductionbaudde~sityofstatesinintermetallicEuiTSz3(T=Rh,Ir)"], "labels": ["WRONG"]}, "correct": {"tokens": ["Enhanced", "conduction", "band", "density", "of", "states", "in", "intermetallic", "EuTSi3", "(T=Rh,", "Ir)"], "labels": ["MIXED", "TOKENIZATION_ERROR", "MIXED", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "MIXED", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR"]}, "predicted": {"google": {"tokens": ["nhallcedconductionbaudde~sityofstatesinintermetallicEuiTSz3(T=Rh,Ir)"], "labels": ["WRONG"]}, "BS-bid-OCR": {"tokens": ["nhallced", "conduction", "baud", "de~sity", "of", "states", "in", "intermetallic", "EuiTSz3", "(T", "=", "Rh,", "Ir)"], "labels": ["WRONG", "TOKENIZATION_ERROR", "WRONG", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "WRONG", "WRONG", "TOKENIZATION_ERROR"]}, "BS-bid-OCR+google": {"tokens": ["enhanced", "conduction", "band", "de~sity", "of", "states", "in", "intermetallic", "EuiTSz3", "(T", "=", "Rh,", "Ir)"], "labels": ["WRONG", "TOKENIZATION_ERROR", "MIXED", "WRONG", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "TOKENIZATION_ERROR", "WRONG", "WRONG", "WRONG", "WRONG", "TOKENIZATION_ERROR"]}}}]}